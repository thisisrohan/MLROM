{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a637f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\":True,\n",
    "    \"font.family\":\"serif\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "array = np.array\n",
    "float32 = np.float32\n",
    "int32 = np.int32\n",
    "float64 = np.float64\n",
    "int64 = np.int64\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "xlabel_kwargs = {\"fontsize\":15}\n",
    "ylabel_kwargs = {\"fontsize\":15}\n",
    "legend_kwargs = {\"fontsize\":12}\n",
    "title_kwargs = {\"fontsize\":18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14277188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ae_v2 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            # gpu_to_use = 0\n",
    "            # tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "            tf.config.set_visible_devices([], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print('')\n",
    "print(tf.config.list_logical_devices())\n",
    "print('')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865779b",
   "metadata": {},
   "source": [
    "# Kolmogorov Flow System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prng_seed = 42\n",
    "np.random.seed(prng_seed)\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_idx = '024'\n",
    "dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_'.format(ds=dir_sep)+ae_idx\n",
    "print(dir_name_ae)\n",
    "\n",
    "# reading simulation parameters\n",
    "with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "data_dir_idx = params_dict['data_dir_idx']\n",
    "normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "ae_module = params_dict['module']\n",
    "try:\n",
    "    use_ae_data = params_rnn_dict['use_ae_data']\n",
    "except:\n",
    "    print(\"'use_ae_data' not present in RNN_specific_data, set to True.\")\n",
    "    use_ae_data = True\n",
    "try:\n",
    "    ae_data_with_params = params_dict['ae_data_with_params']\n",
    "except:\n",
    "    print(\"'ae_data_with_params' not present in ae_data, set to 'True'.\")\n",
    "    ae_data_with_params = True\n",
    "\n",
    "if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "    with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "        normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "print('data_dir_idx:', data_dir_idx)\n",
    "\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "\n",
    "with open(dir_name_data + dir_sep + 'sim_data_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "params_mat = params_dict['params_mat']\n",
    "# init_state = params_dict['init_state']\n",
    "t0 = params_dict['t0']\n",
    "T = params_dict['T']\n",
    "delta_t = params_dict['delta_t']\n",
    "return_params_arr = params_dict['return_params_arr']\n",
    "normalize_flag_ogdata = params_dict['normalize_flag']\n",
    "print('normalize_flag_ogdata:', normalize_flag_ogdata)\n",
    "alldata_withparams_flag = params_dict['alldata_withparams_flag']\n",
    "\n",
    "with np.load(dir_name_data+dir_sep+'data.npz', allow_pickle=True) as fl:\n",
    "    all_data_og = fl['all_data'].astype(FTYPE)#[::10]\n",
    "    boundary_idx_arr = fl['boundary_idx_arr']\n",
    "    normalization_constant_arr_ogdata = fl['normalization_constant_arr'][0]\n",
    "    # initial_t0 = fl['initial_t0']\n",
    "    # init_state_mat = fl['init_state_mat']\n",
    "\n",
    "    lyapunov_spectrum_mat = fl['lyapunov_spectrum_mat']\n",
    "\n",
    "num_params = params_mat.shape[1]\n",
    "og_vars = all_data_og.shape[1]\n",
    "if alldata_withparams_flag == True:\n",
    "    og_vars -= num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ae_data_with_params == False:\n",
    "    all_data_og = all_data_og[:, 0:og_vars]\n",
    "    normalization_constant_arr_aedata = normalization_constant_arr_aedata[:, 0:og_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data_og.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d311da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e98286",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(all_data_og.shape[0]*train_split)\n",
    "num_val = int(all_data_og.shape[0]*val_split)\n",
    "num_test = all_data_og.shape[0] - num_train - num_val\n",
    "\n",
    "idx = np.arange(all_data_og.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "\n",
    "training_data = np.empty(shape=(num_train, ) + tuple(all_data_og.shape[1:]), dtype=FTYPE)\n",
    "val_data = np.empty(shape=(num_val, ) + tuple(all_data_og.shape[1:]), dtype=FTYPE)\n",
    "testing_data = np.empty(shape=(num_test, ) + tuple(all_data_og.shape[1:]), dtype=FTYPE)\n",
    "\n",
    "training_data[:] = all_data_og[idx[0:num_train]]\n",
    "val_data[:] = all_data_og[idx[num_train:num_train+num_val]]\n",
    "testing_data[:] = all_data_og[idx[num_train+num_val:]]\n",
    "\n",
    "del(all_data_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training_data.shape : ', training_data.shape)\n",
    "print('val_data.shape : ', val_data.shape)\n",
    "print('testing_data.shape : ', testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalizeforae_flag == True:\n",
    "    training_data -= normalization_constant_arr_aedata[0]\n",
    "    training_data /= normalization_constant_arr_aedata[1]\n",
    "\n",
    "    testing_data -= normalization_constant_arr_aedata[0]\n",
    "    testing_data /= normalization_constant_arr_aedata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec388c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_class_dict.txt'\n",
    "wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "\n",
    "ae_net = Autoencoder(data_dim=training_data.shape[1], load_file=load_file)\n",
    "ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_states_all_trainingdata = np.array(ae_net.encoder_net.predict(training_data))\n",
    "latent_states_all_testingdata = np.array(ae_net.encoder_net.predict(testing_data))\n",
    "\n",
    "# reconstructed_data_trainingdata = ae_net.decoder_net.predict(latent_states_all_trainingdata)\n",
    "# reconstructed_data_testingdata = ae_net.decoder_net.predict(latent_states_all_testingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_shape = latent_states_all_testingdata.shape[1:]\n",
    "og_shape = training_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ls_shape : ', ls_shape)\n",
    "print('og_shape : ', og_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb40e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('latent_states_all_trainingdata.shape : {}'.format(latent_states_all_trainingdata.shape))\n",
    "print('latent_states_all_testingdata.shape : {}\\n'.format(latent_states_all_testingdata.shape))\n",
    "\n",
    "# print('reconstructed_data_trainingdata.shape : {}'.format(reconstructed_data_trainingdata.shape))\n",
    "# print('reconstructed_data_testingdata.shape : {}'.format(reconstructed_data_testingdata.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalizeforae_flag == True:\n",
    "    # reconstructed_data_trainingdata *= normalization_constant_arr_aedata[1]\n",
    "    # reconstructed_data_trainingdata += normalization_constant_arr_aedata[0]\n",
    "    training_data *= normalization_constant_arr_aedata[1]\n",
    "    training_data += normalization_constant_arr_aedata[0]\n",
    "\n",
    "    # reconstructed_data_testingdata *= normalization_constant_arr_aedata[1]\n",
    "    # reconstructed_data_testingdata += normalization_constant_arr_aedata[0]\n",
    "    testing_data *= normalization_constant_arr_aedata[1]\n",
    "    testing_data += normalization_constant_arr_aedata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6897a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD in latent space\n",
    "latent_states_all_trainingdata = np.reshape(latent_states_all_trainingdata, (latent_states_all_trainingdata.shape[0], -1))\n",
    "mean_ls = np.mean(latent_states_all_trainingdata, axis=0)\n",
    "meancentered_ls = latent_states_all_trainingdata - mean_ls\n",
    "covmat_ls = np.matmul(meancentered_ls.transpose(), meancentered_ls) / (meancentered_ls.shape[0] - 1)\n",
    "\n",
    "eigenvals_ls, eigenvecs_ls = linalg.eig(covmat_ls)\n",
    "eigenvals_ls = np.abs(eigenvals_ls)\n",
    "sorted_idx = np.argsort(eigenvals_ls)\n",
    "eigenvals_ls = eigenvals_ls[sorted_idx]\n",
    "eigenvecs_ls = eigenvecs_ls[:, sorted_idx]\n",
    "\n",
    "del(covmat_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvecs_ls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff202239",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_eigs = np.cumsum(eigenvals_ls[::-1])/np.sum(eigenvals_ls)\n",
    "\n",
    "plt.semilogy(\n",
    "    np.arange(1, cum_eigs.shape[0]+1),\n",
    "    cum_eigs, marker='^', linestyle='--', linewidth=0.8)\n",
    "plt.grid(which='both')\n",
    "plt.ylim(None,1.05)\n",
    "\n",
    "plt.xticks(np.arange(1, cum_eigs.shape[0]+1))\n",
    "\n",
    "plt.xlabel('Index $i$', **xlabel_kwargs)\n",
    "plt.ylabel(r'$$\\frac{\\sum_{k=1}^i \\lambda_k}{\\sum_{k} \\lambda_k}$$', **ylabel_kwargs)\n",
    "plt.title('Cumulative Variance of the \\nLatent Space Principal Directions', **title_kwargs)\n",
    "\n",
    "plt.gcf().set_size_inches(4,3)\n",
    "\n",
    "plt.savefig(dir_name_ae+'/plots/ls_cumvar.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD in actual-data space\n",
    "training_data = np.reshape(training_data, (training_data.shape[0], -1))\n",
    "mean_og = np.mean(training_data, axis=0)\n",
    "meancentered_og = training_data - mean_og\n",
    "covmat_og = np.matmul(meancentered_og.transpose(), meancentered_og) / (meancentered_og.shape[0] - 1)\n",
    "\n",
    "eigenvals_og, eigenvecs_og = linalg.eig(covmat_og)\n",
    "eigenvals_og = np.abs(eigenvals_og)\n",
    "sorted_idx = np.argsort(eigenvals_og)\n",
    "eigenvals_og = eigenvals_og[sorted_idx]\n",
    "eigenvecs_og = eigenvecs_og[:, sorted_idx]\n",
    "\n",
    "del(covmat_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_eigvecs_to_analyse = 3\n",
    "ls_eigvecs_to_analyse = 2\n",
    "\n",
    "eigenvecs_og_norm = linalg.norm(eigenvecs_og[:, -og_eigvecs_to_analyse:].transpose(), axis=1)\n",
    "\n",
    "correlation_mat = np.empty(shape=(ls_eigvecs_to_analyse, og_eigvecs_to_analyse))\n",
    "\n",
    "ls_trainingdata = latent_states_all_trainingdata - mean_ls\n",
    "ls_trainingdata_norm = linalg.norm(ls_trainingdata, axis=1)\n",
    "\n",
    "eigvecs_ls_norm = linalg.norm(eigenvecs_ls.transpose(), axis=1)\n",
    "\n",
    "dummy_ones_mat = np.ones_like(latent_states_all_trainingdata, dtype=FTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb80e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('eigenvecs_og_norm : ', eigenvecs_og_norm)\n",
    "print('eigvecs_ls_norm : ', eigvecs_ls_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_eigenval_sum = 1.0\n",
    "ls_eigenval_sum = np.sum(eigenvals_ls)\n",
    "for i in range(ls_eigvecs_to_analyse):\n",
    "    time_taken = time.time()\n",
    "    # temp_ls = (eigenvals_ls[-i-1]/ls_eigenval_sum) * eigenvecs_ls[:, -i-1]\n",
    "    # temp_ls = eigenvecs_ls[:, -i-1]\n",
    "    temp_ls = (eigenvals_ls[-i-1]/ls_eigenval_sum**0.5) * eigenvecs_ls[:, -i-1]\n",
    "    temp_ls += mean_ls\n",
    "    temp_ls = np.reshape(temp_ls, (1,)+tuple(ls_shape))\n",
    "    \n",
    "    decoded_ls = np.array(ae_net.decoder_net.predict(temp_ls))\n",
    "    \n",
    "    decoded_ls *= normalization_constant_arr_aedata[1]\n",
    "    decoded_ls += normalization_constant_arr_aedata[0]\n",
    "    \n",
    "    decoded_ls = np.reshape(decoded_ls, (decoded_ls.shape[0], -1))\n",
    "    decoded_ls -= mean_og\n",
    "    decoded_ls_norm = np.linalg.norm(decoded_ls, axis=1)\n",
    "\n",
    "    for j in range(og_eigvecs_to_analyse):\n",
    "        time_taken_j = time.time()\n",
    "        coeffs = np.sum(decoded_ls * eigenvecs_og[:, -j-1], axis=1)\n",
    "        coeffs /= decoded_ls_norm * eigenvecs_og_norm[-j-1]\n",
    "        correlation_mat[i, j] = np.mean(coeffs)\n",
    "        time_taken_j = time.time() - time_taken_j\n",
    "#         print('    time_taken_j : {:02d}h {:02d}m {:02d}s'.format(\n",
    "#             int(time_taken_j // 3600),\n",
    "#             int((time_taken_j//60)%60),\n",
    "#             int(time_taken_j % 60)\n",
    "#         ))\n",
    "        \n",
    "    del(decoded_ls)\n",
    "    del(temp_ls)\n",
    "    \n",
    "    time_taken = time.time() - time_taken\n",
    "#     print('time_taken : {:02d}h {:02d}m {:02d}s\\n'.format(\n",
    "#         int(time_taken // 3600),\n",
    "#         int((time_taken//60)%60),\n",
    "#         int(time_taken % 60)\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_name_ae+'/plots/ls_vs_actual_principaldirections.txt', 'w') as f:\n",
    "    s = ''\n",
    "    for i in range(correlation_mat.shape[0]):\n",
    "        temp = ['{:.2E}'.format(elem) for elem in correlation_mat[i]]\n",
    "        s += ', '.join(temp) + '\\n'\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205383",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "im = ax.imshow(correlation_mat, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "# a = plt.gca().get_xticks()\n",
    "# ls_eigvecs_to_analyse = 16\n",
    "\n",
    "ax.set_xticks(\n",
    "    np.arange(0, og_eigvecs_to_analyse, 1),\n",
    "    labels=np.arange(1, og_eigvecs_to_analyse+1, 1),\n",
    "    **legend_kwargs,\n",
    ")\n",
    "ax.set_yticks(\n",
    "    np.arange(0, ls_eigvecs_to_analyse, 1),\n",
    "    labels=np.arange(1, ls_eigvecs_to_analyse+1, 1),\n",
    "    **legend_kwargs,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    'Correlation of Decoded Latent\\nSpace Principal Directions w.r.t.\\nthose of the Actual Data',\n",
    "    **title_kwargs,\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Index $j$', **xlabel_kwargs)\n",
    "ax.set_ylabel('Index $i$', **ylabel_kwargs)\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    bottom=0.22,\n",
    "    # left=0.1,\n",
    "    # top=1.0-0.19,\n",
    ")\n",
    "\n",
    "# original data and recon data colorbar\n",
    "cb_xbegin = ax.transData.transform([-0.5 + 0.0, 0])\n",
    "cb_xbegin = fig.transFigure.inverted().transform(cb_xbegin)[0]\n",
    "cb_xend = ax.transData.transform([correlation_mat.shape[-1]-0.5 - 0.0, 0])\n",
    "cb_xend = fig.transFigure.inverted().transform(cb_xend)[0]\n",
    "\n",
    "cb_ax = fig.add_axes([cb_xbegin, 0.0, cb_xend-cb_xbegin, 0.025])\n",
    "cbar = fig.colorbar(im, cax=cb_ax, orientation='horizontal')\n",
    "# cbar = plt.colorbar(im)\n",
    "cbar.set_label(\n",
    "    r'$\\frac{\\mathcal{D} \\left( \\mathbf{p}^{ls}_i \\right) \\cdot \\mathbf{p}^{true}_j}{\\|\\mathcal{D} \\left( \\mathbf{p}^{ls}_i \\right)\\| \\ \\| \\mathbf{p}^{true}_j \\|}$',\n",
    "    **xlabel_kwargs\n",
    ")\n",
    "\n",
    "plt.savefig(dir_name_ae+'/plots/ls_vs_actual_principaldirections.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_ls_pd_list = []\n",
    "\n",
    "# ls_eigenval_sum = 1.0\n",
    "ls_eigenval_sum = np.sum(eigenvals_ls)\n",
    "for i in range(ls_eigvecs_to_analyse):\n",
    "    time_taken = time.time()\n",
    "#     temp_ls = (eigenvals_ls[-i-1]/ls_eigenval_sum) * eigenvecs_ls[:, -i-1]\n",
    "#     temp_ls = eigenvecs_ls[:, -i-1]\n",
    "    temp_ls = (eigenvals_ls[-i-1]/ls_eigenval_sum**0.5) * eigenvecs_ls[:, -i-1]\n",
    "    temp_ls += mean_ls\n",
    "    temp_ls = np.reshape(temp_ls, (1,)+tuple(ls_shape))\n",
    "    \n",
    "    decoded_ls = np.array(ae_net.decoder_net.predict(temp_ls))\n",
    "    \n",
    "    decoded_ls *= normalization_constant_arr_aedata[1]\n",
    "    decoded_ls += normalization_constant_arr_aedata[0]\n",
    "    \n",
    "    decoded_ls = np.reshape(decoded_ls, (decoded_ls.shape[0], -1))\n",
    "    decoded_ls -= mean_og\n",
    "    decoded_ls_norm = np.linalg.norm(decoded_ls, axis=1)\n",
    "\n",
    "    decoded_ls_pd_list.append(decoded_ls)\n",
    "    # del(decoded_ls)\n",
    "    del(temp_ls)\n",
    "    \n",
    "    time_taken = time.time() - time_taken\n",
    "    # print('time_taken : {:02d}h {:02d}m {:02d}s\\n'.format(\n",
    "    #     int(time_taken // 3600),\n",
    "    #     int((time_taken//60)%60),\n",
    "    #     int(time_taken % 60)\n",
    "    # ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b985a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pd_list = []\n",
    "for i in range(ls_eigvecs_to_analyse):\n",
    "    # actual_pd_list.append(eigenvals_og[-i-1]*eigenvecs_og[:, -i-1])\n",
    "    actual_pd_list.append(eigenvecs_og[:, -i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(decoded_ls_pd_list).shape, np.array(actual_pd_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d50fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls_eigvecs_to_analyse = 2\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    int(np.round(ls_eigvecs_to_analyse/2 + 0.5)), 2,\n",
    "    figsize=(6, 5)#*np.round(ls_eigvecs_to_analyse/2 + 0.5))\n",
    ")\n",
    "# fig, ax = plt.subplots()\n",
    "if len(ax.shape) == 1:\n",
    "    ax = np.array([[elem] for elem in ax])\n",
    "\n",
    "xtick_pos = np.linspace(0, decoded_ls_pd_list[0].shape[-1]-1, 3, dtype=np.int32)\n",
    "xtick_labels = xtick_pos#xtick_pos/xtick_pos[-1]*35.\n",
    "# xtick_labels = [r'0', r'$\\frac{\\pi}{2}$', r'$\\pi$', r'$\\frac{3\\pi}{2}$', r'$2\\pi$']\n",
    "for i in range(ax.shape[0]*ax.shape[1]):\n",
    "    plotidx1 = i//2\n",
    "    plotidx2 = i%2\n",
    "    print(plotidx1,plotidx2)\n",
    "    if i < ls_eigvecs_to_analyse:\n",
    "        vecls = decoded_ls_pd_list[i][0]\n",
    "        vecog = actual_pd_list[i]\n",
    "        vecls_norm = linalg.norm(vecls)\n",
    "        vecog_norm = linalg.norm(vecog)\n",
    "        vecls /= vecls_norm\n",
    "        vecog /= vecog_norm\n",
    "\n",
    "        ax[plotidx1, plotidx2].plot(vecls, label=r'$\\mathcal{D} \\left( \\mathbf{p}_i^{ls} \\right)$')\n",
    "        ax[plotidx1, plotidx2].plot(vecog, label=r'$\\mathbf{p}_i^{true}$')\n",
    "        ax[plotidx1, plotidx2].legend(**legend_kwargs)\n",
    "\n",
    "        ax[plotidx1, plotidx2].grid(True)\n",
    "        ax[plotidx1, plotidx2].set_xticks(\n",
    "            xtick_pos,\n",
    "            xtick_labels,\n",
    "            **legend_kwargs\n",
    "        )\n",
    "        plt.yticks(**legend_kwargs)\n",
    "    #     ax[plotidx1, plotidx2].set_xlabel(r'$x$', **xlabel_kwargs)\n",
    "        ax[plotidx1, plotidx2].set_title(r'Index $'+str(i+1)+'$', **title_kwargs)\n",
    "        \n",
    "        ax[plotidx1, plotidx2].set_xlabel(r'Index $j$', **xlabel_kwargs)\n",
    "        ax[plotidx1, plotidx2].set_ylabel(r'$x_j$', **ylabel_kwargs)\n",
    "    else:\n",
    "        ax[plotidx1, plotidx2].set_visible(False)\n",
    "        \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(dir_name_ae+'/plots/ls_and_actual_pd.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1cd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda4f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50d08b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls_eigvecs_to_analyse = 2\n",
    "fig, ax = plt.subplots(\n",
    "    ls_eigvecs_to_analyse, 2,\n",
    "    figsize=(5.0*2, 5.0*ls_eigvecs_to_analyse)\n",
    ")\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "actual_pd_list = np.array(actual_pd_list)\n",
    "\n",
    "xtick_pos = np.linspace(0, vec.shape[-1]-1, 5, dtype=np.int32)\n",
    "xtick_labels = [r'0', r'$\\frac{\\pi}{2}$', r'$\\pi$', r'$\\frac{3\\pi}{2}$', r'$2\\pi$']\n",
    "for i in range(ls_eigvecs_to_analyse):\n",
    "    vec = actual_pd_list[i]\n",
    "    vec = np.reshape(vec, og_shape)\n",
    "    \n",
    "    u_im = ax[i, 0].imshow(\n",
    "        vec[0].transpose(),\n",
    "        origin='lower',\n",
    "        aspect='equal',\n",
    "        # vmin=vmin0,\n",
    "        # vmax=vmax0,\n",
    "    )\n",
    "    v_im = ax[i, 1].imshow(\n",
    "        vec[1].transpose(),\n",
    "        origin='lower',\n",
    "        aspect='equal',\n",
    "        # vmin=vmin1,\n",
    "        # vmax=vmax1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.colorbar(u_im, ax=ax[i, 0], orientation='horizontal')\n",
    "    plt.colorbar(v_im, ax=ax[i, 1], orientation='horizontal')\n",
    "    \n",
    "    for j in range(2):\n",
    "        ax[i, j].set_xticks(xtick_pos, xtick_labels, **legend_kwargs)\n",
    "        ax[i, j].set_xlabel(r'$x$', **xlabel_kwargs)\n",
    "        ax[i, j].set_yticks(xtick_pos, xtick_labels, **legend_kwargs)\n",
    "        ax[i, j].set_ylabel(r'$y$', **xlabel_kwargs)\n",
    "        \n",
    "    ax[i, 0].set_title(r\"$u$\", **title_kwargs)\n",
    "    ax[i, 1].set_title(r\"$v$\", **title_kwargs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3391b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
