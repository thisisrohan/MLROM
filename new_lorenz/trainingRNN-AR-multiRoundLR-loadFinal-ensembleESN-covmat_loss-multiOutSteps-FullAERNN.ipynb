{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868739487,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3563,
     "status": "ok",
     "timestamp": 1667868743047,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from keras.engine import data_adapter\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\":True,\n",
    "    \"font.family\":\"serif\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667868743048,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "h_qXhHdbCgoj",
    "outputId": "3473a883-d145-4778-9be7-7d44e0c6ea67"
   },
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "array = np.array\n",
    "float32 = np.float32\n",
    "int32 = np.int32\n",
    "float64 = np.float64\n",
    "int64 = np.int64\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667868743048,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "BiLIUmBPneQR"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18870,
     "status": "ok",
     "timestamp": 1667868761912,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "fnTV6Anhni6O",
    "outputId": "bf1d11f8-667f-4cb5-d8d5-b9d860b44d99"
   },
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868761912,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "paDfPOrjnkAS",
    "outputId": "58054510-4476-49b4-f8ba-e2978a028b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/new_lorenz\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4575,
     "status": "ok",
     "timestamp": 1667868766483,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "P6K2YWlR6ZPD"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import create_data_for_RNN, mytimecallback, SaveLosses, plot_losses, plot_reconstructed_data_KS, plot_latent_states_KS , readAndReturnLossHistories, sigmoidWarmupAndDecayLRSchedule\n",
    "from tools.ae_v2 import Autoencoder\n",
    "from tools.ESN_v2_ensembleAR import ESN_ensemble as AR_RNN\n",
    "from tools.AEESN_AR_v1 import AR_AERNN_ESN as AR_AERNN\n",
    "from tools.trainAEESN_ensemble import trainAERNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766483,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "_xtkwXE2tGTP"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "qvA9oeCHCTVM",
    "outputId": "0f2de849-59ee-4ed9-b65d-c5952e0dcb55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 06:52:45.384088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 06:52:45.427389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.427643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.428910: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 06:52:45.429419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.429564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.429690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.941375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.941534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.941668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 06:52:45.941774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23180 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 0\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "c9786b4c-8510-47d0-801d-181e3b12239c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print('')\n",
    "print(tf.config.list_logical_devices())\n",
    "print('')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868766485,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "8aNkoXfyGq52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_AR_AErnn: /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005\n",
      "dir_name_rnn: /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_ESN_ensemble/ESN_ensemble_002\n",
      "dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_ae/ae_024\n",
      "data_dir_idx: 010\n",
      "normalize_flag_ogdata: False\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "from numpy import *\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # RNN directory\n",
    "    dir_name_rnn = os.getcwd()+'/saved_ESN_ensemble/ESN_ensemble_002'\n",
    "\n",
    "    # making AR-RNN save directory\n",
    "    dir_name_ARrnn = os.getcwd() + dir_sep + 'saved_AR_AEESN_rnn'\n",
    "    if not os.path.isdir(dir_name_ARrnn):\n",
    "        os.makedirs(dir_name_ARrnn)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        dir_check = 'AR_ESN_ensemble_' + str(counter).zfill(3)\n",
    "        if os.path.isdir(dir_name_ARrnn + dir_sep + dir_check):\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dir_name_ARrnn = dir_name_ARrnn + dir_sep + dir_check\n",
    "    os.makedirs(dir_name_ARrnn)\n",
    "    os.makedirs(dir_name_ARrnn+dir_sep+'plots')\n",
    "    \n",
    "    # reading RNN paramaters\n",
    "    with open(dir_name_rnn + '/RNN_specific_data.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    params_rnn_dict = eval(''.join(lines))\n",
    "\n",
    "    dt_rnn = params_rnn_dict['dt_rnn']\n",
    "    return_params_arr = params_rnn_dict['return_params_arr']\n",
    "    params = params_rnn_dict['params']\n",
    "    try:\n",
    "        normalize_dataset = params_rnn_dict['normalize_dataset']\n",
    "    except:\n",
    "        print(\"'normalize_dataset' not present in rnn_specific_data, set to False.\")\n",
    "        normalize_dataset = False\n",
    "    try:\n",
    "        stddev_multiplier = params_rnn_dict['stddev_multiplier']\n",
    "    except:\n",
    "        print(\"'stddev_multiplier' not present in RNN_specific_data, set to None.\")\n",
    "        stddev_multiplier = None\n",
    "    try:\n",
    "        skip_intermediate = params_rnn_dict['skip_intermediate']\n",
    "    except:\n",
    "        print(\"'skip_intermediate' not present in RNN_specific_data, set to 1.\")\n",
    "        skip_intermediate = 1\n",
    "    try:\n",
    "        normalization_type = params_rnn_dict['normalization_type']\n",
    "    except:\n",
    "        print(\"'normalization_type' not present in RNN_specific_data, set to 'stddev'.\")\n",
    "        normalization_type = 'stddev'\n",
    "        \n",
    "    \n",
    "    # training params\n",
    "    with open(dir_name_rnn + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "    try:\n",
    "        fRMS = tparams_dict['fRMS']\n",
    "    except:\n",
    "        fRMS = 0.0\n",
    "\n",
    "    loss_weights = 0.98\n",
    "else:\n",
    "    # AR-RNN directory\n",
    "    dir_name_ARrnn = os.getcwd()+'/saved_AR_AERNN_rnn/AR_rnn_014'\n",
    "\n",
    "    # reading AR-RNN parameters\n",
    "    with open(dir_name_ARrnn + '/AR_RNN_specific_data.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    params_AR_rnn_dict = eval(''.join(lines))\n",
    "\n",
    "    dir_name_rnn = params_AR_rnn_dict['dir_name_rnn']\n",
    "    rnn_idx = dir_name_rnn[-3:]\n",
    "    dir_name_rnn = os.getcwd()+'/saved_ESN/ESN_'+rnn_idx\n",
    "\n",
    "    dt_rnn = params_AR_rnn_dict['dt_rnn']\n",
    "    T_sample_input = params_AR_rnn_dict['T_sample_input']\n",
    "    T_sample_output = params_AR_rnn_dict['T_sample_output']\n",
    "    T_offset = params_AR_rnn_dict['T_offset']\n",
    "    return_params_arr = params_AR_rnn_dict['return_params_arr']\n",
    "    params = params_AR_rnn_dict['params']\n",
    "    try:\n",
    "        normalize_dataset = params_AR_rnn_dict['normalize_dataset']\n",
    "    except:\n",
    "        print(\"'normalize_dataset' not present in AR_rnn_specific_data, set to False.\")\n",
    "        normalize_dataset = False\n",
    "    try:\n",
    "        stddev_multiplier = params_AR_rnn_dict['stddev_multiplier']\n",
    "    except:\n",
    "        print(\"'stddev_multiplier' not present in AR_RNN_specific_data, set to None.\")\n",
    "        stddev_multiplier = None\n",
    "    try:\n",
    "        skip_intermediate = params_AR_rnn_dict['skip_intermediate']\n",
    "    except:\n",
    "        print(\"'skip_intermediate' not present in AR_RNN_specific_data, set to 1.\")\n",
    "        skip_intermediate = 1\n",
    "    try:\n",
    "        use_ae_data = params_AR_rnn_dict['use_ae_data']\n",
    "    except:\n",
    "        print(\"'use_ae_data' not present in AR_RNN_specific_data, set to True.\")\n",
    "        use_ae_data = True\n",
    "    try:\n",
    "        normalization_type = params_AR_rnn_dict['normalization_type']\n",
    "    except:\n",
    "        print(\"'normalization_type' not present in AR_RNN_specific_data, set to 'stddev'.\")\n",
    "        normalization_type = 'stddev'\n",
    "\n",
    "    # training params\n",
    "    with open(dir_name_ARrnn + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    learning_rate_list = tparams_dict['learning_rate_list']\n",
    "    epochs = tparams_dict['epochs']\n",
    "    patience = tparams_dict['patience']\n",
    "    min_delta = tparams_dict['min_delta']\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "    covmat_lmda = tparams_dict['covmat_lmda']\n",
    "    try:\n",
    "        lambda_reg = tparams_dict['lambda_reg']\n",
    "    except:\n",
    "        lambda_reg = 1e-6\n",
    "    try:\n",
    "        fRMS = tparams_dict['fRMS']\n",
    "    except:\n",
    "        fRMS = 0.0\n",
    "    try:\n",
    "        loss_weights = tparams_dict['loss_weights']\n",
    "    except:\n",
    "        loss_weights = None\n",
    "    if 'freeze_layers' in tparams_dict.keys():\n",
    "        freeze_layers = tparams_dict['freeze_layers']\n",
    "    else:\n",
    "        freeze_layers = None\n",
    "    if 'clipnorm' in tparams_dict.keys():\n",
    "        clipnorm = tparams_dict['clipnorm']\n",
    "    else:\n",
    "        clipnorm = None\n",
    "    \n",
    "\n",
    "\n",
    "# reading stddev\n",
    "with open(dir_name_rnn + '/final_net/0_final_net_class_dict.txt') as f:\n",
    "    lines = f.readlines()\n",
    "finalnet_dict = eval(''.join(lines))\n",
    "stddev = finalnet_dict['stddev']\n",
    "# stddev = 0.0\n",
    "\n",
    "# reading RNN normalization constants\n",
    "normalization_arr_rnn = None\n",
    "if normalize_dataset == True:\n",
    "    with open(dir_name_rnn + '/final_net/rnn_normalization.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    normarr_rnn_dict = eval(''.join(lines))\n",
    "    normalization_arr_rnn = normarr_rnn_dict['normalization_arr']\n",
    "\n",
    "if os.path.exists(dir_name_rnn+dir_sep+'normalization_data.npz'):\n",
    "    with np.load(dir_name_rnn+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "        normalization_arr_rnn = fl['normalization_arr'][0]\n",
    "\n",
    "# reading AE directory\n",
    "with open(dir_name_rnn + '/sim_data_AE_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "params_dict = eval(''.join(lines))\n",
    "\n",
    "dir_name_ae = params_dict['dir_name_ae']\n",
    "ae_idx = dir_name_ae[-3:]\n",
    "dir_name_ae = os.getcwd()+'/saved_ae/ae_'+ae_idx\n",
    "try:\n",
    "    use_ae_data = params_dict['use_ae_data']\n",
    "except:\n",
    "    print(\"'use_ae_data' not present in sim_data_AE_params, set to True.\")\n",
    "    use_ae_data = True\n",
    "\n",
    "# reading simulation parameters\n",
    "with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "data_dir_idx = params_dict['data_dir_idx']\n",
    "normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "normalization_constant_arr_aedata = params_dict['normalization_constant_arr_aedata']\n",
    "if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "    with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "        normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "try:\n",
    "    ae_data_with_params = params_dict['ae_data_with_params']\n",
    "except:\n",
    "    print(\"'ae_data_with_params' not present in ae_data, set to True.\")\n",
    "    ae_data_with_params = True\n",
    "\n",
    "print('dir_name_AR_AErnn:', dir_name_ARrnn)\n",
    "print('dir_name_rnn:', dir_name_rnn)\n",
    "print('dir_name_ae:', dir_name_ae)\n",
    "print('data_dir_idx:', data_dir_idx)\n",
    "\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "    \n",
    "with open(dir_name_data + dir_sep + 'sim_data_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "params_mat = params_dict['params_mat']\n",
    "# init_state = params_dict['init_state']\n",
    "t0 = params_dict['t0']\n",
    "T = params_dict['T']\n",
    "delta_t = params_dict['delta_t']\n",
    "return_params_arr = params_dict['return_params_arr']\n",
    "normalize_flag_ogdata = params_dict['normalize_flag']\n",
    "print('normalize_flag_ogdata:', normalize_flag_ogdata)\n",
    "alldata_withparams_flag = params_dict['alldata_withparams_flag']\n",
    "\n",
    "with np.load(dir_name_data+dir_sep+'data.npz', allow_pickle=True) as fl:\n",
    "    all_data = fl['all_data'].astype(FTYPE)\n",
    "    boundary_idx_arr = fl['boundary_idx_arr']\n",
    "    normalization_constant_arr_ogdata = fl['normalization_constant_arr'][0]\n",
    "    initial_t0 = fl['initial_t0']\n",
    "    init_state_mat = fl['init_state_mat']\n",
    "\n",
    "    lyapunov_spectrum_mat = fl['lyapunov_spectrum_mat']\n",
    "\n",
    "\n",
    "test_split = 1 - train_split - val_split\n",
    "\n",
    "# setting seed for PRNGs\n",
    "np.random.seed(prng_seed)\n",
    "tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5768,
     "status": "ok",
     "timestamp": 1667868772247,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "O7sl7i5H5Dqz",
    "outputId": "419ef0e0-4d58-454e-d0af-17af3b846b85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1667868772777,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "ySVDz_2U5FH5",
    "outputId": "c57be82f-527d-4e83-a605-aac85c39088e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case : 1, lyapunov exponent : 0.9058021372262592, lyapunov time : 1.1039938926696777s\n"
     ]
    }
   ],
   "source": [
    "lyapunov_time_arr = np.empty(shape=lyapunov_spectrum_mat.shape[0], dtype=FTYPE)\n",
    "for i in range(lyapunov_spectrum_mat.shape[0]):\n",
    "    lyapunov_time_arr[i] = 1/lyapunov_spectrum_mat[i, 0]\n",
    "    print('Case : {}, lyapunov exponent : {}, lyapunov time : {}s'.format(i+1, lyapunov_spectrum_mat[i, 0], lyapunov_time_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868772778,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1667868774262,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "uDhfYHU45IS8",
    "outputId": "5307dc6a-17c5-4c77-dac5-fcb96116ac44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868774263,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "-MJa7P5t5KiC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delaing with normalizing the data before feeding into autoencoder\n",
    "num_params = params_mat.shape[1]\n",
    "og_vars = all_data.shape[1]\n",
    "if alldata_withparams_flag == True:\n",
    "    og_vars -= num_params\n",
    "\n",
    "# if use_ae_data == True:\n",
    "#     if ae_data_with_params == True and alldata_withparams_flag == False:\n",
    "#         new_all_data = np.empty(shape=(all_data.shape[0], og_vars+num_params), dtype=FTYPE)\n",
    "#         new_all_data[:, 0:og_vars] = all_data[:, 0:og_vars]\n",
    "#         del(all_data)\n",
    "#         all_data = new_all_data\n",
    "#         prev_idx = 0\n",
    "#         for i in range(boundary_idx_arr.shape[0]):\n",
    "#             all_data[prev_idx:boundary_idx_arr[i], num_params:] = params_mat[i]\n",
    "#             prev_idx = boundary_idx_arr[i]\n",
    "\n",
    "#     if normalizeforae_flag == True:\n",
    "#         for i in range(all_data.shape[1]):\n",
    "#             all_data[:, i] -= normalization_constant_arr_aedata[0, i]\n",
    "#             all_data[:, i] /= normalization_constant_arr_aedata[1, i]\n",
    "\n",
    "#     if ae_data_with_params == False:\n",
    "#         all_data = all_data[:, 0:og_vars]\n",
    "# else:\n",
    "#     # using raw data, neglecting the params attached (if any)\n",
    "#     all_data = all_data[:, 0:og_vars]\n",
    "\n",
    "if use_ae_data == True and ae_data_with_params == False:\n",
    "    all_data = all_data[:, 0:og_vars]\n",
    "else:\n",
    "    all_data = all_data[:, 0:og_vars]\n",
    "    \n",
    "normalization_constant_arr_aedata = normalization_constant_arr_aedata[:, 0:all_data.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 100001\n",
    "all_data = all_data[0:a]\n",
    "boundary_idx_arr = [all_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1667868775190,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "sMENXULAGFPm",
    "outputId": "dbf2c14d-2e8a-42c9-b6c5-f5f7c7a6092f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data.shape :  (100001, 3)\n",
      "all_data.dtype :  float32\n"
     ]
    }
   ],
   "source": [
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_data.dtype : ', all_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667868775191,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "ZBTJl9PeneQb"
   },
   "outputs": [],
   "source": [
    "# if use_ae_data == True:\n",
    "#     load_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_class_dict.txt'\n",
    "#     wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1667868776552,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "a3Pq-qorneQb"
   },
   "outputs": [],
   "source": [
    "# if use_ae_data == True:\n",
    "#     ae_net = Autoencoder(all_data.shape[1], load_file=load_file)\n",
    "#     ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667868776553,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "wwt4brHcOaXi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IAcFjRRn_IQ"
   },
   "source": [
    "# ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667868778789,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "lPVqWNwjoAGP"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # RNN data parameters\n",
    "    num_lyaptimesteps_totrain = np.array([\n",
    "        5,#10,\n",
    "        10,#16,\n",
    "        15,#23,\n",
    "        20,#30,\n",
    "        # 55,\n",
    "    ])*dt_rnn/np.mean(lyapunov_time_arr)\n",
    "    num_timesteps_warmup = 1*np.mean(lyapunov_time_arr)/dt_rnn\n",
    "    T_sample_input = num_timesteps_warmup*dt_rnn\n",
    "    T_sample_output = num_lyaptimesteps_totrain*np.mean(lyapunov_time_arr)\n",
    "    T_offset = T_sample_input\n",
    "    skip_intermediate = 'full sample'\n",
    "    stateful = True\n",
    "    if return_params_arr != False:\n",
    "        params = params_arr\n",
    "    else:\n",
    "        params = None\n",
    "\n",
    "    # saving AR RNN specific data\n",
    "    AR_RNN_specific_data = {\n",
    "        'dt_rnn':dt_rnn,\n",
    "        'T_sample_input':T_sample_input,\n",
    "        'T_sample_output':T_sample_output,\n",
    "        'T_offset':T_offset,\n",
    "        'boundary_idx_arr':boundary_idx_arr,\n",
    "        'delta_t':delta_t,\n",
    "        'params':params,\n",
    "        'return_params_arr':return_params_arr,\n",
    "        'normalize_dataset':normalize_dataset,\n",
    "        'num_lyaptimesteps_totrain':num_lyaptimesteps_totrain,\n",
    "        'num_timesteps_warmup':num_timesteps_warmup,\n",
    "        'dir_name_rnn':dir_name_rnn,\n",
    "        'dir_name_ae':dir_name_ae,\n",
    "        'stddev_multiplier':stddev_multiplier,\n",
    "        'skip_intermediate':skip_intermediate,\n",
    "        'module':AR_RNN.__module__,\n",
    "        'normalization_type':normalization_type,\n",
    "        'use_ae_data':use_ae_data,\n",
    "        'stateful':stateful,\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ARrnn+dir_sep+'AR_RNN_specific_data.txt', 'w') as f:\n",
    "        f.write(str(AR_RNN_specific_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778789,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "S21-VEUYrkk-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1667868779211,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "-1uL-GomneQi"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    learning_rate_list = [\n",
    "        # [1e-3, 5e-4, 1e-4],\n",
    "        [1e-4, 5e-5, 1e-5],\n",
    "        [1e-5, 5e-6, 1e-6],\n",
    "        [1e-6, 5e-7, 1e-7],\n",
    "        [1e-6, 5e-7, 1e-7],\n",
    "    ]\n",
    "    epochs = [\n",
    "        [200]*len(learning_rate_list[0]),\n",
    "        [200]*len(learning_rate_list[1]),\n",
    "        [200]*len(learning_rate_list[2]),\n",
    "        [200]*len(learning_rate_list[3]),\n",
    "        # [1000],\n",
    "    ]\n",
    "    patience = [\n",
    "        [20]*len(learning_rate_list[0]),\n",
    "        [20]*len(learning_rate_list[1]),\n",
    "        [20]*len(learning_rate_list[2]),\n",
    "        [20]*len(learning_rate_list[3]),\n",
    "        # [50],\n",
    "    ] # parameter for early stopping\n",
    "    min_delta = 5e-6  # parameter for early stopping\n",
    "    lambda_reg = 7e-11  # weight for regularizer\n",
    "    covmat_lmda = 1e-3  # weight for the covmat loss\n",
    "\n",
    "    if loss_weights is None:\n",
    "        loss_weights = 1.0\n",
    "        \n",
    "    freeze_layers = [\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    ]\n",
    "    \n",
    "    clipnorm = None #1.0\n",
    "    batch_size = 32\n",
    "    \n",
    "    train_alpha = [False]*len(learning_rate_list)\n",
    "    train_omega_in = [False]*len(learning_rate_list)\n",
    "    train_rho_res = [False]*len(learning_rate_list)\n",
    "    \n",
    "    # saving training params\n",
    "    training_specific_params = {\n",
    "        'learning_rate_list':learning_rate_list,\n",
    "        'epochs':epochs,\n",
    "        'patience':patience,\n",
    "        'min_delta':min_delta,\n",
    "        'prng_seed':prng_seed,\n",
    "        'train_split':train_split,\n",
    "        'val_split':val_split,\n",
    "        'batch_size':batch_size,\n",
    "        'fRMS':fRMS,\n",
    "        'loss_weights':loss_weights,\n",
    "        'stddev':stddev,\n",
    "        'covmat_lmda':covmat_lmda,\n",
    "        'freeze_layers':freeze_layers,\n",
    "        'clipnorm':clipnorm,\n",
    "        'lambda_reg':lambda_reg,\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ARrnn+dir_sep+'training_specific_params.txt', 'w') as f:\n",
    "        f.write(str(training_specific_params))\n",
    "    \n",
    "    np.savez(\n",
    "        dir_name_ARrnn+dir_sep+'normalization_data',\n",
    "        normalization_arr=[normalization_arr_rnn],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868779212,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "4hx9ZaSpEMmv"
   },
   "outputs": [],
   "source": [
    "rnn_kwargs = {}\n",
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    load_file_rnn = dir_name_rnn + '/final_net/final_net_class_dict.txt'\n",
    "    wt_file_rnn = dir_name_rnn+'/final_net/final_net_ESN_weights.hdf5'\n",
    "    \n",
    "    load_file_ae = dir_name_ae+'/final_net/final_net_class_dict.txt'\n",
    "    wt_file_ae = dir_name_ae+'/final_net/final_net_ae_weights.h5'\n",
    "    \n",
    "    rnn_kwargs = {\n",
    "        'train_alpha':train_alpha,\n",
    "        'train_omega_in':train_omega_in,\n",
    "        'train_rho_res':train_rho_res,\n",
    "        'wts_to_be_loaded':True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_return_load_wt_file_lists(\n",
    "        load_dir,\n",
    "        wt_matcher='weights.hdf5',\n",
    "        classdict_matcher='class_dict.txt',\n",
    "    ):\n",
    "    contents_load_dir = [f for f in os.listdir(load_dir) if os.path.isfile(os.path.join(load_dir, f))]\n",
    "    load_files_lst = [f for f in contents_load_dir if f.endswith(classdict_matcher)]\n",
    "    wt_files_lst = [f for f in contents_load_dir if f.endswith(wt_matcher)]\n",
    "\n",
    "    load_files_lst_startingidx = []\n",
    "    for i in range(len(load_files_lst)):\n",
    "        fn = load_files_lst[i]\n",
    "        idx = fn.find('_')\n",
    "        load_files_lst_startingidx.append(int(fn[0:idx]))\n",
    "\n",
    "    wt_files_lst_startingidx = []\n",
    "    for i in range(len(wt_files_lst)):\n",
    "        fn = wt_files_lst[i]\n",
    "        idx = fn.find('_')\n",
    "        wt_files_lst_startingidx.append(int(fn[0:idx]))\n",
    "\n",
    "    load_files_sortidx = np.argsort(load_files_lst_startingidx)\n",
    "    wt_files_sortidx = np.argsort(wt_files_lst_startingidx)\n",
    "\n",
    "    load_files_lst = np.array(load_files_lst)[load_files_sortidx]\n",
    "    wt_files_lst = np.array(wt_files_lst)[wt_files_sortidx]\n",
    "\n",
    "    load_file_rnn = [load_dir + '/' + fn for fn in load_files_lst]\n",
    "    wt_file_rnn = [load_dir + '/' +  fn for fn in wt_files_lst]\n",
    "    \n",
    "    return load_file_rnn, wt_file_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = dir_name_rnn + '/final_net'\n",
    "load_file_rnn, wt_file_rnn = find_and_return_load_wt_file_lists(load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3631,
     "status": "ok",
     "timestamp": 1667868783230,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "Py-Jg0QKneQk",
    "outputId": "1b768270-9013-4d53-8b5e-63e69776e3ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********************************************************************************\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> num_outsteps : 5 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "clipnorm : None, global_clipnorm : 30\n",
      "2/2 [==============================] - 13s 31ms/step - loss: 0.0169 - mse: 0.0013 - NMSE: 0.0114 - NMSE_wt: 0.0108 - covmat_fro_loss: 0.0000e+00 - global_gradnorm: 0.0000e+00\n",
      "baseline : 1.0768E-02\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0460 - mse: 0.0047 - NMSE: 0.0427 - NMSE_wt: 0.0399 - covmat_fro_loss: 0.0011 - global_gradnorm: 16.4517 - tot_time: 0h 0m 38.0s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.01077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 38s 127ms/step - loss: 0.0460 - mse: 0.0047 - NMSE: 0.0427 - NMSE_wt: 0.0399 - covmat_fro_loss: 0.0011 - global_gradnorm: 17.2985 - val_loss: 0.0181 - val_mse: 0.0014 - val_NMSE: 0.0126 - val_NMSE_wt: 0.0119 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0375 - mse: 0.0037 - NMSE: 0.0335 - NMSE_wt: 0.0314 - covmat_fro_loss: 0.0010 - global_gradnorm: 14.9364 - tot_time: 0h 0m 39.9s\n",
      "\n",
      "Epoch 2: val_NMSE_wt improved from 0.01077 to 0.00838, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 0.0375 - mse: 0.0037 - NMSE: 0.0335 - NMSE_wt: 0.0314 - covmat_fro_loss: 0.0010 - global_gradnorm: 15.8779 - val_loss: 0.0145 - val_mse: 9.8005e-04 - val_NMSE: 0.0088 - val_NMSE_wt: 0.0084 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0309 - mse: 0.0029 - NMSE: 0.0265 - NMSE_wt: 0.0248 - covmat_fro_loss: 8.8339e-04 - global_gradnorm: 17.1702 - tot_time: 0h 0m 41.9s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.00838\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0309 - mse: 0.0029 - NMSE: 0.0265 - NMSE_wt: 0.0248 - covmat_fro_loss: 8.6052e-04 - global_gradnorm: 16.7310 - val_loss: 0.0229 - val_mse: 0.0020 - val_NMSE: 0.0178 - val_NMSE_wt: 0.0168 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0269 - mse: 0.0025 - NMSE: 0.0222 - NMSE_wt: 0.0208 - covmat_fro_loss: 8.0184e-04 - global_gradnorm: 11.1848 - tot_time: 0h 0m 43.7s\n",
      "\n",
      "Epoch 4: val_NMSE_wt improved from 0.00838 to 0.00771, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0269 - mse: 0.0025 - NMSE: 0.0222 - NMSE_wt: 0.0208 - covmat_fro_loss: 8.0941e-04 - global_gradnorm: 11.9808 - val_loss: 0.0138 - val_mse: 8.9859e-04 - val_NMSE: 0.0081 - val_NMSE_wt: 0.0077 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0182 - mse: 0.0014 - NMSE: 0.0128 - NMSE_wt: 0.0120 - covmat_fro_loss: 7.8685e-04 - global_gradnorm: 7.0709 - tot_time: 0h 0m 46.4s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.00771\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 0.0182 - mse: 0.0014 - NMSE: 0.0128 - NMSE_wt: 0.0120 - covmat_fro_loss: 7.9765e-04 - global_gradnorm: 7.8488 - val_loss: 0.0168 - val_mse: 0.0013 - val_NMSE: 0.0113 - val_NMSE_wt: 0.0107 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0185 - mse: 0.0015 - NMSE: 0.0131 - NMSE_wt: 0.0124 - covmat_fro_loss: 7.3774e-04 - global_gradnorm: 9.8217  - tot_time: 0h 0m 48.1s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.00771\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0185 - mse: 0.0015 - NMSE: 0.0131 - NMSE_wt: 0.0124 - covmat_fro_loss: 7.3414e-04 - global_gradnorm: 9.3509 - val_loss: 0.0143 - val_mse: 9.5080e-04 - val_NMSE: 0.0086 - val_NMSE_wt: 0.0081 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0300 - mse: 0.0028 - NMSE: 0.0255 - NMSE_wt: 0.0238 - covmat_fro_loss: 8.7375e-04 - global_gradnorm: 9.7885  - tot_time: 0h 0m 49.9s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00771\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0300 - mse: 0.0028 - NMSE: 0.0255 - NMSE_wt: 0.0238 - covmat_fro_loss: 8.6348e-04 - global_gradnorm: 9.4155 - val_loss: 0.0536 - val_mse: 0.0056 - val_NMSE: 0.0508 - val_NMSE_wt: 0.0475 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0286 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0225 - covmat_fro_loss: 9.2471e-04 - global_gradnorm: 13.2418 - tot_time: 0h 0m 51.7s\n",
      "\n",
      "Epoch 8: val_NMSE_wt improved from 0.00771 to 0.00644, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 0.0286 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0225 - covmat_fro_loss: 9.2418e-04 - global_gradnorm: 13.3153 - val_loss: 0.0126 - val_mse: 7.4821e-04 - val_NMSE: 0.0067 - val_NMSE_wt: 0.0064 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0225 - mse: 0.0019 - NMSE: 0.0174 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.6179e-04 - global_gradnorm: 10.4863 - tot_time: 0h 0m 54.4s\n",
      "\n",
      "Epoch 9: val_NMSE_wt improved from 0.00644 to 0.00574, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 188ms/step - loss: 0.0225 - mse: 0.0019 - NMSE: 0.0174 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.5286e-04 - global_gradnorm: 10.0008 - val_loss: 0.0119 - val_mse: 6.6575e-04 - val_NMSE: 0.0060 - val_NMSE_wt: 0.0057 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0351 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0289 - covmat_fro_loss: 7.6294e-04 - global_gradnorm: 12.1784 - tot_time: 0h 0m 57.2s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.0351 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0289 - covmat_fro_loss: 7.5297e-04 - global_gradnorm: 11.8393 - val_loss: 0.0172 - val_mse: 0.0013 - val_NMSE: 0.0117 - val_NMSE_wt: 0.0111 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0345 - mse: 0.0034 - NMSE: 0.0303 - NMSE_wt: 0.0284 - covmat_fro_loss: 8.7708e-04 - global_gradnorm: 14.1659 - tot_time: 0h 0m 59.0s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.0345 - mse: 0.0034 - NMSE: 0.0303 - NMSE_wt: 0.0284 - covmat_fro_loss: 8.7438e-04 - global_gradnorm: 13.5842 - val_loss: 0.0371 - val_mse: 0.0037 - val_NMSE: 0.0330 - val_NMSE_wt: 0.0309 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0234 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0173 - covmat_fro_loss: 8.0354e-04 - global_gradnorm: 12.2718 - tot_time: 0h 1m 0.6s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.0234 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0173 - covmat_fro_loss: 7.9022e-04 - global_gradnorm: 11.5391 - val_loss: 0.0166 - val_mse: 0.0012 - val_NMSE: 0.0110 - val_NMSE_wt: 0.0104 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0162 - covmat_fro_loss: 7.9490e-04 - global_gradnorm: 7.5069 - tot_time: 0h 1m 2.3s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0162 - covmat_fro_loss: 7.8277e-04 - global_gradnorm: 7.5462 - val_loss: 0.0173 - val_mse: 0.0013 - val_NMSE: 0.0118 - val_NMSE_wt: 0.0111 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0162 - covmat_fro_loss: 7.1005e-04 - global_gradnorm: 7.6634 - tot_time: 0h 1m 3.9s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0162 - covmat_fro_loss: 7.1475e-04 - global_gradnorm: 7.5537 - val_loss: 0.0120 - val_mse: 6.7844e-04 - val_NMSE: 0.0061 - val_NMSE_wt: 0.0058 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0260 - mse: 0.0023 - NMSE: 0.0211 - NMSE_wt: 0.0199 - covmat_fro_loss: 7.9752e-04 - global_gradnorm: 12.4832 - tot_time: 0h 1m 5.7s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0260 - mse: 0.0023 - NMSE: 0.0211 - NMSE_wt: 0.0199 - covmat_fro_loss: 7.9208e-04 - global_gradnorm: 11.7772 - val_loss: 0.0125 - val_mse: 7.4413e-04 - val_NMSE: 0.0067 - val_NMSE_wt: 0.0064 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0244 - mse: 0.0022 - NMSE: 0.0195 - NMSE_wt: 0.0183 - covmat_fro_loss: 8.4453e-04 - global_gradnorm: 10.4467 - tot_time: 0h 1m 7.4s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0244 - mse: 0.0022 - NMSE: 0.0195 - NMSE_wt: 0.0183 - covmat_fro_loss: 8.4025e-04 - global_gradnorm: 10.4012 - val_loss: 0.0164 - val_mse: 0.0012 - val_NMSE: 0.0108 - val_NMSE_wt: 0.0103 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0193 - mse: 0.0015 - NMSE: 0.0139 - NMSE_wt: 0.0132 - covmat_fro_loss: 8.4506e-04 - global_gradnorm: 12.3374 - tot_time: 0h 1m 9.2s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0193 - mse: 0.0015 - NMSE: 0.0139 - NMSE_wt: 0.0132 - covmat_fro_loss: 8.7192e-04 - global_gradnorm: 13.4413 - val_loss: 0.0405 - val_mse: 0.0041 - val_NMSE: 0.0366 - val_NMSE_wt: 0.0344 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0464 - mse: 0.0048 - NMSE: 0.0429 - NMSE_wt: 0.0402 - covmat_fro_loss: 9.8608e-04 - global_gradnorm: 15.2028 - tot_time: 0h 1m 11.0s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0464 - mse: 0.0048 - NMSE: 0.0429 - NMSE_wt: 0.0402 - covmat_fro_loss: 9.6266e-04 - global_gradnorm: 14.3405 - val_loss: 0.0702 - val_mse: 0.0076 - val_NMSE: 0.0687 - val_NMSE_wt: 0.0641 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0356 - mse: 0.0035 - NMSE: 0.0314 - NMSE_wt: 0.0294 - covmat_fro_loss: 0.0010 - global_gradnorm: 18.4707  - tot_time: 0h 1m 12.8s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0356 - mse: 0.0035 - NMSE: 0.0314 - NMSE_wt: 0.0294 - covmat_fro_loss: 0.0010 - global_gradnorm: 17.7987 - val_loss: 0.0283 - val_mse: 0.0026 - val_NMSE: 0.0236 - val_NMSE_wt: 0.0222 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0327 - mse: 0.0032 - NMSE: 0.0284 - NMSE_wt: 0.0266 - covmat_fro_loss: 8.9797e-04 - global_gradnorm: 15.7550 - tot_time: 0h 1m 14.5s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0327 - mse: 0.0032 - NMSE: 0.0284 - NMSE_wt: 0.0266 - covmat_fro_loss: 9.1472e-04 - global_gradnorm: 15.2246 - val_loss: 0.0284 - val_mse: 0.0026 - val_NMSE: 0.0237 - val_NMSE_wt: 0.0223 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0390 - mse: 0.0039 - NMSE: 0.0351 - NMSE_wt: 0.0328 - covmat_fro_loss: 9.3159e-04 - global_gradnorm: 13.7450 - tot_time: 0h 1m 16.3s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0390 - mse: 0.0039 - NMSE: 0.0351 - NMSE_wt: 0.0328 - covmat_fro_loss: 9.2673e-04 - global_gradnorm: 13.2904 - val_loss: 0.0416 - val_mse: 0.0042 - val_NMSE: 0.0376 - val_NMSE_wt: 0.0355 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0389 - mse: 0.0039 - NMSE: 0.0350 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.2315 - tot_time: 0h 1m 18.1s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0389 - mse: 0.0039 - NMSE: 0.0350 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0010 - global_gradnorm: 13.6697 - val_loss: 0.0369 - val_mse: 0.0036 - val_NMSE: 0.0327 - val_NMSE_wt: 0.0308 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0420 - mse: 0.0043 - NMSE: 0.0383 - NMSE_wt: 0.0359 - covmat_fro_loss: 9.8080e-04 - global_gradnorm: 11.9461 - tot_time: 0h 1m 19.8s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0420 - mse: 0.0043 - NMSE: 0.0383 - NMSE_wt: 0.0359 - covmat_fro_loss: 0.0010 - global_gradnorm: 12.3655 - val_loss: 0.0200 - val_mse: 0.0016 - val_NMSE: 0.0147 - val_NMSE_wt: 0.0139 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0247 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 8.1654e-04 - global_gradnorm: 12.7220 - tot_time: 0h 1m 21.5s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0247 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 8.0736e-04 - global_gradnorm: 12.1354 - val_loss: 0.0129 - val_mse: 7.8656e-04 - val_NMSE: 0.0071 - val_NMSE_wt: 0.0068 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0268 - mse: 0.0024 - NMSE: 0.0220 - NMSE_wt: 0.0207 - covmat_fro_loss: 8.3732e-04 - global_gradnorm: 13.6616 - tot_time: 0h 1m 23.3s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0268 - mse: 0.0024 - NMSE: 0.0220 - NMSE_wt: 0.0207 - covmat_fro_loss: 8.3830e-04 - global_gradnorm: 13.8280 - val_loss: 0.0352 - val_mse: 0.0035 - val_NMSE: 0.0311 - val_NMSE_wt: 0.0291 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 8.4875e-04 - global_gradnorm: 13.3808 - tot_time: 0h 1m 25.1s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 8.5183e-04 - global_gradnorm: 13.0991 - val_loss: 0.0515 - val_mse: 0.0053 - val_NMSE: 0.0481 - val_NMSE_wt: 0.0454 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0649 - mse: 0.0070 - NMSE: 0.0627 - NMSE_wt: 0.0587 - covmat_fro_loss: 0.0012 - global_gradnorm: 17.2550 - tot_time: 0h 1m 26.8s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0649 - mse: 0.0070 - NMSE: 0.0627 - NMSE_wt: 0.0587 - covmat_fro_loss: 0.0011 - global_gradnorm: 16.3875 - val_loss: 0.0403 - val_mse: 0.0040 - val_NMSE: 0.0363 - val_NMSE_wt: 0.0342 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0269 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0208 - covmat_fro_loss: 9.3173e-04 - global_gradnorm: 12.4669 - tot_time: 0h 1m 28.6s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0269 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0208 - covmat_fro_loss: 9.4479e-04 - global_gradnorm: 12.9951 - val_loss: 0.0210 - val_mse: 0.0017 - val_NMSE: 0.0157 - val_NMSE_wt: 0.0148 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0193 - mse: 0.0015 - NMSE: 0.0139 - NMSE_wt: 0.0131 - covmat_fro_loss: 8.6418e-04 - global_gradnorm: 10.8907Restoring model weights from the end of the best epoch: 9.\n",
      " - tot_time: 0h 1m 30.5s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 128ms/step - loss: 0.0193 - mse: 0.0015 - NMSE: 0.0139 - NMSE_wt: 0.0131 - covmat_fro_loss: 8.5177e-04 - global_gradnorm: 10.7541 - val_loss: 0.0121 - val_mse: 6.9318e-04 - val_NMSE: 0.0062 - val_NMSE_wt: 0.0060 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 5e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0259 - mse: 0.0023 - NMSE: 0.0210 - NMSE_wt: 0.0197 - covmat_fro_loss: 8.0822e-04 - global_gradnorm: 10.6334 - tot_time: 0h 1m 32.5s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 0.0259 - mse: 0.0023 - NMSE: 0.0210 - NMSE_wt: 0.0197 - covmat_fro_loss: 8.0940e-04 - global_gradnorm: 10.7164 - val_loss: 0.0191 - val_mse: 0.0015 - val_NMSE: 0.0138 - val_NMSE_wt: 0.0130 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0297 - mse: 0.0028 - NMSE: 0.0252 - NMSE_wt: 0.0236 - covmat_fro_loss: 8.5099e-04 - global_gradnorm: 15.8936 - tot_time: 0h 1m 34.4s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 0.0297 - mse: 0.0028 - NMSE: 0.0252 - NMSE_wt: 0.0236 - covmat_fro_loss: 8.5829e-04 - global_gradnorm: 16.7753 - val_loss: 0.0184 - val_mse: 0.0014 - val_NMSE: 0.0130 - val_NMSE_wt: 0.0122 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0247 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 8.0881e-04 - global_gradnorm: 15.1101 - tot_time: 0h 1m 36.1s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0247 - mse: 0.0022 - NMSE: 0.0198 - NMSE_wt: 0.0186 - covmat_fro_loss: 7.9169e-04 - global_gradnorm: 14.7104 - val_loss: 0.0143 - val_mse: 9.6062e-04 - val_NMSE: 0.0086 - val_NMSE_wt: 0.0082 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0261 - mse: 0.0024 - NMSE: 0.0213 - NMSE_wt: 0.0199 - covmat_fro_loss: 7.5357e-04 - global_gradnorm: 13.1490 - tot_time: 0h 1m 37.8s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0261 - mse: 0.0024 - NMSE: 0.0213 - NMSE_wt: 0.0199 - covmat_fro_loss: 7.4087e-04 - global_gradnorm: 12.6675 - val_loss: 0.0156 - val_mse: 0.0011 - val_NMSE: 0.0100 - val_NMSE_wt: 0.0095 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0205 - mse: 0.0017 - NMSE: 0.0153 - NMSE_wt: 0.0144 - covmat_fro_loss: 7.6533e-04 - global_gradnorm: 9.1156 - tot_time: 0h 1m 39.6s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.0205 - mse: 0.0017 - NMSE: 0.0153 - NMSE_wt: 0.0144 - covmat_fro_loss: 7.6172e-04 - global_gradnorm: 8.5930 - val_loss: 0.0387 - val_mse: 0.0039 - val_NMSE: 0.0348 - val_NMSE_wt: 0.0326 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0198 - mse: 0.0016 - NMSE: 0.0145 - NMSE_wt: 0.0137 - covmat_fro_loss: 7.2393e-04 - global_gradnorm: 9.0826 - tot_time: 0h 1m 41.3s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0198 - mse: 0.0016 - NMSE: 0.0145 - NMSE_wt: 0.0137 - covmat_fro_loss: 7.1651e-04 - global_gradnorm: 8.8980 - val_loss: 0.0203 - val_mse: 0.0017 - val_NMSE: 0.0151 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0307 - mse: 0.0029 - NMSE: 0.0262 - NMSE_wt: 0.0245 - covmat_fro_loss: 7.9662e-04 - global_gradnorm: 10.5231 - tot_time: 0h 1m 43.1s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0307 - mse: 0.0029 - NMSE: 0.0262 - NMSE_wt: 0.0245 - covmat_fro_loss: 7.8907e-04 - global_gradnorm: 10.0318 - val_loss: 0.0200 - val_mse: 0.0016 - val_NMSE: 0.0147 - val_NMSE_wt: 0.0139 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0236 - mse: 0.0021 - NMSE: 0.0186 - NMSE_wt: 0.0175 - covmat_fro_loss: 8.1796e-04 - global_gradnorm: 14.2027 - tot_time: 0h 1m 44.8s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0236 - mse: 0.0021 - NMSE: 0.0186 - NMSE_wt: 0.0175 - covmat_fro_loss: 8.3896e-04 - global_gradnorm: 14.7542 - val_loss: 0.0353 - val_mse: 0.0034 - val_NMSE: 0.0310 - val_NMSE_wt: 0.0291 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0208 - mse: 0.0017 - NMSE: 0.0156 - NMSE_wt: 0.0147 - covmat_fro_loss: 7.9030e-04 - global_gradnorm: 12.1320 - tot_time: 0h 1m 46.7s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.0208 - mse: 0.0017 - NMSE: 0.0156 - NMSE_wt: 0.0147 - covmat_fro_loss: 7.8180e-04 - global_gradnorm: 12.0455 - val_loss: 0.0142 - val_mse: 9.5032e-04 - val_NMSE: 0.0086 - val_NMSE_wt: 0.0081 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0230 - mse: 0.0020 - NMSE: 0.0179 - NMSE_wt: 0.0168 - covmat_fro_loss: 7.6832e-04 - global_gradnorm: 10.7815 - tot_time: 0h 1m 48.4s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0230 - mse: 0.0020 - NMSE: 0.0179 - NMSE_wt: 0.0168 - covmat_fro_loss: 7.6737e-04 - global_gradnorm: 11.1441 - val_loss: 0.0287 - val_mse: 0.0027 - val_NMSE: 0.0240 - val_NMSE_wt: 0.0226 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0263 - mse: 0.0024 - NMSE: 0.0215 - NMSE_wt: 0.0202 - covmat_fro_loss: 7.6844e-04 - global_gradnorm: 9.9303  - tot_time: 0h 1m 50.3s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 0.0263 - mse: 0.0024 - NMSE: 0.0215 - NMSE_wt: 0.0202 - covmat_fro_loss: 7.6084e-04 - global_gradnorm: 9.3500 - val_loss: 0.0132 - val_mse: 8.2672e-04 - val_NMSE: 0.0074 - val_NMSE_wt: 0.0071 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0174 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.5021e-04 - global_gradnorm: 11.2561 - tot_time: 0h 1m 52.0s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0174 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.3960e-04 - global_gradnorm: 10.6982 - val_loss: 0.0161 - val_mse: 0.0012 - val_NMSE: 0.0105 - val_NMSE_wt: 0.0099 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0231 - mse: 0.0020 - NMSE: 0.0182 - NMSE_wt: 0.0170 - covmat_fro_loss: 7.6664e-04 - global_gradnorm: 11.3228 - tot_time: 0h 1m 53.8s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.0231 - mse: 0.0020 - NMSE: 0.0182 - NMSE_wt: 0.0170 - covmat_fro_loss: 7.7126e-04 - global_gradnorm: 12.4901 - val_loss: 0.0176 - val_mse: 0.0013 - val_NMSE: 0.0121 - val_NMSE_wt: 0.0114 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0242 - mse: 0.0021 - NMSE: 0.0192 - NMSE_wt: 0.0181 - covmat_fro_loss: 7.1669e-04 - global_gradnorm: 7.5733 - tot_time: 0h 1m 55.6s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0242 - mse: 0.0021 - NMSE: 0.0192 - NMSE_wt: 0.0181 - covmat_fro_loss: 7.1522e-04 - global_gradnorm: 7.9017 - val_loss: 0.0123 - val_mse: 7.1425e-04 - val_NMSE: 0.0064 - val_NMSE_wt: 0.0061 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0163 - covmat_fro_loss: 8.1511e-04 - global_gradnorm: 12.0781 - tot_time: 0h 1m 57.4s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0163 - covmat_fro_loss: 8.0913e-04 - global_gradnorm: 11.4637 - val_loss: 0.0337 - val_mse: 0.0033 - val_NMSE: 0.0295 - val_NMSE_wt: 0.0276 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0200 - NMSE_wt: 0.0187 - covmat_fro_loss: 7.8726e-04 - global_gradnorm: 10.9571 - tot_time: 0h 1m 59.2s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0200 - NMSE_wt: 0.0187 - covmat_fro_loss: 7.8720e-04 - global_gradnorm: 11.0118 - val_loss: 0.0306 - val_mse: 0.0029 - val_NMSE: 0.0262 - val_NMSE_wt: 0.0245 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0199 - NMSE_wt: 0.0187 - covmat_fro_loss: 7.6359e-04 - global_gradnorm: 12.0041 - tot_time: 0h 2m 0.9s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0248 - mse: 0.0022 - NMSE: 0.0199 - NMSE_wt: 0.0187 - covmat_fro_loss: 7.8342e-04 - global_gradnorm: 13.1288 - val_loss: 0.0134 - val_mse: 8.4452e-04 - val_NMSE: 0.0076 - val_NMSE_wt: 0.0072 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0106 - covmat_fro_loss: 7.0416e-04 - global_gradnorm: 9.3411 - tot_time: 0h 2m 2.7s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0106 - covmat_fro_loss: 6.9365e-04 - global_gradnorm: 8.7892 - val_loss: 0.0167 - val_mse: 0.0012 - val_NMSE: 0.0112 - val_NMSE_wt: 0.0105 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0129 - covmat_fro_loss: 7.3428e-04 - global_gradnorm: 8.8210 - tot_time: 0h 2m 4.4s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0129 - covmat_fro_loss: 7.3119e-04 - global_gradnorm: 9.6259 - val_loss: 0.0138 - val_mse: 8.9298e-04 - val_NMSE: 0.0080 - val_NMSE_wt: 0.0076 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0179 - mse: 0.0014 - NMSE: 0.0125 - NMSE_wt: 0.0118 - covmat_fro_loss: 7.3444e-04 - global_gradnorm: 10.4679 - tot_time: 0h 2m 6.2s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0179 - mse: 0.0014 - NMSE: 0.0125 - NMSE_wt: 0.0118 - covmat_fro_loss: 7.3847e-04 - global_gradnorm: 10.0448 - val_loss: 0.0130 - val_mse: 8.0549e-04 - val_NMSE: 0.0072 - val_NMSE_wt: 0.0069 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0226 - mse: 0.0020 - NMSE: 0.0176 - NMSE_wt: 0.0165 - covmat_fro_loss: 7.6149e-04 - global_gradnorm: 12.9953 - tot_time: 0h 2m 7.9s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0226 - mse: 0.0020 - NMSE: 0.0176 - NMSE_wt: 0.0165 - covmat_fro_loss: 7.4800e-04 - global_gradnorm: 12.3629 - val_loss: 0.0146 - val_mse: 9.8647e-04 - val_NMSE: 0.0089 - val_NMSE_wt: 0.0084 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0237 - mse: 0.0021 - NMSE: 0.0188 - NMSE_wt: 0.0176 - covmat_fro_loss: 7.8835e-04 - global_gradnorm: 12.4780 - tot_time: 0h 2m 9.6s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.0237 - mse: 0.0021 - NMSE: 0.0188 - NMSE_wt: 0.0176 - covmat_fro_loss: 7.9159e-04 - global_gradnorm: 13.0081 - val_loss: 0.0135 - val_mse: 8.6739e-04 - val_NMSE: 0.0078 - val_NMSE_wt: 0.0074 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0269 - covmat_fro_loss: 8.0634e-04 - global_gradnorm: 12.5904 - tot_time: 0h 2m 11.3s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.0330 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0269 - covmat_fro_loss: 8.1286e-04 - global_gradnorm: 12.1867 - val_loss: 0.0129 - val_mse: 7.8640e-04 - val_NMSE: 0.0071 - val_NMSE_wt: 0.0067 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0240 - mse: 0.0021 - NMSE: 0.0190 - NMSE_wt: 0.0178 - covmat_fro_loss: 8.2807e-04 - global_gradnorm: 14.9358 - tot_time: 0h 2m 12.9s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0240 - mse: 0.0021 - NMSE: 0.0190 - NMSE_wt: 0.0178 - covmat_fro_loss: 8.1967e-04 - global_gradnorm: 14.1293 - val_loss: 0.0132 - val_mse: 8.2297e-04 - val_NMSE: 0.0074 - val_NMSE_wt: 0.0071 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0268 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0207 - covmat_fro_loss: 8.6374e-04 - global_gradnorm: 13.2964 - tot_time: 0h 2m 14.7s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0268 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0207 - covmat_fro_loss: 8.6190e-04 - global_gradnorm: 13.2073 - val_loss: 0.0272 - val_mse: 0.0025 - val_NMSE: 0.0225 - val_NMSE_wt: 0.0211 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0233 - mse: 0.0020 - NMSE: 0.0183 - NMSE_wt: 0.0172 - covmat_fro_loss: 7.9287e-04 - global_gradnorm: 9.9131  - tot_time: 0h 2m 16.4s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0233 - mse: 0.0020 - NMSE: 0.0183 - NMSE_wt: 0.0172 - covmat_fro_loss: 7.8389e-04 - global_gradnorm: 9.3326 - val_loss: 0.0141 - val_mse: 9.3119e-04 - val_NMSE: 0.0084 - val_NMSE_wt: 0.0080 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0243 - mse: 0.0021 - NMSE: 0.0193 - NMSE_wt: 0.0181 - covmat_fro_loss: 8.1118e-04 - global_gradnorm: 9.9718  - tot_time: 0h 2m 18.2s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00574\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0243 - mse: 0.0021 - NMSE: 0.0193 - NMSE_wt: 0.0181 - covmat_fro_loss: 7.9260e-04 - global_gradnorm: 9.4172 - val_loss: 0.0147 - val_mse: 0.0010 - val_NMSE: 0.0090 - val_NMSE_wt: 0.0085 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.0830e-04 - global_gradnorm: 8.7509 - tot_time: 0h 2m 20.0s\n",
      "\n",
      "Epoch 28: val_NMSE_wt improved from 0.00574 to 0.00541, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.0817e-04 - global_gradnorm: 8.2887 - val_loss: 0.0115 - val_mse: 6.2720e-04 - val_NMSE: 0.0056 - val_NMSE_wt: 0.0054 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0166 - mse: 0.0012 - NMSE: 0.0111 - NMSE_wt: 0.0105 - covmat_fro_loss: 7.7161e-04 - global_gradnorm: 9.7190 - tot_time: 0h 2m 22.8s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 0.0166 - mse: 0.0012 - NMSE: 0.0111 - NMSE_wt: 0.0105 - covmat_fro_loss: 7.6497e-04 - global_gradnorm: 9.7412 - val_loss: 0.0122 - val_mse: 7.0168e-04 - val_NMSE: 0.0063 - val_NMSE_wt: 0.0060 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0233 - mse: 0.0020 - NMSE: 0.0183 - NMSE_wt: 0.0172 - covmat_fro_loss: 7.4564e-04 - global_gradnorm: 9.8365  - tot_time: 0h 2m 24.5s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0233 - mse: 0.0020 - NMSE: 0.0183 - NMSE_wt: 0.0172 - covmat_fro_loss: 7.2978e-04 - global_gradnorm: 9.5811 - val_loss: 0.0138 - val_mse: 8.9910e-04 - val_NMSE: 0.0081 - val_NMSE_wt: 0.0077 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0188 - mse: 0.0015 - NMSE: 0.0135 - NMSE_wt: 0.0127 - covmat_fro_loss: 7.3330e-04 - global_gradnorm: 10.1526 - tot_time: 0h 2m 26.3s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0188 - mse: 0.0015 - NMSE: 0.0135 - NMSE_wt: 0.0127 - covmat_fro_loss: 7.2131e-04 - global_gradnorm: 9.6349 - val_loss: 0.0258 - val_mse: 0.0023 - val_NMSE: 0.0210 - val_NMSE_wt: 0.0197 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0162 - mse: 0.0012 - NMSE: 0.0106 - NMSE_wt: 0.0101 - covmat_fro_loss: 6.9922e-04 - global_gradnorm: 10.3139 - tot_time: 0h 2m 28.1s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.0162 - mse: 0.0012 - NMSE: 0.0106 - NMSE_wt: 0.0101 - covmat_fro_loss: 6.9019e-04 - global_gradnorm: 9.7035 - val_loss: 0.0377 - val_mse: 0.0038 - val_NMSE: 0.0338 - val_NMSE_wt: 0.0316 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0340 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0278 - covmat_fro_loss: 8.1439e-04 - global_gradnorm: 14.8755 - tot_time: 0h 2m 29.9s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0340 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0278 - covmat_fro_loss: 8.0391e-04 - global_gradnorm: 14.1358 - val_loss: 0.0741 - val_mse: 0.0081 - val_NMSE: 0.0729 - val_NMSE_wt: 0.0680 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0381 - mse: 0.0038 - NMSE: 0.0342 - NMSE_wt: 0.0320 - covmat_fro_loss: 0.0010 - global_gradnorm: 19.9045    - tot_time: 0h 2m 31.6s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0381 - mse: 0.0038 - NMSE: 0.0342 - NMSE_wt: 0.0320 - covmat_fro_loss: 0.0010 - global_gradnorm: 20.5355 - val_loss: 0.0308 - val_mse: 0.0029 - val_NMSE: 0.0263 - val_NMSE_wt: 0.0247 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0355 - mse: 0.0035 - NMSE: 0.0313 - NMSE_wt: 0.0294 - covmat_fro_loss: 9.8855e-04 - global_gradnorm: 12.9454 - tot_time: 0h 2m 33.4s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0355 - mse: 0.0035 - NMSE: 0.0313 - NMSE_wt: 0.0294 - covmat_fro_loss: 9.6739e-04 - global_gradnorm: 12.1990 - val_loss: 0.0155 - val_mse: 0.0011 - val_NMSE: 0.0099 - val_NMSE_wt: 0.0094 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0236 - mse: 0.0021 - NMSE: 0.0185 - NMSE_wt: 0.0174 - covmat_fro_loss: 8.5876e-04 - global_gradnorm: 12.0153 - tot_time: 0h 2m 35.2s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0236 - mse: 0.0021 - NMSE: 0.0185 - NMSE_wt: 0.0174 - covmat_fro_loss: 8.4783e-04 - global_gradnorm: 12.0304 - val_loss: 0.0202 - val_mse: 0.0017 - val_NMSE: 0.0149 - val_NMSE_wt: 0.0141 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0210 - mse: 0.0018 - NMSE: 0.0158 - NMSE_wt: 0.0149 - covmat_fro_loss: 7.9933e-04 - global_gradnorm: 11.0077 - tot_time: 0h 2m 36.9s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0210 - mse: 0.0018 - NMSE: 0.0158 - NMSE_wt: 0.0149 - covmat_fro_loss: 7.9985e-04 - global_gradnorm: 10.4837 - val_loss: 0.0144 - val_mse: 9.7244e-04 - val_NMSE: 0.0088 - val_NMSE_wt: 0.0083 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0186 - mse: 0.0015 - NMSE: 0.0132 - NMSE_wt: 0.0124 - covmat_fro_loss: 7.1891e-04 - global_gradnorm: 9.6152 - tot_time: 0h 2m 38.7s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0186 - mse: 0.0015 - NMSE: 0.0132 - NMSE_wt: 0.0124 - covmat_fro_loss: 7.2907e-04 - global_gradnorm: 10.8892 - val_loss: 0.0349 - val_mse: 0.0034 - val_NMSE: 0.0307 - val_NMSE_wt: 0.0287 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0210 - mse: 0.0018 - NMSE: 0.0158 - NMSE_wt: 0.0149 - covmat_fro_loss: 7.8052e-04 - global_gradnorm: 12.1567 - tot_time: 0h 2m 40.4s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0210 - mse: 0.0018 - NMSE: 0.0158 - NMSE_wt: 0.0149 - covmat_fro_loss: 7.7942e-04 - global_gradnorm: 11.5521 - val_loss: 0.0334 - val_mse: 0.0032 - val_NMSE: 0.0291 - val_NMSE_wt: 0.0272 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0340 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0279 - covmat_fro_loss: 9.1014e-04 - global_gradnorm: 14.9472 - tot_time: 0h 2m 42.2s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0340 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0279 - covmat_fro_loss: 8.9338e-04 - global_gradnorm: 14.1143 - val_loss: 0.0191 - val_mse: 0.0015 - val_NMSE: 0.0137 - val_NMSE_wt: 0.0129 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0106 - covmat_fro_loss: 7.4724e-04 - global_gradnorm: 9.0699 - tot_time: 0h 2m 43.8s\n",
      "\n",
      "Epoch 41: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0106 - covmat_fro_loss: 7.4543e-04 - global_gradnorm: 9.5329 - val_loss: 0.0124 - val_mse: 7.2672e-04 - val_NMSE: 0.0065 - val_NMSE_wt: 0.0062 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0231 - mse: 0.0020 - NMSE: 0.0181 - NMSE_wt: 0.0170 - covmat_fro_loss: 8.0511e-04 - global_gradnorm: 11.9101 - tot_time: 0h 2m 45.5s\n",
      "\n",
      "Epoch 42: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0231 - mse: 0.0020 - NMSE: 0.0181 - NMSE_wt: 0.0170 - covmat_fro_loss: 7.8992e-04 - global_gradnorm: 11.2172 - val_loss: 0.0170 - val_mse: 0.0013 - val_NMSE: 0.0115 - val_NMSE_wt: 0.0108 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0230 - mse: 0.0020 - NMSE: 0.0180 - NMSE_wt: 0.0169 - covmat_fro_loss: 7.8262e-04 - global_gradnorm: 11.3392 - tot_time: 0h 2m 47.2s\n",
      "\n",
      "Epoch 43: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.0230 - mse: 0.0020 - NMSE: 0.0180 - NMSE_wt: 0.0169 - covmat_fro_loss: 7.8130e-04 - global_gradnorm: 11.0747 - val_loss: 0.0182 - val_mse: 0.0014 - val_NMSE: 0.0127 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0226 - mse: 0.0019 - NMSE: 0.0175 - NMSE_wt: 0.0164 - covmat_fro_loss: 6.7545e-04 - global_gradnorm: 8.1901 - tot_time: 0h 2m 49.0s\n",
      "\n",
      "Epoch 44: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0226 - mse: 0.0019 - NMSE: 0.0175 - NMSE_wt: 0.0164 - covmat_fro_loss: 6.8476e-04 - global_gradnorm: 8.2914 - val_loss: 0.0129 - val_mse: 7.9360e-04 - val_NMSE: 0.0071 - val_NMSE_wt: 0.0068 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0174 - mse: 0.0013 - NMSE: 0.0119 - NMSE_wt: 0.0113 - covmat_fro_loss: 6.8437e-04 - global_gradnorm: 7.5584 - tot_time: 0h 2m 50.7s\n",
      "\n",
      "Epoch 45: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0174 - mse: 0.0013 - NMSE: 0.0119 - NMSE_wt: 0.0113 - covmat_fro_loss: 6.7643e-04 - global_gradnorm: 7.1569 - val_loss: 0.0150 - val_mse: 0.0010 - val_NMSE: 0.0094 - val_NMSE_wt: 0.0088 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0217 - mse: 0.0018 - NMSE: 0.0166 - NMSE_wt: 0.0156 - covmat_fro_loss: 7.3502e-04 - global_gradnorm: 10.4604 - tot_time: 0h 2m 52.5s\n",
      "\n",
      "Epoch 46: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0217 - mse: 0.0018 - NMSE: 0.0166 - NMSE_wt: 0.0156 - covmat_fro_loss: 7.4437e-04 - global_gradnorm: 11.6816 - val_loss: 0.0141 - val_mse: 9.3077e-04 - val_NMSE: 0.0084 - val_NMSE_wt: 0.0080 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0178 - mse: 0.0014 - NMSE: 0.0124 - NMSE_wt: 0.0116 - covmat_fro_loss: 7.1947e-04 - global_gradnorm: 10.7398 - tot_time: 0h 2m 54.3s\n",
      "\n",
      "Epoch 47: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0178 - mse: 0.0014 - NMSE: 0.0124 - NMSE_wt: 0.0116 - covmat_fro_loss: 7.2168e-04 - global_gradnorm: 10.2177 - val_loss: 0.0225 - val_mse: 0.0019 - val_NMSE: 0.0174 - val_NMSE_wt: 0.0164 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 7.4052e-04 - global_gradnorm: 9.6129 Restoring model weights from the end of the best epoch: 28.\n",
      " - tot_time: 0h 2m 56.1s\n",
      "\n",
      "Epoch 48: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 7.3158e-04 - global_gradnorm: 9.1706 - val_loss: 0.0144 - val_mse: 9.7086e-04 - val_NMSE: 0.0087 - val_NMSE_wt: 0.0083 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 48: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 7.5834e-04 - global_gradnorm: 11.3151 - tot_time: 0h 2m 58.0s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 7.6899e-04 - global_gradnorm: 12.4829 - val_loss: 0.0147 - val_mse: 0.0010 - val_NMSE: 0.0090 - val_NMSE_wt: 0.0086 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0257 - mse: 0.0023 - NMSE: 0.0209 - NMSE_wt: 0.0196 - covmat_fro_loss: 7.7770e-04 - global_gradnorm: 12.2183 - tot_time: 0h 2m 59.8s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.00541\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0257 - mse: 0.0023 - NMSE: 0.0209 - NMSE_wt: 0.0196 - covmat_fro_loss: 7.9175e-04 - global_gradnorm: 13.3296 - val_loss: 0.0124 - val_mse: 7.3632e-04 - val_NMSE: 0.0066 - val_NMSE_wt: 0.0063 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0165 - mse: 0.0012 - NMSE: 0.0109 - NMSE_wt: 0.0103 - covmat_fro_loss: 6.7699e-04 - global_gradnorm: 9.5987 - tot_time: 0h 3m 1.6s\n",
      "\n",
      "Epoch 3: val_NMSE_wt improved from 0.00541 to 0.00509, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 0.0165 - mse: 0.0012 - NMSE: 0.0109 - NMSE_wt: 0.0103 - covmat_fro_loss: 6.6987e-04 - global_gradnorm: 9.5534 - val_loss: 0.0112 - val_mse: 5.9169e-04 - val_NMSE: 0.0053 - val_NMSE_wt: 0.0051 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0177 - mse: 0.0014 - NMSE: 0.0122 - NMSE_wt: 0.0115 - covmat_fro_loss: 6.9287e-04 - global_gradnorm: 8.9978 - tot_time: 0h 3m 4.1s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.00509\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0177 - mse: 0.0014 - NMSE: 0.0122 - NMSE_wt: 0.0115 - covmat_fro_loss: 6.8879e-04 - global_gradnorm: 8.8912 - val_loss: 0.0127 - val_mse: 7.7128e-04 - val_NMSE: 0.0069 - val_NMSE_wt: 0.0066 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0173 - mse: 0.0013 - NMSE: 0.0119 - NMSE_wt: 0.0112 - covmat_fro_loss: 6.7976e-04 - global_gradnorm: 7.2063 - tot_time: 0h 3m 5.9s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.00509\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0173 - mse: 0.0013 - NMSE: 0.0119 - NMSE_wt: 0.0112 - covmat_fro_loss: 6.8591e-04 - global_gradnorm: 7.4391 - val_loss: 0.0157 - val_mse: 0.0011 - val_NMSE: 0.0100 - val_NMSE_wt: 0.0095 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0157 - mse: 0.0011 - NMSE: 0.0101 - NMSE_wt: 0.0096 - covmat_fro_loss: 6.4615e-04 - global_gradnorm: 6.9626 - tot_time: 0h 3m 7.7s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.00509\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.0157 - mse: 0.0011 - NMSE: 0.0101 - NMSE_wt: 0.0096 - covmat_fro_loss: 6.3715e-04 - global_gradnorm: 6.7075 - val_loss: 0.0125 - val_mse: 7.3734e-04 - val_NMSE: 0.0066 - val_NMSE_wt: 0.0063 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 7.0853e-04 - global_gradnorm: 8.4457 - tot_time: 0h 3m 9.4s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00509\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 7.0281e-04 - global_gradnorm: 7.9881 - val_loss: 0.0116 - val_mse: 6.4100e-04 - val_NMSE: 0.0058 - val_NMSE_wt: 0.0055 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0148 - mse: 0.0010 - NMSE: 0.0091 - NMSE_wt: 0.0087 - covmat_fro_loss: 6.5037e-04 - global_gradnorm: 7.9989   - tot_time: 0h 3m 11.3s\n",
      "\n",
      "Epoch 8: val_NMSE_wt improved from 0.00509 to 0.00499, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 0.0148 - mse: 0.0010 - NMSE: 0.0091 - NMSE_wt: 0.0087 - covmat_fro_loss: 6.4853e-04 - global_gradnorm: 7.8804 - val_loss: 0.0111 - val_mse: 5.7897e-04 - val_NMSE: 0.0052 - val_NMSE_wt: 0.0050 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0146 - mse: 9.9154e-04 - NMSE: 0.0089 - NMSE_wt: 0.0085 - covmat_fro_loss: 6.4288e-04 - global_gradnorm: 8.9871 - tot_time: 0h 3m 13.9s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.00499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.0146 - mse: 9.9154e-04 - NMSE: 0.0089 - NMSE_wt: 0.0085 - covmat_fro_loss: 6.4414e-04 - global_gradnorm: 9.1384 - val_loss: 0.0124 - val_mse: 7.2448e-04 - val_NMSE: 0.0065 - val_NMSE_wt: 0.0062 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0183 - mse: 0.0014 - NMSE: 0.0130 - NMSE_wt: 0.0122 - covmat_fro_loss: 6.9364e-04 - global_gradnorm: 10.2822 - tot_time: 0h 3m 15.7s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00499\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0183 - mse: 0.0014 - NMSE: 0.0130 - NMSE_wt: 0.0122 - covmat_fro_loss: 6.8275e-04 - global_gradnorm: 9.7158 - val_loss: 0.0142 - val_mse: 9.4662e-04 - val_NMSE: 0.0085 - val_NMSE_wt: 0.0081 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0105 - covmat_fro_loss: 6.8006e-04 - global_gradnorm: 9.9423  - tot_time: 0h 3m 17.3s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.00499\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0167 - mse: 0.0012 - NMSE: 0.0112 - NMSE_wt: 0.0105 - covmat_fro_loss: 6.7736e-04 - global_gradnorm: 9.3945 - val_loss: 0.0119 - val_mse: 6.7057e-04 - val_NMSE: 0.0060 - val_NMSE_wt: 0.0058 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0194 - mse: 0.0016 - NMSE: 0.0141 - NMSE_wt: 0.0133 - covmat_fro_loss: 6.8726e-04 - global_gradnorm: 10.2699 - tot_time: 0h 3m 19.0s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00499\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.0194 - mse: 0.0016 - NMSE: 0.0141 - NMSE_wt: 0.0133 - covmat_fro_loss: 6.7935e-04 - global_gradnorm: 9.6517 - val_loss: 0.0165 - val_mse: 0.0012 - val_NMSE: 0.0110 - val_NMSE_wt: 0.0104 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0138 - mse: 8.9257e-04 - NMSE: 0.0080 - NMSE_wt: 0.0076 - covmat_fro_loss: 6.5052e-04 - global_gradnorm: 5.8168 - tot_time: 0h 3m 20.7s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00499\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0138 - mse: 8.9257e-04 - NMSE: 0.0080 - NMSE_wt: 0.0076 - covmat_fro_loss: 6.4438e-04 - global_gradnorm: 5.5388 - val_loss: 0.0123 - val_mse: 7.2211e-04 - val_NMSE: 0.0065 - val_NMSE_wt: 0.0062 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0199 - mse: 0.0016 - NMSE: 0.0146 - NMSE_wt: 0.0138 - covmat_fro_loss: 7.0275e-04 - global_gradnorm: 7.9128 - tot_time: 0h 3m 22.4s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00499\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0199 - mse: 0.0016 - NMSE: 0.0146 - NMSE_wt: 0.0138 - covmat_fro_loss: 6.9785e-04 - global_gradnorm: 8.0460 - val_loss: 0.0129 - val_mse: 7.8599e-04 - val_NMSE: 0.0071 - val_NMSE_wt: 0.0067 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0259 - mse: 0.0024 - NMSE: 0.0212 - NMSE_wt: 0.0198 - covmat_fro_loss: 7.7305e-04 - global_gradnorm: 12.3180 - tot_time: 0h 3m 24.2s\n",
      "\n",
      "Epoch 15: val_NMSE_wt improved from 0.00499 to 0.00434, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-5_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 170ms/step - loss: 0.0259 - mse: 0.0024 - NMSE: 0.0212 - NMSE_wt: 0.0198 - covmat_fro_loss: 7.6320e-04 - global_gradnorm: 11.7521 - val_loss: 0.0105 - val_mse: 5.0407e-04 - val_NMSE: 0.0045 - val_NMSE_wt: 0.0043 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0173 - mse: 0.0013 - NMSE: 0.0118 - NMSE_wt: 0.0112 - covmat_fro_loss: 7.0268e-04 - global_gradnorm: 7.8459 - tot_time: 0h 3m 26.7s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0173 - mse: 0.0013 - NMSE: 0.0118 - NMSE_wt: 0.0112 - covmat_fro_loss: 6.9521e-04 - global_gradnorm: 7.4721 - val_loss: 0.0181 - val_mse: 0.0014 - val_NMSE: 0.0127 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.0234e-04 - global_gradnorm: 10.1355 - tot_time: 0h 3m 28.5s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0224 - mse: 0.0019 - NMSE: 0.0173 - NMSE_wt: 0.0163 - covmat_fro_loss: 7.2631e-04 - global_gradnorm: 11.3771 - val_loss: 0.0131 - val_mse: 8.1193e-04 - val_NMSE: 0.0073 - val_NMSE_wt: 0.0070 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0172 - mse: 0.0013 - NMSE: 0.0118 - NMSE_wt: 0.0111 - covmat_fro_loss: 6.5619e-04 - global_gradnorm: 8.0343 - tot_time: 0h 3m 30.3s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0172 - mse: 0.0013 - NMSE: 0.0118 - NMSE_wt: 0.0111 - covmat_fro_loss: 6.4620e-04 - global_gradnorm: 7.5701 - val_loss: 0.0443 - val_mse: 0.0045 - val_NMSE: 0.0409 - val_NMSE_wt: 0.0381 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0144 - mse: 9.7127e-04 - NMSE: 0.0087 - NMSE_wt: 0.0083 - covmat_fro_loss: 6.4807e-04 - global_gradnorm: 6.6710 - tot_time: 0h 3m 32.0s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0144 - mse: 9.7127e-04 - NMSE: 0.0087 - NMSE_wt: 0.0083 - covmat_fro_loss: 6.4363e-04 - global_gradnorm: 6.6793 - val_loss: 0.0156 - val_mse: 0.0011 - val_NMSE: 0.0100 - val_NMSE_wt: 0.0094 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0147 - mse: 0.0010 - NMSE: 0.0090 - NMSE_wt: 0.0085 - covmat_fro_loss: 6.5443e-04 - global_gradnorm: 7.6006 - tot_time: 0h 3m 33.8s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.0147 - mse: 0.0010 - NMSE: 0.0090 - NMSE_wt: 0.0085 - covmat_fro_loss: 6.6016e-04 - global_gradnorm: 7.5970 - val_loss: 0.0109 - val_mse: 5.4844e-04 - val_NMSE: 0.0049 - val_NMSE_wt: 0.0047 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0176 - mse: 0.0013 - NMSE: 0.0121 - NMSE_wt: 0.0114 - covmat_fro_loss: 7.0480e-04 - global_gradnorm: 11.1725 - tot_time: 0h 3m 35.6s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0176 - mse: 0.0013 - NMSE: 0.0121 - NMSE_wt: 0.0114 - covmat_fro_loss: 6.9338e-04 - global_gradnorm: 10.5112 - val_loss: 0.0134 - val_mse: 8.5027e-04 - val_NMSE: 0.0077 - val_NMSE_wt: 0.0073 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.2053e-04 - global_gradnorm: 10.8659 - tot_time: 0h 3m 37.3s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.1386e-04 - global_gradnorm: 10.2856 - val_loss: 0.0127 - val_mse: 7.6392e-04 - val_NMSE: 0.0069 - val_NMSE_wt: 0.0065 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0175 - mse: 0.0013 - NMSE: 0.0121 - NMSE_wt: 0.0114 - covmat_fro_loss: 6.6888e-04 - global_gradnorm: 8.0676 - tot_time: 0h 3m 39.1s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0175 - mse: 0.0013 - NMSE: 0.0121 - NMSE_wt: 0.0114 - covmat_fro_loss: 6.8437e-04 - global_gradnorm: 8.1889 - val_loss: 0.0155 - val_mse: 0.0011 - val_NMSE: 0.0099 - val_NMSE_wt: 0.0093 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0186 - mse: 0.0015 - NMSE: 0.0133 - NMSE_wt: 0.0125 - covmat_fro_loss: 6.7430e-04 - global_gradnorm: 8.7496 - tot_time: 0h 3m 40.8s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0186 - mse: 0.0015 - NMSE: 0.0133 - NMSE_wt: 0.0125 - covmat_fro_loss: 6.6936e-04 - global_gradnorm: 8.2520 - val_loss: 0.0124 - val_mse: 7.3579e-04 - val_NMSE: 0.0066 - val_NMSE_wt: 0.0063 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 7.3289e-04 - global_gradnorm: 9.2610 - tot_time: 0h 3m 42.6s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 7.2480e-04 - global_gradnorm: 8.9861 - val_loss: 0.0154 - val_mse: 0.0011 - val_NMSE: 0.0098 - val_NMSE_wt: 0.0092 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 7.0572e-04 - global_gradnorm: 10.2537 - tot_time: 0h 3m 44.4s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0216 - mse: 0.0018 - NMSE: 0.0165 - NMSE_wt: 0.0155 - covmat_fro_loss: 6.9882e-04 - global_gradnorm: 9.6512 - val_loss: 0.0210 - val_mse: 0.0018 - val_NMSE: 0.0158 - val_NMSE_wt: 0.0149 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.2084e-04 - global_gradnorm: 8.8626 - tot_time: 0h 3m 46.1s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0204 - mse: 0.0017 - NMSE: 0.0152 - NMSE_wt: 0.0143 - covmat_fro_loss: 7.1051e-04 - global_gradnorm: 8.3641 - val_loss: 0.0116 - val_mse: 6.4226e-04 - val_NMSE: 0.0058 - val_NMSE_wt: 0.0055 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0162 - mse: 0.0012 - NMSE: 0.0107 - NMSE_wt: 0.0101 - covmat_fro_loss: 6.7633e-04 - global_gradnorm: 7.7807 - tot_time: 0h 3m 47.9s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.0162 - mse: 0.0012 - NMSE: 0.0107 - NMSE_wt: 0.0101 - covmat_fro_loss: 6.7286e-04 - global_gradnorm: 7.5276 - val_loss: 0.0127 - val_mse: 7.7162e-04 - val_NMSE: 0.0069 - val_NMSE_wt: 0.0066 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0141 - mse: 9.3765e-04 - NMSE: 0.0084 - NMSE_wt: 0.0080 - covmat_fro_loss: 6.4061e-04 - global_gradnorm: 6.4177 - tot_time: 0h 3m 49.7s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.0141 - mse: 9.3765e-04 - NMSE: 0.0084 - NMSE_wt: 0.0080 - covmat_fro_loss: 6.3922e-04 - global_gradnorm: 6.4387 - val_loss: 0.0114 - val_mse: 6.1154e-04 - val_NMSE: 0.0055 - val_NMSE_wt: 0.0053 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 7.0162e-04 - global_gradnorm: 7.0285 - tot_time: 0h 3m 51.4s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0191 - mse: 0.0015 - NMSE: 0.0138 - NMSE_wt: 0.0130 - covmat_fro_loss: 6.8870e-04 - global_gradnorm: 6.8650 - val_loss: 0.0156 - val_mse: 0.0011 - val_NMSE: 0.0100 - val_NMSE_wt: 0.0095 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0156 - mse: 0.0011 - NMSE: 0.0101 - NMSE_wt: 0.0095 - covmat_fro_loss: 6.6174e-04 - global_gradnorm: 9.5965  - tot_time: 0h 3m 53.1s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0156 - mse: 0.0011 - NMSE: 0.0101 - NMSE_wt: 0.0095 - covmat_fro_loss: 6.5532e-04 - global_gradnorm: 9.0984 - val_loss: 0.0164 - val_mse: 0.0012 - val_NMSE: 0.0109 - val_NMSE_wt: 0.0103 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0166 - mse: 0.0012 - NMSE: 0.0111 - NMSE_wt: 0.0105 - covmat_fro_loss: 6.9240e-04 - global_gradnorm: 10.6969 - tot_time: 0h 3m 54.7s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0166 - mse: 0.0012 - NMSE: 0.0111 - NMSE_wt: 0.0105 - covmat_fro_loss: 6.8490e-04 - global_gradnorm: 10.1680 - val_loss: 0.0124 - val_mse: 7.2748e-04 - val_NMSE: 0.0065 - val_NMSE_wt: 0.0062 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0176 - mse: 0.0014 - NMSE: 0.0122 - NMSE_wt: 0.0115 - covmat_fro_loss: 7.0413e-04 - global_gradnorm: 11.6773 - tot_time: 0h 3m 56.5s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0176 - mse: 0.0014 - NMSE: 0.0122 - NMSE_wt: 0.0115 - covmat_fro_loss: 7.0053e-04 - global_gradnorm: 11.0435 - val_loss: 0.0206 - val_mse: 0.0017 - val_NMSE: 0.0153 - val_NMSE_wt: 0.0144 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0189 - mse: 0.0015 - NMSE: 0.0135 - NMSE_wt: 0.0127 - covmat_fro_loss: 7.2431e-04 - global_gradnorm: 10.1480 - tot_time: 0h 3m 58.3s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0189 - mse: 0.0015 - NMSE: 0.0135 - NMSE_wt: 0.0127 - covmat_fro_loss: 7.3019e-04 - global_gradnorm: 11.3888 - val_loss: 0.0154 - val_mse: 0.0011 - val_NMSE: 0.0098 - val_NMSE_wt: 0.0093 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0164 - mse: 0.0012 - NMSE: 0.0109 - NMSE_wt: 0.0103 - covmat_fro_loss: 6.7863e-04 - global_gradnorm: 6.5354Restoring model weights from the end of the best epoch: 15.\n",
      " - tot_time: 0h 4m 0.1s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.00434\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-5_outsteps\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.0164 - mse: 0.0012 - NMSE: 0.0109 - NMSE_wt: 0.0103 - covmat_fro_loss: 6.6653e-04 - global_gradnorm: 6.1652 - val_loss: 0.0110 - val_mse: 5.6669e-04 - val_NMSE: 0.0051 - val_NMSE_wt: 0.0049 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35: early stopping\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>> num_outsteps : 10 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "clipnorm : None, global_clipnorm : 30.0\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.0442 - mse: 0.0047 - NMSE: 0.0422 - NMSE_wt: 0.0381 - covmat_fro_loss: 0.0000e+00 - global_gradnorm: 0.0000e+00\n",
      "baseline : 3.8073E-02\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0366 - mse: 0.0038 - NMSE: 0.0343 - NMSE_wt: 0.0305 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.6057 - tot_time: 0h 1m 10.8s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.03807\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 71s 190ms/step - loss: 0.0366 - mse: 0.0038 - NMSE: 0.0343 - NMSE_wt: 0.0305 - covmat_fro_loss: 0.0011 - global_gradnorm: 15.8886 - val_loss: 0.0956 - val_mse: 0.0111 - val_NMSE: 0.0996 - val_NMSE_wt: 0.0895 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0317 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0256 - covmat_fro_loss: 9.9431e-04 - global_gradnorm: 5.0058 - tot_time: 0h 1m 12.8s\n",
      "\n",
      "Epoch 2: val_NMSE_wt improved from 0.03807 to 0.01652, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 0.0317 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0256 - covmat_fro_loss: 9.9502e-04 - global_gradnorm: 4.6518 - val_loss: 0.0226 - val_mse: 0.0021 - val_NMSE: 0.0185 - val_NMSE_wt: 0.0165 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0300 - mse: 0.0030 - NMSE: 0.0269 - NMSE_wt: 0.0239 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.9496 - tot_time: 0h 1m 15.1s\n",
      "\n",
      "Epoch 3: val_NMSE_wt improved from 0.01652 to 0.01264, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0300 - mse: 0.0030 - NMSE: 0.0269 - NMSE_wt: 0.0239 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.1781 - val_loss: 0.0188 - val_mse: 0.0016 - val_NMSE: 0.0144 - val_NMSE_wt: 0.0126 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0328 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0267 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.6695 - tot_time: 0h 1m 17.9s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.01264\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 186ms/step - loss: 0.0328 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0267 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.9498 - val_loss: 0.0394 - val_mse: 0.0043 - val_NMSE: 0.0390 - val_NMSE_wt: 0.0333 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0378 - mse: 0.0040 - NMSE: 0.0359 - NMSE_wt: 0.0317 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.7579 - tot_time: 0h 1m 19.8s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.01264\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0378 - mse: 0.0040 - NMSE: 0.0359 - NMSE_wt: 0.0317 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.5474 - val_loss: 0.0203 - val_mse: 0.0018 - val_NMSE: 0.0161 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0458 - mse: 0.0051 - NMSE: 0.0455 - NMSE_wt: 0.0397 - covmat_fro_loss: 0.0013 - global_gradnorm: 13.0066 - tot_time: 0h 1m 21.8s\n",
      "\n",
      "Epoch 6: val_NMSE_wt improved from 0.01264 to 0.00807, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.0458 - mse: 0.0051 - NMSE: 0.0455 - NMSE_wt: 0.0397 - covmat_fro_loss: 0.0013 - global_gradnorm: 12.2633 - val_loss: 0.0142 - val_mse: 0.0010 - val_NMSE: 0.0090 - val_NMSE_wt: 0.0081 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0590 - mse: 0.0067 - NMSE: 0.0602 - NMSE_wt: 0.0529 - covmat_fro_loss: 0.0014 - global_gradnorm: 20.0821 - tot_time: 0h 1m 24.5s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00807\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0590 - mse: 0.0067 - NMSE: 0.0602 - NMSE_wt: 0.0529 - covmat_fro_loss: 0.0014 - global_gradnorm: 20.9086 - val_loss: 0.0218 - val_mse: 0.0019 - val_NMSE: 0.0175 - val_NMSE_wt: 0.0157 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0442 - mse: 0.0048 - NMSE: 0.0428 - NMSE_wt: 0.0381 - covmat_fro_loss: 0.0012 - global_gradnorm: 17.3549 - tot_time: 0h 1m 26.4s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.00807\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0442 - mse: 0.0048 - NMSE: 0.0428 - NMSE_wt: 0.0381 - covmat_fro_loss: 0.0012 - global_gradnorm: 18.4086 - val_loss: 0.0586 - val_mse: 0.0069 - val_NMSE: 0.0621 - val_NMSE_wt: 0.0525 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0327 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0266 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2164 - tot_time: 0h 1m 28.4s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.00807\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0327 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0266 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.6884 - val_loss: 0.0245 - val_mse: 0.0023 - val_NMSE: 0.0208 - val_NMSE_wt: 0.0184 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0480 - mse: 0.0053 - NMSE: 0.0476 - NMSE_wt: 0.0419 - covmat_fro_loss: 0.0014 - global_gradnorm: 15.5218 - tot_time: 0h 1m 30.2s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00807\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 0.0480 - mse: 0.0053 - NMSE: 0.0476 - NMSE_wt: 0.0419 - covmat_fro_loss: 0.0014 - global_gradnorm: 15.0949 - val_loss: 0.0344 - val_mse: 0.0035 - val_NMSE: 0.0317 - val_NMSE_wt: 0.0282 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0434 - mse: 0.0047 - NMSE: 0.0421 - NMSE_wt: 0.0373 - covmat_fro_loss: 0.0013 - global_gradnorm: 16.0427 - tot_time: 0h 1m 32.1s\n",
      "\n",
      "Epoch 11: val_NMSE_wt improved from 0.00807 to 0.00766, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.0434 - mse: 0.0047 - NMSE: 0.0421 - NMSE_wt: 0.0373 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.1889 - val_loss: 0.0138 - val_mse: 9.6515e-04 - val_NMSE: 0.0087 - val_NMSE_wt: 0.0077 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0549 - mse: 0.0061 - NMSE: 0.0552 - NMSE_wt: 0.0488 - covmat_fro_loss: 0.0014 - global_gradnorm: 10.7297 - tot_time: 0h 1m 34.6s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 0.0549 - mse: 0.0061 - NMSE: 0.0552 - NMSE_wt: 0.0488 - covmat_fro_loss: 0.0014 - global_gradnorm: 10.7722 - val_loss: 0.0883 - val_mse: 0.0102 - val_NMSE: 0.0914 - val_NMSE_wt: 0.0821 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0326 - mse: 0.0033 - NMSE: 0.0299 - NMSE_wt: 0.0264 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.7453 - tot_time: 0h 1m 36.6s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0326 - mse: 0.0033 - NMSE: 0.0299 - NMSE_wt: 0.0264 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.5354 - val_loss: 0.0201 - val_mse: 0.0018 - val_NMSE: 0.0158 - val_NMSE_wt: 0.0140 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0361 - mse: 0.0038 - NMSE: 0.0339 - NMSE_wt: 0.0300 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.9718  - tot_time: 0h 1m 38.5s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0361 - mse: 0.0038 - NMSE: 0.0339 - NMSE_wt: 0.0300 - covmat_fro_loss: 0.0013 - global_gradnorm: 9.2213 - val_loss: 0.0280 - val_mse: 0.0027 - val_NMSE: 0.0247 - val_NMSE_wt: 0.0219 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0269 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0208 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.6767 - tot_time: 0h 1m 40.4s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0269 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0208 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.5079 - val_loss: 0.0167 - val_mse: 0.0014 - val_NMSE: 0.0122 - val_NMSE_wt: 0.0106 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0584 - mse: 0.0066 - NMSE: 0.0598 - NMSE_wt: 0.0523 - covmat_fro_loss: 0.0014 - global_gradnorm: 19.4788 - tot_time: 0h 1m 42.4s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0584 - mse: 0.0066 - NMSE: 0.0598 - NMSE_wt: 0.0523 - covmat_fro_loss: 0.0015 - global_gradnorm: 20.3555 - val_loss: 0.0291 - val_mse: 0.0029 - val_NMSE: 0.0261 - val_NMSE_wt: 0.0230 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0482 - mse: 0.0053 - NMSE: 0.0475 - NMSE_wt: 0.0420 - covmat_fro_loss: 0.0012 - global_gradnorm: 17.6400 - tot_time: 0h 1m 44.3s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0482 - mse: 0.0053 - NMSE: 0.0475 - NMSE_wt: 0.0420 - covmat_fro_loss: 0.0012 - global_gradnorm: 17.2188 - val_loss: 0.0202 - val_mse: 0.0018 - val_NMSE: 0.0161 - val_NMSE_wt: 0.0141 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0354 - mse: 0.0037 - NMSE: 0.0332 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.7202 - tot_time: 0h 1m 46.2s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0354 - mse: 0.0037 - NMSE: 0.0332 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0013 - global_gradnorm: 9.5574 - val_loss: 0.0178 - val_mse: 0.0015 - val_NMSE: 0.0132 - val_NMSE_wt: 0.0117 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0286 - mse: 0.0028 - NMSE: 0.0256 - NMSE_wt: 0.0224 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.6274 - tot_time: 0h 1m 48.2s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0286 - mse: 0.0028 - NMSE: 0.0256 - NMSE_wt: 0.0224 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.6104 - val_loss: 0.0257 - val_mse: 0.0024 - val_NMSE: 0.0219 - val_NMSE_wt: 0.0196 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0355 - mse: 0.0037 - NMSE: 0.0331 - NMSE_wt: 0.0294 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.7209 - tot_time: 0h 1m 50.1s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0355 - mse: 0.0037 - NMSE: 0.0331 - NMSE_wt: 0.0294 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.8339 - val_loss: 0.0170 - val_mse: 0.0014 - val_NMSE: 0.0124 - val_NMSE_wt: 0.0109 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0320 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0259 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.7740 - tot_time: 0h 1m 52.0s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0320 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0259 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.8955 - val_loss: 0.0485 - val_mse: 0.0052 - val_NMSE: 0.0472 - val_NMSE_wt: 0.0423 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0286 - mse: 0.0029 - NMSE: 0.0258 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.5277 - tot_time: 0h 1m 54.0s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0286 - mse: 0.0029 - NMSE: 0.0258 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.3358 - val_loss: 0.0204 - val_mse: 0.0018 - val_NMSE: 0.0163 - val_NMSE_wt: 0.0143 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0390 - mse: 0.0042 - NMSE: 0.0375 - NMSE_wt: 0.0329 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.3092 - tot_time: 0h 1m 55.9s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0390 - mse: 0.0042 - NMSE: 0.0375 - NMSE_wt: 0.0329 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.5995 - val_loss: 0.0947 - val_mse: 0.0115 - val_NMSE: 0.1032 - val_NMSE_wt: 0.0885 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0404 - mse: 0.0043 - NMSE: 0.0387 - NMSE_wt: 0.0342 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.7191 - tot_time: 0h 1m 57.9s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0404 - mse: 0.0043 - NMSE: 0.0387 - NMSE_wt: 0.0342 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.7339 - val_loss: 0.0268 - val_mse: 0.0026 - val_NMSE: 0.0231 - val_NMSE_wt: 0.0206 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0419 - mse: 0.0045 - NMSE: 0.0405 - NMSE_wt: 0.0358 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.3391 - tot_time: 0h 1m 59.8s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0419 - mse: 0.0045 - NMSE: 0.0405 - NMSE_wt: 0.0358 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.8001 - val_loss: 0.0182 - val_mse: 0.0015 - val_NMSE: 0.0137 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0349 - mse: 0.0036 - NMSE: 0.0326 - NMSE_wt: 0.0288 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.5890 - tot_time: 0h 2m 1.7s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0349 - mse: 0.0036 - NMSE: 0.0326 - NMSE_wt: 0.0288 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.8660 - val_loss: 0.0334 - val_mse: 0.0034 - val_NMSE: 0.0303 - val_NMSE_wt: 0.0273 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0342 - mse: 0.0035 - NMSE: 0.0317 - NMSE_wt: 0.0281 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.4266 - tot_time: 0h 2m 3.5s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.0342 - mse: 0.0035 - NMSE: 0.0317 - NMSE_wt: 0.0281 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.0577 - val_loss: 0.0167 - val_mse: 0.0013 - val_NMSE: 0.0120 - val_NMSE_wt: 0.0106 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0289 - mse: 0.0029 - NMSE: 0.0257 - NMSE_wt: 0.0228 - covmat_fro_loss: 0.0011 - global_gradnorm: 15.4199 - tot_time: 0h 2m 5.3s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 0.0289 - mse: 0.0029 - NMSE: 0.0257 - NMSE_wt: 0.0228 - covmat_fro_loss: 0.0011 - global_gradnorm: 16.6349 - val_loss: 0.0179 - val_mse: 0.0015 - val_NMSE: 0.0134 - val_NMSE_wt: 0.0117 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0162 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.8232 - tot_time: 0h 2m 7.1s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.0224 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0162 - covmat_fro_loss: 0.0010 - global_gradnorm: 8.6054 - val_loss: 0.0312 - val_mse: 0.0031 - val_NMSE: 0.0280 - val_NMSE_wt: 0.0251 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0467 - mse: 0.0051 - NMSE: 0.0459 - NMSE_wt: 0.0406 - covmat_fro_loss: 0.0012 - global_gradnorm: 18.4805 - tot_time: 0h 2m 9.1s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0467 - mse: 0.0051 - NMSE: 0.0459 - NMSE_wt: 0.0406 - covmat_fro_loss: 0.0012 - global_gradnorm: 19.4405 - val_loss: 0.0691 - val_mse: 0.0078 - val_NMSE: 0.0700 - val_NMSE_wt: 0.0630 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0312 - mse: 0.0031 - NMSE: 0.0282 - NMSE_wt: 0.0250 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.1362Restoring model weights from the end of the best epoch: 11.\n",
      " - tot_time: 0h 2m 11.1s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 0.0312 - mse: 0.0031 - NMSE: 0.0282 - NMSE_wt: 0.0250 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.2367 - val_loss: 0.0256 - val_mse: 0.0025 - val_NMSE: 0.0222 - val_NMSE_wt: 0.0195 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 5e-06 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0405 - mse: 0.0043 - NMSE: 0.0387 - NMSE_wt: 0.0343 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.2720 - tot_time: 0h 2m 13.2s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 189ms/step - loss: 0.0405 - mse: 0.0043 - NMSE: 0.0387 - NMSE_wt: 0.0343 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.3458 - val_loss: 0.0203 - val_mse: 0.0018 - val_NMSE: 0.0163 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0368 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0307 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.8347 - tot_time: 0h 2m 15.1s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0368 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0307 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.0659 - val_loss: 0.0770 - val_mse: 0.0092 - val_NMSE: 0.0829 - val_NMSE_wt: 0.0709 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0319 - mse: 0.0033 - NMSE: 0.0293 - NMSE_wt: 0.0257 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.2503 - tot_time: 0h 2m 17.1s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0319 - mse: 0.0033 - NMSE: 0.0293 - NMSE_wt: 0.0257 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.1207 - val_loss: 0.0250 - val_mse: 0.0024 - val_NMSE: 0.0219 - val_NMSE_wt: 0.0188 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0534 - mse: 0.0060 - NMSE: 0.0540 - NMSE_wt: 0.0472 - covmat_fro_loss: 0.0014 - global_gradnorm: 16.7446 - tot_time: 0h 2m 19.0s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0534 - mse: 0.0060 - NMSE: 0.0540 - NMSE_wt: 0.0472 - covmat_fro_loss: 0.0013 - global_gradnorm: 15.9704 - val_loss: 0.0303 - val_mse: 0.0030 - val_NMSE: 0.0271 - val_NMSE_wt: 0.0242 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0344 - mse: 0.0036 - NMSE: 0.0321 - NMSE_wt: 0.0282 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.1231 - tot_time: 0h 2m 21.0s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 0.0344 - mse: 0.0036 - NMSE: 0.0321 - NMSE_wt: 0.0282 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.5786 - val_loss: 0.0177 - val_mse: 0.0015 - val_NMSE: 0.0133 - val_NMSE_wt: 0.0116 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0399 - mse: 0.0043 - NMSE: 0.0385 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0013 - global_gradnorm: 13.3470 - tot_time: 0h 2m 23.0s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.0399 - mse: 0.0043 - NMSE: 0.0385 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0013 - global_gradnorm: 12.4407 - val_loss: 0.0162 - val_mse: 0.0013 - val_NMSE: 0.0114 - val_NMSE_wt: 0.0101 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0413 - mse: 0.0044 - NMSE: 0.0397 - NMSE_wt: 0.0352 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.5250 - tot_time: 0h 2m 25.0s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 0.0413 - mse: 0.0044 - NMSE: 0.0397 - NMSE_wt: 0.0352 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.6048 - val_loss: 0.0838 - val_mse: 0.0101 - val_NMSE: 0.0907 - val_NMSE_wt: 0.0777 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0540 - mse: 0.0061 - NMSE: 0.0545 - NMSE_wt: 0.0478 - covmat_fro_loss: 0.0014 - global_gradnorm: 15.9469 - tot_time: 0h 2m 26.9s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0540 - mse: 0.0061 - NMSE: 0.0545 - NMSE_wt: 0.0478 - covmat_fro_loss: 0.0014 - global_gradnorm: 15.3663 - val_loss: 0.0207 - val_mse: 0.0018 - val_NMSE: 0.0166 - val_NMSE_wt: 0.0146 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0334 - mse: 0.0034 - NMSE: 0.0309 - NMSE_wt: 0.0273 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.7399 - tot_time: 0h 2m 28.9s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0334 - mse: 0.0034 - NMSE: 0.0309 - NMSE_wt: 0.0273 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.7708 - val_loss: 0.0296 - val_mse: 0.0030 - val_NMSE: 0.0271 - val_NMSE_wt: 0.0235 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0392 - mse: 0.0042 - NMSE: 0.0375 - NMSE_wt: 0.0331 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.9839 - tot_time: 0h 2m 30.8s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00766\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0392 - mse: 0.0042 - NMSE: 0.0375 - NMSE_wt: 0.0331 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.3152 - val_loss: 0.0168 - val_mse: 0.0014 - val_NMSE: 0.0122 - val_NMSE_wt: 0.0106 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0397 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0335 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.7282 - tot_time: 0h 2m 32.8s\n",
      "\n",
      "Epoch 11: val_NMSE_wt improved from 0.00766 to 0.00729, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0397 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0335 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.1860 - val_loss: 0.0134 - val_mse: 9.1467e-04 - val_NMSE: 0.0082 - val_NMSE_wt: 0.0073 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0574 - mse: 0.0065 - NMSE: 0.0586 - NMSE_wt: 0.0513 - covmat_fro_loss: 0.0014 - global_gradnorm: 12.6425 - tot_time: 0h 2m 35.5s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0574 - mse: 0.0065 - NMSE: 0.0586 - NMSE_wt: 0.0513 - covmat_fro_loss: 0.0014 - global_gradnorm: 12.6296 - val_loss: 0.0307 - val_mse: 0.0030 - val_NMSE: 0.0273 - val_NMSE_wt: 0.0246 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0421 - mse: 0.0046 - NMSE: 0.0410 - NMSE_wt: 0.0360 - covmat_fro_loss: 0.0013 - global_gradnorm: 15.0256 - tot_time: 0h 2m 37.2s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.0421 - mse: 0.0046 - NMSE: 0.0410 - NMSE_wt: 0.0360 - covmat_fro_loss: 0.0013 - global_gradnorm: 13.9795 - val_loss: 0.0182 - val_mse: 0.0015 - val_NMSE: 0.0134 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0308 - mse: 0.0031 - NMSE: 0.0280 - NMSE_wt: 0.0247 - covmat_fro_loss: 0.0012 - global_gradnorm: 7.0489 - tot_time: 0h 2m 38.9s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 0.0308 - mse: 0.0031 - NMSE: 0.0280 - NMSE_wt: 0.0247 - covmat_fro_loss: 0.0012 - global_gradnorm: 6.9478 - val_loss: 0.0245 - val_mse: 0.0023 - val_NMSE: 0.0209 - val_NMSE_wt: 0.0184 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0270 - mse: 0.0026 - NMSE: 0.0238 - NMSE_wt: 0.0208 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.6811 - tot_time: 0h 2m 40.9s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0270 - mse: 0.0026 - NMSE: 0.0238 - NMSE_wt: 0.0208 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.4574 - val_loss: 0.0172 - val_mse: 0.0014 - val_NMSE: 0.0126 - val_NMSE_wt: 0.0111 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0452 - mse: 0.0049 - NMSE: 0.0440 - NMSE_wt: 0.0391 - covmat_fro_loss: 0.0012 - global_gradnorm: 16.4295 - tot_time: 0h 2m 42.8s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0452 - mse: 0.0049 - NMSE: 0.0440 - NMSE_wt: 0.0391 - covmat_fro_loss: 0.0012 - global_gradnorm: 16.8015 - val_loss: 0.0282 - val_mse: 0.0027 - val_NMSE: 0.0246 - val_NMSE_wt: 0.0221 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0476 - mse: 0.0052 - NMSE: 0.0470 - NMSE_wt: 0.0414 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.4317 - tot_time: 0h 2m 44.8s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0476 - mse: 0.0052 - NMSE: 0.0470 - NMSE_wt: 0.0414 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.3754 - val_loss: 0.0429 - val_mse: 0.0045 - val_NMSE: 0.0408 - val_NMSE_wt: 0.0368 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0263 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.1572 - tot_time: 0h 2m 46.7s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 179ms/step - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0263 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.8941 - val_loss: 0.0153 - val_mse: 0.0011 - val_NMSE: 0.0103 - val_NMSE_wt: 0.0091 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0227 - mse: 0.0021 - NMSE: 0.0188 - NMSE_wt: 0.0166 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.0563 - tot_time: 0h 2m 48.7s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0227 - mse: 0.0021 - NMSE: 0.0188 - NMSE_wt: 0.0166 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.2988 - val_loss: 0.0281 - val_mse: 0.0027 - val_NMSE: 0.0245 - val_NMSE_wt: 0.0220 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0316 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0254 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.7182 - tot_time: 0h 2m 50.6s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0316 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0254 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.0031 - val_loss: 0.0180 - val_mse: 0.0015 - val_NMSE: 0.0133 - val_NMSE_wt: 0.0119 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0396 - mse: 0.0043 - NMSE: 0.0385 - NMSE_wt: 0.0334 - covmat_fro_loss: 0.0013 - global_gradnorm: 8.2215 - tot_time: 0h 2m 52.6s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0396 - mse: 0.0043 - NMSE: 0.0385 - NMSE_wt: 0.0334 - covmat_fro_loss: 0.0013 - global_gradnorm: 7.9772 - val_loss: 0.0328 - val_mse: 0.0033 - val_NMSE: 0.0300 - val_NMSE_wt: 0.0267 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0265 - mse: 0.0026 - NMSE: 0.0232 - NMSE_wt: 0.0204 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.2809 - tot_time: 0h 2m 54.5s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0265 - mse: 0.0026 - NMSE: 0.0232 - NMSE_wt: 0.0204 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.2901 - val_loss: 0.0327 - val_mse: 0.0033 - val_NMSE: 0.0297 - val_NMSE_wt: 0.0266 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0371 - mse: 0.0039 - NMSE: 0.0354 - NMSE_wt: 0.0310 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.9794 - tot_time: 0h 2m 56.5s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0371 - mse: 0.0039 - NMSE: 0.0354 - NMSE_wt: 0.0310 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.9639 - val_loss: 0.0228 - val_mse: 0.0021 - val_NMSE: 0.0187 - val_NMSE_wt: 0.0167 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0349 - mse: 0.0036 - NMSE: 0.0325 - NMSE_wt: 0.0287 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.3434 - tot_time: 0h 2m 58.4s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0349 - mse: 0.0036 - NMSE: 0.0325 - NMSE_wt: 0.0287 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.3908 - val_loss: 0.0196 - val_mse: 0.0017 - val_NMSE: 0.0152 - val_NMSE_wt: 0.0135 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0353 - mse: 0.0037 - NMSE: 0.0330 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.3700 - tot_time: 0h 3m 0.3s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0353 - mse: 0.0037 - NMSE: 0.0330 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.4252 - val_loss: 0.0165 - val_mse: 0.0013 - val_NMSE: 0.0118 - val_NMSE_wt: 0.0104 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0297 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2200 - tot_time: 0h 3m 2.3s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0297 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.7610 - val_loss: 0.0158 - val_mse: 0.0012 - val_NMSE: 0.0109 - val_NMSE_wt: 0.0097 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.2430 - tot_time: 0h 3m 4.2s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.9727 - val_loss: 0.0167 - val_mse: 0.0013 - val_NMSE: 0.0120 - val_NMSE_wt: 0.0106 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0325 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0264 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.1821 - tot_time: 0h 3m 6.2s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0325 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0264 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.5002 - val_loss: 0.0155 - val_mse: 0.0012 - val_NMSE: 0.0107 - val_NMSE_wt: 0.0094 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0357 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0295 - covmat_fro_loss: 0.0013 - global_gradnorm: 12.2731 - tot_time: 0h 3m 8.1s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0357 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0295 - covmat_fro_loss: 0.0013 - global_gradnorm: 12.2564 - val_loss: 0.0193 - val_mse: 0.0017 - val_NMSE: 0.0151 - val_NMSE_wt: 0.0131 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0370 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.2369 - tot_time: 0h 3m 9.9s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0370 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.4416 - val_loss: 0.0877 - val_mse: 0.0105 - val_NMSE: 0.0945 - val_NMSE_wt: 0.0816 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0296 - mse: 0.0030 - NMSE: 0.0266 - NMSE_wt: 0.0235 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.8536Restoring model weights from the end of the best epoch: 11.\n",
      " - tot_time: 0h 3m 11.7s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 0.0296 - mse: 0.0030 - NMSE: 0.0266 - NMSE_wt: 0.0235 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.0877 - val_loss: 0.0212 - val_mse: 0.0019 - val_NMSE: 0.0171 - val_NMSE_wt: 0.0151 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-06 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0377 - mse: 0.0040 - NMSE: 0.0357 - NMSE_wt: 0.0316 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.5931 - tot_time: 0h 3m 13.8s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 0.0377 - mse: 0.0040 - NMSE: 0.0357 - NMSE_wt: 0.0316 - covmat_fro_loss: 0.0012 - global_gradnorm: 16.7937 - val_loss: 0.0200 - val_mse: 0.0018 - val_NMSE: 0.0158 - val_NMSE_wt: 0.0139 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0310 - mse: 0.0031 - NMSE: 0.0281 - NMSE_wt: 0.0248 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.6540 - tot_time: 0h 3m 15.7s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0310 - mse: 0.0031 - NMSE: 0.0281 - NMSE_wt: 0.0248 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.9341 - val_loss: 0.0200 - val_mse: 0.0017 - val_NMSE: 0.0156 - val_NMSE_wt: 0.0139 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0317 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0256 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.2800 - tot_time: 0h 3m 17.7s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.0317 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0256 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.8807 - val_loss: 0.0165 - val_mse: 0.0013 - val_NMSE: 0.0118 - val_NMSE_wt: 0.0104 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0441 - mse: 0.0048 - NMSE: 0.0434 - NMSE_wt: 0.0379 - covmat_fro_loss: 0.0012 - global_gradnorm: 16.1580 - tot_time: 0h 3m 19.7s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0441 - mse: 0.0048 - NMSE: 0.0434 - NMSE_wt: 0.0379 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.2712 - val_loss: 0.0262 - val_mse: 0.0025 - val_NMSE: 0.0225 - val_NMSE_wt: 0.0200 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0340 - mse: 0.0035 - NMSE: 0.0316 - NMSE_wt: 0.0278 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.9294 - tot_time: 0h 3m 21.6s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0340 - mse: 0.0035 - NMSE: 0.0316 - NMSE_wt: 0.0278 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.5781 - val_loss: 0.0212 - val_mse: 0.0019 - val_NMSE: 0.0172 - val_NMSE_wt: 0.0150 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0386 - mse: 0.0041 - NMSE: 0.0370 - NMSE_wt: 0.0325 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.7222 - tot_time: 0h 3m 23.5s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0386 - mse: 0.0041 - NMSE: 0.0370 - NMSE_wt: 0.0325 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.7703 - val_loss: 0.0187 - val_mse: 0.0016 - val_NMSE: 0.0143 - val_NMSE_wt: 0.0126 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0444 - mse: 0.0048 - NMSE: 0.0431 - NMSE_wt: 0.0382 - covmat_fro_loss: 0.0012 - global_gradnorm: 16.3499 - tot_time: 0h 3m 25.5s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0444 - mse: 0.0048 - NMSE: 0.0431 - NMSE_wt: 0.0382 - covmat_fro_loss: 0.0012 - global_gradnorm: 17.1913 - val_loss: 0.0232 - val_mse: 0.0021 - val_NMSE: 0.0192 - val_NMSE_wt: 0.0170 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0542 - mse: 0.0061 - NMSE: 0.0550 - NMSE_wt: 0.0480 - covmat_fro_loss: 0.0015 - global_gradnorm: 17.3803 - tot_time: 0h 3m 27.4s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0542 - mse: 0.0061 - NMSE: 0.0550 - NMSE_wt: 0.0480 - covmat_fro_loss: 0.0015 - global_gradnorm: 18.2983 - val_loss: 0.0736 - val_mse: 0.0088 - val_NMSE: 0.0789 - val_NMSE_wt: 0.0675 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0357 - mse: 0.0037 - NMSE: 0.0334 - NMSE_wt: 0.0296 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.7411 - tot_time: 0h 3m 29.3s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0357 - mse: 0.0037 - NMSE: 0.0334 - NMSE_wt: 0.0296 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.1999 - val_loss: 0.0258 - val_mse: 0.0025 - val_NMSE: 0.0226 - val_NMSE_wt: 0.0197 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0410 - mse: 0.0044 - NMSE: 0.0398 - NMSE_wt: 0.0349 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.5002 - tot_time: 0h 3m 31.3s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.0410 - mse: 0.0044 - NMSE: 0.0398 - NMSE_wt: 0.0349 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.8622 - val_loss: 0.0165 - val_mse: 0.0013 - val_NMSE: 0.0118 - val_NMSE_wt: 0.0103 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0387 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.6866 - tot_time: 0h 3m 33.3s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 0.0387 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.9789 - val_loss: 0.0146 - val_mse: 0.0011 - val_NMSE: 0.0096 - val_NMSE_wt: 0.0084 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0404 - mse: 0.0043 - NMSE: 0.0384 - NMSE_wt: 0.0343 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.2989 - tot_time: 0h 3m 35.3s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0404 - mse: 0.0043 - NMSE: 0.0384 - NMSE_wt: 0.0343 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.9442 - val_loss: 0.0158 - val_mse: 0.0012 - val_NMSE: 0.0110 - val_NMSE_wt: 0.0097 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0272 - mse: 0.0027 - NMSE: 0.0240 - NMSE_wt: 0.0211 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.7441 - tot_time: 0h 3m 37.2s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0272 - mse: 0.0027 - NMSE: 0.0240 - NMSE_wt: 0.0211 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.1681 - val_loss: 0.0150 - val_mse: 0.0011 - val_NMSE: 0.0101 - val_NMSE_wt: 0.0089 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0323 - mse: 0.0033 - NMSE: 0.0297 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0012 - global_gradnorm: 6.0102 - tot_time: 0h 3m 39.2s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0323 - mse: 0.0033 - NMSE: 0.0297 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0012 - global_gradnorm: 6.1702 - val_loss: 0.0228 - val_mse: 0.0021 - val_NMSE: 0.0189 - val_NMSE_wt: 0.0167 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0326 - mse: 0.0034 - NMSE: 0.0303 - NMSE_wt: 0.0265 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.9607 - tot_time: 0h 3m 41.1s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0326 - mse: 0.0034 - NMSE: 0.0303 - NMSE_wt: 0.0265 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.4854 - val_loss: 0.0157 - val_mse: 0.0012 - val_NMSE: 0.0109 - val_NMSE_wt: 0.0096 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0491 - mse: 0.0054 - NMSE: 0.0487 - NMSE_wt: 0.0430 - covmat_fro_loss: 0.0013 - global_gradnorm: 16.4010 - tot_time: 0h 3m 42.8s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.0491 - mse: 0.0054 - NMSE: 0.0487 - NMSE_wt: 0.0430 - covmat_fro_loss: 0.0014 - global_gradnorm: 17.5343 - val_loss: 0.0985 - val_mse: 0.0120 - val_NMSE: 0.1080 - val_NMSE_wt: 0.0924 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0443 - mse: 0.0048 - NMSE: 0.0433 - NMSE_wt: 0.0382 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.2824 - tot_time: 0h 3m 44.6s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 0.0443 - mse: 0.0048 - NMSE: 0.0433 - NMSE_wt: 0.0382 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.2876 - val_loss: 0.0151 - val_mse: 0.0011 - val_NMSE: 0.0101 - val_NMSE_wt: 0.0090 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0337 - mse: 0.0035 - NMSE: 0.0313 - NMSE_wt: 0.0275 - covmat_fro_loss: 0.0012 - global_gradnorm: 7.9750 - tot_time: 0h 3m 46.5s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0337 - mse: 0.0035 - NMSE: 0.0313 - NMSE_wt: 0.0275 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.4328 - val_loss: 0.0168 - val_mse: 0.0013 - val_NMSE: 0.0121 - val_NMSE_wt: 0.0107 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0220 - mse: 0.0020 - NMSE: 0.0179 - NMSE_wt: 0.0158 - covmat_fro_loss: 0.0011 - global_gradnorm: 6.7733 - tot_time: 0h 3m 48.5s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0220 - mse: 0.0020 - NMSE: 0.0179 - NMSE_wt: 0.0158 - covmat_fro_loss: 0.0011 - global_gradnorm: 6.9484 - val_loss: 0.0250 - val_mse: 0.0023 - val_NMSE: 0.0210 - val_NMSE_wt: 0.0189 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0344 - mse: 0.0036 - NMSE: 0.0320 - NMSE_wt: 0.0283 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.3572  - tot_time: 0h 3m 50.4s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0344 - mse: 0.0036 - NMSE: 0.0320 - NMSE_wt: 0.0283 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.7302 - val_loss: 0.0161 - val_mse: 0.0012 - val_NMSE: 0.0112 - val_NMSE_wt: 0.0099 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0286 - mse: 0.0028 - NMSE: 0.0254 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0011 - global_gradnorm: 6.2477 - tot_time: 0h 3m 52.4s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0286 - mse: 0.0028 - NMSE: 0.0254 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0011 - global_gradnorm: 6.2033 - val_loss: 0.0215 - val_mse: 0.0019 - val_NMSE: 0.0175 - val_NMSE_wt: 0.0154 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0279 - mse: 0.0028 - NMSE: 0.0248 - NMSE_wt: 0.0217 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.5388 - tot_time: 0h 3m 54.3s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0279 - mse: 0.0028 - NMSE: 0.0248 - NMSE_wt: 0.0217 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.3961 - val_loss: 0.0239 - val_mse: 0.0022 - val_NMSE: 0.0200 - val_NMSE_wt: 0.0178 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0407 - mse: 0.0044 - NMSE: 0.0396 - NMSE_wt: 0.0346 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.9442 - tot_time: 0h 3m 56.2s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0407 - mse: 0.0044 - NMSE: 0.0396 - NMSE_wt: 0.0346 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.1392 - val_loss: 0.0215 - val_mse: 0.0019 - val_NMSE: 0.0171 - val_NMSE_wt: 0.0153 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0364 - mse: 0.0038 - NMSE: 0.0342 - NMSE_wt: 0.0303 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.6732 - tot_time: 0h 3m 58.2s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0364 - mse: 0.0038 - NMSE: 0.0342 - NMSE_wt: 0.0303 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.5948 - val_loss: 0.0200 - val_mse: 0.0017 - val_NMSE: 0.0157 - val_NMSE_wt: 0.0139 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.7294 - tot_time: 0h 4m 0.1s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.9079 - val_loss: 0.0169 - val_mse: 0.0014 - val_NMSE: 0.0122 - val_NMSE_wt: 0.0108 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0335 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0274 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.4092 - tot_time: 0h 4m 2.1s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.0335 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0274 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.9785 - val_loss: 0.0139 - val_mse: 9.7127e-04 - val_NMSE: 0.0087 - val_NMSE_wt: 0.0078 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0363 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0302 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.5072 - tot_time: 0h 4m 4.1s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0363 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0302 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.9650 - val_loss: 0.0180 - val_mse: 0.0015 - val_NMSE: 0.0134 - val_NMSE_wt: 0.0119 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0287 - mse: 0.0028 - NMSE: 0.0255 - NMSE_wt: 0.0226 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.2019 - tot_time: 0h 4m 6.0s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0287 - mse: 0.0028 - NMSE: 0.0255 - NMSE_wt: 0.0226 - covmat_fro_loss: 0.0011 - global_gradnorm: 15.1321 - val_loss: 0.0349 - val_mse: 0.0037 - val_NMSE: 0.0335 - val_NMSE_wt: 0.0288 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0247 - mse: 0.0023 - NMSE: 0.0211 - NMSE_wt: 0.0186 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2678 - tot_time: 0h 4m 7.9s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0247 - mse: 0.0023 - NMSE: 0.0211 - NMSE_wt: 0.0186 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.0250 - val_loss: 0.0203 - val_mse: 0.0018 - val_NMSE: 0.0162 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.8830 - tot_time: 0h 4m 9.9s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0381 - NMSE_wt: 0.0337 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.5126 - val_loss: 0.0272 - val_mse: 0.0026 - val_NMSE: 0.0234 - val_NMSE_wt: 0.0210 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0312 - mse: 0.0032 - NMSE: 0.0285 - NMSE_wt: 0.0251 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.8899 - tot_time: 0h 4m 11.8s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0312 - mse: 0.0032 - NMSE: 0.0285 - NMSE_wt: 0.0251 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.2146 - val_loss: 0.0230 - val_mse: 0.0021 - val_NMSE: 0.0191 - val_NMSE_wt: 0.0168 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0233 - mse: 0.0022 - NMSE: 0.0196 - NMSE_wt: 0.0172 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.0885 - tot_time: 0h 4m 13.8s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 179ms/step - loss: 0.0233 - mse: 0.0022 - NMSE: 0.0196 - NMSE_wt: 0.0172 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.5892 - val_loss: 0.0244 - val_mse: 0.0023 - val_NMSE: 0.0206 - val_NMSE_wt: 0.0183 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0441 - mse: 0.0048 - NMSE: 0.0431 - NMSE_wt: 0.0380 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.1509 - tot_time: 0h 4m 15.6s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.00729\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 0.0441 - mse: 0.0048 - NMSE: 0.0431 - NMSE_wt: 0.0380 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.4425 - val_loss: 0.0187 - val_mse: 0.0016 - val_NMSE: 0.0144 - val_NMSE_wt: 0.0126 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.8558 - tot_time: 0h 4m 17.4s\n",
      "\n",
      "Epoch 34: val_NMSE_wt improved from 0.00729 to 0.00714, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.0388 - mse: 0.0041 - NMSE: 0.0369 - NMSE_wt: 0.0327 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2115 - val_loss: 0.0133 - val_mse: 8.8569e-04 - val_NMSE: 0.0080 - val_NMSE_wt: 0.0071 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0365 - mse: 0.0038 - NMSE: 0.0346 - NMSE_wt: 0.0304 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.7352 - tot_time: 0h 4m 20.1s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0365 - mse: 0.0038 - NMSE: 0.0346 - NMSE_wt: 0.0304 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.0906 - val_loss: 0.0219 - val_mse: 0.0019 - val_NMSE: 0.0175 - val_NMSE_wt: 0.0158 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0369 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0308 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.3990 - tot_time: 0h 4m 22.0s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0369 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0308 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.5866 - val_loss: 0.0229 - val_mse: 0.0021 - val_NMSE: 0.0188 - val_NMSE_wt: 0.0168 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0343 - mse: 0.0036 - NMSE: 0.0322 - NMSE_wt: 0.0282 - covmat_fro_loss: 0.0011 - global_gradnorm: 4.8855 - tot_time: 0h 4m 24.0s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0343 - mse: 0.0036 - NMSE: 0.0322 - NMSE_wt: 0.0282 - covmat_fro_loss: 0.0012 - global_gradnorm: 4.9392 - val_loss: 0.0189 - val_mse: 0.0016 - val_NMSE: 0.0143 - val_NMSE_wt: 0.0127 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0449 - mse: 0.0049 - NMSE: 0.0439 - NMSE_wt: 0.0388 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.6985 - tot_time: 0h 4m 25.9s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0449 - mse: 0.0049 - NMSE: 0.0439 - NMSE_wt: 0.0388 - covmat_fro_loss: 0.0012 - global_gradnorm: 15.0569 - val_loss: 0.0180 - val_mse: 0.0015 - val_NMSE: 0.0135 - val_NMSE_wt: 0.0119 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0387 - mse: 0.0041 - NMSE: 0.0371 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.6833 - tot_time: 0h 4m 27.9s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0387 - mse: 0.0041 - NMSE: 0.0371 - NMSE_wt: 0.0326 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.8613 - val_loss: 0.0152 - val_mse: 0.0012 - val_NMSE: 0.0105 - val_NMSE_wt: 0.0091 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0551 - mse: 0.0062 - NMSE: 0.0559 - NMSE_wt: 0.0490 - covmat_fro_loss: 0.0014 - global_gradnorm: 16.9292 - tot_time: 0h 4m 29.8s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0551 - mse: 0.0062 - NMSE: 0.0559 - NMSE_wt: 0.0490 - covmat_fro_loss: 0.0014 - global_gradnorm: 18.0184 - val_loss: 0.0227 - val_mse: 0.0021 - val_NMSE: 0.0187 - val_NMSE_wt: 0.0165 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0335 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0273 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.1287 - tot_time: 0h 4m 31.7s\n",
      "\n",
      "Epoch 41: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0335 - mse: 0.0034 - NMSE: 0.0310 - NMSE_wt: 0.0273 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.1353 - val_loss: 0.0171 - val_mse: 0.0014 - val_NMSE: 0.0124 - val_NMSE_wt: 0.0110 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0409 - mse: 0.0044 - NMSE: 0.0394 - NMSE_wt: 0.0348 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.3097 - tot_time: 0h 4m 33.7s\n",
      "\n",
      "Epoch 42: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0409 - mse: 0.0044 - NMSE: 0.0394 - NMSE_wt: 0.0348 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.2179 - val_loss: 0.0192 - val_mse: 0.0016 - val_NMSE: 0.0148 - val_NMSE_wt: 0.0130 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0307 - mse: 0.0031 - NMSE: 0.0280 - NMSE_wt: 0.0246 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.5539 - tot_time: 0h 4m 35.7s\n",
      "\n",
      "Epoch 43: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 0.0307 - mse: 0.0031 - NMSE: 0.0280 - NMSE_wt: 0.0246 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.9244 - val_loss: 0.0195 - val_mse: 0.0017 - val_NMSE: 0.0149 - val_NMSE_wt: 0.0133 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0363 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0302 - covmat_fro_loss: 0.0011 - global_gradnorm: 16.1385 - tot_time: 0h 4m 37.6s\n",
      "\n",
      "Epoch 44: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0363 - mse: 0.0038 - NMSE: 0.0341 - NMSE_wt: 0.0302 - covmat_fro_loss: 0.0011 - global_gradnorm: 15.1603 - val_loss: 0.0155 - val_mse: 0.0012 - val_NMSE: 0.0106 - val_NMSE_wt: 0.0094 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0353 - mse: 0.0037 - NMSE: 0.0332 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.1509 - tot_time: 0h 4m 39.6s\n",
      "\n",
      "Epoch 45: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0353 - mse: 0.0037 - NMSE: 0.0332 - NMSE_wt: 0.0292 - covmat_fro_loss: 0.0012 - global_gradnorm: 10.5966 - val_loss: 0.0228 - val_mse: 0.0021 - val_NMSE: 0.0189 - val_NMSE_wt: 0.0167 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0347 - mse: 0.0036 - NMSE: 0.0322 - NMSE_wt: 0.0286 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.0642 - tot_time: 0h 4m 41.5s\n",
      "\n",
      "Epoch 46: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0347 - mse: 0.0036 - NMSE: 0.0322 - NMSE_wt: 0.0286 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.3927 - val_loss: 0.0150 - val_mse: 0.0011 - val_NMSE: 0.0100 - val_NMSE_wt: 0.0089 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0376 - mse: 0.0040 - NMSE: 0.0356 - NMSE_wt: 0.0315 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.6355 - tot_time: 0h 4m 43.5s\n",
      "\n",
      "Epoch 47: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0376 - mse: 0.0040 - NMSE: 0.0356 - NMSE_wt: 0.0315 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.6750 - val_loss: 0.0225 - val_mse: 0.0020 - val_NMSE: 0.0182 - val_NMSE_wt: 0.0163 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0327 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0265 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.3477 - tot_time: 0h 4m 45.4s\n",
      "\n",
      "Epoch 48: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 179ms/step - loss: 0.0327 - mse: 0.0033 - NMSE: 0.0301 - NMSE_wt: 0.0265 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.9854 - val_loss: 0.0253 - val_mse: 0.0024 - val_NMSE: 0.0215 - val_NMSE_wt: 0.0192 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0397 - mse: 0.0043 - NMSE: 0.0384 - NMSE_wt: 0.0336 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.6767 - tot_time: 0h 4m 47.3s\n",
      "\n",
      "Epoch 49: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 0.0397 - mse: 0.0043 - NMSE: 0.0384 - NMSE_wt: 0.0336 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.9134 - val_loss: 0.0148 - val_mse: 0.0011 - val_NMSE: 0.0098 - val_NMSE_wt: 0.0087 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0296 - mse: 0.0030 - NMSE: 0.0267 - NMSE_wt: 0.0235 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.9498 - tot_time: 0h 4m 49.1s\n",
      "\n",
      "Epoch 50: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.0296 - mse: 0.0030 - NMSE: 0.0267 - NMSE_wt: 0.0235 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.1648 - val_loss: 0.0343 - val_mse: 0.0035 - val_NMSE: 0.0316 - val_NMSE_wt: 0.0282 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0312 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0251 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.0480 - tot_time: 0h 4m 50.9s\n",
      "\n",
      "Epoch 51: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.0312 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0251 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.3237 - val_loss: 0.0189 - val_mse: 0.0016 - val_NMSE: 0.0144 - val_NMSE_wt: 0.0128 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0274 - mse: 0.0027 - NMSE: 0.0242 - NMSE_wt: 0.0213 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.0498 - tot_time: 0h 4m 52.8s\n",
      "\n",
      "Epoch 52: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0274 - mse: 0.0027 - NMSE: 0.0242 - NMSE_wt: 0.0213 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.0038 - val_loss: 0.0197 - val_mse: 0.0017 - val_NMSE: 0.0152 - val_NMSE_wt: 0.0136 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0307 - mse: 0.0031 - NMSE: 0.0281 - NMSE_wt: 0.0246 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.4505 - tot_time: 0h 4m 54.8s\n",
      "\n",
      "Epoch 53: val_NMSE_wt did not improve from 0.00714\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0307 - mse: 0.0031 - NMSE: 0.0281 - NMSE_wt: 0.0246 - covmat_fro_loss: 0.0011 - global_gradnorm: 15.2013 - val_loss: 0.0199 - val_mse: 0.0017 - val_NMSE: 0.0155 - val_NMSE_wt: 0.0138 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0303 - mse: 0.0031 - NMSE: 0.0275 - NMSE_wt: 0.0241 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.7456 - tot_time: 0h 4m 56.8s\n",
      "\n",
      "Epoch 54: val_NMSE_wt improved from 0.00714 to 0.00665, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.0303 - mse: 0.0031 - NMSE: 0.0275 - NMSE_wt: 0.0241 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.7823 - val_loss: 0.0128 - val_mse: 8.2752e-04 - val_NMSE: 0.0074 - val_NMSE_wt: 0.0066 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0315 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0253 - covmat_fro_loss: 0.0012 - global_gradnorm: 7.6154 - tot_time: 0h 4m 59.6s\n",
      "\n",
      "Epoch 55: val_NMSE_wt improved from 0.00665 to 0.00636, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.0315 - mse: 0.0032 - NMSE: 0.0287 - NMSE_wt: 0.0253 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.1678 - val_loss: 0.0125 - val_mse: 7.9683e-04 - val_NMSE: 0.0072 - val_NMSE_wt: 0.0064 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0277 - mse: 0.0027 - NMSE: 0.0243 - NMSE_wt: 0.0215 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.6919 - tot_time: 0h 5m 2.4s\n",
      "\n",
      "Epoch 56: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0277 - mse: 0.0027 - NMSE: 0.0243 - NMSE_wt: 0.0215 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.2322 - val_loss: 0.0168 - val_mse: 0.0013 - val_NMSE: 0.0121 - val_NMSE_wt: 0.0107 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0244 - mse: 0.0023 - NMSE: 0.0208 - NMSE_wt: 0.0183 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.5786 - tot_time: 0h 5m 4.4s\n",
      "\n",
      "Epoch 57: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0244 - mse: 0.0023 - NMSE: 0.0208 - NMSE_wt: 0.0183 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.7182 - val_loss: 0.0183 - val_mse: 0.0015 - val_NMSE: 0.0138 - val_NMSE_wt: 0.0122 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0306 - mse: 0.0031 - NMSE: 0.0278 - NMSE_wt: 0.0244 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.8668 - tot_time: 0h 5m 6.3s\n",
      "\n",
      "Epoch 58: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0306 - mse: 0.0031 - NMSE: 0.0278 - NMSE_wt: 0.0244 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.8144 - val_loss: 0.0173 - val_mse: 0.0014 - val_NMSE: 0.0127 - val_NMSE_wt: 0.0112 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0445 - mse: 0.0048 - NMSE: 0.0435 - NMSE_wt: 0.0383 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.7054 - tot_time: 0h 5m 8.3s\n",
      "\n",
      "Epoch 59: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0445 - mse: 0.0048 - NMSE: 0.0435 - NMSE_wt: 0.0383 - covmat_fro_loss: 0.0012 - global_gradnorm: 9.1189 - val_loss: 0.1080 - val_mse: 0.0133 - val_NMSE: 0.1197 - val_NMSE_wt: 0.1019 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0034 - NMSE: 0.0306 - NMSE_wt: 0.0269 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.9476 - tot_time: 0h 5m 10.2s\n",
      "\n",
      "Epoch 60: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0330 - mse: 0.0034 - NMSE: 0.0306 - NMSE_wt: 0.0269 - covmat_fro_loss: 0.0012 - global_gradnorm: 8.6471 - val_loss: 0.0181 - val_mse: 0.0015 - val_NMSE: 0.0133 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0390 - mse: 0.0041 - NMSE: 0.0371 - NMSE_wt: 0.0328 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.4402 - tot_time: 0h 5m 12.2s\n",
      "\n",
      "Epoch 61: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0390 - mse: 0.0041 - NMSE: 0.0371 - NMSE_wt: 0.0328 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.0535 - val_loss: 0.0222 - val_mse: 0.0020 - val_NMSE: 0.0183 - val_NMSE_wt: 0.0161 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0253 - mse: 0.0024 - NMSE: 0.0218 - NMSE_wt: 0.0192 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.6565 - tot_time: 0h 5m 14.1s\n",
      "\n",
      "Epoch 62: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0253 - mse: 0.0024 - NMSE: 0.0218 - NMSE_wt: 0.0192 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.7684 - val_loss: 0.0203 - val_mse: 0.0018 - val_NMSE: 0.0159 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0321 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0260 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.7647 - tot_time: 0h 5m 16.1s\n",
      "\n",
      "Epoch 63: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0321 - mse: 0.0033 - NMSE: 0.0294 - NMSE_wt: 0.0260 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.0713 - val_loss: 0.0185 - val_mse: 0.0016 - val_NMSE: 0.0142 - val_NMSE_wt: 0.0124 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0258 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0196 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.0694 - tot_time: 0h 5m 18.0s\n",
      "\n",
      "Epoch 64: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.0258 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0196 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.6576 - val_loss: 0.0132 - val_mse: 8.8398e-04 - val_NMSE: 0.0080 - val_NMSE_wt: 0.0071 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0317 - mse: 0.0032 - NMSE: 0.0292 - NMSE_wt: 0.0256 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.6350 - tot_time: 0h 5m 19.8s\n",
      "\n",
      "Epoch 65: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 164ms/step - loss: 0.0317 - mse: 0.0032 - NMSE: 0.0292 - NMSE_wt: 0.0256 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.5424 - val_loss: 0.0152 - val_mse: 0.0012 - val_NMSE: 0.0104 - val_NMSE_wt: 0.0091 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0287 - mse: 0.0028 - NMSE: 0.0254 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.0010 - tot_time: 0h 5m 21.6s\n",
      "\n",
      "Epoch 66: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.0287 - mse: 0.0028 - NMSE: 0.0254 - NMSE_wt: 0.0225 - covmat_fro_loss: 0.0011 - global_gradnorm: 8.6591 - val_loss: 0.0149 - val_mse: 0.0011 - val_NMSE: 0.0098 - val_NMSE_wt: 0.0087 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0411 - mse: 0.0044 - NMSE: 0.0398 - NMSE_wt: 0.0349 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.0882 - tot_time: 0h 5m 23.4s\n",
      "\n",
      "Epoch 67: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 0.0411 - mse: 0.0044 - NMSE: 0.0398 - NMSE_wt: 0.0349 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.1635 - val_loss: 0.0162 - val_mse: 0.0013 - val_NMSE: 0.0116 - val_NMSE_wt: 0.0101 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0256 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0195 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.6677 - tot_time: 0h 5m 25.3s\n",
      "\n",
      "Epoch 68: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0256 - mse: 0.0025 - NMSE: 0.0221 - NMSE_wt: 0.0195 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.1053 - val_loss: 0.0213 - val_mse: 0.0019 - val_NMSE: 0.0169 - val_NMSE_wt: 0.0152 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0260 - mse: 0.0025 - NMSE: 0.0224 - NMSE_wt: 0.0199 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.1616 - tot_time: 0h 5m 27.2s\n",
      "\n",
      "Epoch 69: val_NMSE_wt did not improve from 0.00636\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0260 - mse: 0.0025 - NMSE: 0.0224 - NMSE_wt: 0.0199 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.9583 - val_loss: 0.0204 - val_mse: 0.0018 - val_NMSE: 0.0161 - val_NMSE_wt: 0.0143 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0487 - mse: 0.0054 - NMSE: 0.0486 - NMSE_wt: 0.0426 - covmat_fro_loss: 0.0013 - global_gradnorm: 15.5646 - tot_time: 0h 5m 29.3s\n",
      "\n",
      "Epoch 70: val_NMSE_wt improved from 0.00636 to 0.00622, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-10_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0487 - mse: 0.0054 - NMSE: 0.0486 - NMSE_wt: 0.0426 - covmat_fro_loss: 0.0013 - global_gradnorm: 15.5774 - val_loss: 0.0123 - val_mse: 7.7331e-04 - val_NMSE: 0.0070 - val_NMSE_wt: 0.0062 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0425 - mse: 0.0045 - NMSE: 0.0409 - NMSE_wt: 0.0364 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.2634 - tot_time: 0h 5m 32.1s\n",
      "\n",
      "Epoch 71: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 0.0425 - mse: 0.0045 - NMSE: 0.0409 - NMSE_wt: 0.0364 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.2843 - val_loss: 0.0149 - val_mse: 0.0011 - val_NMSE: 0.0099 - val_NMSE_wt: 0.0087 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0368 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0307 - covmat_fro_loss: 0.0012 - global_gradnorm: 12.3136 - tot_time: 0h 5m 34.0s\n",
      "\n",
      "Epoch 72: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0368 - mse: 0.0039 - NMSE: 0.0348 - NMSE_wt: 0.0307 - covmat_fro_loss: 0.0012 - global_gradnorm: 11.5959 - val_loss: 0.0187 - val_mse: 0.0016 - val_NMSE: 0.0140 - val_NMSE_wt: 0.0126 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0262 - mse: 0.0025 - NMSE: 0.0226 - NMSE_wt: 0.0200 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.7027 - tot_time: 0h 5m 36.0s\n",
      "\n",
      "Epoch 73: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 179ms/step - loss: 0.0262 - mse: 0.0025 - NMSE: 0.0226 - NMSE_wt: 0.0200 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.8734 - val_loss: 0.0198 - val_mse: 0.0017 - val_NMSE: 0.0155 - val_NMSE_wt: 0.0137 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0501 - mse: 0.0056 - NMSE: 0.0500 - NMSE_wt: 0.0440 - covmat_fro_loss: 0.0012 - global_gradnorm: 18.7365 - tot_time: 0h 5m 38.0s\n",
      "\n",
      "Epoch 74: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0501 - mse: 0.0056 - NMSE: 0.0500 - NMSE_wt: 0.0440 - covmat_fro_loss: 0.0012 - global_gradnorm: 19.6752 - val_loss: 0.0199 - val_mse: 0.0017 - val_NMSE: 0.0155 - val_NMSE_wt: 0.0137 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0380 - NMSE_wt: 0.0336 - covmat_fro_loss: 0.0012 - global_gradnorm: 7.5117 - tot_time: 0h 5m 39.9s\n",
      "\n",
      "Epoch 75: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0398 - mse: 0.0042 - NMSE: 0.0380 - NMSE_wt: 0.0336 - covmat_fro_loss: 0.0012 - global_gradnorm: 7.6190 - val_loss: 0.0231 - val_mse: 0.0021 - val_NMSE: 0.0192 - val_NMSE_wt: 0.0170 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0463 - mse: 0.0050 - NMSE: 0.0453 - NMSE_wt: 0.0402 - covmat_fro_loss: 0.0013 - global_gradnorm: 12.8387 - tot_time: 0h 5m 41.8s\n",
      "\n",
      "Epoch 76: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0463 - mse: 0.0050 - NMSE: 0.0453 - NMSE_wt: 0.0402 - covmat_fro_loss: 0.0013 - global_gradnorm: 14.2688 - val_loss: 0.0179 - val_mse: 0.0015 - val_NMSE: 0.0134 - val_NMSE_wt: 0.0118 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0213 - mse: 0.0019 - NMSE: 0.0171 - NMSE_wt: 0.0151 - covmat_fro_loss: 0.0010 - global_gradnorm: 5.1761 - tot_time: 0h 5m 43.8s\n",
      "\n",
      "Epoch 77: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0213 - mse: 0.0019 - NMSE: 0.0171 - NMSE_wt: 0.0151 - covmat_fro_loss: 0.0010 - global_gradnorm: 5.2224 - val_loss: 0.0144 - val_mse: 0.0010 - val_NMSE: 0.0093 - val_NMSE_wt: 0.0083 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0323 - mse: 0.0033 - NMSE: 0.0296 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.4246 - tot_time: 0h 5m 45.7s\n",
      "\n",
      "Epoch 78: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 0.0323 - mse: 0.0033 - NMSE: 0.0296 - NMSE_wt: 0.0262 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.1392 - val_loss: 0.0132 - val_mse: 8.8363e-04 - val_NMSE: 0.0080 - val_NMSE_wt: 0.0071 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0372 - mse: 0.0039 - NMSE: 0.0353 - NMSE_wt: 0.0311 - covmat_fro_loss: 0.0012 - global_gradnorm: 13.3986 - tot_time: 0h 5m 47.7s\n",
      "\n",
      "Epoch 79: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0372 - mse: 0.0039 - NMSE: 0.0353 - NMSE_wt: 0.0311 - covmat_fro_loss: 0.0012 - global_gradnorm: 14.7820 - val_loss: 0.0164 - val_mse: 0.0013 - val_NMSE: 0.0115 - val_NMSE_wt: 0.0103 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0288 - mse: 0.0029 - NMSE: 0.0258 - NMSE_wt: 0.0227 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.9465 - tot_time: 0h 5m 49.6s\n",
      "\n",
      "Epoch 80: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0288 - mse: 0.0029 - NMSE: 0.0258 - NMSE_wt: 0.0227 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.9978 - val_loss: 0.0144 - val_mse: 0.0010 - val_NMSE: 0.0094 - val_NMSE_wt: 0.0083 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0263 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.1675 - tot_time: 0h 5m 51.6s\n",
      "\n",
      "Epoch 81: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0324 - mse: 0.0033 - NMSE: 0.0298 - NMSE_wt: 0.0263 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.1206 - val_loss: 0.0147 - val_mse: 0.0011 - val_NMSE: 0.0095 - val_NMSE_wt: 0.0086 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0352 - mse: 0.0037 - NMSE: 0.0330 - NMSE_wt: 0.0290 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.1104 - tot_time: 0h 5m 53.4s\n",
      "\n",
      "Epoch 82: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 0.0352 - mse: 0.0037 - NMSE: 0.0330 - NMSE_wt: 0.0290 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.4997 - val_loss: 0.0181 - val_mse: 0.0015 - val_NMSE: 0.0137 - val_NMSE_wt: 0.0120 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0338 - mse: 0.0035 - NMSE: 0.0316 - NMSE_wt: 0.0277 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.9631 - tot_time: 0h 5m 55.2s\n",
      "\n",
      "Epoch 83: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 0.0338 - mse: 0.0035 - NMSE: 0.0316 - NMSE_wt: 0.0277 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2305 - val_loss: 0.0260 - val_mse: 0.0025 - val_NMSE: 0.0224 - val_NMSE_wt: 0.0199 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0297 - mse: 0.0030 - NMSE: 0.0268 - NMSE_wt: 0.0236 - covmat_fro_loss: 0.0011 - global_gradnorm: 12.4423 - tot_time: 0h 5m 57.0s\n",
      "\n",
      "Epoch 84: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 172ms/step - loss: 0.0297 - mse: 0.0030 - NMSE: 0.0268 - NMSE_wt: 0.0236 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.7378 - val_loss: 0.0185 - val_mse: 0.0016 - val_NMSE: 0.0141 - val_NMSE_wt: 0.0124 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0420 - mse: 0.0045 - NMSE: 0.0408 - NMSE_wt: 0.0359 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.7896 - tot_time: 0h 5m 59.0s\n",
      "\n",
      "Epoch 85: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 0.0420 - mse: 0.0045 - NMSE: 0.0408 - NMSE_wt: 0.0359 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.2634 - val_loss: 0.0136 - val_mse: 9.3303e-04 - val_NMSE: 0.0084 - val_NMSE_wt: 0.0075 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0273 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0212 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.2011 - tot_time: 0h 6m 0.9s\n",
      "\n",
      "Epoch 86: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0273 - mse: 0.0027 - NMSE: 0.0239 - NMSE_wt: 0.0212 - covmat_fro_loss: 0.0011 - global_gradnorm: 9.4680 - val_loss: 0.0177 - val_mse: 0.0014 - val_NMSE: 0.0130 - val_NMSE_wt: 0.0115 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.0298 - mse: 0.0030 - NMSE: 0.0268 - NMSE_wt: 0.0236 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.5796 - tot_time: 0h 6m 2.9s\n",
      "\n",
      "Epoch 87: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.0298 - mse: 0.0030 - NMSE: 0.0268 - NMSE_wt: 0.0236 - covmat_fro_loss: 0.0011 - global_gradnorm: 7.2027 - val_loss: 0.0133 - val_mse: 8.9871e-04 - val_NMSE: 0.0081 - val_NMSE_wt: 0.0072 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0163 - covmat_fro_loss: 0.0010 - global_gradnorm: 9.2397 - tot_time: 0h 6m 4.8s\n",
      "\n",
      "Epoch 88: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.0224 - mse: 0.0020 - NMSE: 0.0184 - NMSE_wt: 0.0163 - covmat_fro_loss: 0.0010 - global_gradnorm: 9.4756 - val_loss: 0.0203 - val_mse: 0.0018 - val_NMSE: 0.0160 - val_NMSE_wt: 0.0142 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0371 - mse: 0.0039 - NMSE: 0.0351 - NMSE_wt: 0.0310 - covmat_fro_loss: 0.0011 - global_gradnorm: 14.3004 - tot_time: 0h 6m 6.8s\n",
      "\n",
      "Epoch 89: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 0.0371 - mse: 0.0039 - NMSE: 0.0351 - NMSE_wt: 0.0310 - covmat_fro_loss: 0.0011 - global_gradnorm: 13.4747 - val_loss: 0.0177 - val_mse: 0.0014 - val_NMSE: 0.0129 - val_NMSE_wt: 0.0115 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0313 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0252 - covmat_fro_loss: 0.0011 - global_gradnorm: 11.1056Restoring model weights from the end of the best epoch: 70.\n",
      " - tot_time: 0h 6m 8.8s\n",
      "\n",
      "Epoch 90: val_NMSE_wt did not improve from 0.00622\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-10_outsteps\n",
      "11/11 [==============================] - 2s 186ms/step - loss: 0.0313 - mse: 0.0032 - NMSE: 0.0286 - NMSE_wt: 0.0252 - covmat_fro_loss: 0.0011 - global_gradnorm: 10.5737 - val_loss: 0.0299 - val_mse: 0.0030 - val_NMSE: 0.0267 - val_NMSE_wt: 0.0238 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 90: early stopping\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>> num_outsteps : 15 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "clipnorm : None, global_clipnorm : 27.1\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.1466 - mse: 0.0189 - NMSE: 0.1705 - NMSE_wt: 0.1404 - covmat_fro_loss: 0.0000e+00 - global_gradnorm: 0.0000e+00\n",
      "baseline : 1.4043E-01\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-06 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0764 - mse: 0.0095 - NMSE: 0.0859 - NMSE_wt: 0.0702 - covmat_fro_loss: 0.0017 - global_gradnorm: 10.9928 - tot_time: 0h 1m 48.2s\n",
      "\n",
      "Epoch 1: val_NMSE_wt improved from 0.14043 to 0.06028, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 108s 283ms/step - loss: 0.0764 - mse: 0.0095 - NMSE: 0.0859 - NMSE_wt: 0.0702 - covmat_fro_loss: 0.0017 - global_gradnorm: 10.2284 - val_loss: 0.0664 - val_mse: 0.0082 - val_NMSE: 0.0737 - val_NMSE_wt: 0.0603 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0962 - mse: 0.0122 - NMSE: 0.1096 - NMSE_wt: 0.0901 - covmat_fro_loss: 0.0022 - global_gradnorm: 13.6314 - tot_time: 0h 1m 50.8s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0962 - mse: 0.0122 - NMSE: 0.1096 - NMSE_wt: 0.0901 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.3723 - val_loss: 0.1392 - val_mse: 0.0180 - val_NMSE: 0.1617 - val_NMSE_wt: 0.1331 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1207 - mse: 0.0155 - NMSE: 0.1394 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0025 - global_gradnorm: 21.1360 - tot_time: 0h 1m 53.1s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.1207 - mse: 0.0155 - NMSE: 0.1394 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0024 - global_gradnorm: 20.0452 - val_loss: 0.1610 - val_mse: 0.0210 - val_NMSE: 0.1889 - val_NMSE_wt: 0.1548 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0971 - mse: 0.0124 - NMSE: 0.1118 - NMSE_wt: 0.0910 - covmat_fro_loss: 0.0025 - global_gradnorm: 12.3065 - tot_time: 0h 1m 55.5s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0971 - mse: 0.0124 - NMSE: 0.1118 - NMSE_wt: 0.0910 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.0537 - val_loss: 0.1135 - val_mse: 0.0144 - val_NMSE: 0.1293 - val_NMSE_wt: 0.1074 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1032 - mse: 0.0133 - NMSE: 0.1197 - NMSE_wt: 0.0971 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.8149 - tot_time: 0h 1m 57.7s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.1032 - mse: 0.0133 - NMSE: 0.1197 - NMSE_wt: 0.0971 - covmat_fro_loss: 0.0031 - global_gradnorm: 16.8408 - val_loss: 0.1681 - val_mse: 0.0219 - val_NMSE: 0.1968 - val_NMSE_wt: 0.1619 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0705 - mse: 0.0088 - NMSE: 0.0794 - NMSE_wt: 0.0644 - covmat_fro_loss: 0.0021 - global_gradnorm: 13.9854 - tot_time: 0h 1m 59.8s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.0705 - mse: 0.0088 - NMSE: 0.0794 - NMSE_wt: 0.0644 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.1776 - val_loss: 0.1097 - val_mse: 0.0140 - val_NMSE: 0.1260 - val_NMSE_wt: 0.1036 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1036 - mse: 0.0134 - NMSE: 0.1204 - NMSE_wt: 0.0975 - covmat_fro_loss: 0.0029 - global_gradnorm: 15.6210 - tot_time: 0h 2m 2.1s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.06028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 229ms/step - loss: 0.1036 - mse: 0.0134 - NMSE: 0.1204 - NMSE_wt: 0.0975 - covmat_fro_loss: 0.0028 - global_gradnorm: 15.0944 - val_loss: 0.1419 - val_mse: 0.0186 - val_NMSE: 0.1674 - val_NMSE_wt: 0.1358 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0703 - mse: 0.0088 - NMSE: 0.0792 - NMSE_wt: 0.0642 - covmat_fro_loss: 0.0018 - global_gradnorm: 10.8892 - tot_time: 0h 2m 4.5s\n",
      "\n",
      "Epoch 8: val_NMSE_wt improved from 0.06028 to 0.04384, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.0703 - mse: 0.0088 - NMSE: 0.0792 - NMSE_wt: 0.0642 - covmat_fro_loss: 0.0020 - global_gradnorm: 12.3629 - val_loss: 0.0500 - val_mse: 0.0060 - val_NMSE: 0.0539 - val_NMSE_wt: 0.0438 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0897 - mse: 0.0114 - NMSE: 0.1029 - NMSE_wt: 0.0836 - covmat_fro_loss: 0.0022 - global_gradnorm: 17.3063 - tot_time: 0h 2m 7.7s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0897 - mse: 0.0114 - NMSE: 0.1029 - NMSE_wt: 0.0836 - covmat_fro_loss: 0.0022 - global_gradnorm: 18.1966 - val_loss: 0.1351 - val_mse: 0.0173 - val_NMSE: 0.1556 - val_NMSE_wt: 0.1290 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0754 - mse: 0.0094 - NMSE: 0.0850 - NMSE_wt: 0.0693 - covmat_fro_loss: 0.0018 - global_gradnorm: 13.5794 - tot_time: 0h 2m 10.0s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0754 - mse: 0.0094 - NMSE: 0.0850 - NMSE_wt: 0.0693 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.4614 - val_loss: 0.1014 - val_mse: 0.0132 - val_NMSE: 0.1188 - val_NMSE_wt: 0.0953 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0968 - mse: 0.0125 - NMSE: 0.1128 - NMSE_wt: 0.0906 - covmat_fro_loss: 0.0029 - global_gradnorm: 18.4847 - tot_time: 0h 2m 12.5s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.0968 - mse: 0.0125 - NMSE: 0.1128 - NMSE_wt: 0.0906 - covmat_fro_loss: 0.0033 - global_gradnorm: 19.2679 - val_loss: 0.1498 - val_mse: 0.0193 - val_NMSE: 0.1737 - val_NMSE_wt: 0.1436 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0685 - mse: 0.0085 - NMSE: 0.0764 - NMSE_wt: 0.0624 - covmat_fro_loss: 0.0016 - global_gradnorm: 7.7553 - tot_time: 0h 2m 14.9s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 0.0685 - mse: 0.0085 - NMSE: 0.0764 - NMSE_wt: 0.0624 - covmat_fro_loss: 0.0016 - global_gradnorm: 7.2293 - val_loss: 0.1136 - val_mse: 0.0143 - val_NMSE: 0.1284 - val_NMSE_wt: 0.1075 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0688 - mse: 0.0085 - NMSE: 0.0768 - NMSE_wt: 0.0626 - covmat_fro_loss: 0.0017 - global_gradnorm: 14.3705 - tot_time: 0h 2m 17.3s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0688 - mse: 0.0085 - NMSE: 0.0768 - NMSE_wt: 0.0626 - covmat_fro_loss: 0.0017 - global_gradnorm: 13.3251 - val_loss: 0.1309 - val_mse: 0.0167 - val_NMSE: 0.1503 - val_NMSE_wt: 0.1248 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0678 - mse: 0.0084 - NMSE: 0.0753 - NMSE_wt: 0.0617 - covmat_fro_loss: 0.0016 - global_gradnorm: 9.1487 - tot_time: 0h 2m 19.7s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.0678 - mse: 0.0084 - NMSE: 0.0753 - NMSE_wt: 0.0617 - covmat_fro_loss: 0.0016 - global_gradnorm: 8.6357 - val_loss: 0.0568 - val_mse: 0.0069 - val_NMSE: 0.0624 - val_NMSE_wt: 0.0507 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0648 - mse: 0.0080 - NMSE: 0.0723 - NMSE_wt: 0.0587 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.3769 - tot_time: 0h 2m 22.1s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0648 - mse: 0.0080 - NMSE: 0.0723 - NMSE_wt: 0.0587 - covmat_fro_loss: 0.0016 - global_gradnorm: 11.3474 - val_loss: 0.0615 - val_mse: 0.0075 - val_NMSE: 0.0679 - val_NMSE_wt: 0.0553 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1083 - mse: 0.0140 - NMSE: 0.1263 - NMSE_wt: 0.1022 - covmat_fro_loss: 0.0027 - global_gradnorm: 14.4382 - tot_time: 0h 2m 24.4s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.1083 - mse: 0.0140 - NMSE: 0.1263 - NMSE_wt: 0.1022 - covmat_fro_loss: 0.0026 - global_gradnorm: 14.0813 - val_loss: 0.1220 - val_mse: 0.0155 - val_NMSE: 0.1392 - val_NMSE_wt: 0.1159 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0827 - mse: 0.0104 - NMSE: 0.0940 - NMSE_wt: 0.0766 - covmat_fro_loss: 0.0020 - global_gradnorm: 14.1737 - tot_time: 0h 2m 26.8s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0827 - mse: 0.0104 - NMSE: 0.0940 - NMSE_wt: 0.0766 - covmat_fro_loss: 0.0023 - global_gradnorm: 15.3488 - val_loss: 0.0503 - val_mse: 0.0060 - val_NMSE: 0.0539 - val_NMSE_wt: 0.0442 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0874 - mse: 0.0110 - NMSE: 0.0993 - NMSE_wt: 0.0813 - covmat_fro_loss: 0.0021 - global_gradnorm: 14.4148 - tot_time: 0h 2m 29.1s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.0874 - mse: 0.0110 - NMSE: 0.0993 - NMSE_wt: 0.0813 - covmat_fro_loss: 0.0020 - global_gradnorm: 15.5680 - val_loss: 0.1367 - val_mse: 0.0175 - val_NMSE: 0.1575 - val_NMSE_wt: 0.1306 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0876 - mse: 0.0110 - NMSE: 0.0990 - NMSE_wt: 0.0815 - covmat_fro_loss: 0.0019 - global_gradnorm: 16.1992 - tot_time: 0h 2m 31.2s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.0876 - mse: 0.0110 - NMSE: 0.0990 - NMSE_wt: 0.0815 - covmat_fro_loss: 0.0019 - global_gradnorm: 17.1902 - val_loss: 0.1318 - val_mse: 0.0169 - val_NMSE: 0.1518 - val_NMSE_wt: 0.1256 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0625 - mse: 0.0077 - NMSE: 0.0692 - NMSE_wt: 0.0564 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.9632 - tot_time: 0h 2m 33.4s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.0625 - mse: 0.0077 - NMSE: 0.0692 - NMSE_wt: 0.0564 - covmat_fro_loss: 0.0016 - global_gradnorm: 18.7938 - val_loss: 0.1243 - val_mse: 0.0161 - val_NMSE: 0.1451 - val_NMSE_wt: 0.1181 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1019 - mse: 0.0131 - NMSE: 0.1176 - NMSE_wt: 0.0958 - covmat_fro_loss: 0.0023 - global_gradnorm: 17.6000 - tot_time: 0h 2m 35.7s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.1019 - mse: 0.0131 - NMSE: 0.1176 - NMSE_wt: 0.0958 - covmat_fro_loss: 0.0023 - global_gradnorm: 18.4636 - val_loss: 0.1131 - val_mse: 0.0143 - val_NMSE: 0.1283 - val_NMSE_wt: 0.1069 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0931 - mse: 0.0119 - NMSE: 0.1071 - NMSE_wt: 0.0870 - covmat_fro_loss: 0.0026 - global_gradnorm: 11.7133 - tot_time: 0h 2m 38.1s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.0931 - mse: 0.0119 - NMSE: 0.1071 - NMSE_wt: 0.0870 - covmat_fro_loss: 0.0025 - global_gradnorm: 11.0282 - val_loss: 0.1041 - val_mse: 0.0130 - val_NMSE: 0.1171 - val_NMSE_wt: 0.0980 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0821 - mse: 0.0104 - NMSE: 0.0937 - NMSE_wt: 0.0760 - covmat_fro_loss: 0.0021 - global_gradnorm: 13.4482 - tot_time: 0h 2m 40.4s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0821 - mse: 0.0104 - NMSE: 0.0937 - NMSE_wt: 0.0760 - covmat_fro_loss: 0.0020 - global_gradnorm: 14.6893 - val_loss: 0.1070 - val_mse: 0.0135 - val_NMSE: 0.1213 - val_NMSE_wt: 0.1009 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0978 - mse: 0.0125 - NMSE: 0.1125 - NMSE_wt: 0.0917 - covmat_fro_loss: 0.0023 - global_gradnorm: 23.7242 - tot_time: 0h 2m 42.8s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0978 - mse: 0.0125 - NMSE: 0.1125 - NMSE_wt: 0.0917 - covmat_fro_loss: 0.0023 - global_gradnorm: 23.8487 - val_loss: 0.0561 - val_mse: 0.0067 - val_NMSE: 0.0604 - val_NMSE_wt: 0.0500 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0916 - mse: 0.0117 - NMSE: 0.1052 - NMSE_wt: 0.0855 - covmat_fro_loss: 0.0019 - global_gradnorm: 16.8577 - tot_time: 0h 2m 45.2s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.0916 - mse: 0.0117 - NMSE: 0.1052 - NMSE_wt: 0.0855 - covmat_fro_loss: 0.0019 - global_gradnorm: 17.4088 - val_loss: 0.0708 - val_mse: 0.0088 - val_NMSE: 0.0790 - val_NMSE_wt: 0.0646 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0623 - mse: 0.0077 - NMSE: 0.0697 - NMSE_wt: 0.0562 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.0264 - tot_time: 0h 2m 47.5s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0623 - mse: 0.0077 - NMSE: 0.0697 - NMSE_wt: 0.0562 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.4042 - val_loss: 0.0860 - val_mse: 0.0110 - val_NMSE: 0.0992 - val_NMSE_wt: 0.0798 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1011 - mse: 0.0129 - NMSE: 0.1163 - NMSE_wt: 0.0950 - covmat_fro_loss: 0.0024 - global_gradnorm: 17.4207 - tot_time: 0h 2m 49.8s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.1011 - mse: 0.0129 - NMSE: 0.1163 - NMSE_wt: 0.0950 - covmat_fro_loss: 0.0023 - global_gradnorm: 17.9251 - val_loss: 0.1229 - val_mse: 0.0156 - val_NMSE: 0.1404 - val_NMSE_wt: 0.1167 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0691 - mse: 0.0086 - NMSE: 0.0770 - NMSE_wt: 0.0629 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.1514Restoring model weights from the end of the best epoch: 8.\n",
      " - tot_time: 0h 2m 52.3s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.04384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.0691 - mse: 0.0086 - NMSE: 0.0770 - NMSE_wt: 0.0629 - covmat_fro_loss: 0.0017 - global_gradnorm: 11.5373 - val_loss: 0.0978 - val_mse: 0.0121 - val_NMSE: 0.1093 - val_NMSE_wt: 0.0917 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 5e-07 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0848 - mse: 0.0108 - NMSE: 0.0973 - NMSE_wt: 0.0787 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.0064 - tot_time: 0h 2m 54.8s\n",
      "\n",
      "Epoch 1: val_NMSE_wt improved from 0.04384 to 0.04064, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.0848 - mse: 0.0108 - NMSE: 0.0973 - NMSE_wt: 0.0787 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.6049 - val_loss: 0.0468 - val_mse: 0.0056 - val_NMSE: 0.0502 - val_NMSE_wt: 0.0406 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0793 - mse: 0.0100 - NMSE: 0.0903 - NMSE_wt: 0.0732 - covmat_fro_loss: 0.0023 - global_gradnorm: 15.4694 - tot_time: 0h 2m 57.9s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0793 - mse: 0.0100 - NMSE: 0.0903 - NMSE_wt: 0.0732 - covmat_fro_loss: 0.0023 - global_gradnorm: 16.5267 - val_loss: 0.1301 - val_mse: 0.0167 - val_NMSE: 0.1506 - val_NMSE_wt: 0.1239 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1184 - mse: 0.0152 - NMSE: 0.1370 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0028 - global_gradnorm: 19.6704 - tot_time: 0h 3m 0.3s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.1184 - mse: 0.0152 - NMSE: 0.1370 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0026 - global_gradnorm: 18.6519 - val_loss: 0.1579 - val_mse: 0.0206 - val_NMSE: 0.1853 - val_NMSE_wt: 0.1518 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0928 - mse: 0.0118 - NMSE: 0.1064 - NMSE_wt: 0.0867 - covmat_fro_loss: 0.0024 - global_gradnorm: 16.0186 - tot_time: 0h 3m 2.4s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.0928 - mse: 0.0118 - NMSE: 0.1064 - NMSE_wt: 0.0867 - covmat_fro_loss: 0.0023 - global_gradnorm: 17.0260 - val_loss: 0.1126 - val_mse: 0.0142 - val_NMSE: 0.1282 - val_NMSE_wt: 0.1065 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1138 - mse: 0.0148 - NMSE: 0.1333 - NMSE_wt: 0.1077 - covmat_fro_loss: 0.0030 - global_gradnorm: 17.6181 - tot_time: 0h 3m 4.5s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.1138 - mse: 0.0148 - NMSE: 0.1333 - NMSE_wt: 0.1077 - covmat_fro_loss: 0.0029 - global_gradnorm: 18.2275 - val_loss: 0.1721 - val_mse: 0.0225 - val_NMSE: 0.2022 - val_NMSE_wt: 0.1660 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0589 - mse: 0.0072 - NMSE: 0.0651 - NMSE_wt: 0.0528 - covmat_fro_loss: 0.0015 - global_gradnorm: 9.5024  - tot_time: 0h 3m 6.9s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0589 - mse: 0.0072 - NMSE: 0.0651 - NMSE_wt: 0.0528 - covmat_fro_loss: 0.0016 - global_gradnorm: 8.9646 - val_loss: 0.1426 - val_mse: 0.0185 - val_NMSE: 0.1666 - val_NMSE_wt: 0.1364 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0901 - mse: 0.0115 - NMSE: 0.1039 - NMSE_wt: 0.0839 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.1476 - tot_time: 0h 3m 9.2s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0901 - mse: 0.0115 - NMSE: 0.1039 - NMSE_wt: 0.0839 - covmat_fro_loss: 0.0022 - global_gradnorm: 12.8891 - val_loss: 0.1390 - val_mse: 0.0181 - val_NMSE: 0.1632 - val_NMSE_wt: 0.1329 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0720 - mse: 0.0090 - NMSE: 0.0811 - NMSE_wt: 0.0659 - covmat_fro_loss: 0.0018 - global_gradnorm: 13.0309 - tot_time: 0h 3m 11.6s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0720 - mse: 0.0090 - NMSE: 0.0811 - NMSE_wt: 0.0659 - covmat_fro_loss: 0.0019 - global_gradnorm: 14.3099 - val_loss: 0.0494 - val_mse: 0.0059 - val_NMSE: 0.0531 - val_NMSE_wt: 0.0433 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0781 - mse: 0.0098 - NMSE: 0.0883 - NMSE_wt: 0.0720 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.9545 - tot_time: 0h 3m 13.9s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0781 - mse: 0.0098 - NMSE: 0.0883 - NMSE_wt: 0.0720 - covmat_fro_loss: 0.0020 - global_gradnorm: 15.6396 - val_loss: 0.1303 - val_mse: 0.0166 - val_NMSE: 0.1495 - val_NMSE_wt: 0.1241 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0808 - mse: 0.0102 - NMSE: 0.0918 - NMSE_wt: 0.0746 - covmat_fro_loss: 0.0022 - global_gradnorm: 11.0677 - tot_time: 0h 3m 16.3s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0808 - mse: 0.0102 - NMSE: 0.0918 - NMSE_wt: 0.0746 - covmat_fro_loss: 0.0021 - global_gradnorm: 10.2092 - val_loss: 0.0933 - val_mse: 0.0121 - val_NMSE: 0.1088 - val_NMSE_wt: 0.0871 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0688 - mse: 0.0086 - NMSE: 0.0774 - NMSE_wt: 0.0627 - covmat_fro_loss: 0.0019 - global_gradnorm: 15.2983 - tot_time: 0h 3m 18.7s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0688 - mse: 0.0086 - NMSE: 0.0774 - NMSE_wt: 0.0627 - covmat_fro_loss: 0.0019 - global_gradnorm: 16.3712 - val_loss: 0.1493 - val_mse: 0.0192 - val_NMSE: 0.1732 - val_NMSE_wt: 0.1432 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0797 - mse: 0.0100 - NMSE: 0.0903 - NMSE_wt: 0.0735 - covmat_fro_loss: 0.0020 - global_gradnorm: 11.8671 - tot_time: 0h 3m 21.1s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0797 - mse: 0.0100 - NMSE: 0.0903 - NMSE_wt: 0.0735 - covmat_fro_loss: 0.0020 - global_gradnorm: 12.1193 - val_loss: 0.1123 - val_mse: 0.0141 - val_NMSE: 0.1268 - val_NMSE_wt: 0.1061 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mse: 0.0087 - NMSE: 0.0783 - NMSE_wt: 0.0636 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.9977 - tot_time: 0h 3m 23.5s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.04064\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0697 - mse: 0.0087 - NMSE: 0.0783 - NMSE_wt: 0.0636 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.5275 - val_loss: 0.1253 - val_mse: 0.0159 - val_NMSE: 0.1432 - val_NMSE_wt: 0.1192 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0849 - mse: 0.0108 - NMSE: 0.0971 - NMSE_wt: 0.0787 - covmat_fro_loss: 0.0023 - global_gradnorm: 11.9715 - tot_time: 0h 3m 25.9s\n",
      "\n",
      "Epoch 14: val_NMSE_wt improved from 0.04064 to 0.03970, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.0849 - mse: 0.0108 - NMSE: 0.0971 - NMSE_wt: 0.0787 - covmat_fro_loss: 0.0023 - global_gradnorm: 12.4039 - val_loss: 0.0458 - val_mse: 0.0055 - val_NMSE: 0.0492 - val_NMSE_wt: 0.0397 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0574 - mse: 0.0070 - NMSE: 0.0634 - NMSE_wt: 0.0512 - covmat_fro_loss: 0.0016 - global_gradnorm: 13.2658 - tot_time: 0h 3m 29.1s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0574 - mse: 0.0070 - NMSE: 0.0634 - NMSE_wt: 0.0512 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.6671 - val_loss: 0.0505 - val_mse: 0.0061 - val_NMSE: 0.0549 - val_NMSE_wt: 0.0444 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0954 - mse: 0.0122 - NMSE: 0.1098 - NMSE_wt: 0.0892 - covmat_fro_loss: 0.0021 - global_gradnorm: 16.4864 - tot_time: 0h 3m 31.5s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0954 - mse: 0.0122 - NMSE: 0.1098 - NMSE_wt: 0.0892 - covmat_fro_loss: 0.0021 - global_gradnorm: 16.9431 - val_loss: 0.1199 - val_mse: 0.0152 - val_NMSE: 0.1366 - val_NMSE_wt: 0.1137 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0713 - mse: 0.0089 - NMSE: 0.0798 - NMSE_wt: 0.0652 - covmat_fro_loss: 0.0017 - global_gradnorm: 14.2083 - tot_time: 0h 3m 33.7s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.0713 - mse: 0.0089 - NMSE: 0.0798 - NMSE_wt: 0.0652 - covmat_fro_loss: 0.0018 - global_gradnorm: 15.3802 - val_loss: 0.0513 - val_mse: 0.0061 - val_NMSE: 0.0549 - val_NMSE_wt: 0.0452 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0797 - mse: 0.0100 - NMSE: 0.0904 - NMSE_wt: 0.0736 - covmat_fro_loss: 0.0021 - global_gradnorm: 15.1954 - tot_time: 0h 3m 35.7s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.0797 - mse: 0.0100 - NMSE: 0.0904 - NMSE_wt: 0.0736 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.2776 - val_loss: 0.1324 - val_mse: 0.0169 - val_NMSE: 0.1521 - val_NMSE_wt: 0.1263 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1135 - mse: 0.0147 - NMSE: 0.1326 - NMSE_wt: 0.1074 - covmat_fro_loss: 0.0027 - global_gradnorm: 16.5506 - tot_time: 0h 3m 38.0s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.1135 - mse: 0.0147 - NMSE: 0.1326 - NMSE_wt: 0.1074 - covmat_fro_loss: 0.0026 - global_gradnorm: 17.5096 - val_loss: 0.1304 - val_mse: 0.0167 - val_NMSE: 0.1501 - val_NMSE_wt: 0.1243 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0656 - mse: 0.0081 - NMSE: 0.0729 - NMSE_wt: 0.0595 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.9462 - tot_time: 0h 3m 40.4s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0656 - mse: 0.0081 - NMSE: 0.0729 - NMSE_wt: 0.0595 - covmat_fro_loss: 0.0016 - global_gradnorm: 16.9602 - val_loss: 0.1190 - val_mse: 0.0154 - val_NMSE: 0.1385 - val_NMSE_wt: 0.1129 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0980 - mse: 0.0125 - NMSE: 0.1126 - NMSE_wt: 0.0919 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.8285 - tot_time: 0h 3m 42.7s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0980 - mse: 0.0125 - NMSE: 0.1126 - NMSE_wt: 0.0919 - covmat_fro_loss: 0.0023 - global_gradnorm: 15.9441 - val_loss: 0.1117 - val_mse: 0.0141 - val_NMSE: 0.1266 - val_NMSE_wt: 0.1055 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0734 - mse: 0.0092 - NMSE: 0.0826 - NMSE_wt: 0.0673 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.1452 - tot_time: 0h 3m 45.1s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0734 - mse: 0.0092 - NMSE: 0.0826 - NMSE_wt: 0.0673 - covmat_fro_loss: 0.0016 - global_gradnorm: 11.2210 - val_loss: 0.1033 - val_mse: 0.0129 - val_NMSE: 0.1160 - val_NMSE_wt: 0.0971 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0621 - mse: 0.0076 - NMSE: 0.0688 - NMSE_wt: 0.0560 - covmat_fro_loss: 0.0016 - global_gradnorm: 10.8380 - tot_time: 0h 3m 47.5s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.03970\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0621 - mse: 0.0076 - NMSE: 0.0688 - NMSE_wt: 0.0560 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.3164 - val_loss: 0.1052 - val_mse: 0.0132 - val_NMSE: 0.1189 - val_NMSE_wt: 0.0990 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0719 - mse: 0.0089 - NMSE: 0.0802 - NMSE_wt: 0.0657 - covmat_fro_loss: 0.0016 - global_gradnorm: 19.2175 - tot_time: 0h 3m 49.8s\n",
      "\n",
      "Epoch 24: val_NMSE_wt improved from 0.03970 to 0.03558, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.0719 - mse: 0.0089 - NMSE: 0.0802 - NMSE_wt: 0.0657 - covmat_fro_loss: 0.0016 - global_gradnorm: 19.9341 - val_loss: 0.0417 - val_mse: 0.0048 - val_NMSE: 0.0433 - val_NMSE_wt: 0.0356 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0857 - mse: 0.0109 - NMSE: 0.0977 - NMSE_wt: 0.0796 - covmat_fro_loss: 0.0021 - global_gradnorm: 17.2090 - tot_time: 0h 3m 53.0s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0857 - mse: 0.0109 - NMSE: 0.0977 - NMSE_wt: 0.0796 - covmat_fro_loss: 0.0024 - global_gradnorm: 18.1082 - val_loss: 0.0700 - val_mse: 0.0087 - val_NMSE: 0.0782 - val_NMSE_wt: 0.0639 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0676 - mse: 0.0084 - NMSE: 0.0758 - NMSE_wt: 0.0614 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.2254 - tot_time: 0h 3m 55.4s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0676 - mse: 0.0084 - NMSE: 0.0758 - NMSE_wt: 0.0614 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.0762 - val_loss: 0.1563 - val_mse: 0.0203 - val_NMSE: 0.1828 - val_NMSE_wt: 0.1502 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0813 - mse: 0.0102 - NMSE: 0.0914 - NMSE_wt: 0.0752 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.3085 - tot_time: 0h 3m 57.7s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0813 - mse: 0.0102 - NMSE: 0.0914 - NMSE_wt: 0.0752 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.3204 - val_loss: 0.1235 - val_mse: 0.0157 - val_NMSE: 0.1412 - val_NMSE_wt: 0.1174 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mse: 0.0079 - NMSE: 0.0714 - NMSE_wt: 0.0577 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.1985 - tot_time: 0h 4m 0.1s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0639 - mse: 0.0079 - NMSE: 0.0714 - NMSE_wt: 0.0577 - covmat_fro_loss: 0.0016 - global_gradnorm: 11.3207 - val_loss: 0.0995 - val_mse: 0.0124 - val_NMSE: 0.1112 - val_NMSE_wt: 0.0933 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0623 - mse: 0.0076 - NMSE: 0.0688 - NMSE_wt: 0.0561 - covmat_fro_loss: 0.0017 - global_gradnorm: 16.0381 - tot_time: 0h 4m 2.5s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0623 - mse: 0.0076 - NMSE: 0.0688 - NMSE_wt: 0.0561 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.0663 - val_loss: 0.1619 - val_mse: 0.0211 - val_NMSE: 0.1899 - val_NMSE_wt: 0.1558 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0961 - mse: 0.0124 - NMSE: 0.1112 - NMSE_wt: 0.0899 - covmat_fro_loss: 0.0028 - global_gradnorm: 13.8684 - tot_time: 0h 4m 4.8s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0961 - mse: 0.0124 - NMSE: 0.1112 - NMSE_wt: 0.0899 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.0712 - val_loss: 0.1279 - val_mse: 0.0163 - val_NMSE: 0.1470 - val_NMSE_wt: 0.1217 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0734 - mse: 0.0091 - NMSE: 0.0822 - NMSE_wt: 0.0673 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.3726 - tot_time: 0h 4m 6.9s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.0734 - mse: 0.0091 - NMSE: 0.0822 - NMSE_wt: 0.0673 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.2082 - val_loss: 0.1112 - val_mse: 0.0139 - val_NMSE: 0.1253 - val_NMSE_wt: 0.1050 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0665 - mse: 0.0082 - NMSE: 0.0736 - NMSE_wt: 0.0604 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.8364 - tot_time: 0h 4m 9.0s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.0665 - mse: 0.0082 - NMSE: 0.0736 - NMSE_wt: 0.0604 - covmat_fro_loss: 0.0016 - global_gradnorm: 16.4961 - val_loss: 0.1114 - val_mse: 0.0140 - val_NMSE: 0.1256 - val_NMSE_wt: 0.1053 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0708 - mse: 0.0089 - NMSE: 0.0800 - NMSE_wt: 0.0646 - covmat_fro_loss: 0.0021 - global_gradnorm: 20.9973 - tot_time: 0h 4m 11.4s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0708 - mse: 0.0089 - NMSE: 0.0800 - NMSE_wt: 0.0646 - covmat_fro_loss: 0.0020 - global_gradnorm: 21.5521 - val_loss: 0.0908 - val_mse: 0.0112 - val_NMSE: 0.1012 - val_NMSE_wt: 0.0847 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0675 - mse: 0.0083 - NMSE: 0.0750 - NMSE_wt: 0.0614 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.5477 - tot_time: 0h 4m 13.8s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0675 - mse: 0.0083 - NMSE: 0.0750 - NMSE_wt: 0.0614 - covmat_fro_loss: 0.0017 - global_gradnorm: 13.8707 - val_loss: 0.1074 - val_mse: 0.0135 - val_NMSE: 0.1217 - val_NMSE_wt: 0.1013 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0700 - mse: 0.0087 - NMSE: 0.0786 - NMSE_wt: 0.0638 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.6863 - tot_time: 0h 4m 16.1s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0700 - mse: 0.0087 - NMSE: 0.0786 - NMSE_wt: 0.0638 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.2408 - val_loss: 0.0507 - val_mse: 0.0061 - val_NMSE: 0.0545 - val_NMSE_wt: 0.0445 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0864 - mse: 0.0110 - NMSE: 0.0988 - NMSE_wt: 0.0803 - covmat_fro_loss: 0.0022 - global_gradnorm: 15.3136 - tot_time: 0h 4m 18.5s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0864 - mse: 0.0110 - NMSE: 0.0988 - NMSE_wt: 0.0803 - covmat_fro_loss: 0.0021 - global_gradnorm: 15.3840 - val_loss: 0.0743 - val_mse: 0.0089 - val_NMSE: 0.0805 - val_NMSE_wt: 0.0682 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0840 - mse: 0.0106 - NMSE: 0.0952 - NMSE_wt: 0.0779 - covmat_fro_loss: 0.0018 - global_gradnorm: 16.3762 - tot_time: 0h 4m 20.8s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0840 - mse: 0.0106 - NMSE: 0.0952 - NMSE_wt: 0.0779 - covmat_fro_loss: 0.0018 - global_gradnorm: 15.0516 - val_loss: 0.0758 - val_mse: 0.0096 - val_NMSE: 0.0864 - val_NMSE_wt: 0.0697 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0963 - mse: 0.0122 - NMSE: 0.1101 - NMSE_wt: 0.0901 - covmat_fro_loss: 0.0021 - global_gradnorm: 16.5461 - tot_time: 0h 4m 23.2s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0963 - mse: 0.0122 - NMSE: 0.1101 - NMSE_wt: 0.0901 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.1430 - val_loss: 0.1108 - val_mse: 0.0142 - val_NMSE: 0.1280 - val_NMSE_wt: 0.1047 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0805 - mse: 0.0101 - NMSE: 0.0909 - NMSE_wt: 0.0744 - covmat_fro_loss: 0.0021 - global_gradnorm: 12.9524 - tot_time: 0h 4m 25.6s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0805 - mse: 0.0101 - NMSE: 0.0909 - NMSE_wt: 0.0744 - covmat_fro_loss: 0.0020 - global_gradnorm: 11.9850 - val_loss: 0.1433 - val_mse: 0.0186 - val_NMSE: 0.1671 - val_NMSE_wt: 0.1372 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0934 - mse: 0.0119 - NMSE: 0.1074 - NMSE_wt: 0.0873 - covmat_fro_loss: 0.0027 - global_gradnorm: 17.9772 - tot_time: 0h 4m 28.0s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0934 - mse: 0.0119 - NMSE: 0.1074 - NMSE_wt: 0.0873 - covmat_fro_loss: 0.0026 - global_gradnorm: 18.8065 - val_loss: 0.0832 - val_mse: 0.0107 - val_NMSE: 0.0960 - val_NMSE_wt: 0.0771 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0777 - mse: 0.0099 - NMSE: 0.0889 - NMSE_wt: 0.0716 - covmat_fro_loss: 0.0022 - global_gradnorm: 12.9142 - tot_time: 0h 4m 30.3s\n",
      "\n",
      "Epoch 41: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0777 - mse: 0.0099 - NMSE: 0.0889 - NMSE_wt: 0.0716 - covmat_fro_loss: 0.0021 - global_gradnorm: 12.9792 - val_loss: 0.0562 - val_mse: 0.0068 - val_NMSE: 0.0610 - val_NMSE_wt: 0.0501 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0985 - mse: 0.0127 - NMSE: 0.1143 - NMSE_wt: 0.0924 - covmat_fro_loss: 0.0023 - global_gradnorm: 20.4845 - tot_time: 0h 4m 32.7s\n",
      "\n",
      "Epoch 42: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0985 - mse: 0.0127 - NMSE: 0.1143 - NMSE_wt: 0.0924 - covmat_fro_loss: 0.0022 - global_gradnorm: 19.4766 - val_loss: 0.1478 - val_mse: 0.0190 - val_NMSE: 0.1711 - val_NMSE_wt: 0.1417 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0782 - mse: 0.0099 - NMSE: 0.0888 - NMSE_wt: 0.0721 - covmat_fro_loss: 0.0022 - global_gradnorm: 18.6714 - tot_time: 0h 4m 35.1s\n",
      "\n",
      "Epoch 43: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0782 - mse: 0.0099 - NMSE: 0.0888 - NMSE_wt: 0.0721 - covmat_fro_loss: 0.0021 - global_gradnorm: 19.4376 - val_loss: 0.1427 - val_mse: 0.0183 - val_NMSE: 0.1647 - val_NMSE_wt: 0.1366 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0779 - mse: 0.0098 - NMSE: 0.0884 - NMSE_wt: 0.0718 - covmat_fro_loss: 0.0019 - global_gradnorm: 18.3099Restoring model weights from the end of the best epoch: 24.\n",
      " - tot_time: 0h 4m 37.4s\n",
      "\n",
      "Epoch 44: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0779 - mse: 0.0098 - NMSE: 0.0884 - NMSE_wt: 0.0718 - covmat_fro_loss: 0.0019 - global_gradnorm: 18.3534 - val_loss: 0.0947 - val_mse: 0.0119 - val_NMSE: 0.1067 - val_NMSE_wt: 0.0886 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-07 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1046 - mse: 0.0135 - NMSE: 0.1212 - NMSE_wt: 0.0984 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.5779 - tot_time: 0h 4m 39.7s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.1046 - mse: 0.0135 - NMSE: 0.1212 - NMSE_wt: 0.0984 - covmat_fro_loss: 0.0025 - global_gradnorm: 16.6253 - val_loss: 0.0495 - val_mse: 0.0059 - val_NMSE: 0.0530 - val_NMSE_wt: 0.0434 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0899 - mse: 0.0114 - NMSE: 0.1029 - NMSE_wt: 0.0838 - covmat_fro_loss: 0.0022 - global_gradnorm: 13.0452 - tot_time: 0h 4m 42.0s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.0899 - mse: 0.0114 - NMSE: 0.1029 - NMSE_wt: 0.0838 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.3229 - val_loss: 0.1212 - val_mse: 0.0156 - val_NMSE: 0.1400 - val_NMSE_wt: 0.1151 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1026 - mse: 0.0130 - NMSE: 0.1173 - NMSE_wt: 0.0965 - covmat_fro_loss: 0.0024 - global_gradnorm: 19.0240 - tot_time: 0h 4m 44.4s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.1026 - mse: 0.0130 - NMSE: 0.1173 - NMSE_wt: 0.0965 - covmat_fro_loss: 0.0023 - global_gradnorm: 17.6661 - val_loss: 0.1238 - val_mse: 0.0160 - val_NMSE: 0.1437 - val_NMSE_wt: 0.1177 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0834 - mse: 0.0105 - NMSE: 0.0948 - NMSE_wt: 0.0773 - covmat_fro_loss: 0.0021 - global_gradnorm: 16.6748 - tot_time: 0h 4m 46.7s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0834 - mse: 0.0105 - NMSE: 0.0948 - NMSE_wt: 0.0773 - covmat_fro_loss: 0.0021 - global_gradnorm: 17.6225 - val_loss: 0.1064 - val_mse: 0.0134 - val_NMSE: 0.1206 - val_NMSE_wt: 0.1003 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1039 - mse: 0.0134 - NMSE: 0.1205 - NMSE_wt: 0.0977 - covmat_fro_loss: 0.0025 - global_gradnorm: 16.4691 - tot_time: 0h 4m 49.0s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.1039 - mse: 0.0134 - NMSE: 0.1205 - NMSE_wt: 0.0977 - covmat_fro_loss: 0.0025 - global_gradnorm: 17.0931 - val_loss: 0.1618 - val_mse: 0.0210 - val_NMSE: 0.1891 - val_NMSE_wt: 0.1557 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0584 - mse: 0.0072 - NMSE: 0.0644 - NMSE_wt: 0.0523 - covmat_fro_loss: 0.0016 - global_gradnorm: 14.1153 - tot_time: 0h 4m 51.4s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0584 - mse: 0.0072 - NMSE: 0.0644 - NMSE_wt: 0.0523 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.1654 - val_loss: 0.0770 - val_mse: 0.0097 - val_NMSE: 0.0872 - val_NMSE_wt: 0.0709 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1027 - mse: 0.0133 - NMSE: 0.1193 - NMSE_wt: 0.0965 - covmat_fro_loss: 0.0027 - global_gradnorm: 14.9328 - tot_time: 0h 4m 53.8s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.1027 - mse: 0.0133 - NMSE: 0.1193 - NMSE_wt: 0.0965 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.4722 - val_loss: 0.0935 - val_mse: 0.0120 - val_NMSE: 0.1078 - val_NMSE_wt: 0.0873 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0811 - mse: 0.0103 - NMSE: 0.0927 - NMSE_wt: 0.0750 - covmat_fro_loss: 0.0022 - global_gradnorm: 11.1372 - tot_time: 0h 4m 56.2s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0811 - mse: 0.0103 - NMSE: 0.0927 - NMSE_wt: 0.0750 - covmat_fro_loss: 0.0021 - global_gradnorm: 12.5883 - val_loss: 0.0509 - val_mse: 0.0060 - val_NMSE: 0.0542 - val_NMSE_wt: 0.0448 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0832 - mse: 0.0105 - NMSE: 0.0943 - NMSE_wt: 0.0771 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.4240 - tot_time: 0h 4m 58.6s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0832 - mse: 0.0105 - NMSE: 0.0943 - NMSE_wt: 0.0771 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.6759 - val_loss: 0.1278 - val_mse: 0.0163 - val_NMSE: 0.1464 - val_NMSE_wt: 0.1217 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0868 - mse: 0.0110 - NMSE: 0.0992 - NMSE_wt: 0.0807 - covmat_fro_loss: 0.0024 - global_gradnorm: 12.9590 - tot_time: 0h 5m 1.0s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0868 - mse: 0.0110 - NMSE: 0.0992 - NMSE_wt: 0.0807 - covmat_fro_loss: 0.0023 - global_gradnorm: 11.8833 - val_loss: 0.0894 - val_mse: 0.0116 - val_NMSE: 0.1040 - val_NMSE_wt: 0.0833 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0725 - mse: 0.0091 - NMSE: 0.0823 - NMSE_wt: 0.0664 - covmat_fro_loss: 0.0021 - global_gradnorm: 14.6015 - tot_time: 0h 5m 3.3s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0725 - mse: 0.0091 - NMSE: 0.0823 - NMSE_wt: 0.0664 - covmat_fro_loss: 0.0020 - global_gradnorm: 15.7378 - val_loss: 0.1474 - val_mse: 0.0190 - val_NMSE: 0.1709 - val_NMSE_wt: 0.1413 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0713 - mse: 0.0089 - NMSE: 0.0797 - NMSE_wt: 0.0652 - covmat_fro_loss: 0.0017 - global_gradnorm: 9.4416 - tot_time: 0h 5m 5.7s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0713 - mse: 0.0089 - NMSE: 0.0797 - NMSE_wt: 0.0652 - covmat_fro_loss: 0.0016 - global_gradnorm: 9.0422 - val_loss: 0.1085 - val_mse: 0.0136 - val_NMSE: 0.1220 - val_NMSE_wt: 0.1023 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0852 - mse: 0.0109 - NMSE: 0.0977 - NMSE_wt: 0.0791 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.6077 - tot_time: 0h 5m 8.0s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0852 - mse: 0.0109 - NMSE: 0.0977 - NMSE_wt: 0.0791 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.0131 - val_loss: 0.1184 - val_mse: 0.0149 - val_NMSE: 0.1345 - val_NMSE_wt: 0.1123 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1020 - mse: 0.0132 - NMSE: 0.1189 - NMSE_wt: 0.0958 - covmat_fro_loss: 0.0030 - global_gradnorm: 12.5876 - tot_time: 0h 5m 10.3s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 0.1020 - mse: 0.0132 - NMSE: 0.1189 - NMSE_wt: 0.0958 - covmat_fro_loss: 0.0036 - global_gradnorm: 13.9069 - val_loss: 0.0462 - val_mse: 0.0055 - val_NMSE: 0.0491 - val_NMSE_wt: 0.0401 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0643 - mse: 0.0080 - NMSE: 0.0717 - NMSE_wt: 0.0582 - covmat_fro_loss: 0.0017 - global_gradnorm: 17.3677 - tot_time: 0h 5m 12.4s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.0643 - mse: 0.0080 - NMSE: 0.0717 - NMSE_wt: 0.0582 - covmat_fro_loss: 0.0017 - global_gradnorm: 18.2524 - val_loss: 0.0490 - val_mse: 0.0059 - val_NMSE: 0.0529 - val_NMSE_wt: 0.0429 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0819 - mse: 0.0102 - NMSE: 0.0919 - NMSE_wt: 0.0758 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.0423 - tot_time: 0h 5m 14.6s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 229ms/step - loss: 0.0819 - mse: 0.0102 - NMSE: 0.0919 - NMSE_wt: 0.0758 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.1516 - val_loss: 0.1167 - val_mse: 0.0147 - val_NMSE: 0.1327 - val_NMSE_wt: 0.1106 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mse: 0.0082 - NMSE: 0.0741 - NMSE_wt: 0.0609 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.6515 - tot_time: 0h 5m 17.0s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 0.0671 - mse: 0.0082 - NMSE: 0.0741 - NMSE_wt: 0.0609 - covmat_fro_loss: 0.0017 - global_gradnorm: 18.5105 - val_loss: 0.0544 - val_mse: 0.0065 - val_NMSE: 0.0582 - val_NMSE_wt: 0.0483 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1141 - mse: 0.0149 - NMSE: 0.1337 - NMSE_wt: 0.1080 - covmat_fro_loss: 0.0032 - global_gradnorm: 12.8973 - tot_time: 0h 5m 19.3s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.1141 - mse: 0.0149 - NMSE: 0.1337 - NMSE_wt: 0.1080 - covmat_fro_loss: 0.0031 - global_gradnorm: 12.7188 - val_loss: 0.1279 - val_mse: 0.0163 - val_NMSE: 0.1464 - val_NMSE_wt: 0.1217 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0943 - mse: 0.0120 - NMSE: 0.1082 - NMSE_wt: 0.0882 - covmat_fro_loss: 0.0021 - global_gradnorm: 14.5176 - tot_time: 0h 5m 21.7s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0943 - mse: 0.0120 - NMSE: 0.1082 - NMSE_wt: 0.0882 - covmat_fro_loss: 0.0021 - global_gradnorm: 15.6086 - val_loss: 0.1271 - val_mse: 0.0162 - val_NMSE: 0.1459 - val_NMSE_wt: 0.1209 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0599 - mse: 0.0073 - NMSE: 0.0659 - NMSE_wt: 0.0538 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.0439 - tot_time: 0h 5m 24.0s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.0599 - mse: 0.0073 - NMSE: 0.0659 - NMSE_wt: 0.0538 - covmat_fro_loss: 0.0016 - global_gradnorm: 17.5674 - val_loss: 0.0949 - val_mse: 0.0122 - val_NMSE: 0.1095 - val_NMSE_wt: 0.0888 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0766 - mse: 0.0095 - NMSE: 0.0856 - NMSE_wt: 0.0705 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.6412 - tot_time: 0h 5m 26.4s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0766 - mse: 0.0095 - NMSE: 0.0856 - NMSE_wt: 0.0705 - covmat_fro_loss: 0.0017 - global_gradnorm: 16.5033 - val_loss: 0.1113 - val_mse: 0.0140 - val_NMSE: 0.1261 - val_NMSE_wt: 0.1052 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0754 - mse: 0.0094 - NMSE: 0.0850 - NMSE_wt: 0.0693 - covmat_fro_loss: 0.0017 - global_gradnorm: 12.5026 - tot_time: 0h 5m 28.7s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0754 - mse: 0.0094 - NMSE: 0.0850 - NMSE_wt: 0.0693 - covmat_fro_loss: 0.0016 - global_gradnorm: 11.5879 - val_loss: 0.1028 - val_mse: 0.0128 - val_NMSE: 0.1155 - val_NMSE_wt: 0.0966 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0832 - mse: 0.0105 - NMSE: 0.0947 - NMSE_wt: 0.0771 - covmat_fro_loss: 0.0020 - global_gradnorm: 16.1485 - tot_time: 0h 5m 31.1s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.03558\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.0832 - mse: 0.0105 - NMSE: 0.0947 - NMSE_wt: 0.0771 - covmat_fro_loss: 0.0019 - global_gradnorm: 17.1441 - val_loss: 0.1039 - val_mse: 0.0131 - val_NMSE: 0.1175 - val_NMSE_wt: 0.0978 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0752 - mse: 0.0094 - NMSE: 0.0849 - NMSE_wt: 0.0691 - covmat_fro_loss: 0.0017 - global_gradnorm: 20.9107 - tot_time: 0h 5m 33.5s\n",
      "\n",
      "Epoch 24: val_NMSE_wt improved from 0.03558 to 0.02719, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-15_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.0752 - mse: 0.0094 - NMSE: 0.0849 - NMSE_wt: 0.0691 - covmat_fro_loss: 0.0017 - global_gradnorm: 21.4733 - val_loss: 0.0333 - val_mse: 0.0037 - val_NMSE: 0.0334 - val_NMSE_wt: 0.0272 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0829 - mse: 0.0105 - NMSE: 0.0947 - NMSE_wt: 0.0768 - covmat_fro_loss: 0.0020 - global_gradnorm: 20.3801 - tot_time: 0h 5m 36.8s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.0829 - mse: 0.0105 - NMSE: 0.0947 - NMSE_wt: 0.0768 - covmat_fro_loss: 0.0023 - global_gradnorm: 20.9910 - val_loss: 0.0688 - val_mse: 0.0085 - val_NMSE: 0.0765 - val_NMSE_wt: 0.0626 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0672 - mse: 0.0084 - NMSE: 0.0753 - NMSE_wt: 0.0611 - covmat_fro_loss: 0.0016 - global_gradnorm: 11.6024 - tot_time: 0h 5m 39.1s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0672 - mse: 0.0084 - NMSE: 0.0753 - NMSE_wt: 0.0611 - covmat_fro_loss: 0.0017 - global_gradnorm: 11.8045 - val_loss: 0.1553 - val_mse: 0.0202 - val_NMSE: 0.1820 - val_NMSE_wt: 0.1491 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0938 - mse: 0.0119 - NMSE: 0.1074 - NMSE_wt: 0.0877 - covmat_fro_loss: 0.0021 - global_gradnorm: 15.2689 - tot_time: 0h 5m 41.5s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 0.0938 - mse: 0.0119 - NMSE: 0.1074 - NMSE_wt: 0.0877 - covmat_fro_loss: 0.0021 - global_gradnorm: 16.1415 - val_loss: 0.1226 - val_mse: 0.0156 - val_NMSE: 0.1401 - val_NMSE_wt: 0.1165 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0710 - mse: 0.0089 - NMSE: 0.0798 - NMSE_wt: 0.0648 - covmat_fro_loss: 0.0016 - global_gradnorm: 16.8303 - tot_time: 0h 5m 43.6s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 213ms/step - loss: 0.0710 - mse: 0.0089 - NMSE: 0.0798 - NMSE_wt: 0.0648 - covmat_fro_loss: 0.0016 - global_gradnorm: 15.4948 - val_loss: 0.0984 - val_mse: 0.0122 - val_NMSE: 0.1100 - val_NMSE_wt: 0.0923 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0668 - mse: 0.0083 - NMSE: 0.0749 - NMSE_wt: 0.0607 - covmat_fro_loss: 0.0021 - global_gradnorm: 13.6612 - tot_time: 0h 5m 45.8s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 0.0668 - mse: 0.0083 - NMSE: 0.0749 - NMSE_wt: 0.0607 - covmat_fro_loss: 0.0020 - global_gradnorm: 13.5701 - val_loss: 0.1622 - val_mse: 0.0211 - val_NMSE: 0.1903 - val_NMSE_wt: 0.1561 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0966 - mse: 0.0125 - NMSE: 0.1123 - NMSE_wt: 0.0905 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.7481 - tot_time: 0h 5m 48.1s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 0.0966 - mse: 0.0125 - NMSE: 0.1123 - NMSE_wt: 0.0905 - covmat_fro_loss: 0.0024 - global_gradnorm: 15.8710 - val_loss: 0.1279 - val_mse: 0.0163 - val_NMSE: 0.1470 - val_NMSE_wt: 0.1217 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0771 - mse: 0.0097 - NMSE: 0.0871 - NMSE_wt: 0.0710 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.8793 - tot_time: 0h 5m 50.5s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0771 - mse: 0.0097 - NMSE: 0.0871 - NMSE_wt: 0.0710 - covmat_fro_loss: 0.0017 - global_gradnorm: 16.8993 - val_loss: 0.1113 - val_mse: 0.0139 - val_NMSE: 0.1254 - val_NMSE_wt: 0.1051 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0727 - mse: 0.0090 - NMSE: 0.0814 - NMSE_wt: 0.0666 - covmat_fro_loss: 0.0018 - global_gradnorm: 17.2008 - tot_time: 0h 5m 52.9s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0727 - mse: 0.0090 - NMSE: 0.0814 - NMSE_wt: 0.0666 - covmat_fro_loss: 0.0018 - global_gradnorm: 17.5196 - val_loss: 0.1122 - val_mse: 0.0141 - val_NMSE: 0.1266 - val_NMSE_wt: 0.1060 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0709 - mse: 0.0089 - NMSE: 0.0802 - NMSE_wt: 0.0647 - covmat_fro_loss: 0.0019 - global_gradnorm: 17.8870 - tot_time: 0h 5m 55.2s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0709 - mse: 0.0089 - NMSE: 0.0802 - NMSE_wt: 0.0647 - covmat_fro_loss: 0.0018 - global_gradnorm: 18.7246 - val_loss: 0.0907 - val_mse: 0.0112 - val_NMSE: 0.1011 - val_NMSE_wt: 0.0845 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0657 - mse: 0.0081 - NMSE: 0.0726 - NMSE_wt: 0.0595 - covmat_fro_loss: 0.0016 - global_gradnorm: 13.9016 - tot_time: 0h 5m 57.6s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0657 - mse: 0.0081 - NMSE: 0.0726 - NMSE_wt: 0.0595 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.1015 - val_loss: 0.1045 - val_mse: 0.0132 - val_NMSE: 0.1186 - val_NMSE_wt: 0.0984 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0649 - mse: 0.0080 - NMSE: 0.0721 - NMSE_wt: 0.0588 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.6731 - tot_time: 0h 5m 60.0s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0649 - mse: 0.0080 - NMSE: 0.0721 - NMSE_wt: 0.0588 - covmat_fro_loss: 0.0016 - global_gradnorm: 12.8223 - val_loss: 0.0501 - val_mse: 0.0060 - val_NMSE: 0.0539 - val_NMSE_wt: 0.0440 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0767 - mse: 0.0096 - NMSE: 0.0865 - NMSE_wt: 0.0706 - covmat_fro_loss: 0.0017 - global_gradnorm: 14.5551 - tot_time: 0h 6m 2.3s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0767 - mse: 0.0096 - NMSE: 0.0865 - NMSE_wt: 0.0706 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.6956 - val_loss: 0.0774 - val_mse: 0.0094 - val_NMSE: 0.0842 - val_NMSE_wt: 0.0713 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0867 - mse: 0.0110 - NMSE: 0.0986 - NMSE_wt: 0.0806 - covmat_fro_loss: 0.0020 - global_gradnorm: 17.6832 - tot_time: 0h 6m 4.7s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 0.0867 - mse: 0.0110 - NMSE: 0.0986 - NMSE_wt: 0.0806 - covmat_fro_loss: 0.0019 - global_gradnorm: 16.1916 - val_loss: 0.0746 - val_mse: 0.0095 - val_NMSE: 0.0853 - val_NMSE_wt: 0.0685 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0839 - mse: 0.0106 - NMSE: 0.0950 - NMSE_wt: 0.0777 - covmat_fro_loss: 0.0018 - global_gradnorm: 15.7116 - tot_time: 0h 6m 7.0s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0839 - mse: 0.0106 - NMSE: 0.0950 - NMSE_wt: 0.0777 - covmat_fro_loss: 0.0017 - global_gradnorm: 15.3611 - val_loss: 0.1147 - val_mse: 0.0147 - val_NMSE: 0.1321 - val_NMSE_wt: 0.1086 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0918 - mse: 0.0116 - NMSE: 0.1048 - NMSE_wt: 0.0856 - covmat_fro_loss: 0.0023 - global_gradnorm: 17.6186 - tot_time: 0h 6m 9.4s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0918 - mse: 0.0116 - NMSE: 0.1048 - NMSE_wt: 0.0856 - covmat_fro_loss: 0.0022 - global_gradnorm: 16.4446 - val_loss: 0.1482 - val_mse: 0.0192 - val_NMSE: 0.1732 - val_NMSE_wt: 0.1421 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0912 - mse: 0.0117 - NMSE: 0.1049 - NMSE_wt: 0.0851 - covmat_fro_loss: 0.0026 - global_gradnorm: 11.7831 - tot_time: 0h 6m 11.8s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0912 - mse: 0.0117 - NMSE: 0.1049 - NMSE_wt: 0.0851 - covmat_fro_loss: 0.0024 - global_gradnorm: 11.5589 - val_loss: 0.1065 - val_mse: 0.0137 - val_NMSE: 0.1234 - val_NMSE_wt: 0.1004 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0721 - mse: 0.0091 - NMSE: 0.0821 - NMSE_wt: 0.0659 - covmat_fro_loss: 0.0024 - global_gradnorm: 14.8837 - tot_time: 0h 6m 14.0s\n",
      "\n",
      "Epoch 41: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 0.0721 - mse: 0.0091 - NMSE: 0.0821 - NMSE_wt: 0.0659 - covmat_fro_loss: 0.0023 - global_gradnorm: 14.4788 - val_loss: 0.0562 - val_mse: 0.0068 - val_NMSE: 0.0611 - val_NMSE_wt: 0.0501 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1136 - mse: 0.0148 - NMSE: 0.1333 - NMSE_wt: 0.1075 - covmat_fro_loss: 0.0031 - global_gradnorm: 22.5087 - tot_time: 0h 6m 16.2s\n",
      "\n",
      "Epoch 42: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 213ms/step - loss: 0.1136 - mse: 0.0148 - NMSE: 0.1333 - NMSE_wt: 0.1075 - covmat_fro_loss: 0.0029 - global_gradnorm: 22.9261 - val_loss: 0.1559 - val_mse: 0.0202 - val_NMSE: 0.1818 - val_NMSE_wt: 0.1498 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1003 - mse: 0.0130 - NMSE: 0.1171 - NMSE_wt: 0.0942 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.8660 - tot_time: 0h 6m 18.4s\n",
      "\n",
      "Epoch 43: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.1003 - mse: 0.0130 - NMSE: 0.1171 - NMSE_wt: 0.0942 - covmat_fro_loss: 0.0034 - global_gradnorm: 15.9782 - val_loss: 0.1338 - val_mse: 0.0171 - val_NMSE: 0.1540 - val_NMSE_wt: 0.1277 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0784 - mse: 0.0099 - NMSE: 0.0892 - NMSE_wt: 0.0723 - covmat_fro_loss: 0.0022 - global_gradnorm: 18.2528Restoring model weights from the end of the best epoch: 24.\n",
      " - tot_time: 0h 6m 20.8s\n",
      "\n",
      "Epoch 44: val_NMSE_wt did not improve from 0.02719\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-15_outsteps\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.0784 - mse: 0.0099 - NMSE: 0.0892 - NMSE_wt: 0.0723 - covmat_fro_loss: 0.0021 - global_gradnorm: 18.9768 - val_loss: 0.0944 - val_mse: 0.0118 - val_NMSE: 0.1063 - val_NMSE_wt: 0.0883 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 44: early stopping\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>> num_outsteps : 20 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "clipnorm : None, global_clipnorm : 21.200000000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 50s 50s/step - loss: 0.0279 - mse: 0.0032 - NMSE: 0.0290 - NMSE_wt: 0.0218 - covmat_fro_loss: 0.0000e+00 - global_gradnorm: 0.0000e+00\n",
      "baseline : 2.1773E-02\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-06 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1476 - mse: 0.0212 - NMSE: 0.1907 - NMSE_wt: 0.1415 - covmat_fro_loss: 0.0035 - global_gradnorm: 13.4186 - tot_time: 0h 2m 21.9s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 142s 312ms/step - loss: 0.1476 - mse: 0.0212 - NMSE: 0.1907 - NMSE_wt: 0.1415 - covmat_fro_loss: 0.0033 - global_gradnorm: 12.6484 - val_loss: 0.0344 - val_mse: 0.0041 - val_NMSE: 0.0368 - val_NMSE_wt: 0.0283 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1267 - mse: 0.0179 - NMSE: 0.1614 - NMSE_wt: 0.1206 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.1833 - tot_time: 0h 2m 24.3s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.1267 - mse: 0.0179 - NMSE: 0.1614 - NMSE_wt: 0.1206 - covmat_fro_loss: 0.0036 - global_gradnorm: 14.9630 - val_loss: 0.0337 - val_mse: 0.0040 - val_NMSE: 0.0359 - val_NMSE_wt: 0.0275 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1185 - mse: 0.0168 - NMSE: 0.1509 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0026 - global_gradnorm: 16.9256 - tot_time: 0h 2m 26.7s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 307ms/step - loss: 0.1185 - mse: 0.0168 - NMSE: 0.1509 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0025 - global_gradnorm: 16.4067 - val_loss: 0.0289 - val_mse: 0.0033 - val_NMSE: 0.0301 - val_NMSE_wt: 0.0227 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1451 - mse: 0.0206 - NMSE: 0.1855 - NMSE_wt: 0.1390 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.4039 - tot_time: 0h 2m 29.1s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1451 - mse: 0.0206 - NMSE: 0.1855 - NMSE_wt: 0.1390 - covmat_fro_loss: 0.0035 - global_gradnorm: 16.0479 - val_loss: 0.0360 - val_mse: 0.0042 - val_NMSE: 0.0382 - val_NMSE_wt: 0.0299 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1185 - mse: 0.0167 - NMSE: 0.1505 - NMSE_wt: 0.1124 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.7206 - tot_time: 0h 2m 31.5s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.1185 - mse: 0.0167 - NMSE: 0.1505 - NMSE_wt: 0.1124 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.1910 - val_loss: 0.0328 - val_mse: 0.0039 - val_NMSE: 0.0351 - val_NMSE_wt: 0.0267 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1201 - mse: 0.0170 - NMSE: 0.1532 - NMSE_wt: 0.1140 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.1981 - tot_time: 0h 2m 33.8s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.1201 - mse: 0.0170 - NMSE: 0.1532 - NMSE_wt: 0.1140 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.8650 - val_loss: 0.0293 - val_mse: 0.0034 - val_NMSE: 0.0307 - val_NMSE_wt: 0.0231 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1227 - mse: 0.0174 - NMSE: 0.1564 - NMSE_wt: 0.1166 - covmat_fro_loss: 0.0028 - global_gradnorm: 13.7948 - tot_time: 0h 2m 36.2s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.02177\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.1227 - mse: 0.0174 - NMSE: 0.1564 - NMSE_wt: 0.1166 - covmat_fro_loss: 0.0028 - global_gradnorm: 14.6176 - val_loss: 0.0378 - val_mse: 0.0045 - val_NMSE: 0.0407 - val_NMSE_wt: 0.0317 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1161 - mse: 0.0163 - NMSE: 0.1468 - NMSE_wt: 0.1099 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.5964 - tot_time: 0h 2m 38.6s\n",
      "\n",
      "Epoch 8: val_NMSE_wt improved from 0.02177 to 0.02081, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-20_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.1161 - mse: 0.0163 - NMSE: 0.1468 - NMSE_wt: 0.1099 - covmat_fro_loss: 0.0025 - global_gradnorm: 15.3302 - val_loss: 0.0269 - val_mse: 0.0031 - val_NMSE: 0.0278 - val_NMSE_wt: 0.0208 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1226 - mse: 0.0173 - NMSE: 0.1560 - NMSE_wt: 0.1165 - covmat_fro_loss: 0.0026 - global_gradnorm: 12.7006 - tot_time: 0h 2m 41.1s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 0.1226 - mse: 0.0173 - NMSE: 0.1560 - NMSE_wt: 0.1165 - covmat_fro_loss: 0.0030 - global_gradnorm: 13.6450 - val_loss: 0.0401 - val_mse: 0.0047 - val_NMSE: 0.0425 - val_NMSE_wt: 0.0340 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1189 - mse: 0.0168 - NMSE: 0.1512 - NMSE_wt: 0.1128 - covmat_fro_loss: 0.0026 - global_gradnorm: 12.0649 - tot_time: 0h 2m 43.3s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.1189 - mse: 0.0168 - NMSE: 0.1512 - NMSE_wt: 0.1128 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.0799 - val_loss: 0.0844 - val_mse: 0.0110 - val_NMSE: 0.0993 - val_NMSE_wt: 0.0782 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1200 - mse: 0.0171 - NMSE: 0.1537 - NMSE_wt: 0.1139 - covmat_fro_loss: 0.0030 - global_gradnorm: 17.1499 - tot_time: 0h 2m 45.5s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.02081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 0.1200 - mse: 0.0171 - NMSE: 0.1537 - NMSE_wt: 0.1139 - covmat_fro_loss: 0.0032 - global_gradnorm: 17.5999 - val_loss: 0.0336 - val_mse: 0.0040 - val_NMSE: 0.0361 - val_NMSE_wt: 0.0274 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1189 - mse: 0.0167 - NMSE: 0.1506 - NMSE_wt: 0.1127 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.0176 - tot_time: 0h 2m 47.9s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1189 - mse: 0.0167 - NMSE: 0.1506 - NMSE_wt: 0.1127 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.8156 - val_loss: 0.0695 - val_mse: 0.0096 - val_NMSE: 0.0867 - val_NMSE_wt: 0.0633 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1236 - mse: 0.0174 - NMSE: 0.1565 - NMSE_wt: 0.1174 - covmat_fro_loss: 0.0027 - global_gradnorm: 16.4075 - tot_time: 0h 2m 50.3s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.1236 - mse: 0.0174 - NMSE: 0.1565 - NMSE_wt: 0.1174 - covmat_fro_loss: 0.0028 - global_gradnorm: 16.9400 - val_loss: 0.0327 - val_mse: 0.0039 - val_NMSE: 0.0353 - val_NMSE_wt: 0.0266 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1303 - mse: 0.0185 - NMSE: 0.1667 - NMSE_wt: 0.1242 - covmat_fro_loss: 0.0028 - global_gradnorm: 20.5716 - tot_time: 0h 2m 52.7s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1303 - mse: 0.0185 - NMSE: 0.1667 - NMSE_wt: 0.1242 - covmat_fro_loss: 0.0028 - global_gradnorm: 20.6414 - val_loss: 0.0469 - val_mse: 0.0061 - val_NMSE: 0.0545 - val_NMSE_wt: 0.0407 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1292 - mse: 0.0185 - NMSE: 0.1665 - NMSE_wt: 0.1231 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.8123 - tot_time: 0h 2m 55.1s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1292 - mse: 0.0185 - NMSE: 0.1665 - NMSE_wt: 0.1231 - covmat_fro_loss: 0.0031 - global_gradnorm: 15.5220 - val_loss: 0.0340 - val_mse: 0.0041 - val_NMSE: 0.0368 - val_NMSE_wt: 0.0279 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1402 - mse: 0.0198 - NMSE: 0.1783 - NMSE_wt: 0.1341 - covmat_fro_loss: 0.0038 - global_gradnorm: 18.1571 - tot_time: 0h 2m 57.5s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1402 - mse: 0.0198 - NMSE: 0.1783 - NMSE_wt: 0.1341 - covmat_fro_loss: 0.0036 - global_gradnorm: 18.4952 - val_loss: 0.0294 - val_mse: 0.0034 - val_NMSE: 0.0305 - val_NMSE_wt: 0.0232 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1272 - mse: 0.0181 - NMSE: 0.1626 - NMSE_wt: 0.1211 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.7003 - tot_time: 0h 2m 59.8s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.1272 - mse: 0.0181 - NMSE: 0.1626 - NMSE_wt: 0.1211 - covmat_fro_loss: 0.0028 - global_gradnorm: 13.8966 - val_loss: 0.1963 - val_mse: 0.0285 - val_NMSE: 0.2566 - val_NMSE_wt: 0.1902 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1085 - mse: 0.0152 - NMSE: 0.1364 - NMSE_wt: 0.1024 - covmat_fro_loss: 0.0024 - global_gradnorm: 15.2571 - tot_time: 0h 3m 2.2s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1085 - mse: 0.0152 - NMSE: 0.1364 - NMSE_wt: 0.1024 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.9174 - val_loss: 0.0508 - val_mse: 0.0067 - val_NMSE: 0.0600 - val_NMSE_wt: 0.0447 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1116 - mse: 0.0156 - NMSE: 0.1403 - NMSE_wt: 0.1054 - covmat_fro_loss: 0.0022 - global_gradnorm: 16.1230 - tot_time: 0h 3m 4.5s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.02081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1116 - mse: 0.0156 - NMSE: 0.1403 - NMSE_wt: 0.1054 - covmat_fro_loss: 0.0023 - global_gradnorm: 16.6871 - val_loss: 0.0653 - val_mse: 0.0087 - val_NMSE: 0.0786 - val_NMSE_wt: 0.0592 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1287 - mse: 0.0184 - NMSE: 0.1657 - NMSE_wt: 0.1226 - covmat_fro_loss: 0.0032 - global_gradnorm: 15.4761 - tot_time: 0h 3m 6.9s\n",
      "\n",
      "Epoch 20: val_NMSE_wt improved from 0.02081 to 0.01931, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/checkpoint-20_outsteps\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.1287 - mse: 0.0184 - NMSE: 0.1657 - NMSE_wt: 0.1226 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.0801 - val_loss: 0.0254 - val_mse: 0.0028 - val_NMSE: 0.0255 - val_NMSE_wt: 0.0193 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1189 - mse: 0.0168 - NMSE: 0.1512 - NMSE_wt: 0.1127 - covmat_fro_loss: 0.0026 - global_gradnorm: 14.4829 - tot_time: 0h 3m 10.2s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1189 - mse: 0.0168 - NMSE: 0.1512 - NMSE_wt: 0.1127 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.2292 - val_loss: 0.0381 - val_mse: 0.0047 - val_NMSE: 0.0424 - val_NMSE_wt: 0.0320 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1238 - mse: 0.0177 - NMSE: 0.1591 - NMSE_wt: 0.1177 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.1763 - tot_time: 0h 3m 12.5s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 0.1238 - mse: 0.0177 - NMSE: 0.1591 - NMSE_wt: 0.1177 - covmat_fro_loss: 0.0031 - global_gradnorm: 14.9567 - val_loss: 0.0640 - val_mse: 0.0085 - val_NMSE: 0.0763 - val_NMSE_wt: 0.0579 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1325 - mse: 0.0188 - NMSE: 0.1692 - NMSE_wt: 0.1264 - covmat_fro_loss: 0.0028 - global_gradnorm: 16.9352 - tot_time: 0h 3m 14.6s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 0.1325 - mse: 0.0188 - NMSE: 0.1692 - NMSE_wt: 0.1264 - covmat_fro_loss: 0.0028 - global_gradnorm: 17.4091 - val_loss: 0.0293 - val_mse: 0.0033 - val_NMSE: 0.0301 - val_NMSE_wt: 0.0232 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1610 - mse: 0.0229 - NMSE: 0.2063 - NMSE_wt: 0.1549 - covmat_fro_loss: 0.0043 - global_gradnorm: 15.6964 - tot_time: 0h 3m 16.9s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.1610 - mse: 0.0229 - NMSE: 0.2063 - NMSE_wt: 0.1549 - covmat_fro_loss: 0.0041 - global_gradnorm: 16.3079 - val_loss: 0.0483 - val_mse: 0.0063 - val_NMSE: 0.0567 - val_NMSE_wt: 0.0422 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1156 - mse: 0.0162 - NMSE: 0.1459 - NMSE_wt: 0.1095 - covmat_fro_loss: 0.0024 - global_gradnorm: 11.8652 - tot_time: 0h 3m 19.3s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1156 - mse: 0.0162 - NMSE: 0.1459 - NMSE_wt: 0.1095 - covmat_fro_loss: 0.0023 - global_gradnorm: 10.6809 - val_loss: 0.0297 - val_mse: 0.0035 - val_NMSE: 0.0311 - val_NMSE_wt: 0.0235 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1124 - mse: 0.0159 - NMSE: 0.1432 - NMSE_wt: 0.1062 - covmat_fro_loss: 0.0026 - global_gradnorm: 11.7692 - tot_time: 0h 3m 21.7s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1124 - mse: 0.0159 - NMSE: 0.1432 - NMSE_wt: 0.1062 - covmat_fro_loss: 0.0029 - global_gradnorm: 12.8170 - val_loss: 0.0464 - val_mse: 0.0058 - val_NMSE: 0.0522 - val_NMSE_wt: 0.0403 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1206 - mse: 0.0170 - NMSE: 0.1533 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0030 - global_gradnorm: 13.2262 - tot_time: 0h 3m 24.0s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.1206 - mse: 0.0170 - NMSE: 0.1533 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0028 - global_gradnorm: 14.1122 - val_loss: 0.0582 - val_mse: 0.0074 - val_NMSE: 0.0667 - val_NMSE_wt: 0.0521 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1489 - mse: 0.0213 - NMSE: 0.1921 - NMSE_wt: 0.1428 - covmat_fro_loss: 0.0038 - global_gradnorm: 11.9320 - tot_time: 0h 3m 26.4s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.1489 - mse: 0.0213 - NMSE: 0.1921 - NMSE_wt: 0.1428 - covmat_fro_loss: 0.0036 - global_gradnorm: 10.9363 - val_loss: 0.0794 - val_mse: 0.0104 - val_NMSE: 0.0940 - val_NMSE_wt: 0.0733 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1131 - mse: 0.0159 - NMSE: 0.1427 - NMSE_wt: 0.1070 - covmat_fro_loss: 0.0025 - global_gradnorm: 15.0025 - tot_time: 0h 3m 28.7s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.1131 - mse: 0.0159 - NMSE: 0.1427 - NMSE_wt: 0.1070 - covmat_fro_loss: 0.0024 - global_gradnorm: 13.6370 - val_loss: 0.0550 - val_mse: 0.0069 - val_NMSE: 0.0620 - val_NMSE_wt: 0.0489 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1162 - mse: 0.0164 - NMSE: 0.1477 - NMSE_wt: 0.1101 - covmat_fro_loss: 0.0025 - global_gradnorm: 15.9613 - tot_time: 0h 3m 31.1s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1162 - mse: 0.0164 - NMSE: 0.1477 - NMSE_wt: 0.1101 - covmat_fro_loss: 0.0025 - global_gradnorm: 16.5434 - val_loss: 0.0461 - val_mse: 0.0060 - val_NMSE: 0.0536 - val_NMSE_wt: 0.0400 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1206 - mse: 0.0169 - NMSE: 0.1521 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0023 - global_gradnorm: 16.1406 - tot_time: 0h 3m 33.5s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.1206 - mse: 0.0169 - NMSE: 0.1521 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0024 - global_gradnorm: 16.7027 - val_loss: 0.0342 - val_mse: 0.0041 - val_NMSE: 0.0366 - val_NMSE_wt: 0.0281 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1248 - mse: 0.0177 - NMSE: 0.1596 - NMSE_wt: 0.1186 - covmat_fro_loss: 0.0031 - global_gradnorm: 14.4003 - tot_time: 0h 3m 36.0s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 306ms/step - loss: 0.1248 - mse: 0.0177 - NMSE: 0.1596 - NMSE_wt: 0.1186 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.1558 - val_loss: 0.0363 - val_mse: 0.0044 - val_NMSE: 0.0397 - val_NMSE_wt: 0.0302 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1194 - mse: 0.0166 - NMSE: 0.1498 - NMSE_wt: 0.1133 - covmat_fro_loss: 0.0023 - global_gradnorm: 15.3049 - tot_time: 0h 3m 38.4s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 305ms/step - loss: 0.1194 - mse: 0.0166 - NMSE: 0.1498 - NMSE_wt: 0.1133 - covmat_fro_loss: 0.0024 - global_gradnorm: 15.9599 - val_loss: 0.0303 - val_mse: 0.0035 - val_NMSE: 0.0318 - val_NMSE_wt: 0.0242 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.1446 - mse: 0.0206 - NMSE: 0.1851 - NMSE_wt: 0.1384 - covmat_fro_loss: 0.0041 - global_gradnorm: 17.2951 - tot_time: 0h 3m 40.8s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1446 - mse: 0.0206 - NMSE: 0.1851 - NMSE_wt: 0.1384 - covmat_fro_loss: 0.0040 - global_gradnorm: 17.3285 - val_loss: 0.2093 - val_mse: 0.0304 - val_NMSE: 0.2737 - val_NMSE_wt: 0.2031 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1385 - mse: 0.0195 - NMSE: 0.1754 - NMSE_wt: 0.1324 - covmat_fro_loss: 0.0024 - global_gradnorm: 13.0902 - tot_time: 0h 3m 43.2s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1385 - mse: 0.0195 - NMSE: 0.1754 - NMSE_wt: 0.1324 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.0440 - val_loss: 0.0315 - val_mse: 0.0037 - val_NMSE: 0.0337 - val_NMSE_wt: 0.0253 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1254 - mse: 0.0177 - NMSE: 0.1591 - NMSE_wt: 0.1192 - covmat_fro_loss: 0.0026 - global_gradnorm: 11.7031 - tot_time: 0h 3m 45.3s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.1254 - mse: 0.0177 - NMSE: 0.1591 - NMSE_wt: 0.1192 - covmat_fro_loss: 0.0026 - global_gradnorm: 10.9066 - val_loss: 0.0488 - val_mse: 0.0061 - val_NMSE: 0.0545 - val_NMSE_wt: 0.0426 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1214 - mse: 0.0170 - NMSE: 0.1531 - NMSE_wt: 0.1153 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.2762 - tot_time: 0h 3m 47.4s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 0.1214 - mse: 0.0170 - NMSE: 0.1531 - NMSE_wt: 0.1153 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.1566 - val_loss: 0.0521 - val_mse: 0.0067 - val_NMSE: 0.0602 - val_NMSE_wt: 0.0459 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1404 - mse: 0.0200 - NMSE: 0.1797 - NMSE_wt: 0.1343 - covmat_fro_loss: 0.0035 - global_gradnorm: 16.2477 - tot_time: 0h 3m 49.8s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1404 - mse: 0.0200 - NMSE: 0.1797 - NMSE_wt: 0.1343 - covmat_fro_loss: 0.0033 - global_gradnorm: 16.4319 - val_loss: 0.0531 - val_mse: 0.0069 - val_NMSE: 0.0625 - val_NMSE_wt: 0.0469 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1631 - mse: 0.0232 - NMSE: 0.2091 - NMSE_wt: 0.1569 - covmat_fro_loss: 0.0041 - global_gradnorm: 18.7416 - tot_time: 0h 3m 52.2s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1631 - mse: 0.0232 - NMSE: 0.2091 - NMSE_wt: 0.1569 - covmat_fro_loss: 0.0041 - global_gradnorm: 19.0147 - val_loss: 0.0326 - val_mse: 0.0039 - val_NMSE: 0.0349 - val_NMSE_wt: 0.0265 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1179 - mse: 0.0166 - NMSE: 0.1497 - NMSE_wt: 0.1117 - covmat_fro_loss: 0.0026 - global_gradnorm: 18.7620Restoring model weights from the end of the best epoch: 20.\n",
      " - tot_time: 0h 3m 54.6s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1179 - mse: 0.0166 - NMSE: 0.1497 - NMSE_wt: 0.1117 - covmat_fro_loss: 0.0025 - global_gradnorm: 18.9922 - val_loss: 0.0450 - val_mse: 0.0056 - val_NMSE: 0.0505 - val_NMSE_wt: 0.0388 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 5e-07 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1417 - mse: 0.0202 - NMSE: 0.1818 - NMSE_wt: 0.1356 - covmat_fro_loss: 0.0032 - global_gradnorm: 14.7069 - tot_time: 0h 3m 57.1s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 315ms/step - loss: 0.1417 - mse: 0.0202 - NMSE: 0.1818 - NMSE_wt: 0.1356 - covmat_fro_loss: 0.0032 - global_gradnorm: 15.4284 - val_loss: 0.0340 - val_mse: 0.0040 - val_NMSE: 0.0362 - val_NMSE_wt: 0.0279 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1327 - mse: 0.0188 - NMSE: 0.1693 - NMSE_wt: 0.1265 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.7237 - tot_time: 0h 3m 59.5s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1327 - mse: 0.0188 - NMSE: 0.1693 - NMSE_wt: 0.1265 - covmat_fro_loss: 0.0032 - global_gradnorm: 16.3321 - val_loss: 0.0358 - val_mse: 0.0043 - val_NMSE: 0.0390 - val_NMSE_wt: 0.0297 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1225 - mse: 0.0174 - NMSE: 0.1562 - NMSE_wt: 0.1164 - covmat_fro_loss: 0.0027 - global_gradnorm: 17.2869 - tot_time: 0h 4m 2.0s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 310ms/step - loss: 0.1225 - mse: 0.0174 - NMSE: 0.1562 - NMSE_wt: 0.1164 - covmat_fro_loss: 0.0026 - global_gradnorm: 16.9677 - val_loss: 0.0289 - val_mse: 0.0034 - val_NMSE: 0.0303 - val_NMSE_wt: 0.0228 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1448 - mse: 0.0205 - NMSE: 0.1845 - NMSE_wt: 0.1387 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.4728 - tot_time: 0h 4m 4.3s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1448 - mse: 0.0205 - NMSE: 0.1845 - NMSE_wt: 0.1387 - covmat_fro_loss: 0.0027 - global_gradnorm: 14.3314 - val_loss: 0.0504 - val_mse: 0.0065 - val_NMSE: 0.0585 - val_NMSE_wt: 0.0443 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1259 - mse: 0.0178 - NMSE: 0.1602 - NMSE_wt: 0.1198 - covmat_fro_loss: 0.0027 - global_gradnorm: 18.0184 - tot_time: 0h 4m 6.7s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1259 - mse: 0.0178 - NMSE: 0.1602 - NMSE_wt: 0.1198 - covmat_fro_loss: 0.0027 - global_gradnorm: 18.1747 - val_loss: 0.0388 - val_mse: 0.0048 - val_NMSE: 0.0433 - val_NMSE_wt: 0.0327 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1067 - mse: 0.0149 - NMSE: 0.1343 - NMSE_wt: 0.1006 - covmat_fro_loss: 0.0024 - global_gradnorm: 10.9546 - tot_time: 0h 4m 9.1s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 305ms/step - loss: 0.1067 - mse: 0.0149 - NMSE: 0.1343 - NMSE_wt: 0.1006 - covmat_fro_loss: 0.0023 - global_gradnorm: 10.4987 - val_loss: 0.0309 - val_mse: 0.0036 - val_NMSE: 0.0328 - val_NMSE_wt: 0.0248 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1236 - mse: 0.0175 - NMSE: 0.1578 - NMSE_wt: 0.1175 - covmat_fro_loss: 0.0027 - global_gradnorm: 14.4379 - tot_time: 0h 4m 11.5s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1236 - mse: 0.0175 - NMSE: 0.1578 - NMSE_wt: 0.1175 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.1892 - val_loss: 0.0391 - val_mse: 0.0047 - val_NMSE: 0.0426 - val_NMSE_wt: 0.0330 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1263 - mse: 0.0180 - NMSE: 0.1616 - NMSE_wt: 0.1202 - covmat_fro_loss: 0.0030 - global_gradnorm: 16.0337 - tot_time: 0h 4m 13.9s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1263 - mse: 0.0180 - NMSE: 0.1616 - NMSE_wt: 0.1202 - covmat_fro_loss: 0.0030 - global_gradnorm: 16.6078 - val_loss: 0.0301 - val_mse: 0.0036 - val_NMSE: 0.0321 - val_NMSE_wt: 0.0239 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1387 - mse: 0.0197 - NMSE: 0.1771 - NMSE_wt: 0.1326 - covmat_fro_loss: 0.0030 - global_gradnorm: 13.9784 - tot_time: 0h 4m 16.2s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 0.1387 - mse: 0.0197 - NMSE: 0.1771 - NMSE_wt: 0.1326 - covmat_fro_loss: 0.0033 - global_gradnorm: 14.7808 - val_loss: 0.0365 - val_mse: 0.0043 - val_NMSE: 0.0384 - val_NMSE_wt: 0.0304 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1362 - mse: 0.0195 - NMSE: 0.1751 - NMSE_wt: 0.1301 - covmat_fro_loss: 0.0033 - global_gradnorm: 12.2736 - tot_time: 0h 4m 18.3s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 0.1362 - mse: 0.0195 - NMSE: 0.1751 - NMSE_wt: 0.1301 - covmat_fro_loss: 0.0032 - global_gradnorm: 11.3611 - val_loss: 0.0557 - val_mse: 0.0069 - val_NMSE: 0.0617 - val_NMSE_wt: 0.0495 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0993 - mse: 0.0138 - NMSE: 0.1246 - NMSE_wt: 0.0931 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.6608 - tot_time: 0h 4m 20.5s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.0993 - mse: 0.0138 - NMSE: 0.1246 - NMSE_wt: 0.0931 - covmat_fro_loss: 0.0024 - global_gradnorm: 14.4985 - val_loss: 0.0378 - val_mse: 0.0047 - val_NMSE: 0.0420 - val_NMSE_wt: 0.0317 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1220 - mse: 0.0172 - NMSE: 0.1551 - NMSE_wt: 0.1159 - covmat_fro_loss: 0.0027 - global_gradnorm: 12.9351 - tot_time: 0h 4m 22.9s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1220 - mse: 0.0172 - NMSE: 0.1551 - NMSE_wt: 0.1159 - covmat_fro_loss: 0.0026 - global_gradnorm: 12.1781 - val_loss: 0.0736 - val_mse: 0.0102 - val_NMSE: 0.0922 - val_NMSE_wt: 0.0674 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1300 - mse: 0.0183 - NMSE: 0.1651 - NMSE_wt: 0.1239 - covmat_fro_loss: 0.0028 - global_gradnorm: 14.2553 - tot_time: 0h 4m 25.2s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 291ms/step - loss: 0.1300 - mse: 0.0183 - NMSE: 0.1651 - NMSE_wt: 0.1239 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.0269 - val_loss: 0.0319 - val_mse: 0.0038 - val_NMSE: 0.0341 - val_NMSE_wt: 0.0258 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1369 - mse: 0.0194 - NMSE: 0.1749 - NMSE_wt: 0.1307 - covmat_fro_loss: 0.0030 - global_gradnorm: 19.1277 - tot_time: 0h 4m 27.6s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1369 - mse: 0.0194 - NMSE: 0.1749 - NMSE_wt: 0.1307 - covmat_fro_loss: 0.0030 - global_gradnorm: 18.2951 - val_loss: 0.0431 - val_mse: 0.0054 - val_NMSE: 0.0484 - val_NMSE_wt: 0.0370 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1377 - mse: 0.0198 - NMSE: 0.1780 - NMSE_wt: 0.1316 - covmat_fro_loss: 0.0031 - global_gradnorm: 12.3957 - tot_time: 0h 4m 30.0s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1377 - mse: 0.0198 - NMSE: 0.1780 - NMSE_wt: 0.1316 - covmat_fro_loss: 0.0033 - global_gradnorm: 13.3739 - val_loss: 0.0352 - val_mse: 0.0043 - val_NMSE: 0.0385 - val_NMSE_wt: 0.0291 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1315 - mse: 0.0185 - NMSE: 0.1667 - NMSE_wt: 0.1254 - covmat_fro_loss: 0.0039 - global_gradnorm: 15.5503 - tot_time: 0h 4m 32.4s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.01931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1315 - mse: 0.0185 - NMSE: 0.1667 - NMSE_wt: 0.1254 - covmat_fro_loss: 0.0037 - global_gradnorm: 15.0959 - val_loss: 0.0295 - val_mse: 0.0034 - val_NMSE: 0.0306 - val_NMSE_wt: 0.0234 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1550 - mse: 0.0224 - NMSE: 0.2012 - NMSE_wt: 0.1488 - covmat_fro_loss: 0.0041 - global_gradnorm: 16.7671 - tot_time: 0h 4m 34.7s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1550 - mse: 0.0224 - NMSE: 0.2012 - NMSE_wt: 0.1488 - covmat_fro_loss: 0.0040 - global_gradnorm: 17.2596 - val_loss: 0.0681 - val_mse: 0.0087 - val_NMSE: 0.0787 - val_NMSE_wt: 0.0620 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1118 - mse: 0.0157 - NMSE: 0.1414 - NMSE_wt: 0.1057 - covmat_fro_loss: 0.0027 - global_gradnorm: 13.5242 - tot_time: 0h 4m 37.1s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1118 - mse: 0.0157 - NMSE: 0.1414 - NMSE_wt: 0.1057 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.3771 - val_loss: 0.0486 - val_mse: 0.0063 - val_NMSE: 0.0566 - val_NMSE_wt: 0.0425 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1240 - mse: 0.0175 - NMSE: 0.1575 - NMSE_wt: 0.1179 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.0433 - tot_time: 0h 4m 39.5s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1240 - mse: 0.0175 - NMSE: 0.1575 - NMSE_wt: 0.1179 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.7274 - val_loss: 0.0587 - val_mse: 0.0078 - val_NMSE: 0.0699 - val_NMSE_wt: 0.0525 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1426 - mse: 0.0206 - NMSE: 0.1852 - NMSE_wt: 0.1365 - covmat_fro_loss: 0.0037 - global_gradnorm: 20.0577 - tot_time: 0h 4m 41.9s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.1426 - mse: 0.0206 - NMSE: 0.1852 - NMSE_wt: 0.1365 - covmat_fro_loss: 0.0035 - global_gradnorm: 20.1292 - val_loss: 0.0266 - val_mse: 0.0030 - val_NMSE: 0.0270 - val_NMSE_wt: 0.0205 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1230 - mse: 0.0174 - NMSE: 0.1568 - NMSE_wt: 0.1169 - covmat_fro_loss: 0.0029 - global_gradnorm: 12.9246 - tot_time: 0h 4m 44.2s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1230 - mse: 0.0174 - NMSE: 0.1568 - NMSE_wt: 0.1169 - covmat_fro_loss: 0.0027 - global_gradnorm: 13.8272 - val_loss: 0.0395 - val_mse: 0.0049 - val_NMSE: 0.0442 - val_NMSE_wt: 0.0334 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1234 - mse: 0.0175 - NMSE: 0.1579 - NMSE_wt: 0.1173 - covmat_fro_loss: 0.0028 - global_gradnorm: 15.5309 - tot_time: 0h 4m 46.6s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1234 - mse: 0.0175 - NMSE: 0.1579 - NMSE_wt: 0.1173 - covmat_fro_loss: 0.0028 - global_gradnorm: 16.1608 - val_loss: 0.0788 - val_mse: 0.0106 - val_NMSE: 0.0952 - val_NMSE_wt: 0.0726 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1382 - mse: 0.0197 - NMSE: 0.1773 - NMSE_wt: 0.1321 - covmat_fro_loss: 0.0031 - global_gradnorm: 19.0690 - tot_time: 0h 4m 48.9s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 287ms/step - loss: 0.1382 - mse: 0.0197 - NMSE: 0.1773 - NMSE_wt: 0.1321 - covmat_fro_loss: 0.0030 - global_gradnorm: 18.9124 - val_loss: 0.0306 - val_mse: 0.0035 - val_NMSE: 0.0318 - val_NMSE_wt: 0.0244 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1125 - mse: 0.0157 - NMSE: 0.1414 - NMSE_wt: 0.1064 - covmat_fro_loss: 0.0024 - global_gradnorm: 12.6923 - tot_time: 0h 4m 51.0s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 266ms/step - loss: 0.1125 - mse: 0.0157 - NMSE: 0.1414 - NMSE_wt: 0.1064 - covmat_fro_loss: 0.0024 - global_gradnorm: 13.6376 - val_loss: 0.0513 - val_mse: 0.0068 - val_NMSE: 0.0609 - val_NMSE_wt: 0.0452 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1206 - mse: 0.0169 - NMSE: 0.1522 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0026 - global_gradnorm: 13.8430 - tot_time: 0h 4m 53.3s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 284ms/step - loss: 0.1206 - mse: 0.0169 - NMSE: 0.1522 - NMSE_wt: 0.1145 - covmat_fro_loss: 0.0025 - global_gradnorm: 12.4506 - val_loss: 0.0283 - val_mse: 0.0033 - val_NMSE: 0.0293 - val_NMSE_wt: 0.0221 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1165 - mse: 0.0165 - NMSE: 0.1487 - NMSE_wt: 0.1104 - covmat_fro_loss: 0.0025 - global_gradnorm: 11.2990 - tot_time: 0h 4m 55.7s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.1165 - mse: 0.0165 - NMSE: 0.1487 - NMSE_wt: 0.1104 - covmat_fro_loss: 0.0027 - global_gradnorm: 12.3991 - val_loss: 0.0447 - val_mse: 0.0056 - val_NMSE: 0.0501 - val_NMSE_wt: 0.0386 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1031 - mse: 0.0143 - NMSE: 0.1289 - NMSE_wt: 0.0970 - covmat_fro_loss: 0.0023 - global_gradnorm: 15.6619 - tot_time: 0h 4m 58.0s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1031 - mse: 0.0143 - NMSE: 0.1289 - NMSE_wt: 0.0970 - covmat_fro_loss: 0.0023 - global_gradnorm: 16.2772 - val_loss: 0.0390 - val_mse: 0.0047 - val_NMSE: 0.0424 - val_NMSE_wt: 0.0328 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1420 - mse: 0.0202 - NMSE: 0.1822 - NMSE_wt: 0.1359 - covmat_fro_loss: 0.0037 - global_gradnorm: 15.9162 - tot_time: 0h 5m 0.4s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1420 - mse: 0.0202 - NMSE: 0.1822 - NMSE_wt: 0.1359 - covmat_fro_loss: 0.0036 - global_gradnorm: 14.9143 - val_loss: 0.0751 - val_mse: 0.0099 - val_NMSE: 0.0891 - val_NMSE_wt: 0.0690 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1292 - mse: 0.0183 - NMSE: 0.1651 - NMSE_wt: 0.1231 - covmat_fro_loss: 0.0031 - global_gradnorm: 16.5675 - tot_time: 0h 5m 2.8s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 291ms/step - loss: 0.1292 - mse: 0.0183 - NMSE: 0.1651 - NMSE_wt: 0.1231 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.9376 - val_loss: 0.2042 - val_mse: 0.0297 - val_NMSE: 0.2677 - val_NMSE_wt: 0.1980 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1194 - mse: 0.0168 - NMSE: 0.1514 - NMSE_wt: 0.1133 - covmat_fro_loss: 0.0024 - global_gradnorm: 13.5015 - tot_time: 0h 5m 5.1s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.1194 - mse: 0.0168 - NMSE: 0.1514 - NMSE_wt: 0.1133 - covmat_fro_loss: 0.0024 - global_gradnorm: 14.3568 - val_loss: 0.0479 - val_mse: 0.0062 - val_NMSE: 0.0562 - val_NMSE_wt: 0.0417 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1209 - mse: 0.0171 - NMSE: 0.1536 - NMSE_wt: 0.1148 - covmat_fro_loss: 0.0027 - global_gradnorm: 11.7661 - tot_time: 0h 5m 7.5s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1209 - mse: 0.0171 - NMSE: 0.1536 - NMSE_wt: 0.1148 - covmat_fro_loss: 0.0030 - global_gradnorm: 12.8143 - val_loss: 0.0605 - val_mse: 0.0081 - val_NMSE: 0.0731 - val_NMSE_wt: 0.0544 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1096 - mse: 0.0153 - NMSE: 0.1379 - NMSE_wt: 0.1034 - covmat_fro_loss: 0.0024 - global_gradnorm: 14.8730 - tot_time: 0h 5m 9.9s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.1096 - mse: 0.0153 - NMSE: 0.1379 - NMSE_wt: 0.1034 - covmat_fro_loss: 0.0025 - global_gradnorm: 15.5760 - val_loss: 0.0367 - val_mse: 0.0044 - val_NMSE: 0.0399 - val_NMSE_wt: 0.0306 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1307 - mse: 0.0185 - NMSE: 0.1663 - NMSE_wt: 0.1246 - covmat_fro_loss: 0.0029 - global_gradnorm: 18.4010 - tot_time: 0h 5m 12.3s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1307 - mse: 0.0185 - NMSE: 0.1663 - NMSE_wt: 0.1246 - covmat_fro_loss: 0.0032 - global_gradnorm: 18.7120 - val_loss: 0.0392 - val_mse: 0.0049 - val_NMSE: 0.0438 - val_NMSE_wt: 0.0331 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1185 - mse: 0.0167 - NMSE: 0.1505 - NMSE_wt: 0.1124 - covmat_fro_loss: 0.0027 - global_gradnorm: 17.3478 - tot_time: 0h 5m 14.7s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1185 - mse: 0.0167 - NMSE: 0.1505 - NMSE_wt: 0.1124 - covmat_fro_loss: 0.0028 - global_gradnorm: 17.7759 - val_loss: 0.2121 - val_mse: 0.0307 - val_NMSE: 0.2762 - val_NMSE_wt: 0.2060 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1427 - mse: 0.0203 - NMSE: 0.1823 - NMSE_wt: 0.1366 - covmat_fro_loss: 0.0028 - global_gradnorm: 17.4989 - tot_time: 0h 5m 17.1s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1427 - mse: 0.0203 - NMSE: 0.1823 - NMSE_wt: 0.1366 - covmat_fro_loss: 0.0027 - global_gradnorm: 17.0661 - val_loss: 0.0401 - val_mse: 0.0051 - val_NMSE: 0.0458 - val_NMSE_wt: 0.0340 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1431 - mse: 0.0204 - NMSE: 0.1835 - NMSE_wt: 0.1370 - covmat_fro_loss: 0.0033 - global_gradnorm: 12.0277 - tot_time: 0h 5m 19.5s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1431 - mse: 0.0204 - NMSE: 0.1835 - NMSE_wt: 0.1370 - covmat_fro_loss: 0.0033 - global_gradnorm: 13.0468 - val_loss: 0.0532 - val_mse: 0.0068 - val_NMSE: 0.0608 - val_NMSE_wt: 0.0471 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1184 - mse: 0.0166 - NMSE: 0.1493 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0023 - global_gradnorm: 12.5186 - tot_time: 0h 5m 21.7s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.1184 - mse: 0.0166 - NMSE: 0.1493 - NMSE_wt: 0.1123 - covmat_fro_loss: 0.0024 - global_gradnorm: 12.6370 - val_loss: 0.0568 - val_mse: 0.0074 - val_NMSE: 0.0665 - val_NMSE_wt: 0.0507 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1482 - mse: 0.0212 - NMSE: 0.1907 - NMSE_wt: 0.1421 - covmat_fro_loss: 0.0038 - global_gradnorm: 16.5067 - tot_time: 0h 5m 23.8s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 266ms/step - loss: 0.1482 - mse: 0.0212 - NMSE: 0.1907 - NMSE_wt: 0.1421 - covmat_fro_loss: 0.0036 - global_gradnorm: 14.8839 - val_loss: 0.0555 - val_mse: 0.0073 - val_NMSE: 0.0659 - val_NMSE_wt: 0.0494 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1933 - mse: 0.0279 - NMSE: 0.2515 - NMSE_wt: 0.1872 - covmat_fro_loss: 0.0050 - global_gradnorm: 19.7529 - tot_time: 0h 5m 26.2s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.01931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 305ms/step - loss: 0.1933 - mse: 0.0279 - NMSE: 0.2515 - NMSE_wt: 0.1872 - covmat_fro_loss: 0.0048 - global_gradnorm: 19.9137 - val_loss: 0.0329 - val_mse: 0.0039 - val_NMSE: 0.0354 - val_NMSE_wt: 0.0268 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1193 - mse: 0.0168 - NMSE: 0.1515 - NMSE_wt: 0.1131 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.8717Restoring model weights from the end of the best epoch: 20.\n",
      " - tot_time: 0h 5m 28.6s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 309ms/step - loss: 0.1193 - mse: 0.0168 - NMSE: 0.1515 - NMSE_wt: 0.1131 - covmat_fro_loss: 0.0027 - global_gradnorm: 15.1715 - val_loss: 0.0457 - val_mse: 0.0057 - val_NMSE: 0.0510 - val_NMSE_wt: 0.0395 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-07 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1400 - mse: 0.0199 - NMSE: 0.1795 - NMSE_wt: 0.1339 - covmat_fro_loss: 0.0031 - global_gradnorm: 13.7360 - tot_time: 0h 5m 31.2s\n",
      "\n",
      "Epoch 1: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 312ms/step - loss: 0.1400 - mse: 0.0199 - NMSE: 0.1795 - NMSE_wt: 0.1339 - covmat_fro_loss: 0.0031 - global_gradnorm: 14.5653 - val_loss: 0.0353 - val_mse: 0.0042 - val_NMSE: 0.0379 - val_NMSE_wt: 0.0291 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1259 - mse: 0.0177 - NMSE: 0.1594 - NMSE_wt: 0.1198 - covmat_fro_loss: 0.0026 - global_gradnorm: 14.1374 - tot_time: 0h 5m 33.6s\n",
      "\n",
      "Epoch 2: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1259 - mse: 0.0177 - NMSE: 0.1594 - NMSE_wt: 0.1198 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.3943 - val_loss: 0.0339 - val_mse: 0.0040 - val_NMSE: 0.0361 - val_NMSE_wt: 0.0277 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1322 - mse: 0.0188 - NMSE: 0.1694 - NMSE_wt: 0.1260 - covmat_fro_loss: 0.0030 - global_gradnorm: 18.3618 - tot_time: 0h 5m 36.0s\n",
      "\n",
      "Epoch 3: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.1322 - mse: 0.0188 - NMSE: 0.1694 - NMSE_wt: 0.1260 - covmat_fro_loss: 0.0028 - global_gradnorm: 18.3281 - val_loss: 0.0292 - val_mse: 0.0034 - val_NMSE: 0.0307 - val_NMSE_wt: 0.0230 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1346 - mse: 0.0190 - NMSE: 0.1709 - NMSE_wt: 0.1284 - covmat_fro_loss: 0.0025 - global_gradnorm: 13.6648 - tot_time: 0h 5m 38.4s\n",
      "\n",
      "Epoch 4: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1346 - mse: 0.0190 - NMSE: 0.1709 - NMSE_wt: 0.1284 - covmat_fro_loss: 0.0026 - global_gradnorm: 14.5020 - val_loss: 0.0386 - val_mse: 0.0047 - val_NMSE: 0.0419 - val_NMSE_wt: 0.0325 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1252 - mse: 0.0177 - NMSE: 0.1596 - NMSE_wt: 0.1191 - covmat_fro_loss: 0.0029 - global_gradnorm: 15.6145 - tot_time: 0h 5m 40.7s\n",
      "\n",
      "Epoch 5: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1252 - mse: 0.0177 - NMSE: 0.1596 - NMSE_wt: 0.1191 - covmat_fro_loss: 0.0032 - global_gradnorm: 16.2351 - val_loss: 0.0365 - val_mse: 0.0044 - val_NMSE: 0.0399 - val_NMSE_wt: 0.0303 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1224 - mse: 0.0172 - NMSE: 0.1551 - NMSE_wt: 0.1163 - covmat_fro_loss: 0.0027 - global_gradnorm: 16.6881 - tot_time: 0h 5m 43.1s\n",
      "\n",
      "Epoch 6: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1224 - mse: 0.0172 - NMSE: 0.1551 - NMSE_wt: 0.1163 - covmat_fro_loss: 0.0026 - global_gradnorm: 16.0491 - val_loss: 0.0321 - val_mse: 0.0038 - val_NMSE: 0.0344 - val_NMSE_wt: 0.0260 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1343 - mse: 0.0192 - NMSE: 0.1729 - NMSE_wt: 0.1281 - covmat_fro_loss: 0.0029 - global_gradnorm: 17.0004 - tot_time: 0h 5m 45.4s\n",
      "\n",
      "Epoch 7: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.1343 - mse: 0.0192 - NMSE: 0.1729 - NMSE_wt: 0.1281 - covmat_fro_loss: 0.0028 - global_gradnorm: 17.4670 - val_loss: 0.0377 - val_mse: 0.0045 - val_NMSE: 0.0409 - val_NMSE_wt: 0.0316 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1236 - mse: 0.0175 - NMSE: 0.1572 - NMSE_wt: 0.1175 - covmat_fro_loss: 0.0029 - global_gradnorm: 13.1184 - tot_time: 0h 5m 47.8s\n",
      "\n",
      "Epoch 8: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.1236 - mse: 0.0175 - NMSE: 0.1572 - NMSE_wt: 0.1175 - covmat_fro_loss: 0.0032 - global_gradnorm: 14.0164 - val_loss: 0.0328 - val_mse: 0.0040 - val_NMSE: 0.0359 - val_NMSE_wt: 0.0267 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1295 - mse: 0.0184 - NMSE: 0.1656 - NMSE_wt: 0.1234 - covmat_fro_loss: 0.0029 - global_gradnorm: 13.8109 - tot_time: 0h 5m 50.2s\n",
      "\n",
      "Epoch 9: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1295 - mse: 0.0184 - NMSE: 0.1656 - NMSE_wt: 0.1234 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.6319 - val_loss: 0.0331 - val_mse: 0.0038 - val_NMSE: 0.0343 - val_NMSE_wt: 0.0270 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.1214 - mse: 0.0171 - NMSE: 0.1537 - NMSE_wt: 0.1152 - covmat_fro_loss: 0.0025 - global_gradnorm: 10.2321 - tot_time: 0h 5m 52.6s\n",
      "\n",
      "Epoch 10: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.1214 - mse: 0.0171 - NMSE: 0.1537 - NMSE_wt: 0.1152 - covmat_fro_loss: 0.0025 - global_gradnorm: 9.4569 - val_loss: 0.0454 - val_mse: 0.0055 - val_NMSE: 0.0497 - val_NMSE_wt: 0.0393 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1169 - mse: 0.0165 - NMSE: 0.1487 - NMSE_wt: 0.1107 - covmat_fro_loss: 0.0025 - global_gradnorm: 15.9111 - tot_time: 0h 5m 54.7s\n",
      "\n",
      "Epoch 11: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.1169 - mse: 0.0165 - NMSE: 0.1487 - NMSE_wt: 0.1107 - covmat_fro_loss: 0.0026 - global_gradnorm: 16.4987 - val_loss: 0.0381 - val_mse: 0.0047 - val_NMSE: 0.0423 - val_NMSE_wt: 0.0319 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1168 - mse: 0.0164 - NMSE: 0.1473 - NMSE_wt: 0.1107 - covmat_fro_loss: 0.0025 - global_gradnorm: 6.3528 - tot_time: 0h 5m 57.0s\n",
      "\n",
      "Epoch 12: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 0.1168 - mse: 0.0164 - NMSE: 0.1473 - NMSE_wt: 0.1107 - covmat_fro_loss: 0.0024 - global_gradnorm: 6.5188 - val_loss: 0.0717 - val_mse: 0.0099 - val_NMSE: 0.0893 - val_NMSE_wt: 0.0656 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1241 - mse: 0.0175 - NMSE: 0.1578 - NMSE_wt: 0.1179 - covmat_fro_loss: 0.0031 - global_gradnorm: 11.7660 - tot_time: 0h 5m 59.3s\n",
      "\n",
      "Epoch 13: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.1241 - mse: 0.0175 - NMSE: 0.1578 - NMSE_wt: 0.1179 - covmat_fro_loss: 0.0032 - global_gradnorm: 12.8143 - val_loss: 0.0301 - val_mse: 0.0035 - val_NMSE: 0.0315 - val_NMSE_wt: 0.0240 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1247 - mse: 0.0176 - NMSE: 0.1585 - NMSE_wt: 0.1185 - covmat_fro_loss: 0.0026 - global_gradnorm: 19.0413 - tot_time: 0h 6m 1.7s\n",
      "\n",
      "Epoch 14: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.1247 - mse: 0.0176 - NMSE: 0.1585 - NMSE_wt: 0.1185 - covmat_fro_loss: 0.0027 - global_gradnorm: 19.2811 - val_loss: 0.0439 - val_mse: 0.0055 - val_NMSE: 0.0492 - val_NMSE_wt: 0.0377 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1327 - mse: 0.0191 - NMSE: 0.1716 - NMSE_wt: 0.1266 - covmat_fro_loss: 0.0032 - global_gradnorm: 12.2843 - tot_time: 0h 6m 4.1s\n",
      "\n",
      "Epoch 15: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.1327 - mse: 0.0191 - NMSE: 0.1716 - NMSE_wt: 0.1266 - covmat_fro_loss: 0.0035 - global_gradnorm: 11.8778 - val_loss: 0.0359 - val_mse: 0.0044 - val_NMSE: 0.0395 - val_NMSE_wt: 0.0298 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1391 - mse: 0.0196 - NMSE: 0.1762 - NMSE_wt: 0.1330 - covmat_fro_loss: 0.0035 - global_gradnorm: 15.5882 - tot_time: 0h 6m 6.5s\n",
      "\n",
      "Epoch 16: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1391 - mse: 0.0196 - NMSE: 0.1762 - NMSE_wt: 0.1330 - covmat_fro_loss: 0.0034 - global_gradnorm: 15.9300 - val_loss: 0.0301 - val_mse: 0.0035 - val_NMSE: 0.0314 - val_NMSE_wt: 0.0240 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1359 - mse: 0.0194 - NMSE: 0.1742 - NMSE_wt: 0.1297 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.5483 - tot_time: 0h 6m 8.9s\n",
      "\n",
      "Epoch 17: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1359 - mse: 0.0194 - NMSE: 0.1742 - NMSE_wt: 0.1297 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.7098 - val_loss: 0.1830 - val_mse: 0.0261 - val_NMSE: 0.2348 - val_NMSE_wt: 0.1768 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1116 - mse: 0.0157 - NMSE: 0.1413 - NMSE_wt: 0.1055 - covmat_fro_loss: 0.0029 - global_gradnorm: 16.5222 - tot_time: 0h 6m 11.3s\n",
      "\n",
      "Epoch 18: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1116 - mse: 0.0157 - NMSE: 0.1413 - NMSE_wt: 0.1055 - covmat_fro_loss: 0.0030 - global_gradnorm: 17.0419 - val_loss: 0.0536 - val_mse: 0.0071 - val_NMSE: 0.0636 - val_NMSE_wt: 0.0475 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1115 - mse: 0.0157 - NMSE: 0.1409 - NMSE_wt: 0.1054 - covmat_fro_loss: 0.0023 - global_gradnorm: 13.9330 - tot_time: 0h 6m 13.7s\n",
      "\n",
      "Epoch 19: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.1115 - mse: 0.0157 - NMSE: 0.1409 - NMSE_wt: 0.1054 - covmat_fro_loss: 0.0024 - global_gradnorm: 13.2506 - val_loss: 0.0638 - val_mse: 0.0086 - val_NMSE: 0.0771 - val_NMSE_wt: 0.0576 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1404 - mse: 0.0202 - NMSE: 0.1815 - NMSE_wt: 0.1343 - covmat_fro_loss: 0.0033 - global_gradnorm: 16.5827 - tot_time: 0h 6m 16.1s\n",
      "\n",
      "Epoch 20: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1404 - mse: 0.0202 - NMSE: 0.1815 - NMSE_wt: 0.1343 - covmat_fro_loss: 0.0031 - global_gradnorm: 17.0024 - val_loss: 0.0260 - val_mse: 0.0029 - val_NMSE: 0.0262 - val_NMSE_wt: 0.0199 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1140 - mse: 0.0160 - NMSE: 0.1436 - NMSE_wt: 0.1079 - covmat_fro_loss: 0.0024 - global_gradnorm: 14.2467 - tot_time: 0h 6m 18.5s\n",
      "\n",
      "Epoch 21: val_NMSE_wt did not improve from 0.01931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1140 - mse: 0.0160 - NMSE: 0.1436 - NMSE_wt: 0.1079 - covmat_fro_loss: 0.0024 - global_gradnorm: 15.0193 - val_loss: 0.0407 - val_mse: 0.0051 - val_NMSE: 0.0456 - val_NMSE_wt: 0.0346 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1375 - mse: 0.0198 - NMSE: 0.1784 - NMSE_wt: 0.1314 - covmat_fro_loss: 0.0036 - global_gradnorm: 15.5178 - tot_time: 0h 6m 20.9s\n",
      "\n",
      "Epoch 22: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 308ms/step - loss: 0.1375 - mse: 0.0198 - NMSE: 0.1784 - NMSE_wt: 0.1314 - covmat_fro_loss: 0.0042 - global_gradnorm: 16.1492 - val_loss: 0.0670 - val_mse: 0.0089 - val_NMSE: 0.0802 - val_NMSE_wt: 0.0609 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1504 - mse: 0.0215 - NMSE: 0.1934 - NMSE_wt: 0.1443 - covmat_fro_loss: 0.0033 - global_gradnorm: 18.6606 - tot_time: 0h 6m 23.3s\n",
      "\n",
      "Epoch 23: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.1504 - mse: 0.0215 - NMSE: 0.1934 - NMSE_wt: 0.1443 - covmat_fro_loss: 0.0032 - global_gradnorm: 18.9428 - val_loss: 0.0301 - val_mse: 0.0035 - val_NMSE: 0.0313 - val_NMSE_wt: 0.0240 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1609 - mse: 0.0230 - NMSE: 0.2070 - NMSE_wt: 0.1548 - covmat_fro_loss: 0.0048 - global_gradnorm: 14.3964 - tot_time: 0h 6m 25.5s\n",
      "\n",
      "Epoch 24: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 0.1609 - mse: 0.0230 - NMSE: 0.2070 - NMSE_wt: 0.1548 - covmat_fro_loss: 0.0045 - global_gradnorm: 15.1524 - val_loss: 0.0512 - val_mse: 0.0067 - val_NMSE: 0.0607 - val_NMSE_wt: 0.0450 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1173 - mse: 0.0163 - NMSE: 0.1469 - NMSE_wt: 0.1111 - covmat_fro_loss: 0.0023 - global_gradnorm: 14.8407 - tot_time: 0h 6m 27.6s\n",
      "\n",
      "Epoch 25: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.1173 - mse: 0.0163 - NMSE: 0.1469 - NMSE_wt: 0.1111 - covmat_fro_loss: 0.0022 - global_gradnorm: 13.3263 - val_loss: 0.0285 - val_mse: 0.0033 - val_NMSE: 0.0296 - val_NMSE_wt: 0.0224 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1260 - mse: 0.0180 - NMSE: 0.1624 - NMSE_wt: 0.1199 - covmat_fro_loss: 0.0032 - global_gradnorm: 12.5163 - tot_time: 0h 6m 30.0s\n",
      "\n",
      "Epoch 26: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1260 - mse: 0.0180 - NMSE: 0.1624 - NMSE_wt: 0.1199 - covmat_fro_loss: 0.0035 - global_gradnorm: 13.4812 - val_loss: 0.0454 - val_mse: 0.0057 - val_NMSE: 0.0510 - val_NMSE_wt: 0.0393 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1277 - mse: 0.0181 - NMSE: 0.1631 - NMSE_wt: 0.1216 - covmat_fro_loss: 0.0032 - global_gradnorm: 12.1431 - tot_time: 0h 6m 32.3s\n",
      "\n",
      "Epoch 27: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1277 - mse: 0.0181 - NMSE: 0.1631 - NMSE_wt: 0.1216 - covmat_fro_loss: 0.0031 - global_gradnorm: 13.1494 - val_loss: 0.0463 - val_mse: 0.0057 - val_NMSE: 0.0515 - val_NMSE_wt: 0.0401 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1253 - mse: 0.0177 - NMSE: 0.1590 - NMSE_wt: 0.1192 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.1736 - tot_time: 0h 6m 34.7s\n",
      "\n",
      "Epoch 28: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.1253 - mse: 0.0177 - NMSE: 0.1590 - NMSE_wt: 0.1192 - covmat_fro_loss: 0.0026 - global_gradnorm: 13.6520 - val_loss: 0.0765 - val_mse: 0.0101 - val_NMSE: 0.0907 - val_NMSE_wt: 0.0704 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1071 - mse: 0.0150 - NMSE: 0.1347 - NMSE_wt: 0.1010 - covmat_fro_loss: 0.0022 - global_gradnorm: 15.3817 - tot_time: 0h 6m 37.1s\n",
      "\n",
      "Epoch 29: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.1071 - mse: 0.0150 - NMSE: 0.1347 - NMSE_wt: 0.1010 - covmat_fro_loss: 0.0022 - global_gradnorm: 14.6300 - val_loss: 0.0584 - val_mse: 0.0074 - val_NMSE: 0.0662 - val_NMSE_wt: 0.0523 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1198 - mse: 0.0170 - NMSE: 0.1531 - NMSE_wt: 0.1137 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.6453 - tot_time: 0h 6m 39.5s\n",
      "\n",
      "Epoch 30: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 0.1198 - mse: 0.0170 - NMSE: 0.1531 - NMSE_wt: 0.1137 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.3736 - val_loss: 0.0462 - val_mse: 0.0060 - val_NMSE: 0.0539 - val_NMSE_wt: 0.0400 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1255 - mse: 0.0178 - NMSE: 0.1602 - NMSE_wt: 0.1194 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.0506 - tot_time: 0h 6m 41.8s\n",
      "\n",
      "Epoch 31: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.1255 - mse: 0.0178 - NMSE: 0.1602 - NMSE_wt: 0.1194 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.8450 - val_loss: 0.0456 - val_mse: 0.0058 - val_NMSE: 0.0525 - val_NMSE_wt: 0.0394 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1211 - mse: 0.0171 - NMSE: 0.1542 - NMSE_wt: 0.1150 - covmat_fro_loss: 0.0029 - global_gradnorm: 14.0958 - tot_time: 0h 6m 44.2s\n",
      "\n",
      "Epoch 32: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.1211 - mse: 0.0171 - NMSE: 0.1542 - NMSE_wt: 0.1150 - covmat_fro_loss: 0.0028 - global_gradnorm: 14.8851 - val_loss: 0.0364 - val_mse: 0.0044 - val_NMSE: 0.0396 - val_NMSE_wt: 0.0303 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1285 - mse: 0.0181 - NMSE: 0.1628 - NMSE_wt: 0.1224 - covmat_fro_loss: 0.0027 - global_gradnorm: 16.6940 - tot_time: 0h 6m 46.6s\n",
      "\n",
      "Epoch 33: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.1285 - mse: 0.0181 - NMSE: 0.1628 - NMSE_wt: 0.1224 - covmat_fro_loss: 0.0028 - global_gradnorm: 17.1947 - val_loss: 0.0350 - val_mse: 0.0042 - val_NMSE: 0.0382 - val_NMSE_wt: 0.0289 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1490 - mse: 0.0213 - NMSE: 0.1919 - NMSE_wt: 0.1429 - covmat_fro_loss: 0.0038 - global_gradnorm: 18.9291 - tot_time: 0h 6m 49.0s\n",
      "\n",
      "Epoch 34: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.1490 - mse: 0.0213 - NMSE: 0.1919 - NMSE_wt: 0.1429 - covmat_fro_loss: 0.0037 - global_gradnorm: 19.1814 - val_loss: 0.2050 - val_mse: 0.0298 - val_NMSE: 0.2684 - val_NMSE_wt: 0.1989 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1379 - mse: 0.0195 - NMSE: 0.1758 - NMSE_wt: 0.1318 - covmat_fro_loss: 0.0026 - global_gradnorm: 15.2451 - tot_time: 0h 6m 51.3s\n",
      "\n",
      "Epoch 35: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.1379 - mse: 0.0195 - NMSE: 0.1758 - NMSE_wt: 0.1318 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.7239 - val_loss: 0.0355 - val_mse: 0.0043 - val_NMSE: 0.0391 - val_NMSE_wt: 0.0294 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1205 - mse: 0.0169 - NMSE: 0.1525 - NMSE_wt: 0.1144 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.0663 - tot_time: 0h 6m 53.7s\n",
      "\n",
      "Epoch 36: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.1205 - mse: 0.0169 - NMSE: 0.1525 - NMSE_wt: 0.1144 - covmat_fro_loss: 0.0025 - global_gradnorm: 14.2378 - val_loss: 0.0528 - val_mse: 0.0067 - val_NMSE: 0.0602 - val_NMSE_wt: 0.0466 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1281 - mse: 0.0181 - NMSE: 0.1632 - NMSE_wt: 0.1220 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.6299 - tot_time: 0h 6m 56.1s\n",
      "\n",
      "Epoch 37: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.1281 - mse: 0.0181 - NMSE: 0.1632 - NMSE_wt: 0.1220 - covmat_fro_loss: 0.0030 - global_gradnorm: 15.3599 - val_loss: 0.0562 - val_mse: 0.0073 - val_NMSE: 0.0658 - val_NMSE_wt: 0.0501 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1316 - mse: 0.0186 - NMSE: 0.1675 - NMSE_wt: 0.1255 - covmat_fro_loss: 0.0032 - global_gradnorm: 17.3317 - tot_time: 0h 6m 58.2s\n",
      "\n",
      "Epoch 38: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 0.1316 - mse: 0.0186 - NMSE: 0.1675 - NMSE_wt: 0.1255 - covmat_fro_loss: 0.0031 - global_gradnorm: 15.7459 - val_loss: 0.0547 - val_mse: 0.0072 - val_NMSE: 0.0650 - val_NMSE_wt: 0.0486 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1649 - mse: 0.0236 - NMSE: 0.2124 - NMSE_wt: 0.1588 - covmat_fro_loss: 0.0042 - global_gradnorm: 18.1851 - tot_time: 0h 7m 0.3s\n",
      "\n",
      "Epoch 39: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 0.1649 - mse: 0.0236 - NMSE: 0.2124 - NMSE_wt: 0.1588 - covmat_fro_loss: 0.0041 - global_gradnorm: 18.5201 - val_loss: 0.0330 - val_mse: 0.0040 - val_NMSE: 0.0356 - val_NMSE_wt: 0.0269 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1266 - mse: 0.0181 - NMSE: 0.1626 - NMSE_wt: 0.1205 - covmat_fro_loss: 0.0031 - global_gradnorm: 15.3633Restoring model weights from the end of the best epoch: 20.\n",
      " - tot_time: 0h 7m 2.8s\n",
      "\n",
      "Epoch 40: val_NMSE_wt did not improve from 0.01931\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_AR_AEESN_rnn/AR_ESN_ensemble_005/checkpoints/LossHistoriesCheckpoint-20_outsteps\n",
      "8/8 [==============================] - 2s 310ms/step - loss: 0.1266 - mse: 0.0181 - NMSE: 0.1626 - NMSE_wt: 0.1205 - covmat_fro_loss: 0.0030 - global_gradnorm: 14.9692 - val_loss: 0.0497 - val_mse: 0.0063 - val_NMSE: 0.0565 - val_NMSE_wt: 0.0435 - val_covmat_fro_loss: 0.0000e+00 - val_global_gradnorm: 0.0000e+00\n",
      "Epoch 40: early stopping\n"
     ]
    }
   ],
   "source": [
    "global_clipnorm = 30\n",
    "for kk in range(len(T_sample_output)):\n",
    "\n",
    "    num_outsteps = int((T_sample_output[kk] + 0.5*dt_rnn)//dt_rnn)\n",
    "    if type(freeze_layers) == type(None):\n",
    "        freeze_layers_thisoutstep = []\n",
    "    else:\n",
    "        if kk > len(freeze_layers) - 1:\n",
    "            freeze_layers_thisoutstep = freeze_layers[-1]\n",
    "        else:\n",
    "            freeze_layers_thisoutstep = freeze_layers[kk]\n",
    "        \n",
    "        if type(freeze_layers_thisoutstep) == type(None):\n",
    "            freeze_layers_thisoutstep = []\n",
    "\n",
    "    total_s_len = 80\n",
    "    sep_lr_s = ' num_outsteps : {} '.format(num_outsteps)\n",
    "    sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'>' + sep_lr_s\n",
    "    sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'<'\n",
    "    print('\\n\\n' + '*'*len(sep_lr_s))\n",
    "    print('' + sep_lr_s+'')\n",
    "    print('*'*len(sep_lr_s) + '\\n\\n')\n",
    "\n",
    "    if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "        if kk < len(T_sample_output) - 1:\n",
    "            temp = int((T_sample_output[kk+1] + 0.5*dt_rnn)//dt_rnn)\n",
    "        else:\n",
    "            temp = num_outsteps\n",
    "        checkfile1 = dir_name_ARrnn+'/final_net/final_net-{}_outsteps_rnn_weights.hdf5'.format(temp)\n",
    "        checkfile2 = dir_name_ARrnn+'/final_net/final_net-{}_outsteps_ae_weights.h5'.format(temp)\n",
    "        check1 = os.path.exists(checkfile1)\n",
    "        check2 = os.path.exists(checkfile2)\n",
    "        if check1 and check2:\n",
    "            # move on to checking the next time-step\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    print('clipnorm : {}, global_clipnorm : {}'.format(clipnorm, global_clipnorm))\n",
    "    \n",
    "    trainAERNN(\n",
    "        create_data_for_RNN,\n",
    "        Autoencoder,\n",
    "        AR_RNN,\n",
    "        all_data,\n",
    "        AR_AERNN,\n",
    "        dt_rnn=dt_rnn,\n",
    "        T_sample_input=T_sample_input,\n",
    "        T_sample_output=T_sample_output[kk],\n",
    "        T_offset=T_offset,\n",
    "        boundary_idx_arr=boundary_idx_arr,\n",
    "        delta_t=delta_t,\n",
    "        params=params,\n",
    "        normalize_dataset=normalize_dataset,\n",
    "        stddev_multiplier=stddev_multiplier,\n",
    "        skip_intermediate=skip_intermediate,\n",
    "        normalization_type=normalization_type,\n",
    "        normalization_constant_arr_aedata=normalization_constant_arr_aedata,\n",
    "        normalization_constant_arr_rnndata=normalization_arr_rnn,\n",
    "        learning_rate_list=learning_rate_list[kk],\n",
    "        epochs=epochs[kk],\n",
    "        patience=patience[kk],\n",
    "        loss_weights=loss_weights,\n",
    "        min_delta=min_delta,\n",
    "        lambda_reg=lambda_reg,\n",
    "        stddev_rnn=stddev,\n",
    "        stateful=False,\n",
    "        behaviour=behaviour,\n",
    "        strategy=strategy,\n",
    "        dir_name_rnn=dir_name_rnn,\n",
    "        dir_name_AR_AErnn=dir_name_ARrnn,\n",
    "        batch_size=batch_size,\n",
    "        load_file_rnn=load_file_rnn,\n",
    "        wt_file_rnn=wt_file_rnn,\n",
    "        load_file_ae=load_file_ae,\n",
    "        wt_file_ae=wt_file_ae,\n",
    "        covmat_lmda=covmat_lmda,\n",
    "        readAndReturnLossHistories=readAndReturnLossHistories,\n",
    "        mytimecallback=mytimecallback,\n",
    "        plot_losses=plot_losses,\n",
    "        SaveLosses=SaveLosses,\n",
    "        train_split=train_split,\n",
    "        test_split=test_split,\n",
    "        val_split=val_split,\n",
    "        freeze_layers=freeze_layers_thisoutstep,\n",
    "        clipnorm=clipnorm,\n",
    "        global_clipnorm=global_clipnorm,\n",
    "        ESN_flag=True,\n",
    "        rnn_kwargs=rnn_kwargs,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    load_dir = dir_name_ARrnn+'/final_net/{}_outsteps'.format(num_outsteps)\n",
    "    load_file_rnn, wt_file_rnn = find_and_return_load_wt_file_lists(\n",
    "        load_dir,\n",
    "        wt_matcher='ESN_weights.hdf5',\n",
    "        classdict_matcher='ESN_class_dict.txt'\n",
    "    )\n",
    "    \n",
    "    load_file_ae = load_dir + '/final_net-{}_outsteps_ae_class_dict.txt'.format(num_outsteps)\n",
    "    wt_file_ae = load_dir + '/final_net-{}_outsteps_ae_weights.h5'.format(num_outsteps)\n",
    "    \n",
    "    with open(load_dir+'/losses-{}_outsteps.txt'.format(num_outsteps), 'r') as fl:\n",
    "        lines = fl.readlines()\n",
    "\n",
    "    loss_dict = eval(''.join(lines))\n",
    "    train_global_gradnorm_hist = loss_dict['train_global_gradnorm_hist']\n",
    "    # lr_change = loss_dict['lr_change']\n",
    "    # trained_epochs = len(train_global_gradnorm_hist)\n",
    "    # if lr_change[-1] - lr_change[-2] == epochs[kk][-1]:\n",
    "    #     global_clipnorm = train_global_gradnorm_hist[-1]\n",
    "    # else:\n",
    "    #     global_clipnorm = train_global_gradnorm_hist[-patience[kk][-1]]\n",
    "\n",
    "    alpha1 = 0.9\n",
    "    alpha2 = 0.1\n",
    "    # global_clipnorm = train_global_gradnorm_hist[0]\n",
    "    for i in range(1, len(train_global_gradnorm_hist)):\n",
    "        train_global_gradnorm_hist[i] = alpha1*train_global_gradnorm_hist[i-1] + alpha2*train_global_gradnorm_hist[i]\n",
    "\n",
    "    idxs_to_ignore = 1\n",
    "    global_clipnorm_min = 3.0\n",
    "    global_clipnorm = np.max(train_global_gradnorm_hist[idxs_to_ignore:])\n",
    "    global_clipnorm = 0.1 * np.round(10*global_clipnorm)\n",
    "    global_clipnorm = max(global_clipnorm, global_clipnorm_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the combined AE-RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667868783568,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "7ASCopnIH6nl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4769220,
     "status": "ok",
     "timestamp": 1667873552785,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "6hh1pbKjCcO4",
    "outputId": "e594f4de-ec70-465e-eef7-bdef301361fa",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10543,
     "status": "ok",
     "timestamp": 1667873563321,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "SO7iK4mbneQm",
    "outputId": "48110900-962a-49c1-c532-718999590884"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1667873564544,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "nDv5D8APneQm",
    "outputId": "ee911dc8-4d36-48af-8ad0-07cef0dbaf81"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 11096,
     "status": "ok",
     "timestamp": 1667873575637,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "dbLa0AwlDBWh",
    "outputId": "d3f93f58-9ce7-4994-8d68-29520477e02d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1667873575638,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "MDopQ4JMhRPV",
    "outputId": "f6480bb7-5837-4a80-9333-f9acd175b27a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667873576097,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "2_fAlJz2Vdev"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667873576098,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "s5BNteRC7COC",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
