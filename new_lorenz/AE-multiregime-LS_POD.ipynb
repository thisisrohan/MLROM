{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a637f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\":True,\n",
    "    \"font.family\":\"serif\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abad82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "array = np.array\n",
    "float32 = np.float32\n",
    "int32 = np.int32\n",
    "float64 = np.float64\n",
    "int64 = np.int64\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "xlabel_kwargs = {\"fontsize\":15}\n",
    "ylabel_kwargs = {\"fontsize\":15}\n",
    "legend_kwargs = {\"fontsize\":12}\n",
    "title_kwargs = {\"fontsize\":18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e751d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14277188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddad9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/new_lorenz\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8df8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ae_v1 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844fb65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:41:45.508412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-06 09:41:45.545635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-06 09:41:45.545846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-06 09:41:45.546704: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            # gpu_to_use = 0\n",
    "            # tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "            tf.config.set_visible_devices([], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56c6491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print('')\n",
    "print(tf.config.list_logical_devices())\n",
    "print('')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865779b",
   "metadata": {},
   "source": [
    "# Kolmogorov Flow System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11bb908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prng_seed = 42\n",
    "np.random.seed(prng_seed)\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba6a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_ae/ae_002\n",
      "'use_ae_data' not present in RNN_specific_data, set to True.\n",
      "data_dir_idx: 006\n",
      "normalize_flag_ogdata: False\n"
     ]
    }
   ],
   "source": [
    "ae_idx = '002'\n",
    "dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_'.format(ds=dir_sep)+ae_idx\n",
    "print(dir_name_ae)\n",
    "\n",
    "# reading simulation parameters\n",
    "with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "data_dir_idx = params_dict['data_dir_idx']\n",
    "normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "ae_module = params_dict['module']\n",
    "try:\n",
    "    use_ae_data = params_rnn_dict['use_ae_data']\n",
    "except:\n",
    "    print(\"'use_ae_data' not present in RNN_specific_data, set to True.\")\n",
    "    use_ae_data = True\n",
    "try:\n",
    "    ae_data_with_params = params_dict['ae_data_with_params']\n",
    "except:\n",
    "    print(\"'ae_data_with_params' not present in ae_data, set to 'True'.\")\n",
    "    ae_data_with_params = True\n",
    "\n",
    "if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "    with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "        normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "print('data_dir_idx:', data_dir_idx)\n",
    "\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "\n",
    "with open(dir_name_data + dir_sep + 'sim_data_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "params_mat = params_dict['params_mat']\n",
    "# init_state = params_dict['init_state']\n",
    "t0 = params_dict['t0']\n",
    "T = params_dict['T']\n",
    "delta_t = params_dict['delta_t']\n",
    "return_params_arr = params_dict['return_params_arr']\n",
    "normalize_flag_ogdata = params_dict['normalize_flag']\n",
    "print('normalize_flag_ogdata:', normalize_flag_ogdata)\n",
    "alldata_withparams_flag = params_dict['alldata_withparams_flag']\n",
    "\n",
    "with np.load(dir_name_data+dir_sep+'data.npz', allow_pickle=True) as fl:\n",
    "    all_data_og = fl['all_data'].astype(FTYPE)\n",
    "    boundary_idx_arr = fl['boundary_idx_arr']\n",
    "    normalization_constant_arr_ogdata = fl['normalization_constant_arr'][0]\n",
    "    initial_t0 = fl['initial_t0']\n",
    "    init_state_mat = fl['init_state_mat']\n",
    "\n",
    "    lyapunov_spectrum_mat = fl['lyapunov_spectrum_mat']\n",
    "\n",
    "num_params = params_mat.shape[1]\n",
    "og_vars = all_data_og.shape[1]\n",
    "if alldata_withparams_flag == True:\n",
    "    og_vars -= num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4399929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ae_data_with_params == False and alldata_withparams_flag == True:\n",
    "    all_data_og = all_data_og[:, 0:og_vars]\n",
    "    normalization_constant_arr_aedata = normalization_constant_arr_aedata[:, 0:og_vars]\n",
    "\n",
    "if ae_data_with_params == True and alldata_withparams_flag == False:\n",
    "    new_all_data = np.empty(shape=(all_data_og.shape[0], og_vars+num_params), dtype=FTYPE)\n",
    "    new_all_data[:, 0:og_vars] = all_data_og[:, 0:og_vars]\n",
    "    del(all_data_og)\n",
    "    all_data_og = new_all_data\n",
    "    prev_idx = 0\n",
    "    for i in range(boundary_idx_arr.shape[0]):\n",
    "        all_data_og[prev_idx:boundary_idx_arr[i], num_params:] = params_mat[i]\n",
    "        prev_idx = boundary_idx_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae9f7107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400008, 3)\n"
     ]
    }
   ],
   "source": [
    "print(all_data_og.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d311da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e98286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_samples = boundary_idx_arr[-1]\n",
    "# idx = np.arange(cum_samples)\n",
    "# np.random.shuffle(idx)\n",
    "num_train = 0\n",
    "num_val = 0\n",
    "begin_idx = 0\n",
    "for i in range(len(boundary_idx_arr)):\n",
    "    num_samples = boundary_idx_arr[i] - begin_idx\n",
    "    num_train += int( np.round(train_split*num_samples) )\n",
    "    num_val += int( np.round(val_split*num_samples) )\n",
    "    begin_idx = boundary_idx_arr[i]\n",
    "\n",
    "# defining shapes\n",
    "training_shape = [num_train]\n",
    "training_shape.extend(all_data_og.shape[1:])\n",
    "\n",
    "val_shape = [num_val]\n",
    "val_shape.extend(all_data_og.shape[1:])\n",
    "\n",
    "testing_shape = [cum_samples-num_train-num_val]\n",
    "testing_shape.extend(all_data_og.shape[1:])\n",
    "\n",
    "# defining required arrays\n",
    "training_data = np.empty(shape=training_shape)\n",
    "\n",
    "val_data = np.empty(shape=val_shape)\n",
    "\n",
    "testing_data = np.empty(shape=testing_shape)\n",
    "\n",
    "boundary_idx_arr_testing = np.empty_like(boundary_idx_arr)\n",
    "boundary_idx_arr_training = np.empty_like(boundary_idx_arr)\n",
    "\n",
    "begin_idx = 0\n",
    "training_data_rolling_count = 0\n",
    "val_data_rolling_count = 0\n",
    "testing_data_rolling_count = 0\n",
    "for i in range(len(boundary_idx_arr)):\n",
    "    num_samples = boundary_idx_arr[i] - begin_idx\n",
    "    num_train = int( np.round(train_split*num_samples) )\n",
    "    num_val = int( np.round(val_split*num_samples) )\n",
    "\n",
    "    training_data[training_data_rolling_count:training_data_rolling_count+num_train] = all_data_og[begin_idx:begin_idx+num_train]\n",
    "    training_data_rolling_count += num_train\n",
    "    boundary_idx_arr_training[i] = training_data_rolling_count\n",
    "\n",
    "    val_data[val_data_rolling_count:val_data_rolling_count+num_val] = all_data_og[begin_idx+num_train:begin_idx+num_train+num_val]\n",
    "    val_data_rolling_count += num_val\n",
    "\n",
    "    num_test = num_samples-num_train-num_val\n",
    "    testing_data[testing_data_rolling_count:testing_data_rolling_count+num_test] = all_data_og[begin_idx+num_train+num_val:begin_idx+num_train+num_val+num_test]\n",
    "    testing_data_rolling_count += num_test\n",
    "    boundary_idx_arr_testing[i] = testing_data_rolling_count\n",
    "\n",
    "    begin_idx = boundary_idx_arr[i]\n",
    "\n",
    "# further shuffling\n",
    "# idx = np.arange(0, training_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# training_data_rnn_input = training_data_rnn_input[idx]\n",
    "# np.random.shuffle(training_data)\n",
    "\n",
    "# idx = np.arange(0, val_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# val_data = val_data[idx]\n",
    "# np.random.shuffle(val_data)\n",
    "\n",
    "# idx = np.arange(0, testing_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# testing_data = testing_data[idx]\n",
    "# np.random.shuffle(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ab8629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape :  (320008, 3)\n",
      "val_data.shape :  (40000, 3)\n",
      "testing_data.shape :  (40000, 3)\n",
      "og_vars :  3\n"
     ]
    }
   ],
   "source": [
    "print('training_data.shape : ', training_data.shape)\n",
    "print('val_data.shape : ', val_data.shape)\n",
    "print('testing_data.shape : ', testing_data.shape)\n",
    "print('og_vars : ', og_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aef64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalizeforae_flag == True:\n",
    "    training_data -= normalization_constant_arr_aedata[0]\n",
    "    training_data /= normalization_constant_arr_aedata[1]\n",
    "\n",
    "    testing_data -= normalization_constant_arr_aedata[0]\n",
    "    testing_data /= normalization_constant_arr_aedata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec388c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_class_dict.txt'\n",
    "wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "\n",
    "ae_net = Autoencoder(data_dim=training_data.shape[1], load_file=load_file)\n",
    "ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbb774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_states_all_trainingdata = np.array(ae_net.encoder_net.predict(training_data))\n",
    "latent_states_all_testingdata = np.array(ae_net.encoder_net.predict(testing_data))\n",
    "\n",
    "reconstructed_data_trainingdata = ae_net.decoder_net.predict(latent_states_all_trainingdata)\n",
    "reconstructed_data_testingdata = ae_net.decoder_net.predict(latent_states_all_testingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73c13ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_NRMSE_test = np.empty(shape=len(boundary_idx_arr_testing))\n",
    "\n",
    "begin_train = 0\n",
    "begin_test = 0\n",
    "\n",
    "ogog_vars = og_vars\n",
    "og_vars = training_data.shape[1]\n",
    "\n",
    "for i in range(len(boundary_idx_arr_testing)):\n",
    "    end_train = boundary_idx_arr_training[i]\n",
    "    end_test = boundary_idx_arr_testing[i]\n",
    "    \n",
    "    stddev = np.std(training_data[begin_train:end_train, 0:og_vars], axis=0)\n",
    "    stddev[ogog_vars:] = 1.\n",
    "    \n",
    "    individual_NRMSE_test[i] = np.mean(np.mean((testing_data[begin_test:end_test, 0:og_vars]-reconstructed_data_testingdata[begin_test:end_test, 0:og_vars])**2/stddev**2, axis=1)**0.5, axis=0)\n",
    "    \n",
    "    begin_train = boundary_idx_arr_training[i]\n",
    "    begin_test = boundary_idx_arr_testing[i]\n",
    "\n",
    "og_vars = ogog_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b77a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07288962, 0.09713386, 0.11459896, 0.08378267, 0.05173538,\n",
       "       0.07141185, 0.07066203, 0.0390779 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_NRMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae5d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    dir_name_ae+'/plots/individual_NRMSE_test',\n",
    "    individual_NRMSE_test=individual_NRMSE_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eb4e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_name_ae+'/plots/individual_NRMSE_test.txt', 'w') as f:\n",
    "    s = ', '.join(['{:.2E}'.format(elem) for elem in individual_NRMSE_test])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26440edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(training_data)\n",
    "del(val_data)\n",
    "# del(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_shape = latent_states_all_testingdata.shape[1:]\n",
    "og_shape = training_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ls_shape : ', ls_shape)\n",
    "print('og_shape : ', og_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb40e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('latent_states_all_trainingdata.shape : {}'.format(latent_states_all_trainingdata.shape))\n",
    "print('latent_states_all_testingdata.shape : {}\\n'.format(latent_states_all_testingdata.shape))\n",
    "\n",
    "# print('reconstructed_data_trainingdata.shape : {}'.format(reconstructed_data_trainingdata.shape))\n",
    "# print('reconstructed_data_testingdata.shape : {}'.format(reconstructed_data_testingdata.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalizeforae_flag == True:\n",
    "    # reconstructed_data_trainingdata *= normalization_constant_arr_aedata[1]\n",
    "    # reconstructed_data_trainingdata += normalization_constant_arr_aedata[0]\n",
    "    training_data *= normalization_constant_arr_aedata[1]\n",
    "    training_data += normalization_constant_arr_aedata[0]\n",
    "\n",
    "    # reconstructed_data_testingdata *= normalization_constant_arr_aedata[1]\n",
    "    # reconstructed_data_testingdata += normalization_constant_arr_aedata[0]\n",
    "    testing_data *= normalization_constant_arr_aedata[1]\n",
    "    testing_data += normalization_constant_arr_aedata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6897a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD in latent space\n",
    "latent_states_all_trainingdata = np.reshape(latent_states_all_trainingdata, (latent_states_all_trainingdata.shape[0], -1))\n",
    "mean_ls = np.mean(latent_states_all_trainingdata, axis=0)\n",
    "meancentered_ls = latent_states_all_trainingdata - mean_ls\n",
    "covmat_ls = np.matmul(meancentered_ls.transpose(), meancentered_ls) / (meancentered_ls.shape[0] - 1)\n",
    "\n",
    "eigenvals_ls, eigenvecs_ls = linalg.eig(covmat_ls)\n",
    "eigenvals_ls = np.abs(eigenvals_ls)\n",
    "sorted_idx = np.argsort(eigenvals_ls)\n",
    "eigenvals_ls = eigenvals_ls[sorted_idx]\n",
    "eigenvecs_ls = eigenvecs_ls[:, sorted_idx]\n",
    "\n",
    "del(covmat_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvecs_ls.shape, eigenvals_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff202239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD in actual-data space\n",
    "training_data = np.reshape(training_data, (training_data.shape[0], -1))\n",
    "mean_og = np.mean(training_data, axis=0)\n",
    "meancentered_og = training_data - mean_og\n",
    "covmat_og = np.matmul(meancentered_og.transpose(), meancentered_og) / (meancentered_og.shape[0] - 1)\n",
    "\n",
    "eigenvals_og, eigenvecs_og = linalg.eig(covmat_og)\n",
    "eigenvals_og = np.abs(eigenvals_og)\n",
    "sorted_idx = np.argsort(eigenvals_og)\n",
    "eigenvals_og = eigenvals_og[sorted_idx]\n",
    "eigenvecs_og = eigenvecs_og[:, sorted_idx]\n",
    "\n",
    "del(covmat_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_PODcomps = testing_data @ eigenvecs_og[:, :]\n",
    "ls_testing_data_PODcomps = latent_states_all_testingdata @ eigenvecs_ls[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ee5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb80e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(\n",
    "#     projection='3d'\n",
    "# )\n",
    "# # ax.view_init(\n",
    "# #     elev=30,\n",
    "# #     azim=-60,\n",
    "# # #     roll=15,\n",
    "# # )\n",
    "\n",
    "# begin_idx = 0\n",
    "# idx1 = -1\n",
    "# idx2 = -2\n",
    "# idx3 = -3\n",
    "# for i in range(len(boundary_idx_arr_testing)):\n",
    "#     end_idx = boundary_idx_arr_testing[i]\n",
    "#     ax.scatter(\n",
    "#         testing_data_PODcomps[begin_idx:end_idx, idx1].transpose(),\n",
    "#         testing_data_PODcomps[begin_idx:end_idx, idx2].transpose(),\n",
    "#         testing_data_PODcomps[begin_idx:end_idx, idx3].transpose(),\n",
    "#         label=r\"$(\\nu_1, \\nu_2, \\nu_3) = (\"+'{:.0f}, {:.0f}, {:.0f}'.format(*params_mat[i])+r')$',\n",
    "#         s=0.2\n",
    "#     )\n",
    "#     begin_idx = boundary_idx_arr_testing[i]\n",
    "\n",
    "# ax.set_xlabel(r'$p_'+str(-idx1)+r'$')\n",
    "# ax.set_ylabel(r'$p_'+str(-idx2)+r'$')\n",
    "# ax.set_zlabel(r'$p_'+str(-idx3)+r'$')\n",
    "\n",
    "# plt.legend(markerscale=10)\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(\n",
    "#     projection='3d'\n",
    "# )\n",
    "# # ax.view_init(\n",
    "# #     elev=30,\n",
    "# #     azim=-60,\n",
    "# # #     roll=15,\n",
    "# # )\n",
    "\n",
    "# begin_idx = 0\n",
    "# idx1 = -3\n",
    "# idx2 = -4\n",
    "# idx3 = -5\n",
    "# for i in range(len(boundary_idx_arr_testing)):\n",
    "#     end_idx = boundary_idx_arr_testing[i]\n",
    "#     ax.scatter(\n",
    "#         ls_testing_data_PODcomps[begin_idx:end_idx, idx1].transpose(),\n",
    "#         ls_testing_data_PODcomps[begin_idx:end_idx, idx2].transpose(),\n",
    "#         ls_testing_data_PODcomps[begin_idx:end_idx, idx3].transpose(),\n",
    "#         label=r\"$(\\nu_1, \\nu_2, \\nu_3) = (\"+'{:.0f}, {:.0f}, {:.0f}'.format(*params_mat[i])+r')$',\n",
    "#         s=0.2\n",
    "#     )\n",
    "#     begin_idx = boundary_idx_arr_testing[i]\n",
    "\n",
    "# ax.set_xlabel(r'$p_'+str(-idx1)+r'$')\n",
    "# ax.set_ylabel(r'$p_'+str(-idx2)+r'$')\n",
    "# ax.set_zlabel(r'$p_'+str(-idx3)+r'$')\n",
    "\n",
    "# plt.legend(markerscale=10)\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # fig = plt.figure()\n",
    "\n",
    "# snap = 5\n",
    "# xmax = snap*int((np.max(testing_data[:, 0])+0.5*snap)//snap)\n",
    "# xmin = snap*int((np.min(testing_data[:, 0])+0.5*snap)//snap)\n",
    "\n",
    "# snap = 5\n",
    "# ymax = snap*int((np.max(testing_data[:, 1])+0.5*snap)//snap)\n",
    "# ymin = snap*int((np.min(testing_data[:, 1])+0.5*snap)//snap)\n",
    "\n",
    "# snap = 5\n",
    "# zmax = snap*int((np.max(testing_data[:, 2])+0.5*snap)//snap)\n",
    "# zmin = snap*int((np.min(testing_data[:, 2])+0.5*snap)//snap)\n",
    "\n",
    "# begin_idx = 0\n",
    "# for j in range(boundary_idx_arr_testing.shape[0]):\n",
    "    \n",
    "#     fig = plt.figure(figsize=(3,3))\n",
    "#     n1 = j // 4 + 1\n",
    "#     n2 = j % 4 + 1\n",
    "#     ax = fig.add_subplot(\n",
    "#         projection='3d',\n",
    "#     )\n",
    "#     end_idx = boundary_idx_arr_testing[j]\n",
    "#     ax.plot(\n",
    "#         testing_data[begin_idx:end_idx, 0].transpose(),\n",
    "#         testing_data[begin_idx:end_idx, 1].transpose(),\n",
    "#         testing_data[begin_idx:end_idx, 2].transpose(),\n",
    "#         label=r'Phase Space Trajectory',\n",
    "#         # label=r\"$(\\sigma, \\rho, \\beta) = (\"+'{:.2f}, {:.2f}, {:.2f}'.format(*params_mat[j])+r')$',\n",
    "#         linewidth=0.4\n",
    "#     )\n",
    "#     attractor_pos = np.empty(shape=(2,3))\n",
    "#     attractor_pos[:, 2] = params_mat[j][1]-1\n",
    "#     attractor_pos[0, 0] = (params_mat[j][2]*(params_mat[j][1]-1))**0.5\n",
    "#     attractor_pos[0, 1] = attractor_pos[0, 0]\n",
    "#     attractor_pos[1, 0:2] = -attractor_pos[0, 0:2]\n",
    "    \n",
    "#     ax.plot(\n",
    "#         *attractor_pos.transpose(),\n",
    "#         marker='x',\n",
    "#         markersize=4,\n",
    "#         linestyle='',\n",
    "#         label='Attractor Positions'\n",
    "#     )\n",
    "    \n",
    "#     begin_idx = boundary_idx_arr_testing[j]\n",
    "\n",
    "#     ax.set_xlabel(r'$x_1$', fontsize=15)\n",
    "#     ax.set_ylabel(r'$x_2$', fontsize=15)\n",
    "#     ax.set_zlabel(r'$x_3$', fontsize=15)\n",
    "    \n",
    "#     ax.set_xlim(xmin, xmax)\n",
    "#     ax.set_ylim(ymin, ymax)\n",
    "#     ax.set_zlim(zmin, zmax)\n",
    "    \n",
    "#     ax.legend(loc='upper right')\n",
    "#     ax.set_title(r\"$(\\sigma, \\rho, \\beta) = (\"+'{:.0f}, {:.0f}, {:.2f}'.format(*params_mat[j])+r')$', fontsize=17)\n",
    "    \n",
    "#     plt.savefig(dir_name_data+'/plots/phasespace_{:2d}.png'.format(j), dpi=600, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_idx = 0\n",
    "for j in range(boundary_idx_arr.shape[0]):\n",
    "    end_idx = boundary_idx_arr_testing[j]\n",
    "    plt.scatter(\n",
    "        *latent_states_all_testingdata[begin_idx:end_idx].transpose(),\n",
    "        s=0.2,\n",
    "        label=r\"$(\\sigma, \\rho, \\beta) = (\"+'{:.0f}, {:.0f}, {:.2f}'.format(*params_mat[j])+r')$',\n",
    "    )\n",
    "    begin_idx = boundary_idx_arr_testing[j]\n",
    "\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlabel(r'$z_1$', fontsize=15)\n",
    "plt.ylabel(r'$z_2$', fontsize=15)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.title(r'Latent Space', fontsize=17)\n",
    "\n",
    "plt.gcf().legend(\n",
    "    fontsize=12, \n",
    "    markerscale=10,\n",
    "    loc='center right',\n",
    "    bbox_to_anchor=(1.3, 0.5),\n",
    ")\n",
    "\n",
    "plt.gcf().set_size_inches(4,4)\n",
    "\n",
    "plt.savefig(dir_name_ae+'/plots/NEW--ls.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b985a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92ccda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d50fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1cd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda4f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50d08b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3391b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
