{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868739487,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3563,
     "status": "ok",
     "timestamp": 1667868743047,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\":True,\n",
    "    \"font.family\":\"serif\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667868743048,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "h_qXhHdbCgoj",
    "outputId": "3473a883-d145-4778-9be7-7d44e0c6ea67"
   },
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "array = np.array\n",
    "float32 = np.float32\n",
    "int32 = np.int32\n",
    "float64 = np.float64\n",
    "int64 = np.int64\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667868743048,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "BiLIUmBPneQR"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18870,
     "status": "ok",
     "timestamp": 1667868761912,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "fnTV6Anhni6O",
    "outputId": "bf1d11f8-667f-4cb5-d8d5-b9d860b44d99"
   },
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868761912,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "paDfPOrjnkAS",
    "outputId": "58054510-4476-49b4-f8ba-e2978a028b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/new_lorenz\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4575,
     "status": "ok",
     "timestamp": 1667868766483,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "P6K2YWlR6ZPD"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import create_data_for_RNN, mytimecallback, SaveLosses, plot_losses, return_hilbert_x0\n",
    "from tools.ae_v2 import Autoencoder\n",
    "from tools.GRU_SingleStep_v1 import RNN_GRU\n",
    "from tools.GRU_AR_v1 import AR_RNN_GRU\n",
    "from tools.AEGRU_AR_v1 import AR_AERNN_GRU\n",
    "from tools.hyper_param_GRU import trainGRU_and_return_PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766483,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "_xtkwXE2tGTP"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": [
    "# setting seed for PRNGs\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    prng_seed = 42\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "qvA9oeCHCTVM",
    "outputId": "0f2de849-59ee-4ed9-b65d-c5952e0dcb55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 01:05:26.801709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.801952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.839607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.839861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.840060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.840250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.841256: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 01:05:26.841898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.842244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:26.842489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:27.392694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:27.392912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:27.393096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-01 01:05:27.393238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3365 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 1\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1667868766484,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "c9786b4c-8510-47d0-801d-181e3b12239c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868766485,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "8aNkoXfyGq52"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5768,
     "status": "ok",
     "timestamp": 1667868772247,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "O7sl7i5H5Dqz",
    "outputId": "419ef0e0-4d58-454e-d0af-17af3b846b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_rnn: /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000\n",
      "use_ae_data : True, dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/saved_ae/ae_024\n",
      "data_dir_idx: 010\n",
      "normalize_flag_ogdata: False\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "# from numpy import *\n",
    "\n",
    "# making RNN save directory\n",
    "dir_name_rnn = os.getcwd() + dir_sep + 'GRU_params_Search'\n",
    "if not os.path.isdir(dir_name_rnn):\n",
    "    os.makedirs(dir_name_rnn)\n",
    "\n",
    "counter = 0\n",
    "while True:\n",
    "    dir_check = 'params_search_' + str(counter).zfill(3)\n",
    "    if os.path.isdir(dir_name_rnn + dir_sep + dir_check):\n",
    "        counter += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "dir_name_rnn = dir_name_rnn + dir_sep + dir_check\n",
    "os.makedirs(dir_name_rnn)\n",
    "dir_name_rnn_plots = dir_name_rnn+dir_sep+'plots'\n",
    "os.makedirs(dir_name_rnn_plots)\n",
    "\n",
    "# whether to use AE data or just work on raw data\n",
    "use_ae_data = True # if false, specifying ae_idx will only show which dataset to use\n",
    "\n",
    "# autoencoder directory\n",
    "# ae_idx = '046'\n",
    "# dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_'.format(ds=dir_sep)+ae_idx\n",
    "dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_024'.format(ds=dir_sep)\n",
    "\n",
    "# reading simulation parameters\n",
    "with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "data_dir_idx = params_dict['data_dir_idx']\n",
    "normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "normalization_constant_arr_aedata = params_dict['normalization_constant_arr_aedata']\n",
    "try:\n",
    "    ae_data_with_params = params_dict['ae_data_with_params']\n",
    "except:\n",
    "    print(\"'ae_data_with_params' not present in ae_data, set to 'True'.\")\n",
    "    ae_data_with_params = True\n",
    "\n",
    "if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "    with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "        normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "\n",
    "print('dir_name_rnn:', dir_name_rnn)\n",
    "print('use_ae_data : ' + str(use_ae_data) + ', dir_name_ae:', dir_name_ae)\n",
    "print('data_dir_idx:', data_dir_idx)\n",
    "\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "    \n",
    "with open(dir_name_data + dir_sep + 'sim_data_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "params_mat = params_dict['params_mat']\n",
    "# init_state = params_dict['init_state']\n",
    "t0 = params_dict['t0']\n",
    "T = params_dict['T']\n",
    "delta_t = params_dict['delta_t']\n",
    "return_params_arr = params_dict['return_params_arr']\n",
    "normalize_flag_ogdata = params_dict['normalize_flag']\n",
    "print('normalize_flag_ogdata:', normalize_flag_ogdata)\n",
    "alldata_withparams_flag = params_dict['alldata_withparams_flag']\n",
    "\n",
    "with np.load(dir_name_data+dir_sep+'data.npz', allow_pickle=True) as fl:\n",
    "    all_data = fl['all_data'].astype(FTYPE)\n",
    "    boundary_idx_arr = fl['boundary_idx_arr']\n",
    "    normalization_constant_arr_ogdata = fl['normalization_constant_arr'][0]\n",
    "    initial_t0 = fl['initial_t0']\n",
    "    init_state_mat = fl['init_state_mat']\n",
    "\n",
    "    lyapunov_spectrum_mat = fl['lyapunov_spectrum_mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1667868772777,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "ySVDz_2U5FH5",
    "outputId": "c57be82f-527d-4e83-a605-aac85c39088e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case : 1, lyapunov exponent : 0.9058021372262592, lyapunov time : 1.1039938926696777s\n"
     ]
    }
   ],
   "source": [
    "lyapunov_time_arr = np.empty(shape=lyapunov_spectrum_mat.shape[0], dtype=FTYPE)\n",
    "for i in range(lyapunov_spectrum_mat.shape[0]):\n",
    "    lyapunov_time_arr[i] = 1/lyapunov_spectrum_mat[i, 0]\n",
    "    print('Case : {}, lyapunov exponent : {}, lyapunov time : {}s'.format(i+1, lyapunov_spectrum_mat[i, 0], lyapunov_time_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868772778,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "positve_lp_idx = np.where(lyapunov_time_arr > 0)[0]\n",
    "print(positve_lp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1667868774262,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "uDhfYHU45IS8",
    "outputId": "5307dc6a-17c5-4c77-dac5-fcb96116ac44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0 4200001]\n"
     ]
    }
   ],
   "source": [
    "last_idx = all_data.shape[0]\n",
    "temp_bia = np.zeros(shape=1+boundary_idx_arr.shape[0], dtype=np.int32)\n",
    "temp_bia[1:] = boundary_idx_arr\n",
    "print(temp_bia)\n",
    "for i in range(boundary_idx_arr.shape[0]-1, -1, -1):\n",
    "    if not (i in positve_lp_idx):\n",
    "        print(i)\n",
    "        num_idxs = last_idx - temp_bia[i+1]\n",
    "        all_data[temp_bia[i]:temp_bia[i]+num_idxs] = all_data[temp_bia[i+1]:last_idx]\n",
    "        last_idx = last_idx - (temp_bia[i+1]-temp_bia[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bia = np.empty_like(boundary_idx_arr)\n",
    "new_bia[:] = boundary_idx_arr\n",
    "new_pmat = np.empty_like(params_mat)\n",
    "new_pmat[:, :] = params_mat\n",
    "counter = 0\n",
    "bia_counter = boundary_idx_arr.shape[0]\n",
    "for i in range(boundary_idx_arr.shape[0]):\n",
    "    if not (i in positve_lp_idx):\n",
    "        new_bia[i:] -= temp_bia[i+1] - temp_bia[i]\n",
    "        new_bia[i:bia_counter-1] = new_bia[i+1:bia_counter]\n",
    "        new_pmat[i:bia_counter-1] = new_pmat[i+1:bia_counter]\n",
    "        bia_counter -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bia = new_bia[0:bia_counter]\n",
    "new_pmat = new_pmat[0:bia_counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[0:new_bia[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bia, boundary_idx_arr = boundary_idx_arr, new_bia\n",
    "new_pmat, params_mat = params_mat, new_pmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868774263,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "-MJa7P5t5KiC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delaing with normalizing the data before feeding into autoencoder\n",
    "num_params = params_mat.shape[1]\n",
    "og_vars = all_data.shape[1]\n",
    "if alldata_withparams_flag == True:\n",
    "    og_vars -= num_params\n",
    "\n",
    "time_stddev_ogdata = np.std(all_data[:, 0:og_vars], axis=0)\n",
    "time_mean_ogdata = np.mean(all_data[:, 0:og_vars], axis=0)\n",
    "    \n",
    "if use_ae_data == True:\n",
    "    if ae_data_with_params == True and alldata_withparams_flag == False:\n",
    "        new_all_data = np.empty(shape=(all_data.shape[0], og_vars+num_params), dtype=FTYPE)\n",
    "        new_all_data[:, 0:og_vars] = all_data[:, 0:og_vars]\n",
    "        del(all_data)\n",
    "        all_data = new_all_data\n",
    "        prev_idx = 0\n",
    "        for i in range(boundary_idx_arr.shape[0]):\n",
    "            all_data[prev_idx:boundary_idx_arr[i], num_params:] = params_mat[i]\n",
    "            prev_idx = boundary_idx_arr[i]\n",
    "\n",
    "    if normalizeforae_flag == True:\n",
    "        for i in range(all_data.shape[1]):\n",
    "            all_data[:, i] -= normalization_constant_arr_aedata[0, i]\n",
    "            all_data[:, i] /= normalization_constant_arr_aedata[1, i]\n",
    "\n",
    "    if ae_data_with_params == False:\n",
    "        all_data = all_data[:, 0:og_vars]\n",
    "else:\n",
    "    # using raw data, neglecting the params attached (if any)\n",
    "    all_data = all_data[:, 0:og_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1667868775190,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "sMENXULAGFPm",
    "outputId": "dbf2c14d-2e8a-42c9-b6c5-f5f7c7a6092f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667868775191,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "ZBTJl9PeneQb"
   },
   "outputs": [],
   "source": [
    "if use_ae_data == True:\n",
    "    load_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_class_dict.txt'\n",
    "    wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1667868776552,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "a3Pq-qorneQb"
   },
   "outputs": [],
   "source": [
    "if use_ae_data == True:\n",
    "    ae_net = Autoencoder(all_data.shape[1], load_file=load_file)\n",
    "    ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667868776553,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "wwt4brHcOaXi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667868776553,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "Zl6ZvgtNtA_u",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667868776554,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "lXpoaKRIneQc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1667868777509,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "Q3a8HHyvneQc",
    "outputId": "51084913-6faf-4bb5-db69-2cbea705dd28"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "if use_ae_data == True:\n",
    "    latent_states_all = ae_net.encoder_net.predict(all_data)\n",
    "    # del(all_data)\n",
    "else:\n",
    "    latent_states_all = all_data\n",
    "num_latent_states = latent_states_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1667868778304,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "wjgPNitSrt5p",
    "outputId": "0c916524-33ec-47bf-a16a-51e53d2e25f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200001, 2)\n"
     ]
    }
   ],
   "source": [
    "print(latent_states_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1667868778305,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "wnLnqg0Jrt5t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1667868778788,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "BOJE8vREtque"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667868778788,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "fwjcsAxKneQe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778788,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "aFd7XgwVneQe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IAcFjRRn_IQ"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667868778789,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "lPVqWNwjoAGP"
   },
   "outputs": [],
   "source": [
    "# RNN data parameters\n",
    "num_lyaptimesteps_totrain = 5 # int(5000/np.mean(lyapunov_time_arr))#\n",
    "dt_rnn = 0.1\n",
    "T_sample_input = num_lyaptimesteps_totrain*np.mean(lyapunov_time_arr)\n",
    "T_sample_output = num_lyaptimesteps_totrain*np.mean(lyapunov_time_arr)\n",
    "T_offset = dt_rnn\n",
    "normalize_dataset = True # whether the data for the RNN should be normalized by the dataset's mean and std\n",
    "normalization_arr = None\n",
    "skip_intermediate = 'full sample'\n",
    "noise_type = 'normal' # can be 'uniform' or 'normal'\n",
    "\n",
    "# can be 'minmax', 'minmax2', 'stddev', or a list with\n",
    "# sequential order of any of these; if it is 'minmax'\n",
    "# then stddev_multiplier has no effect\n",
    "normalization_type = 'stddev'\n",
    "stddev_multiplier = 3\n",
    "\n",
    "dense_layer_act_func = ['tanh']\n",
    "use_weights_post_dense = True\n",
    "stateful = True\n",
    "use_learnable_state = False\n",
    "use_trainable_weights_with_reslayers = False\n",
    "\n",
    "if return_params_arr != False:\n",
    "    params = params_arr\n",
    "else:\n",
    "    params = None\n",
    "\n",
    "scalar_weights = None\n",
    "num_layers = 1\n",
    "if not isinstance(scalar_weights, type(None)):\n",
    "    num_layers += int(((8*len(scalar_weights)+1)**0.5 - 1)/2)\n",
    "rnn_layers_units = [20*num_latent_states]*num_layers\n",
    "    \n",
    "zoneout_x0 = 0.00\n",
    "vary_zoneout = False\n",
    "\n",
    "\n",
    "if return_params_arr != False:\n",
    "    params = params_arr\n",
    "else:\n",
    "    params = None\n",
    "\n",
    "# saving simulation data\n",
    "sim_data = {\n",
    "    'params_mat':params_mat,\n",
    "    'init_state_mat':init_state_mat,\n",
    "    't0':t0,\n",
    "    'T':T,\n",
    "    'delta_t':delta_t,\n",
    "    'return_params_arr':return_params_arr,\n",
    "    'dir_name_ae':dir_name_ae,\n",
    "    'normalize_dataset':normalize_dataset,\n",
    "    'stddev_multiplier':stddev_multiplier,\n",
    "    'use_ae_data':use_ae_data,\n",
    "}\n",
    "\n",
    "# saving RNN specific data\n",
    "RNN_specific_data = {    \n",
    "    'dt_rnn':dt_rnn,\n",
    "    'T_sample_input':T_sample_input,\n",
    "    'T_sample_output':T_sample_output,\n",
    "    'T_offset':T_offset,\n",
    "    'boundary_idx_arr':boundary_idx_arr,\n",
    "    'delta_t':delta_t,\n",
    "    'params':params,\n",
    "    'return_params_arr':return_params_arr,\n",
    "    'normalize_dataset':normalize_dataset,\n",
    "    'num_lyaptimesteps_totrain':num_lyaptimesteps_totrain,\n",
    "    'stddev_multiplier':stddev_multiplier,\n",
    "    'skip_intermediate':skip_intermediate,\n",
    "    'module':RNN_GRU.__module__,\n",
    "    'noise_type':noise_type,\n",
    "    'normalization_type':normalization_type,\n",
    "    'dense_layer_act_func':dense_layer_act_func,\n",
    "    'stateful':stateful,\n",
    "    'use_learnable_state':use_learnable_state,\n",
    "    'use_weights_post_dense':use_weights_post_dense,\n",
    "    'use_trainable_weights_with_reslayers':use_trainable_weights_with_reslayers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778789,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "S21-VEUYrkk-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778789,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "UGnj8uQQ83-y"
   },
   "outputs": [],
   "source": [
    "# latent_states_all = latent_states_all[0:375009]\n",
    "# boundary_idx_arr = [375009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667868778790,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "0t2_8mzI1fhX"
   },
   "outputs": [],
   "source": [
    "rnn_res_dict = create_data_for_RNN(\n",
    "    latent_states_all,\n",
    "    dt_rnn,\n",
    "    T_sample_input,\n",
    "    T_sample_output,\n",
    "    T_offset,\n",
    "    None,\n",
    "    boundary_idx_arr,\n",
    "    delta_t,\n",
    "    params=params,\n",
    "    return_numsamples=True,\n",
    "    normalize_dataset=normalize_dataset,\n",
    "    stddev_multiplier=stddev_multiplier,\n",
    "    skip_intermediate=skip_intermediate,\n",
    "    return_OrgDataIdxArr=False,\n",
    "    normalization_arr_external=normalization_arr,\n",
    "    normalization_type=normalization_type,\n",
    "    FTYPE=FTYPE,\n",
    "    ITYPE=ITYPE)\n",
    "    \n",
    "data_rnn_input = rnn_res_dict['data_rnn_input']\n",
    "data_rnn_output = rnn_res_dict['data_rnn_output']\n",
    "org_data_idx_arr_input = rnn_res_dict['org_data_idx_arr_input']\n",
    "org_data_idx_arr_output = rnn_res_dict['org_data_idx_arr_output']\n",
    "num_samples = rnn_res_dict['num_samples']\n",
    "normalization_arr = rnn_res_dict['normalization_arr']\n",
    "rnn_data_boundary_idx_arr = rnn_res_dict['rnn_data_boundary_idx_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778790,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "pIsWCXkbr7ws"
   },
   "outputs": [],
   "source": [
    "temp = np.divide(latent_states_all-normalization_arr[0], normalization_arr[1])\n",
    "time_stddev = np.std(temp, axis=0)\n",
    "timeMeanofSpaceRMS = np.mean(np.mean(temp**2, axis=1)**0.5)\n",
    "del(org_data_idx_arr_input)\n",
    "del(org_data_idx_arr_output)\n",
    "del(latent_states_all)\n",
    "del(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667868778790,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "Hem_9PUqneQi"
   },
   "outputs": [],
   "source": [
    "rnn_res_dict = create_data_for_RNN(\n",
    "    all_data,\n",
    "    dt_rnn,\n",
    "    T_sample_input,\n",
    "    T_sample_output,\n",
    "    T_offset,\n",
    "    None,\n",
    "    boundary_idx_arr,\n",
    "    delta_t,\n",
    "    params=params,\n",
    "    return_numsamples=True,\n",
    "    normalize_dataset=False,\n",
    "    stddev_multiplier=stddev_multiplier,\n",
    "    skip_intermediate=skip_intermediate,\n",
    "    return_OrgDataIdxArr=False,\n",
    "    normalization_arr_external=normalization_arr,\n",
    "    normalization_type=normalization_type,\n",
    "    FTYPE=FTYPE,\n",
    "    ITYPE=ITYPE)\n",
    "    \n",
    "AR_data_rnn_input = rnn_res_dict['data_rnn_input']\n",
    "AR_data_rnn_output = rnn_res_dict['data_rnn_output']\n",
    "AR_org_data_idx_arr_input = rnn_res_dict['org_data_idx_arr_input']\n",
    "AR_org_data_idx_arr_output = rnn_res_dict['org_data_idx_arr_output']\n",
    "AR_num_samples = rnn_res_dict['num_samples']\n",
    "AR_normalization_arr = rnn_res_dict['normalization_arr']\n",
    "AR_rnn_data_boundary_idx_arr = rnn_res_dict['rnn_data_boundary_idx_arr']\n",
    "\n",
    "del(AR_org_data_idx_arr_input)\n",
    "del(AR_org_data_idx_arr_output)\n",
    "del(AR_rnn_data_boundary_idx_arr)\n",
    "\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667868778791,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "uskBAAXpneQi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 55, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_rnn_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1667868779211,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "-1uL-GomneQi"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "learning_rate_list = [1e-2, 1e-3, 1e-4]#, 1e-5]\n",
    "epochs = 125\n",
    "patience = 10 # parameter for early stopping\n",
    "min_delta = 1e-6  # parameter for early stopping\n",
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 1 - train_split - val_split\n",
    "batch_size = 32\n",
    "rnncell_dropout_rate = 0.0\n",
    "denselayer_dropout_rate = 0.0\n",
    "\n",
    "lambda_reg_x0 = 1e-7 # weight for regularizer\n",
    "fRMS_x0 = 1e-3\n",
    "\n",
    "rnncell_dropout_rate = 0.0\n",
    "denselayer_dropout_rate = 0.0\n",
    "\n",
    "# ph computation parameters\n",
    "num_runs = 25\n",
    "T_sample_input_AR_ratio = 1\n",
    "T_sample_output_AR_ratio = 2\n",
    "\n",
    "# saving training params\n",
    "training_specific_params = {\n",
    "    'epochs':epochs,\n",
    "    'prng_seed':prng_seed,\n",
    "    'train_split':train_split,\n",
    "    'val_split':val_split,\n",
    "    'batch_size':batch_size,\n",
    "    # 'fRMS':fRMS,\n",
    "    'timeMeanofSpaceRMS':timeMeanofSpaceRMS,\n",
    "    # 'stddev':stddev,\n",
    "    # 'lambda_reg':lambda_reg,\n",
    "    'min_delta':min_delta,\n",
    "    'patience':patience,\n",
    "    'rnncell_dropout_rate':rnncell_dropout_rate,\n",
    "    'denselayer_dropout_rate':denselayer_dropout_rate,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667868779212,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "4hx9ZaSpEMmv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1667868779601,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "EENXaWqcKW7j"
   },
   "outputs": [],
   "source": [
    "cum_samples = rnn_data_boundary_idx_arr[-1]\n",
    "# idx = np.arange(cum_samples)\n",
    "# np.random.shuffle(idx)\n",
    "num_train_arr = np.zeros(shape=rnn_data_boundary_idx_arr.shape[0], dtype='int32')\n",
    "num_val_arr = np.zeros(shape=rnn_data_boundary_idx_arr.shape[0], dtype='int32')\n",
    "num_test_arr = np.zeros(shape=rnn_data_boundary_idx_arr.shape[0], dtype='int32')\n",
    "num_samples_arr = np.zeros(shape=rnn_data_boundary_idx_arr.shape[0], dtype='int32')\n",
    "begin_idx = 0\n",
    "for i in range(len(rnn_data_boundary_idx_arr)):\n",
    "    num_samples = rnn_data_boundary_idx_arr[i] - begin_idx\n",
    "    num_train_arr[i] = batch_size * int( np.round(train_split*num_samples/batch_size) )\n",
    "    num_val_arr[i] = batch_size * int( np.round(val_split*num_samples/batch_size) )\n",
    "    num_test_arr[i] = batch_size * int( np.round((num_samples - num_train_arr[i] - num_val_arr[i])/batch_size) )\n",
    "    num_samples_arr[i] = num_train_arr[i] + num_val_arr[i] + num_test_arr[i]\n",
    "    begin_idx = rnn_data_boundary_idx_arr[i]\n",
    "\n",
    "# defining shapes\n",
    "training_input_shape = [np.sum(num_train_arr)]\n",
    "training_input_shape.extend(data_rnn_input.shape[1:])\n",
    "\n",
    "training_output_shape = [np.sum(num_train_arr)]\n",
    "training_output_shape.extend(data_rnn_output.shape[1:])\n",
    "\n",
    "val_input_shape = [np.sum(num_val_arr)]\n",
    "val_input_shape.extend(data_rnn_input.shape[1:])\n",
    "\n",
    "val_output_shape = [np.sum(num_val_arr)]\n",
    "val_output_shape.extend(data_rnn_output.shape[1:])\n",
    "\n",
    "testing_input_shape = [np.sum(num_test_arr)]\n",
    "testing_input_shape.extend(data_rnn_input.shape[1:])\n",
    "\n",
    "testing_output_shape = [np.sum(num_test_arr)]\n",
    "testing_output_shape.extend(data_rnn_output.shape[1:])\n",
    "\n",
    "# defining required arrays\n",
    "training_data_rnn_input = np.empty(shape=training_input_shape, dtype=FTYPE)\n",
    "training_data_rnn_output = np.empty(shape=training_output_shape, dtype=FTYPE)\n",
    "\n",
    "val_data_rnn_input = np.empty(shape=val_input_shape, dtype=FTYPE)\n",
    "val_data_rnn_output = np.empty(shape=val_output_shape, dtype=FTYPE)\n",
    "\n",
    "testing_data_rnn_input = np.empty(shape=testing_input_shape, dtype=FTYPE)\n",
    "testing_data_rnn_output = np.empty(shape=testing_output_shape, dtype=FTYPE)\n",
    "\n",
    "AR_testing_data_rnn_input = np.empty(shape=tuple(testing_input_shape[0:2])+tuple(AR_data_rnn_input.shape[2:]), dtype=FTYPE)\n",
    "AR_testing_data_rnn_output = np.empty(shape=tuple(testing_input_shape[0:2])+tuple(AR_data_rnn_input.shape[2:]), dtype=FTYPE)\n",
    "\n",
    "begin_idx = 0\n",
    "training_data_rolling_count = 0\n",
    "val_data_rolling_count = 0\n",
    "testing_data_rolling_count = 0\n",
    "for i in range(len(boundary_idx_arr)):\n",
    "    idx = np.arange(begin_idx, rnn_data_boundary_idx_arr[i])\n",
    "    # np.random.shuffle(idx)\n",
    "    # num_samples = idx.shape[0]\n",
    "    # num_train = int( np.round(train_split*num_samples/batch_size) )*batch_size\n",
    "    # num_val = int( np.round(val_split*num_samples/batch_size) )*batch_size\n",
    "    \n",
    "    num_samples = num_samples_arr[i]\n",
    "    num_train = num_train_arr[i]\n",
    "    num_val = num_val_arr[i]\n",
    "    num_test = num_test_arr[i]\n",
    "    \n",
    "    nbatches_train = num_train // batch_size\n",
    "    nbatches_val = num_val // batch_size\n",
    "    nbatches_test = num_test // batch_size\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        training_data_rnn_input[training_data_rolling_count+j:training_data_rolling_count+num_train:batch_size] = data_rnn_input[idx[0:num_train]][j*nbatches_train:(j+1)*nbatches_train]\n",
    "        training_data_rnn_output[training_data_rolling_count+j:training_data_rolling_count+num_train:batch_size] = data_rnn_output[idx[0:num_train]][j*nbatches_train:(j+1)*nbatches_train]\n",
    "        \n",
    "        val_data_rnn_input[val_data_rolling_count+j:val_data_rolling_count+num_val:batch_size] = data_rnn_input[idx[num_train:num_train+num_val]][j*nbatches_val:(j+1)*nbatches_val]\n",
    "        val_data_rnn_output[val_data_rolling_count+j:val_data_rolling_count+num_val:batch_size] = data_rnn_output[idx[num_train:num_train+num_val]][j*nbatches_val:(j+1)*nbatches_val]\n",
    "\n",
    "        testing_data_rnn_input[testing_data_rolling_count+j:testing_data_rolling_count+num_test:batch_size] = data_rnn_input[idx[num_train+num_val:num_samples]][j*nbatches_test:(j+1)*nbatches_test]\n",
    "        testing_data_rnn_output[testing_data_rolling_count+j:testing_data_rolling_count+num_test:batch_size] = data_rnn_output[idx[num_train+num_val:num_samples]][j*nbatches_test:(j+1)*nbatches_test]\n",
    "        \n",
    "        AR_testing_data_rnn_input[testing_data_rolling_count+j:testing_data_rolling_count+num_test:batch_size] = AR_data_rnn_input[idx[num_train+num_val:num_samples]][j*nbatches_test:(j+1)*nbatches_test]\n",
    "        AR_testing_data_rnn_output[testing_data_rolling_count+j:testing_data_rolling_count+num_test:batch_size] = AR_data_rnn_output[idx[num_train+num_val:num_samples]][j*nbatches_test:(j+1)*nbatches_test]\n",
    "\n",
    "\n",
    "    # training_data_rnn_input[training_data_rolling_count:training_data_rolling_count+num_train] = data_rnn_input[idx[0:num_train]]\n",
    "    # training_data_rnn_output[training_data_rolling_count:training_data_rolling_count+num_train] = data_rnn_output[idx[0:num_train]]\n",
    "    training_data_rolling_count += num_train\n",
    "\n",
    "    # val_data_rnn_input[val_data_rolling_count:val_data_rolling_count+num_val] = data_rnn_input[idx[num_train:num_train+num_val]]\n",
    "    # val_data_rnn_output[val_data_rolling_count:val_data_rolling_count+num_val] = data_rnn_output[idx[num_train:num_train+num_val]]\n",
    "    val_data_rolling_count += num_val\n",
    "\n",
    "    # num_test = num_samples-num_train-num_val+1\n",
    "    # testing_data_rnn_input[testing_data_rolling_count:testing_data_rolling_count+num_test] = data_rnn_input[idx[num_train+num_val:]]\n",
    "    # testing_data_rnn_output[testing_data_rolling_count:testing_data_rolling_count+num_test] = data_rnn_output[idx[num_train+num_val:]]\n",
    "    testing_data_rolling_count += num_test\n",
    "\n",
    "    begin_idx = rnn_data_boundary_idx_arr[i]\n",
    "\n",
    "# cleaning up\n",
    "del(data_rnn_input)\n",
    "del(data_rnn_output)\n",
    "del(AR_data_rnn_input)\n",
    "del(AR_data_rnn_output)\n",
    "\n",
    "# further shuffling\n",
    "if stateful == False:\n",
    "    idx = np.arange(0, training_data_rnn_input.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    training_data_rnn_input = training_data_rnn_input[idx]\n",
    "    training_data_rnn_output = training_data_rnn_output[idx]\n",
    "\n",
    "    idx = np.arange(0, val_data_rnn_input.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    val_data_rnn_input = val_data_rnn_input[idx]\n",
    "    val_data_rnn_output = val_data_rnn_output[idx]\n",
    "\n",
    "    idx = np.arange(0, testing_data_rnn_input.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    testing_data_rnn_input = testing_data_rnn_input[idx]\n",
    "    testing_data_rnn_output = testing_data_rnn_output[idx]\n",
    "\n",
    "    del(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_runs :  25\n"
     ]
    }
   ],
   "source": [
    "s_in = AR_testing_data_rnn_input.shape\n",
    "AR_testing_data_rnn_input = AR_testing_data_rnn_input.reshape((1, s_in[0]*s_in[1]) + s_in[2:])\n",
    "\n",
    "s_out = AR_testing_data_rnn_output.shape\n",
    "AR_testing_data_rnn_output = AR_testing_data_rnn_output.reshape((1, s_out[0]*s_out[1]) + s_out[2:])\n",
    "\n",
    "T_sample_input_AR = T_sample_input_AR_ratio*np.mean(lyapunov_time_arr)#50.1*dt_rnn\n",
    "num_sample_input_AR = int((T_sample_input_AR+0.5*dt_rnn)//dt_rnn)\n",
    "\n",
    "T_sample_output_AR = T_sample_output_AR_ratio*np.mean(lyapunov_time_arr)\n",
    "num_sample_output_AR = int((T_sample_output_AR+0.5*dt_rnn)//dt_rnn)\n",
    "\n",
    "num_offset_AR = num_sample_input_AR\n",
    "T_offset_AR = num_offset_AR*dt_rnn\n",
    "\n",
    "batch_idx = np.random.randint(low=0, high=AR_testing_data_rnn_input.shape[0])\n",
    "maxpossible_num_runs = AR_testing_data_rnn_input.shape[1]-(num_sample_input_AR+num_sample_output_AR)\n",
    "\n",
    "num_runs = np.min([num_runs, maxpossible_num_runs])\n",
    "\n",
    "print('num_runs : ', num_runs)\n",
    "\n",
    "data_idx_arr = np.linspace(0, maxpossible_num_runs-1, num_runs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_data_in = np.empty(shape=(num_runs, num_sample_input_AR)+tuple(s_in[2:]))\n",
    "AR_data_out = np.empty(shape=(num_runs, num_sample_output_AR)+tuple(s_out[2:]))\n",
    "\n",
    "for i in range(num_runs):\n",
    "    d_idx = data_idx_arr[i]\n",
    "    AR_data_in[i] = AR_testing_data_rnn_input[0, d_idx:d_idx+num_sample_input_AR]\n",
    "    AR_data_out[i] = AR_testing_data_rnn_input[0, d_idx+num_sample_input_AR:d_idx+num_sample_input_AR+num_sample_output_AR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(AR_testing_data_rnn_input)\n",
    "del(AR_testing_data_rnn_output)\n",
    "AR_testing_data_rnn_input = AR_data_in\n",
    "AR_testing_data_rnn_output = AR_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667868779603,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "8isZN1tYBifp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   training_data_rnn_input.shape :  (6016, 55, 2)\n",
      "  training_data_rnn_output.shape :  (6016, 55, 2)\n",
      "    testing_data_rnn_input.shape :  (736, 55, 2)\n",
      "   testing_data_rnn_output.shape :  (736, 55, 2)\n",
      "        val_data_rnn_input.shape :  (736, 55, 2)\n",
      "       val_data_rnn_output.shape :  (736, 55, 2)\n",
      "\n",
      " AR_testing_data_rnn_input.shape :  (25, 11, 3)\n",
      "AR_testing_data_rnn_output.shape :  (25, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "print('   training_data_rnn_input.shape : ', training_data_rnn_input.shape)\n",
    "print('  training_data_rnn_output.shape : ', training_data_rnn_output.shape)\n",
    "print('    testing_data_rnn_input.shape : ', testing_data_rnn_input.shape)\n",
    "print('   testing_data_rnn_output.shape : ', testing_data_rnn_output.shape)\n",
    "print('        val_data_rnn_input.shape : ', val_data_rnn_input.shape)\n",
    "print('       val_data_rnn_output.shape : ', val_data_rnn_output.shape)\n",
    "print('')\n",
    "print(' AR_testing_data_rnn_input.shape : ', AR_testing_data_rnn_input.shape)\n",
    "print('AR_testing_data_rnn_output.shape : ', AR_testing_data_rnn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667868779605,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "x3KglJsgneQj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1667868779606,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "ixetsZHjCMKO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667868779606,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "_NSTtZuyneQk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3631,
     "status": "ok",
     "timestamp": 1667868783230,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "Py-Jg0QKneQk",
    "outputId": "1b768270-9013-4d53-8b5e-63e69776e3ac",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667868783568,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "7ASCopnIH6nl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_rnn_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4769220,
     "status": "ok",
     "timestamp": 1667873552785,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "6hh1pbKjCcO4",
    "outputId": "e594f4de-ec70-465e-eef7-bdef301361fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optim_func(\n",
    "        x, # [fRMS, lambda_reg, zoneout]\n",
    "        time_stddev=time_stddev,\n",
    "        og_vars=og_vars,\n",
    "        RNN_GRU=RNN_GRU,\n",
    "        AR_RNN_GRU=AR_RNN_GRU,\n",
    "        AR_AERNN_GRU=AR_AERNN_GRU,\n",
    "        ae_net=ae_net,\n",
    "        mytimecallback=mytimecallback,\n",
    "        SaveLosses=SaveLosses,\n",
    "        plot_losses=plot_losses,\n",
    "        dir_name_rnn=dir_name_rnn,\n",
    "        boundary_idx_arr=rnn_data_boundary_idx_arr,\n",
    "        lyapunov_time_arr=lyapunov_time_arr,\n",
    "        sim_data_dict=sim_data,\n",
    "        RNN_specific_data_dict=RNN_specific_data,\n",
    "        training_specific_params_dict=training_specific_params,\n",
    "        normalization_arr=normalization_arr,\n",
    "        training_data_rnn_input=training_data_rnn_input,\n",
    "        training_data_rnn_output=training_data_rnn_output,\n",
    "        testing_data_rnn_input=testing_data_rnn_input,\n",
    "        testing_data_rnn_output=testing_data_rnn_output,\n",
    "        val_data_rnn_input=val_data_rnn_input,\n",
    "        val_data_rnn_output=val_data_rnn_output,\n",
    "        AR_testing_data_rnn_input=AR_testing_data_rnn_input,\n",
    "        AR_testing_data_rnn_output=AR_testing_data_rnn_output,\n",
    "        return_params_arr=return_params_arr,\n",
    "        normalize_dataset=normalize_dataset,\n",
    "        dt_rnn=dt_rnn,\n",
    "        noise_type=noise_type,\n",
    "        ae_data_normalization_arr=normalization_constant_arr_aedata,\n",
    "        time_stddev_ogdata=time_stddev_ogdata,\n",
    "        time_mean_ogdata=time_mean_ogdata,\n",
    "        T_sample_input=T_sample_input_AR,\n",
    "        T_sample_output=T_sample_output_AR,\n",
    "        rnn_layers_units=rnn_layers_units,\n",
    "        stateful=stateful,\n",
    "        reg_name='L2',\n",
    "        dense_layer_act_func=dense_layer_act_func,\n",
    "        use_learnable_state=use_learnable_state,\n",
    "        use_weights_post_dense=use_weights_post_dense,\n",
    "        rnncell_dropout_rate=rnncell_dropout_rate,\n",
    "        denselayer_dropout_rate=denselayer_dropout_rate,\n",
    "        scalar_weights=scalar_weights,\n",
    "        prng_seed=prng_seed,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        patience=patience,  # parameter for early stopping\n",
    "        min_delta=min_delta,  # parameter for early stopping\n",
    "        batch_size=batch_size,\n",
    "        zoneout=zoneout_x0,\n",
    "    ):\n",
    "    \n",
    "    compute_time = time.time()\n",
    "    \n",
    "    x = [elem for elem in np.array(x).flatten()]\n",
    "    if len(x) < 3:\n",
    "        x.append(zoneout)\n",
    "\n",
    "    median_PH = trainGRU_and_return_PH(\n",
    "        x, # [fRMS, lambda_reg, zoneout]\n",
    "        time_stddev,\n",
    "        og_vars,\n",
    "        RNN_GRU,\n",
    "        AR_RNN_GRU,\n",
    "        AR_AERNN_GRU,\n",
    "        ae_net,\n",
    "        mytimecallback,\n",
    "        SaveLosses,\n",
    "        plot_losses,\n",
    "        dir_name_rnn,\n",
    "        boundary_idx_arr,\n",
    "        lyapunov_time_arr,\n",
    "        sim_data_dict,\n",
    "        RNN_specific_data_dict,\n",
    "        training_specific_params_dict,\n",
    "        normalization_arr,\n",
    "        training_data_rnn_input,\n",
    "        training_data_rnn_output,\n",
    "        testing_data_rnn_input,\n",
    "        testing_data_rnn_output,\n",
    "        val_data_rnn_input,\n",
    "        val_data_rnn_output,\n",
    "        AR_testing_data_rnn_input,\n",
    "        AR_testing_data_rnn_output,\n",
    "        return_params_arr,\n",
    "        normalize_dataset,\n",
    "        dt_rnn,\n",
    "        noise_type,\n",
    "        ae_data_normalization_arr,\n",
    "        time_stddev_ogdata,\n",
    "        time_mean_ogdata,\n",
    "        T_sample_input=T_sample_input,\n",
    "        T_sample_output=T_sample_output,\n",
    "        rnn_layers_units=rnn_layers_units,\n",
    "        stateful=stateful,\n",
    "        reg_name=reg_name,\n",
    "        dense_layer_act_func=dense_layer_act_func,\n",
    "        use_learnable_state=use_learnable_state,\n",
    "        use_weights_post_dense=use_weights_post_dense,\n",
    "        rnncell_dropout_rate=rnncell_dropout_rate,\n",
    "        denselayer_dropout_rate=denselayer_dropout_rate,\n",
    "        scalar_weights=scalar_weights,\n",
    "        prng_seed=prng_seed,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        patience=patience,  # parameter for early stopping\n",
    "        min_delta=min_delta,  # parameter for early stopping\n",
    "        batch_size=batch_size,\n",
    "        error_threshold=0.5,\n",
    "        xlabel_kwargs={'fontsize':15},\n",
    "        ylabel_kwargs={'fontsize':15},\n",
    "        legend_kwargs={'fontsize':12},\n",
    "    )\n",
    "    \n",
    "    compute_time = time.time() - compute_time\n",
    "    print('compute_time : {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        float(compute_time // 3600),\n",
    "        float((compute_time%3600)//60),\n",
    "        float((compute_time%3600)%60),\n",
    "    ))\n",
    "    \n",
    "    return -median_PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bounds = [\n",
    "    [1e-4, 1e-1, \"log-uniform\", \"Real\"], # fRMS\n",
    "    [1e-7, 1e-3, \"log-uniform\", \"Real\"], # lambda_reg\n",
    "]\n",
    "if vary_zoneout == True:\n",
    "    x_bounds.append([0.0, 0.5, \"uniform\", \"Real\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_dims : 2 ; num_points : 20 ; h_order : 3\n"
     ]
    }
   ],
   "source": [
    "h_dims = len(x_bounds)\n",
    "# num_points = 10*h_dims\n",
    "num_points = 20\n",
    "\n",
    "h_order = 0\n",
    "while(True):\n",
    "    if 2**(h_dims*h_order) >= num_points:\n",
    "        break\n",
    "    else:\n",
    "        h_order += 1\n",
    "\n",
    "print('h_dims : {} ; num_points : {} ; h_order : {}'.format(h_dims, num_points, h_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = return_hilbert_x0(num_points, h_dims, h_order)\n",
    "# print(locs)\n",
    "locs = np.array(locs, dtype=np.float64)\n",
    "locs /= 2**h_order-1\n",
    "# print(locs)\n",
    "\n",
    "for i in range(h_dims):\n",
    "    x1 = x_bounds[i][0]\n",
    "    x2 = x_bounds[i][1]\n",
    "    if x_bounds[i][2] == \"log-uniform\":\n",
    "        x1 = np.log10(x1)\n",
    "        x2 = np.log10(x2)\n",
    "    spread = x2 - x1\n",
    "    locs[:, i] *= spread\n",
    "    locs[:, i] += x1\n",
    "    if x_bounds[i][2] == \"log-uniform\":\n",
    "        locs[:, i] = 10**(locs[:, i])\n",
    "\n",
    "# print(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    eval(elem[3])(*elem[0:3]) for elem in x_bounds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e-04 1.00000000e-07]\n",
      " [2.68269580e-04 1.00000000e-07]\n",
      " [1.93069773e-03 3.72759372e-07]\n",
      " [1.93069773e-03 1.38949549e-06]\n",
      " [2.68269580e-04 5.17947468e-06]\n",
      " [1.00000000e-04 1.93069773e-05]\n",
      " [1.00000000e-04 7.19685673e-05]\n",
      " [2.68269580e-04 1.00000000e-03]\n",
      " [7.19685673e-04 1.00000000e-03]\n",
      " [1.93069773e-03 7.19685673e-05]\n",
      " [5.17947468e-03 1.93069773e-05]\n",
      " [5.17947468e-03 7.19685673e-05]\n",
      " [1.38949549e-02 1.00000000e-03]\n",
      " [3.72759372e-02 1.00000000e-03]\n",
      " [1.00000000e-01 7.19685673e-05]\n",
      " [1.00000000e-01 5.17947468e-06]\n",
      " [3.72759372e-02 5.17947468e-06]\n",
      " [5.17947468e-03 1.38949549e-06]\n",
      " [5.17947468e-03 3.72759372e-07]\n",
      " [3.72759372e-02 1.00000000e-07]]\n",
      "[[0.0001, 1e-07], [0.00026826957952797245, 1e-07], [0.0019306977288832496, 3.727593720314938e-07], [0.0019306977288832496, 1.389495494373136e-06], [0.00026826957952797245, 5.179474679231212e-06], [0.0001, 1.9306977288832496e-05], [0.0001, 7.196856730011529e-05], [0.00026826957952797245, 0.001], [0.0007196856730011522, 0.001], [0.0019306977288832496, 7.196856730011529e-05], [0.005179474679231213, 1.9306977288832496e-05], [0.005179474679231213, 7.196856730011529e-05], [0.013894954943731374, 0.001], [0.03727593720314938, 0.001], [0.1, 7.196856730011529e-05], [0.1, 5.179474679231212e-06], [0.03727593720314938, 5.179474679231212e-06], [0.005179474679231213, 1.389495494373136e-06], [0.005179474679231213, 3.727593720314938e-07], [0.03727593720314938, 1e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(locs)\n",
    "\n",
    "x0 = [\n",
    "    [elem2 for elem2 in elem1] for elem1 in locs\n",
    "]\n",
    "\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_func = \"EI\"\n",
    "n_initial_points = 0\n",
    "n_calls = n_initial_points + len(x0) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {\n",
    "    'fRMS_bounds':x_bounds[0],\n",
    "    'lambda_reg_bounds':x_bounds[1],\n",
    "    'n_calls':n_calls,\n",
    "    'acq_func':acq_func,\n",
    "    'n_initial_points':n_initial_points,\n",
    "    'random_state':prng_seed,\n",
    "    'vary_zoneout':vary_zoneout,\n",
    "}\n",
    "if vary_zoneout == True:\n",
    "    optim_dict['zoneout_bounds'] = x_bounds[2]\n",
    "with open(dir_name_rnn + '/optim_params.txt', 'w') as f:\n",
    "    f.write(str(optim_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10543,
     "status": "ok",
     "timestamp": 1667873563321,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "SO7iK4mbneQm",
    "outputId": "48110900-962a-49c1-c532-718999590884",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------- LEARNING RATE : 0.01 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0109 - mse: 0.0109 - NMSE: 0.0982 - tot_time: 0h 0m 11.1s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.00934, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 49ms/step - loss: 0.0109 - mse: 0.0109 - NMSE: 0.0982 - val_loss: 0.0011 - val_mse: 0.0010 - val_NMSE: 0.0093\n",
      "Epoch 2/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 6.8255e-04 - mse: 6.2144e-04 - NMSE: 0.0056 - tot_time: 0h 0m 20.2s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00934 to 0.00520, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 6.8134e-04 - mse: 6.2021e-04 - NMSE: 0.0056 - val_loss: 6.4025e-04 - val_mse: 5.7555e-04 - val_NMSE: 0.0052\n",
      "Epoch 3/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4198e-04 - mse: 3.7554e-04 - NMSE: 0.0034 - tot_time: 0h 0m 29.2s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00520 to 0.00341, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.4198e-04 - mse: 3.7554e-04 - NMSE: 0.0034 - val_loss: 4.4558e-04 - val_mse: 3.7769e-04 - val_NMSE: 0.0034\n",
      "Epoch 4/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.1961e-04 - mse: 3.5074e-04 - NMSE: 0.0032 - tot_time: 0h 0m 37.8s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00341 to 0.00241, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.1876e-04 - mse: 3.4989e-04 - NMSE: 0.0032 - val_loss: 3.3687e-04 - val_mse: 2.6706e-04 - val_NMSE: 0.0024\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 3.2140e-04 - mse: 2.5145e-04 - NMSE: 0.0023 - tot_time: 0h 0m 46.6s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.00241 to 0.00219, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.2140e-04 - mse: 2.5145e-04 - NMSE: 0.0023 - val_loss: 3.1233e-04 - val_mse: 2.4212e-04 - val_NMSE: 0.0022\n",
      "Epoch 6/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.8606e-04 - mse: 2.1582e-04 - NMSE: 0.0020 - tot_time: 0h 0m 55.3s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00219 to 0.00187, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.8557e-04 - mse: 2.1533e-04 - NMSE: 0.0019 - val_loss: 2.7701e-04 - val_mse: 2.0675e-04 - val_NMSE: 0.0019\n",
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.6801e-04 - mse: 1.9786e-04 - NMSE: 0.0018 - tot_time: 0h 1m 4.2s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00187 to 0.00150, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.6751e-04 - mse: 1.9737e-04 - NMSE: 0.0018 - val_loss: 2.3593e-04 - val_mse: 1.6585e-04 - val_NMSE: 0.0015\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.7353e-04 - mse: 2.0354e-04 - NMSE: 0.0018 - tot_time: 0h 1m 13.0s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.00150 to 0.00136, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.7311e-04 - mse: 2.0312e-04 - NMSE: 0.0018 - val_loss: 2.2028e-04 - val_mse: 1.5047e-04 - val_NMSE: 0.0014\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.2656e-04 - mse: 1.5710e-04 - NMSE: 0.0014 - tot_time: 0h 1m 21.7s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.00136 to 0.00119, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.2617e-04 - mse: 1.5672e-04 - NMSE: 0.0014 - val_loss: 2.0080e-04 - val_mse: 1.3165e-04 - val_NMSE: 0.0012\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.2044e-04 - mse: 1.5162e-04 - NMSE: 0.0014 - tot_time: 0h 1m 30.5s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.00119 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.2044e-04 - mse: 1.5162e-04 - NMSE: 0.0014 - val_loss: 1.8190e-04 - val_mse: 1.1337e-04 - val_NMSE: 0.0010\n",
      "Epoch 11/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.2151e-04 - mse: 1.5324e-04 - NMSE: 0.0014 - tot_time: 0h 1m 39.8s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 2.2151e-04 - mse: 1.5324e-04 - NMSE: 0.0014 - val_loss: 2.0400e-04 - val_mse: 1.3603e-04 - val_NMSE: 0.0012\n",
      "Epoch 12/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.8273e-04 - mse: 1.1520e-04 - NMSE: 0.0010 - tot_time: 0h 1m 48.6s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.8245e-04 - mse: 1.1492e-04 - NMSE: 0.0010 - val_loss: 1.9520e-04 - val_mse: 1.2811e-04 - val_NMSE: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.8571e-04 - mse: 1.1900e-04 - NMSE: 0.0011 - tot_time: 0h 1m 57.4s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.8571e-04 - mse: 1.1900e-04 - NMSE: 0.0011 - val_loss: 1.9180e-04 - val_mse: 1.2547e-04 - val_NMSE: 0.0011\n",
      "Epoch 14/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.7080e-04 - mse: 1.0490e-04 - NMSE: 9.4816e-04 - tot_time: 0h 2m 6.2s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.00102 to 0.00083, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.7080e-04 - mse: 1.0490e-04 - NMSE: 9.4816e-04 - val_loss: 1.5711e-04 - val_mse: 9.1664e-05 - val_NMSE: 8.2857e-04\n",
      "Epoch 15/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6644e-04 - mse: 1.0139e-04 - NMSE: 9.1648e-04 - tot_time: 0h 2m 14.9s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.00083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.6644e-04 - mse: 1.0139e-04 - NMSE: 9.1648e-04 - val_loss: 1.7380e-04 - val_mse: 1.0918e-04 - val_NMSE: 9.8695e-04\n",
      "Epoch 16/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6425e-04 - mse: 1.0001e-04 - NMSE: 9.0394e-04 - tot_time: 0h 2m 23.5s\n",
      "\n",
      "Epoch 16: val_NMSE did not improve from 0.00083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.6425e-04 - mse: 1.0001e-04 - NMSE: 9.0394e-04 - val_loss: 1.5922e-04 - val_mse: 9.5372e-05 - val_NMSE: 8.6210e-04\n",
      "Epoch 17/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.7914e-04 - mse: 1.1572e-04 - NMSE: 0.0010 - tot_time: 0h 2m 32.3s\n",
      "\n",
      "Epoch 17: val_NMSE did not improve from 0.00083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.7887e-04 - mse: 1.1544e-04 - NMSE: 0.0010 - val_loss: 1.7683e-04 - val_mse: 1.1359e-04 - val_NMSE: 0.0010\n",
      "Epoch 18/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3633e-04 - mse: 7.3657e-05 - NMSE: 6.6576e-04 - tot_time: 0h 2m 41.0s\n",
      "\n",
      "Epoch 18: val_NMSE did not improve from 0.00083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.3633e-04 - mse: 7.3657e-05 - NMSE: 6.6576e-04 - val_loss: 1.7180e-04 - val_mse: 1.0971e-04 - val_NMSE: 9.9168e-04\n",
      "Epoch 19/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.5622e-04 - mse: 9.4580e-05 - NMSE: 8.5488e-04 - tot_time: 0h 2m 49.8s\n",
      "\n",
      "Epoch 19: val_NMSE improved from 0.00083 to 0.00070, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.5591e-04 - mse: 9.4274e-05 - NMSE: 8.5210e-04 - val_loss: 1.3877e-04 - val_mse: 7.7479e-05 - val_NMSE: 7.0034e-04\n",
      "Epoch 20/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4476e-04 - mse: 8.4025e-05 - NMSE: 7.5944e-04 - tot_time: 0h 2m 58.7s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.00070\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.4476e-04 - mse: 8.4025e-05 - NMSE: 7.5944e-04 - val_loss: 1.4668e-04 - val_mse: 8.6320e-05 - val_NMSE: 7.8022e-04\n",
      "Epoch 21/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3051e-04 - mse: 7.0562e-05 - NMSE: 6.3782e-04 - tot_time: 0h 3m 7.6s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.00070\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.3051e-04 - mse: 7.0562e-05 - NMSE: 6.3782e-04 - val_loss: 1.8316e-04 - val_mse: 1.2376e-04 - val_NMSE: 0.0011\n",
      "Epoch 22/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5984e-04 - mse: 1.0072e-04 - NMSE: 9.1041e-04 - tot_time: 0h 3m 16.5s\n",
      "\n",
      "Epoch 22: val_NMSE did not improve from 0.00070\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.5984e-04 - mse: 1.0072e-04 - NMSE: 9.1041e-04 - val_loss: 1.4659e-04 - val_mse: 8.7608e-05 - val_NMSE: 7.9192e-04\n",
      "Epoch 23/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2043e-04 - mse: 6.1900e-05 - NMSE: 5.5949e-04 - tot_time: 0h 3m 25.3s\n",
      "\n",
      "Epoch 23: val_NMSE did not improve from 0.00070\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.2243e-04 - mse: 6.3903e-05 - NMSE: 5.7760e-04 - val_loss: 7.0078e-04 - val_mse: 6.4286e-04 - val_NMSE: 0.0058\n",
      "Epoch 24/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4046e-04 - mse: 8.2621e-05 - NMSE: 7.4682e-04 - tot_time: 0h 3m 34.0s\n",
      "\n",
      "Epoch 24: val_NMSE improved from 0.00070 to 0.00062, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.4019e-04 - mse: 8.2350e-05 - NMSE: 7.4437e-04 - val_loss: 1.2549e-04 - val_mse: 6.8151e-05 - val_NMSE: 6.1602e-04\n",
      "Epoch 25/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2607e-04 - mse: 6.9092e-05 - NMSE: 6.2452e-04 - tot_time: 0h 3m 42.9s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.00062\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.2608e-04 - mse: 6.9110e-05 - NMSE: 6.2468e-04 - val_loss: 1.3741e-04 - val_mse: 8.0874e-05 - val_NMSE: 7.3099e-04\n",
      "Epoch 26/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1996e-04 - mse: 6.3878e-05 - NMSE: 5.7739e-04 - tot_time: 0h 3m 51.8s\n",
      "\n",
      "Epoch 26: val_NMSE did not improve from 0.00062\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1996e-04 - mse: 6.3878e-05 - NMSE: 5.7739e-04 - val_loss: 1.3037e-04 - val_mse: 7.4802e-05 - val_NMSE: 6.7610e-04\n",
      "Epoch 27/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3125e-04 - mse: 7.5870e-05 - NMSE: 6.8578e-04 - tot_time: 0h 4m 0.9s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.00062 to 0.00058, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.3125e-04 - mse: 7.5870e-05 - NMSE: 6.8578e-04 - val_loss: 1.1887e-04 - val_mse: 6.3817e-05 - val_NMSE: 5.7684e-04\n",
      "Epoch 28/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2525e-04 - mse: 7.0516e-05 - NMSE: 6.3738e-04 - tot_time: 0h 4m 9.6s\n",
      "\n",
      "Epoch 28: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2520e-04 - mse: 7.0466e-05 - NMSE: 6.3692e-04 - val_loss: 1.7494e-04 - val_mse: 1.2064e-04 - val_NMSE: 0.0011\n",
      "Epoch 29/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1122e-04 - mse: 5.7243e-05 - NMSE: 5.1742e-04 - tot_time: 0h 4m 18.5s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1146e-04 - mse: 5.7484e-05 - NMSE: 5.1960e-04 - val_loss: 2.0137e-04 - val_mse: 1.4786e-04 - val_NMSE: 0.0013\n",
      "Epoch 30/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2083e-04 - mse: 6.7513e-05 - NMSE: 6.1024e-04 - tot_time: 0h 4m 27.1s\n",
      "\n",
      "Epoch 30: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2123e-04 - mse: 6.7918e-05 - NMSE: 6.1390e-04 - val_loss: 2.0624e-04 - val_mse: 1.5334e-04 - val_NMSE: 0.0014\n",
      "Epoch 31/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.3246e-04 - mse: 7.9672e-05 - NMSE: 7.2020e-04 - tot_time: 0h 4m 35.8s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.3260e-04 - mse: 7.9819e-05 - NMSE: 7.2152e-04 - val_loss: 1.7516e-04 - val_mse: 1.2253e-04 - val_NMSE: 0.0011\n",
      "Epoch 32/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2486e-04 - mse: 7.2547e-05 - NMSE: 6.5573e-04 - tot_time: 0h 4m 44.4s\n",
      "\n",
      "Epoch 32: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 1.2486e-04 - mse: 7.2547e-05 - NMSE: 6.5573e-04 - val_loss: 1.1780e-04 - val_mse: 6.5741e-05 - val_NMSE: 5.9423e-04\n",
      "Epoch 33/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1513e-04 - mse: 6.3338e-05 - NMSE: 5.7251e-04 - tot_time: 0h 4m 53.5s\n",
      "\n",
      "Epoch 33: val_NMSE improved from 0.00058 to 0.00048, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.1492e-04 - mse: 6.3131e-05 - NMSE: 5.7064e-04 - val_loss: 1.0426e-04 - val_mse: 5.2683e-05 - val_NMSE: 4.7620e-04\n",
      "Epoch 34/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0787e-04 - mse: 5.6681e-05 - NMSE: 5.1233e-04 - tot_time: 0h 5m 2.4s\n",
      "\n",
      "Epoch 34: val_NMSE did not improve from 0.00048\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.0787e-04 - mse: 5.6681e-05 - NMSE: 5.1233e-04 - val_loss: 1.3566e-04 - val_mse: 8.4946e-05 - val_NMSE: 7.6789e-04\n",
      "Epoch 35/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0498e-04 - mse: 5.4594e-05 - NMSE: 4.9347e-04 - tot_time: 0h 5m 11.0s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.00048\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.0498e-04 - mse: 5.4594e-05 - NMSE: 4.9347e-04 - val_loss: 1.1133e-04 - val_mse: 6.1405e-05 - val_NMSE: 5.5505e-04\n",
      "Epoch 36/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1500e-04 - mse: 6.5317e-05 - NMSE: 5.9039e-04 - tot_time: 0h 5m 20.0s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.00048\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.1500e-04 - mse: 6.5317e-05 - NMSE: 5.9039e-04 - val_loss: 1.0506e-04 - val_mse: 5.5702e-05 - val_NMSE: 5.0351e-04\n",
      "Epoch 37/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5531e-04 - mse: 1.0578e-04 - NMSE: 9.5607e-04 - tot_time: 0h 5m 28.6s\n",
      "\n",
      "Epoch 37: val_NMSE improved from 0.00048 to 0.00044, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.5531e-04 - mse: 1.0578e-04 - NMSE: 9.5607e-04 - val_loss: 9.7952e-05 - val_mse: 4.8385e-05 - val_NMSE: 4.3736e-04\n",
      "Epoch 38/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.0226e-05 - mse: 4.1134e-05 - NMSE: 3.7182e-04 - tot_time: 0h 5m 37.1s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.00044\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 9.0226e-05 - mse: 4.1134e-05 - NMSE: 3.7182e-04 - val_loss: 1.0577e-04 - val_mse: 5.7228e-05 - val_NMSE: 5.1730e-04\n",
      "Epoch 39/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0794e-04 - mse: 5.9632e-05 - NMSE: 5.3904e-04 - tot_time: 0h 5m 45.9s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.00044\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.0780e-04 - mse: 5.9494e-05 - NMSE: 5.3780e-04 - val_loss: 1.1158e-04 - val_mse: 6.3639e-05 - val_NMSE: 5.7521e-04\n",
      "Epoch 40/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1348e-04 - mse: 6.5710e-05 - NMSE: 5.9393e-04 - tot_time: 0h 5m 54.6s\n",
      "\n",
      "Epoch 40: val_NMSE did not improve from 0.00044\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.1348e-04 - mse: 6.5710e-05 - NMSE: 5.9393e-04 - val_loss: 9.7899e-05 - val_mse: 5.0558e-05 - val_NMSE: 4.5700e-04\n",
      "Epoch 41/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.4775e-05 - mse: 4.7812e-05 - NMSE: 4.3217e-04 - tot_time: 0h 6m 3.2s\n",
      "\n",
      "Epoch 41: val_NMSE did not improve from 0.00044\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.4775e-05 - mse: 4.7812e-05 - NMSE: 4.3217e-04 - val_loss: 1.7039e-04 - val_mse: 1.2391e-04 - val_NMSE: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.5932e-04 - mse: 1.1254e-04 - NMSE: 0.0010 - tot_time: 0h 6m 12.1s\n",
      "\n",
      "Epoch 42: val_NMSE improved from 0.00044 to 0.00043, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.5884e-04 - mse: 1.1206e-04 - NMSE: 0.0010 - val_loss: 9.4894e-05 - val_mse: 4.7958e-05 - val_NMSE: 4.3350e-04\n",
      "Epoch 43/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.9480e-05 - mse: 5.2801e-05 - NMSE: 4.7722e-04 - tot_time: 0h 6m 20.8s\n",
      "\n",
      "Epoch 43: val_NMSE improved from 0.00043 to 0.00040, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.9302e-05 - mse: 5.2625e-05 - NMSE: 4.7563e-04 - val_loss: 9.0547e-05 - val_mse: 4.4263e-05 - val_NMSE: 4.0010e-04\n",
      "Epoch 44/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.6851e-05 - mse: 4.1040e-05 - NMSE: 3.7097e-04 - tot_time: 0h 6m 29.7s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.00040\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.6846e-05 - mse: 4.1037e-05 - NMSE: 3.7095e-04 - val_loss: 1.0970e-04 - val_mse: 6.4380e-05 - val_NMSE: 5.8197e-04\n",
      "Epoch 45/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.5138e-05 - mse: 5.0139e-05 - NMSE: 4.5321e-04 - tot_time: 0h 6m 38.2s\n",
      "\n",
      "Epoch 45: val_NMSE did not improve from 0.00040\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 9.5138e-05 - mse: 5.0139e-05 - NMSE: 4.5321e-04 - val_loss: 1.0243e-04 - val_mse: 5.7826e-05 - val_NMSE: 5.2272e-04\n",
      "Epoch 46/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1842e-04 - mse: 7.3786e-05 - NMSE: 6.6699e-04 - tot_time: 0h 6m 47.4s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.00040\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.1842e-04 - mse: 7.3786e-05 - NMSE: 6.6699e-04 - val_loss: 9.5655e-05 - val_mse: 5.1104e-05 - val_NMSE: 4.6192e-04\n",
      "Epoch 47/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.8594e-05 - mse: 4.4348e-05 - NMSE: 4.0084e-04 - tot_time: 0h 6m 56.3s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.00040\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.8594e-05 - mse: 4.4348e-05 - NMSE: 4.0084e-04 - val_loss: 1.0638e-04 - val_mse: 6.2532e-05 - val_NMSE: 5.6525e-04\n",
      "Epoch 48/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0318e-04 - mse: 5.9453e-05 - NMSE: 5.3738e-04 - tot_time: 0h 7m 5.4s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.00040\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0318e-04 - mse: 5.9453e-05 - NMSE: 5.3738e-04 - val_loss: 1.0687e-04 - val_mse: 6.3493e-05 - val_NMSE: 5.7388e-04\n",
      "Epoch 49/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.8224e-05 - mse: 4.5080e-05 - NMSE: 4.0749e-04 - tot_time: 0h 7m 14.2s\n",
      "\n",
      "Epoch 49: val_NMSE improved from 0.00040 to 0.00039, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.8088e-05 - mse: 4.4945e-05 - NMSE: 4.0627e-04 - val_loss: 8.6358e-05 - val_mse: 4.3599e-05 - val_NMSE: 3.9408e-04\n",
      "Epoch 50/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0197e-04 - mse: 5.9166e-05 - NMSE: 5.3477e-04 - tot_time: 0h 7m 23.1s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0197e-04 - mse: 5.9166e-05 - NMSE: 5.3477e-04 - val_loss: 9.0863e-05 - val_mse: 4.8399e-05 - val_NMSE: 4.3750e-04\n",
      "Epoch 51/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0144e-04 - mse: 5.9082e-05 - NMSE: 5.3409e-04 - tot_time: 0h 7m 32.0s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.0144e-04 - mse: 5.9082e-05 - NMSE: 5.3409e-04 - val_loss: 1.4710e-04 - val_mse: 1.0497e-04 - val_NMSE: 9.4862e-04\n",
      "Epoch 52/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.8456e-05 - mse: 4.6547e-05 - NMSE: 4.2071e-04 - tot_time: 0h 7m 40.7s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.8456e-05 - mse: 4.6547e-05 - NMSE: 4.2071e-04 - val_loss: 9.3527e-05 - val_mse: 5.1961e-05 - val_NMSE: 4.6966e-04\n",
      "Epoch 53/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0256e-04 - mse: 6.1048e-05 - NMSE: 5.5182e-04 - tot_time: 0h 7m 49.8s\n",
      "\n",
      "Epoch 53: val_NMSE improved from 0.00039 to 0.00037, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0237e-04 - mse: 6.0856e-05 - NMSE: 5.5008e-04 - val_loss: 8.2079e-05 - val_mse: 4.0702e-05 - val_NMSE: 3.6792e-04\n",
      "Epoch 54/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.2615e-05 - mse: 4.1555e-05 - NMSE: 3.7562e-04 - tot_time: 0h 7m 58.7s\n",
      "\n",
      "Epoch 54: val_NMSE did not improve from 0.00037\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.2564e-05 - mse: 4.1505e-05 - NMSE: 3.7517e-04 - val_loss: 1.1450e-04 - val_mse: 7.3817e-05 - val_NMSE: 6.6721e-04\n",
      "Epoch 55/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.5634e-05 - mse: 4.5108e-05 - NMSE: 4.0772e-04 - tot_time: 0h 8m 7.5s\n",
      "\n",
      "Epoch 55: val_NMSE improved from 0.00037 to 0.00037, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.5634e-05 - mse: 4.5108e-05 - NMSE: 4.0772e-04 - val_loss: 8.0828e-05 - val_mse: 4.0615e-05 - val_NMSE: 3.6711e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0057e-04 - mse: 6.0308e-05 - NMSE: 5.4513e-04 - tot_time: 0h 8m 16.8s\n",
      "\n",
      "Epoch 56: val_NMSE did not improve from 0.00037\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.0130e-04 - mse: 6.1036e-05 - NMSE: 5.5172e-04 - val_loss: 2.4244e-04 - val_mse: 2.0245e-04 - val_NMSE: 0.0018\n",
      "Epoch 57/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.6334e-05 - mse: 4.6523e-05 - NMSE: 4.2051e-04 - tot_time: 0h 8m 25.8s\n",
      "\n",
      "Epoch 57: val_NMSE did not improve from 0.00037\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.6252e-05 - mse: 4.6443e-05 - NMSE: 4.1979e-04 - val_loss: 1.0793e-04 - val_mse: 6.8421e-05 - val_NMSE: 6.1848e-04\n",
      "Epoch 58/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.2718e-05 - mse: 4.3364e-05 - NMSE: 3.9198e-04 - tot_time: 0h 8m 34.5s\n",
      "\n",
      "Epoch 58: val_NMSE did not improve from 0.00037\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.2718e-05 - mse: 4.3364e-05 - NMSE: 3.9198e-04 - val_loss: 8.7910e-05 - val_mse: 4.8848e-05 - val_NMSE: 4.4153e-04\n",
      "Epoch 59/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.0884e-05 - mse: 5.1921e-05 - NMSE: 4.6930e-04 - tot_time: 0h 8m 43.2s\n",
      "\n",
      "Epoch 59: val_NMSE improved from 0.00037 to 0.00034, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.0884e-05 - mse: 5.1921e-05 - NMSE: 4.6930e-04 - val_loss: 7.6643e-05 - val_mse: 3.7858e-05 - val_NMSE: 3.4221e-04\n",
      "Epoch 60/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.7355e-05 - mse: 4.8762e-05 - NMSE: 4.4079e-04 - tot_time: 0h 8m 52.0s\n",
      "\n",
      "Epoch 60: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.7355e-05 - mse: 4.8762e-05 - NMSE: 4.4079e-04 - val_loss: 8.2385e-05 - val_mse: 4.3933e-05 - val_NMSE: 3.9712e-04\n",
      "Epoch 61/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.0457e-05 - mse: 4.2197e-05 - NMSE: 3.8139e-04 - tot_time: 0h 9m 0.6s\n",
      "\n",
      "Epoch 61: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.0457e-05 - mse: 4.2197e-05 - NMSE: 3.8139e-04 - val_loss: 1.5035e-04 - val_mse: 1.1235e-04 - val_NMSE: 0.0010\n",
      "Epoch 62/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.2470e-05 - mse: 4.4568e-05 - NMSE: 4.0286e-04 - tot_time: 0h 9m 9.3s\n",
      "\n",
      "Epoch 62: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.2470e-05 - mse: 4.4568e-05 - NMSE: 4.0286e-04 - val_loss: 1.0072e-04 - val_mse: 6.3106e-05 - val_NMSE: 5.7043e-04\n",
      "Epoch 63/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.3550e-05 - mse: 4.6006e-05 - NMSE: 4.1585e-04 - tot_time: 0h 9m 18.1s\n",
      "\n",
      "Epoch 63: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.3512e-05 - mse: 4.5969e-05 - NMSE: 4.1552e-04 - val_loss: 9.2371e-05 - val_mse: 5.5081e-05 - val_NMSE: 4.9792e-04\n",
      "Epoch 64/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.4847e-05 - mse: 4.7625e-05 - NMSE: 4.3048e-04 - tot_time: 0h 9m 26.6s\n",
      "\n",
      "Epoch 64: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 8.5875e-05 - mse: 4.8655e-05 - NMSE: 4.3978e-04 - val_loss: 2.7593e-04 - val_mse: 2.3895e-04 - val_NMSE: 0.0022\n",
      "Epoch 65/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.6482e-05 - mse: 5.9462e-05 - NMSE: 5.3750e-04 - tot_time: 0h 9m 35.2s\n",
      "\n",
      "Epoch 65: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.6482e-05 - mse: 5.9462e-05 - NMSE: 5.3750e-04 - val_loss: 7.6912e-05 - val_mse: 3.9828e-05 - val_NMSE: 3.6001e-04\n",
      "Epoch 66/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 6.8508e-05 - mse: 3.1760e-05 - NMSE: 2.8707e-04 - tot_time: 0h 9m 44.0s\n",
      "\n",
      "Epoch 66: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 6.8508e-05 - mse: 3.1760e-05 - NMSE: 2.8707e-04 - val_loss: 1.0615e-04 - val_mse: 6.9726e-05 - val_NMSE: 6.3019e-04\n",
      "Epoch 67/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.3771e-05 - mse: 5.7384e-05 - NMSE: 5.1871e-04 - tot_time: 0h 9m 52.7s\n",
      "\n",
      "Epoch 67: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.3551e-05 - mse: 5.7164e-05 - NMSE: 5.1673e-04 - val_loss: 7.6740e-05 - val_mse: 4.0390e-05 - val_NMSE: 3.6508e-04\n",
      "Epoch 68/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 7.2821e-05 - mse: 3.6766e-05 - NMSE: 3.3229e-04 - tot_time: 0h 10m 1.5s\n",
      "\n",
      "Epoch 68: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 7.2821e-05 - mse: 3.6766e-05 - NMSE: 3.3229e-04 - val_loss: 8.6099e-05 - val_mse: 5.0267e-05 - val_NMSE: 4.5438e-04\n",
      "Epoch 69/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.0350e-05 - mse: 4.4683e-05 - NMSE: 4.0391e-04Restoring model weights from the end of the best epoch: 59.\n",
      " - tot_time: 0h 10m 10.5s\n",
      "\n",
      "Epoch 69: val_NMSE did not improve from 0.00034\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.0350e-05 - mse: 4.4683e-05 - NMSE: 4.0391e-04 - val_loss: 1.1543e-04 - val_mse: 7.9894e-05 - val_NMSE: 7.2217e-04\n",
      "Epoch 69: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 5.4968e-05 - mse: 1.6234e-05 - NMSE: 1.4675e-04 - tot_time: 0h 10m 21.5s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.00034 to 0.00030, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 5.4968e-05 - mse: 1.6234e-05 - NMSE: 1.4675e-04 - val_loss: 7.1868e-05 - val_mse: 3.3194e-05 - val_NMSE: 3.0004e-04\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.3399e-05 - mse: 1.4791e-05 - NMSE: 1.3371e-04 - tot_time: 0h 10m 32.5s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00030 to 0.00029, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 5.3399e-05 - mse: 1.4791e-05 - NMSE: 1.3371e-04 - val_loss: 7.1019e-05 - val_mse: 3.2484e-05 - val_NMSE: 2.9362e-04\n",
      "Epoch 3/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2881e-05 - mse: 1.4421e-05 - NMSE: 1.3036e-04 - tot_time: 0h 10m 43.2s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00029 to 0.00029, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 5.2881e-05 - mse: 1.4421e-05 - NMSE: 1.3036e-04 - val_loss: 7.0367e-05 - val_mse: 3.1990e-05 - val_NMSE: 2.8916e-04\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2439e-05 - mse: 1.4144e-05 - NMSE: 1.2785e-04 - tot_time: 0h 10m 54.3s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00029 to 0.00029, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 5.2439e-05 - mse: 1.4144e-05 - NMSE: 1.2785e-04 - val_loss: 6.9951e-05 - val_mse: 3.1745e-05 - val_NMSE: 2.8695e-04\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2063e-05 - mse: 1.3944e-05 - NMSE: 1.2604e-04 - tot_time: 0h 11m 6.0s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.00029 to 0.00029, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 5.2063e-05 - mse: 1.3944e-05 - NMSE: 1.2604e-04 - val_loss: 6.9674e-05 - val_mse: 3.1648e-05 - val_NMSE: 2.8607e-04\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.1738e-05 - mse: 1.3801e-05 - NMSE: 1.2475e-04 - tot_time: 0h 11m 17.5s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00029 to 0.00028, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 5.1738e-05 - mse: 1.3801e-05 - NMSE: 1.2475e-04 - val_loss: 6.8928e-05 - val_mse: 3.1086e-05 - val_NMSE: 2.8099e-04\n",
      "Epoch 7/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.1509e-05 - mse: 1.3754e-05 - NMSE: 1.2433e-04 - tot_time: 0h 11m 29.2s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00028 to 0.00028, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 5.1509e-05 - mse: 1.3754e-05 - NMSE: 1.2433e-04 - val_loss: 6.8480e-05 - val_mse: 3.0819e-05 - val_NMSE: 2.7857e-04\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.1395e-05 - mse: 1.3816e-05 - NMSE: 1.2489e-04 - tot_time: 0h 11m 40.7s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.00028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 5.1378e-05 - mse: 1.3800e-05 - NMSE: 1.2475e-04 - val_loss: 6.8421e-05 - val_mse: 3.0930e-05 - val_NMSE: 2.7958e-04\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.1234e-05 - mse: 1.3817e-05 - NMSE: 1.2490e-04 - tot_time: 0h 11m 49.7s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.00028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 5.1220e-05 - mse: 1.3803e-05 - NMSE: 1.2477e-04 - val_loss: 6.8789e-05 - val_mse: 3.1450e-05 - val_NMSE: 2.8427e-04\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.1357e-05 - mse: 1.4080e-05 - NMSE: 1.2728e-04 - tot_time: 0h 11m 58.4s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.00028 to 0.00028, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.1357e-05 - mse: 1.4080e-05 - NMSE: 1.2728e-04 - val_loss: 6.7855e-05 - val_mse: 3.0645e-05 - val_NMSE: 2.7700e-04\n",
      "Epoch 11/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.1867e-05 - mse: 1.4710e-05 - NMSE: 1.3297e-04 - tot_time: 0h 12m 7.4s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.00028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.1854e-05 - mse: 1.4697e-05 - NMSE: 1.3285e-04 - val_loss: 6.8426e-05 - val_mse: 3.1332e-05 - val_NMSE: 2.8321e-04\n",
      "Epoch 12/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2140e-05 - mse: 1.5094e-05 - NMSE: 1.3644e-04 - tot_time: 0h 12m 16.2s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.00028\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.2140e-05 - mse: 1.5094e-05 - NMSE: 1.3644e-04 - val_loss: 6.9286e-05 - val_mse: 3.2299e-05 - val_NMSE: 2.9195e-04\n",
      "Epoch 13/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2094e-05 - mse: 1.5156e-05 - NMSE: 1.3701e-04 - tot_time: 0h 12m 25.0s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.00028 to 0.00027, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.2094e-05 - mse: 1.5156e-05 - NMSE: 1.3701e-04 - val_loss: 6.7153e-05 - val_mse: 3.0277e-05 - val_NMSE: 2.7367e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2346e-05 - mse: 1.5524e-05 - NMSE: 1.4033e-04 - tot_time: 0h 12m 33.8s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.00027\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.2346e-05 - mse: 1.5524e-05 - NMSE: 1.4033e-04 - val_loss: 6.8527e-05 - val_mse: 3.1773e-05 - val_NMSE: 2.8720e-04\n",
      "Epoch 15/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.1923e-05 - mse: 1.5230e-05 - NMSE: 1.3767e-04 - tot_time: 0h 12m 42.6s\n",
      "\n",
      "Epoch 15: val_NMSE improved from 0.00027 to 0.00027, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.1923e-05 - mse: 1.5230e-05 - NMSE: 1.3767e-04 - val_loss: 6.6582e-05 - val_mse: 2.9963e-05 - val_NMSE: 2.7083e-04\n",
      "Epoch 16/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.1674e-05 - mse: 1.5123e-05 - NMSE: 1.3670e-04 - tot_time: 0h 12m 51.5s\n",
      "\n",
      "Epoch 16: val_NMSE improved from 0.00027 to 0.00027, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.1651e-05 - mse: 1.5100e-05 - NMSE: 1.3650e-04 - val_loss: 6.6178e-05 - val_mse: 2.9709e-05 - val_NMSE: 2.6854e-04\n",
      "Epoch 17/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.1116e-05 - mse: 1.4722e-05 - NMSE: 1.3308e-04 - tot_time: 0h 13m 0.2s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.00027 to 0.00027, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 5.1116e-05 - mse: 1.4722e-05 - NMSE: 1.3308e-04 - val_loss: 6.5776e-05 - val_mse: 2.9470e-05 - val_NMSE: 2.6637e-04\n",
      "Epoch 18/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.0651e-05 - mse: 1.4424e-05 - NMSE: 1.3038e-04 - tot_time: 0h 13m 8.9s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.00027 to 0.00026, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 5.0651e-05 - mse: 1.4424e-05 - NMSE: 1.3038e-04 - val_loss: 6.5292e-05 - val_mse: 2.9158e-05 - val_NMSE: 2.6355e-04\n",
      "Epoch 19/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.0230e-05 - mse: 1.4177e-05 - NMSE: 1.2816e-04 - tot_time: 0h 13m 17.5s\n",
      "\n",
      "Epoch 19: val_NMSE improved from 0.00026 to 0.00026, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 5.0230e-05 - mse: 1.4177e-05 - NMSE: 1.2816e-04 - val_loss: 6.4475e-05 - val_mse: 2.8518e-05 - val_NMSE: 2.5776e-04\n",
      "Epoch 20/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.9781e-05 - mse: 1.3906e-05 - NMSE: 1.2571e-04 - tot_time: 0h 13m 26.3s\n",
      "\n",
      "Epoch 20: val_NMSE improved from 0.00026 to 0.00025, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.9763e-05 - mse: 1.3888e-05 - NMSE: 1.2554e-04 - val_loss: 6.3837e-05 - val_mse: 2.8058e-05 - val_NMSE: 2.5361e-04\n",
      "Epoch 21/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.9377e-05 - mse: 1.3680e-05 - NMSE: 1.2366e-04 - tot_time: 0h 13m 35.4s\n",
      "\n",
      "Epoch 21: val_NMSE improved from 0.00025 to 0.00025, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.9377e-05 - mse: 1.3680e-05 - NMSE: 1.2366e-04 - val_loss: 6.3485e-05 - val_mse: 2.7882e-05 - val_NMSE: 2.5201e-04\n",
      "Epoch 22/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8968e-05 - mse: 1.3445e-05 - NMSE: 1.2154e-04 - tot_time: 0h 13m 44.1s\n",
      "\n",
      "Epoch 22: val_NMSE did not improve from 0.00025\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.8968e-05 - mse: 1.3445e-05 - NMSE: 1.2154e-04 - val_loss: 6.3369e-05 - val_mse: 2.7939e-05 - val_NMSE: 2.5253e-04\n",
      "Epoch 23/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.8672e-05 - mse: 1.3319e-05 - NMSE: 1.2040e-04 - tot_time: 0h 13m 53.0s\n",
      "\n",
      "Epoch 23: val_NMSE improved from 0.00025 to 0.00025, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.8655e-05 - mse: 1.3303e-05 - NMSE: 1.2025e-04 - val_loss: 6.3044e-05 - val_mse: 2.7782e-05 - val_NMSE: 2.5111e-04\n",
      "Epoch 24/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8399e-05 - mse: 1.3214e-05 - NMSE: 1.1944e-04 - tot_time: 0h 14m 1.8s\n",
      "\n",
      "Epoch 24: val_NMSE improved from 0.00025 to 0.00025, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.8399e-05 - mse: 1.3214e-05 - NMSE: 1.1944e-04 - val_loss: 6.2520e-05 - val_mse: 2.7422e-05 - val_NMSE: 2.4786e-04\n",
      "Epoch 25/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.8151e-05 - mse: 1.3128e-05 - NMSE: 1.1867e-04 - tot_time: 0h 14m 10.6s\n",
      "\n",
      "Epoch 25: val_NMSE improved from 0.00025 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.8135e-05 - mse: 1.3112e-05 - NMSE: 1.1853e-04 - val_loss: 6.2040e-05 - val_mse: 2.7103e-05 - val_NMSE: 2.4497e-04\n",
      "Epoch 26/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/188 [============================>.] - ETA: 0s - loss: 4.7799e-05 - mse: 1.2934e-05 - NMSE: 1.1692e-04 - tot_time: 0h 14m 19.3s\n",
      "\n",
      "Epoch 26: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7783e-05 - mse: 1.2918e-05 - NMSE: 1.1677e-04 - val_loss: 6.1619e-05 - val_mse: 2.6838e-05 - val_NMSE: 2.4257e-04\n",
      "Epoch 27/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7547e-05 - mse: 1.2836e-05 - NMSE: 1.1603e-04 - tot_time: 0h 14m 28.1s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.7547e-05 - mse: 1.2836e-05 - NMSE: 1.1603e-04 - val_loss: 6.1130e-05 - val_mse: 2.6500e-05 - val_NMSE: 2.3952e-04\n",
      "Epoch 28/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7300e-05 - mse: 1.2738e-05 - NMSE: 1.1515e-04 - tot_time: 0h 14m 37.0s\n",
      "\n",
      "Epoch 28: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7300e-05 - mse: 1.2738e-05 - NMSE: 1.1515e-04 - val_loss: 6.0738e-05 - val_mse: 2.6255e-05 - val_NMSE: 2.3730e-04\n",
      "Epoch 29/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.7036e-05 - mse: 1.2619e-05 - NMSE: 1.1406e-04 - tot_time: 0h 14m 46.1s\n",
      "\n",
      "Epoch 29: val_NMSE improved from 0.00024 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 4.7019e-05 - mse: 1.2602e-05 - NMSE: 1.1391e-04 - val_loss: 6.0287e-05 - val_mse: 2.5946e-05 - val_NMSE: 2.3451e-04\n",
      "Epoch 30/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.6834e-05 - mse: 1.2557e-05 - NMSE: 1.1351e-04 - tot_time: 0h 14m 55.2s\n",
      "\n",
      "Epoch 30: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.6817e-05 - mse: 1.2540e-05 - NMSE: 1.1335e-04 - val_loss: 5.9888e-05 - val_mse: 2.5685e-05 - val_NMSE: 2.3216e-04\n",
      "Epoch 31/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.6627e-05 - mse: 1.2486e-05 - NMSE: 1.1287e-04 - tot_time: 0h 15m 4.0s\n",
      "\n",
      "Epoch 31: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.6610e-05 - mse: 1.2469e-05 - NMSE: 1.1271e-04 - val_loss: 5.9515e-05 - val_mse: 2.5446e-05 - val_NMSE: 2.2999e-04\n",
      "Epoch 32/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.6352e-05 - mse: 1.2343e-05 - NMSE: 1.1157e-04 - tot_time: 0h 15m 12.5s\n",
      "\n",
      "Epoch 32: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 4.6352e-05 - mse: 1.2343e-05 - NMSE: 1.1157e-04 - val_loss: 5.9217e-05 - val_mse: 2.5277e-05 - val_NMSE: 2.2847e-04\n",
      "Epoch 33/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.6234e-05 - mse: 1.2352e-05 - NMSE: 1.1166e-04 - tot_time: 0h 15m 21.2s\n",
      "\n",
      "Epoch 33: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.6217e-05 - mse: 1.2336e-05 - NMSE: 1.1151e-04 - val_loss: 5.8928e-05 - val_mse: 2.5113e-05 - val_NMSE: 2.2699e-04\n",
      "Epoch 34/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5959e-05 - mse: 1.2201e-05 - NMSE: 1.1029e-04 - tot_time: 0h 15m 30.4s\n",
      "\n",
      "Epoch 34: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 4.5959e-05 - mse: 1.2201e-05 - NMSE: 1.1029e-04 - val_loss: 5.8757e-05 - val_mse: 2.5063e-05 - val_NMSE: 2.2653e-04\n",
      "Epoch 35/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.5831e-05 - mse: 1.2191e-05 - NMSE: 1.1020e-04 - tot_time: 0h 15m 39.3s\n",
      "\n",
      "Epoch 35: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.5816e-05 - mse: 1.2176e-05 - NMSE: 1.1007e-04 - val_loss: 5.8571e-05 - val_mse: 2.4994e-05 - val_NMSE: 2.2591e-04\n",
      "Epoch 36/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5657e-05 - mse: 1.2132e-05 - NMSE: 1.0967e-04 - tot_time: 0h 15m 47.9s\n",
      "\n",
      "Epoch 36: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.5657e-05 - mse: 1.2132e-05 - NMSE: 1.0967e-04 - val_loss: 5.8417e-05 - val_mse: 2.4953e-05 - val_NMSE: 2.2554e-04\n",
      "Epoch 37/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5510e-05 - mse: 1.2096e-05 - NMSE: 1.0934e-04 - tot_time: 0h 15m 56.5s\n",
      "\n",
      "Epoch 37: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 4.5510e-05 - mse: 1.2096e-05 - NMSE: 1.0934e-04 - val_loss: 5.8290e-05 - val_mse: 2.4935e-05 - val_NMSE: 2.2537e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.5384e-05 - mse: 1.2076e-05 - NMSE: 1.0916e-04 - tot_time: 0h 16m 5.1s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.5371e-05 - mse: 1.2063e-05 - NMSE: 1.0905e-04 - val_loss: 5.8228e-05 - val_mse: 2.4977e-05 - val_NMSE: 2.2575e-04\n",
      "Epoch 39/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.5261e-05 - mse: 1.2057e-05 - NMSE: 1.0899e-04 - tot_time: 0h 16m 13.7s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.5248e-05 - mse: 1.2044e-05 - NMSE: 1.0887e-04 - val_loss: 5.8095e-05 - val_mse: 2.4946e-05 - val_NMSE: 2.2547e-04\n",
      "Epoch 40/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.5128e-05 - mse: 1.2024e-05 - NMSE: 1.0869e-04 - tot_time: 0h 16m 22.5s\n",
      "\n",
      "Epoch 40: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.5115e-05 - mse: 1.2012e-05 - NMSE: 1.0858e-04 - val_loss: 5.8015e-05 - val_mse: 2.4965e-05 - val_NMSE: 2.2564e-04\n",
      "Epoch 41/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4979e-05 - mse: 1.1972e-05 - NMSE: 1.0822e-04 - tot_time: 0h 16m 31.2s\n",
      "\n",
      "Epoch 41: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.4979e-05 - mse: 1.1972e-05 - NMSE: 1.0822e-04 - val_loss: 5.7957e-05 - val_mse: 2.5003e-05 - val_NMSE: 2.2599e-04\n",
      "Epoch 42/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.4833e-05 - mse: 1.1921e-05 - NMSE: 1.0776e-04 - tot_time: 0h 16m 40.3s\n",
      "\n",
      "Epoch 42: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.4826e-05 - mse: 1.1915e-05 - NMSE: 1.0770e-04 - val_loss: 5.8362e-05 - val_mse: 2.5502e-05 - val_NMSE: 2.3049e-04\n",
      "Epoch 43/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.4751e-05 - mse: 1.1932e-05 - NMSE: 1.0786e-04 - tot_time: 0h 16m 49.4s\n",
      "\n",
      "Epoch 43: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.4751e-05 - mse: 1.1932e-05 - NMSE: 1.0786e-04 - val_loss: 5.9944e-05 - val_mse: 2.7176e-05 - val_NMSE: 2.4562e-04\n",
      "Epoch 44/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5030e-05 - mse: 1.2305e-05 - NMSE: 1.1122e-04 - tot_time: 0h 16m 57.9s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.5030e-05 - mse: 1.2305e-05 - NMSE: 1.1122e-04 - val_loss: 5.7703e-05 - val_mse: 2.5027e-05 - val_NMSE: 2.2620e-04\n",
      "Epoch 45/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.4325e-05 - mse: 1.1689e-05 - NMSE: 1.0566e-04Restoring model weights from the end of the best epoch: 35.\n",
      " - tot_time: 0h 17m 6.7s\n",
      "\n",
      "Epoch 45: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.4332e-05 - mse: 1.1697e-05 - NMSE: 1.0573e-04 - val_loss: 6.2106e-05 - val_mse: 2.9520e-05 - val_NMSE: 2.6680e-04\n",
      "Epoch 45: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.3685e-05 - mse: 1.0114e-05 - NMSE: 9.1425e-05 - tot_time: 0h 17m 15.7s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.00023 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.3675e-05 - mse: 1.0104e-05 - NMSE: 9.1332e-05 - val_loss: 5.7908e-05 - val_mse: 2.4343e-05 - val_NMSE: 2.2002e-04\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3261e-05 - mse: 9.7018e-06 - NMSE: 8.7700e-05 - tot_time: 0h 17m 24.7s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3261e-05 - mse: 9.7018e-06 - NMSE: 8.7700e-05 - val_loss: 5.7854e-05 - val_mse: 2.4302e-05 - val_NMSE: 2.1965e-04\n",
      "Epoch 3/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.3254e-05 - mse: 9.7082e-06 - NMSE: 8.7757e-05 - tot_time: 0h 17m 33.5s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3246e-05 - mse: 9.6998e-06 - NMSE: 8.7682e-05 - val_loss: 5.7818e-05 - val_mse: 2.4280e-05 - val_NMSE: 2.1945e-04\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3236e-05 - mse: 9.7040e-06 - NMSE: 8.7720e-05 - tot_time: 0h 17m 42.3s\n",
      "\n",
      "Epoch 4: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3236e-05 - mse: 9.7040e-06 - NMSE: 8.7720e-05 - val_loss: 5.7805e-05 - val_mse: 2.4281e-05 - val_NMSE: 2.1946e-04\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3226e-05 - mse: 9.7091e-06 - NMSE: 8.7766e-05 - tot_time: 0h 17m 51.3s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.3226e-05 - mse: 9.7091e-06 - NMSE: 8.7766e-05 - val_loss: 5.7800e-05 - val_mse: 2.4291e-05 - val_NMSE: 2.1955e-04\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3209e-05 - mse: 9.7081e-06 - NMSE: 8.7757e-05 - tot_time: 0h 18m 0.2s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3209e-05 - mse: 9.7081e-06 - NMSE: 8.7757e-05 - val_loss: 5.7775e-05 - val_mse: 2.4283e-05 - val_NMSE: 2.1948e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.3200e-05 - mse: 9.7152e-06 - NMSE: 8.7821e-05 - tot_time: 0h 18m 8.8s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.3192e-05 - mse: 9.7069e-06 - NMSE: 8.7746e-05 - val_loss: 5.7734e-05 - val_mse: 2.4259e-05 - val_NMSE: 2.1926e-04\n",
      "Epoch 8/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3176e-05 - mse: 9.7091e-06 - NMSE: 8.7765e-05 - tot_time: 0h 18m 17.5s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.3176e-05 - mse: 9.7091e-06 - NMSE: 8.7765e-05 - val_loss: 5.7714e-05 - val_mse: 2.4257e-05 - val_NMSE: 2.1924e-04\n",
      "Epoch 9/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3160e-05 - mse: 9.7121e-06 - NMSE: 8.7793e-05 - tot_time: 0h 18m 27.8s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 4.3160e-05 - mse: 9.7121e-06 - NMSE: 8.7793e-05 - val_loss: 5.7685e-05 - val_mse: 2.4247e-05 - val_NMSE: 2.1915e-04\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3151e-05 - mse: 9.7232e-06 - NMSE: 8.7893e-05 - tot_time: 0h 18m 38.8s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 4.3151e-05 - mse: 9.7232e-06 - NMSE: 8.7893e-05 - val_loss: 5.7678e-05 - val_mse: 2.4260e-05 - val_NMSE: 2.1927e-04\n",
      "Epoch 11/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3133e-05 - mse: 9.7258e-06 - NMSE: 8.7917e-05Restoring model weights from the end of the best epoch: 1.\n",
      " - tot_time: 0h 18m 49.9s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_000/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 4.3133e-05 - mse: 9.7258e-06 - NMSE: 8.7917e-05 - val_loss: 5.7713e-05 - val_mse: 2.4317e-05 - val_NMSE: 2.1979e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.2747e-04 - mse: 9.3904e-05 - NMSE: 8.4882e-04\n",
      "tested_rnn/test_rnn_000\n",
      "num_runs : 25\n",
      "    1 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    2 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    3 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    4 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    5 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    6 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    7 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    8 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    9 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    10 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    11 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    12 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    13 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    14 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    15 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    16 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    17 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    18 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    19 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    20 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    21 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    22 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    23 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    24 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    25 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "\n",
      "error_threshold = 0.5\n",
      "prediction_horizon : 1.2753693741866408, median : 1.2681229572878527\n",
      "ph_min : 0.0, ph_max : 1.9927646471666258\n",
      "stddev : 0.5595012875304072, IQR : 0.9058021123484664\n",
      "1st quartile : 0.8152219011136196, 3rd quartile : 1.721024013462086\n",
      "analysis time : 3.983947277069092 s\n",
      "\n",
      "compute_time : 0h 18m 58s\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------- LEARNING RATE : 0.01 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0109 - mse: 0.0109 - NMSE: 0.0982 - tot_time: 0h 0m 12.8s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.00932, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 13s 63ms/step - loss: 0.0109 - mse: 0.0109 - NMSE: 0.0982 - val_loss: 0.0011 - val_mse: 0.0010 - val_NMSE: 0.0093\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 6.8702e-04 - mse: 6.2591e-04 - NMSE: 0.0057 - tot_time: 0h 0m 24.2s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00932 to 0.00464, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 6.8702e-04 - mse: 6.2591e-04 - NMSE: 0.0057 - val_loss: 5.7767e-04 - val_mse: 5.1294e-04 - val_NMSE: 0.0046\n",
      "Epoch 3/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.6722e-04 - mse: 4.0072e-04 - NMSE: 0.0036 - tot_time: 0h 0m 35.6s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00464 to 0.00339, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 4.6722e-04 - mse: 4.0072e-04 - NMSE: 0.0036 - val_loss: 4.4331e-04 - val_mse: 3.7521e-04 - val_NMSE: 0.0034\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 3.5002e-04 - mse: 2.8112e-04 - NMSE: 0.0025 - tot_time: 0h 0m 47.0s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00339 to 0.00239, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 3.5002e-04 - mse: 2.8112e-04 - NMSE: 0.0025 - val_loss: 3.3444e-04 - val_mse: 2.6490e-04 - val_NMSE: 0.0024\n",
      "Epoch 5/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/188 [============================>.] - ETA: 0s - loss: 3.6302e-04 - mse: 2.9322e-04 - NMSE: 0.0027 - tot_time: 0h 0m 57.2s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.00239\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 3.6244e-04 - mse: 2.9263e-04 - NMSE: 0.0026 - val_loss: 3.5209e-04 - val_mse: 2.8177e-04 - val_NMSE: 0.0025\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.6980e-04 - mse: 1.9949e-04 - NMSE: 0.0018 - tot_time: 0h 1m 6.0s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00239 to 0.00189, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.6980e-04 - mse: 1.9949e-04 - NMSE: 0.0018 - val_loss: 2.7915e-04 - val_mse: 2.0886e-04 - val_NMSE: 0.0019\n",
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.9372e-04 - mse: 2.2356e-04 - NMSE: 0.0020 - tot_time: 0h 1m 14.7s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00189 to 0.00179, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.9346e-04 - mse: 2.2331e-04 - NMSE: 0.0020 - val_loss: 2.6821e-04 - val_mse: 1.9800e-04 - val_NMSE: 0.0018\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.3499e-04 - mse: 1.6506e-04 - NMSE: 0.0015 - tot_time: 0h 1m 23.5s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.00179 to 0.00153, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.3466e-04 - mse: 1.6474e-04 - NMSE: 0.0015 - val_loss: 2.3908e-04 - val_mse: 1.6934e-04 - val_NMSE: 0.0015\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.5580e-04 - mse: 1.8631e-04 - NMSE: 0.0017 - tot_time: 0h 1m 32.3s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.00153 to 0.00124, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.5526e-04 - mse: 1.8577e-04 - NMSE: 0.0017 - val_loss: 2.0682e-04 - val_mse: 1.3748e-04 - val_NMSE: 0.0012\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.0225e-04 - mse: 1.3334e-04 - NMSE: 0.0012 - tot_time: 0h 1m 41.2s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.0225e-04 - mse: 1.3334e-04 - NMSE: 0.0012 - val_loss: 2.7201e-04 - val_mse: 2.0346e-04 - val_NMSE: 0.0018\n",
      "Epoch 11/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.1751e-04 - mse: 1.4921e-04 - NMSE: 0.0013 - tot_time: 0h 1m 50.5s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.00124 to 0.00109, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 2.1751e-04 - mse: 1.4921e-04 - NMSE: 0.0013 - val_loss: 1.8838e-04 - val_mse: 1.2043e-04 - val_NMSE: 0.0011\n",
      "Epoch 12/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.8340e-04 - mse: 1.1593e-04 - NMSE: 0.0010 - tot_time: 0h 1m 59.5s\n",
      "\n",
      "Epoch 12: val_NMSE improved from 0.00109 to 0.00095, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.8340e-04 - mse: 1.1593e-04 - NMSE: 0.0010 - val_loss: 1.7191e-04 - val_mse: 1.0484e-04 - val_NMSE: 9.4766e-04\n",
      "Epoch 13/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.8936e-04 - mse: 1.2270e-04 - NMSE: 0.0011 - tot_time: 0h 2m 8.3s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.00095\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.8936e-04 - mse: 1.2270e-04 - NMSE: 0.0011 - val_loss: 2.3358e-04 - val_mse: 1.6734e-04 - val_NMSE: 0.0015\n",
      "Epoch 14/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6720e-04 - mse: 1.0141e-04 - NMSE: 9.1667e-04 - tot_time: 0h 2m 17.2s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.00095 to 0.00089, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.6720e-04 - mse: 1.0141e-04 - NMSE: 9.1667e-04 - val_loss: 1.6352e-04 - val_mse: 9.8179e-05 - val_NMSE: 8.8742e-04\n",
      "Epoch 15/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.7204e-04 - mse: 1.0704e-04 - NMSE: 9.6753e-04 - tot_time: 0h 2m 26.0s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.00089\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.7204e-04 - mse: 1.0704e-04 - NMSE: 9.6753e-04 - val_loss: 1.6922e-04 - val_mse: 1.0467e-04 - val_NMSE: 9.4610e-04\n",
      "Epoch 16/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.6240e-04 - mse: 9.8275e-05 - NMSE: 8.8828e-04 - tot_time: 0h 2m 35.3s\n",
      "\n",
      "Epoch 16: val_NMSE improved from 0.00089 to 0.00080, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 1.6217e-04 - mse: 9.8041e-05 - NMSE: 8.8617e-04 - val_loss: 1.5231e-04 - val_mse: 8.8615e-05 - val_NMSE: 8.0101e-04\n",
      "Epoch 17/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.6747e-04 - mse: 1.0410e-04 - NMSE: 9.4093e-04 - tot_time: 0h 2m 44.2s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.00080 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.6712e-04 - mse: 1.0375e-04 - NMSE: 9.3777e-04 - val_loss: 1.4558e-04 - val_mse: 8.2602e-05 - val_NMSE: 7.4665e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5584e-04 - mse: 9.3260e-05 - NMSE: 8.4298e-04 - tot_time: 0h 2m 53.0s\n",
      "\n",
      "Epoch 18: val_NMSE did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.5584e-04 - mse: 9.3260e-05 - NMSE: 8.4298e-04 - val_loss: 1.9043e-04 - val_mse: 1.2831e-04 - val_NMSE: 0.0012\n",
      "Epoch 19/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.6012e-04 - mse: 9.8283e-05 - NMSE: 8.8839e-04 - tot_time: 0h 3m 2.2s\n",
      "\n",
      "Epoch 19: val_NMSE improved from 0.00075 to 0.00071, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.5979e-04 - mse: 9.7955e-05 - NMSE: 8.8543e-04 - val_loss: 1.3975e-04 - val_mse: 7.8268e-05 - val_NMSE: 7.0746e-04\n",
      "Epoch 20/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4693e-04 - mse: 8.5960e-05 - NMSE: 7.7697e-04 - tot_time: 0h 3m 11.0s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.00071\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.4693e-04 - mse: 8.5960e-05 - NMSE: 7.7697e-04 - val_loss: 1.8058e-04 - val_mse: 1.2006e-04 - val_NMSE: 0.0011\n",
      "Epoch 21/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4329e-04 - mse: 8.3153e-05 - NMSE: 7.5155e-04 - tot_time: 0h 3m 19.7s\n",
      "\n",
      "Epoch 21: val_NMSE improved from 0.00071 to 0.00070, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.4306e-04 - mse: 8.2927e-05 - NMSE: 7.4952e-04 - val_loss: 1.3709e-04 - val_mse: 7.7364e-05 - val_NMSE: 6.9929e-04\n",
      "Epoch 22/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4228e-04 - mse: 8.2926e-05 - NMSE: 7.4960e-04 - tot_time: 0h 3m 28.5s\n",
      "\n",
      "Epoch 22: val_NMSE did not improve from 0.00070\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.4228e-04 - mse: 8.2926e-05 - NMSE: 7.4960e-04 - val_loss: 1.4786e-04 - val_mse: 8.8861e-05 - val_NMSE: 8.0317e-04\n",
      "Epoch 23/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5073e-04 - mse: 9.2096e-05 - NMSE: 8.3247e-04 - tot_time: 0h 3m 37.2s\n",
      "\n",
      "Epoch 23: val_NMSE improved from 0.00070 to 0.00067, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.5073e-04 - mse: 9.2096e-05 - NMSE: 8.3247e-04 - val_loss: 1.3278e-04 - val_mse: 7.4276e-05 - val_NMSE: 6.7139e-04\n",
      "Epoch 24/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2021e-04 - mse: 6.2238e-05 - NMSE: 5.6253e-04 - tot_time: 0h 3m 45.9s\n",
      "\n",
      "Epoch 24: val_NMSE did not improve from 0.00067\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2006e-04 - mse: 6.2099e-05 - NMSE: 5.6128e-04 - val_loss: 1.3271e-04 - val_mse: 7.5308e-05 - val_NMSE: 6.8070e-04\n",
      "Epoch 25/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4265e-04 - mse: 8.5509e-05 - NMSE: 7.7290e-04 - tot_time: 0h 3m 54.8s\n",
      "\n",
      "Epoch 25: val_NMSE improved from 0.00067 to 0.00065, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.4241e-04 - mse: 8.5269e-05 - NMSE: 7.7074e-04 - val_loss: 1.2839e-04 - val_mse: 7.1551e-05 - val_NMSE: 6.4674e-04\n",
      "Epoch 26/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3090e-04 - mse: 7.4367e-05 - NMSE: 6.7221e-04 - tot_time: 0h 4m 3.6s\n",
      "\n",
      "Epoch 26: val_NMSE did not improve from 0.00065\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.3090e-04 - mse: 7.4367e-05 - NMSE: 6.7221e-04 - val_loss: 1.5480e-04 - val_mse: 9.8625e-05 - val_NMSE: 8.9135e-04\n",
      "Epoch 27/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2936e-04 - mse: 7.3536e-05 - NMSE: 6.6470e-04 - tot_time: 0h 4m 12.3s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.00065 to 0.00058, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2925e-04 - mse: 7.3426e-05 - NMSE: 6.6370e-04 - val_loss: 1.1924e-04 - val_mse: 6.3749e-05 - val_NMSE: 5.7623e-04\n",
      "Epoch 28/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3253e-04 - mse: 7.7359e-05 - NMSE: 6.9922e-04 - tot_time: 0h 4m 21.2s\n",
      "\n",
      "Epoch 28: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.3253e-04 - mse: 7.7359e-05 - NMSE: 6.9922e-04 - val_loss: 1.7064e-04 - val_mse: 1.1587e-04 - val_NMSE: 0.0010\n",
      "Epoch 29/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1629e-04 - mse: 6.1777e-05 - NMSE: 5.5839e-04 - tot_time: 0h 4m 29.9s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.1629e-04 - mse: 6.1777e-05 - NMSE: 5.5839e-04 - val_loss: 1.3762e-04 - val_mse: 8.3504e-05 - val_NMSE: 7.5478e-04\n",
      "Epoch 30/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2629e-04 - mse: 7.2522e-05 - NMSE: 6.5554e-04 - tot_time: 0h 4m 38.9s\n",
      "\n",
      "Epoch 30: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2737e-04 - mse: 7.3604e-05 - NMSE: 6.6532e-04 - val_loss: 4.0225e-04 - val_mse: 3.4890e-04 - val_NMSE: 0.0032\n",
      "Epoch 31/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2787e-04 - mse: 7.4412e-05 - NMSE: 6.7261e-04 - tot_time: 0h 4m 47.6s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2780e-04 - mse: 7.4343e-05 - NMSE: 6.7198e-04 - val_loss: 1.3624e-04 - val_mse: 8.3093e-05 - val_NMSE: 7.5099e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1612e-04 - mse: 6.3318e-05 - NMSE: 5.7232e-04 - tot_time: 0h 4m 56.6s\n",
      "\n",
      "Epoch 32: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.1623e-04 - mse: 6.3432e-05 - NMSE: 5.7335e-04 - val_loss: 1.6698e-04 - val_mse: 1.1459e-04 - val_NMSE: 0.0010\n",
      "Epoch 33/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2138e-04 - mse: 6.9272e-05 - NMSE: 6.2614e-04 - tot_time: 0h 5m 5.5s\n",
      "\n",
      "Epoch 33: val_NMSE did not improve from 0.00058\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2138e-04 - mse: 6.9272e-05 - NMSE: 6.2614e-04 - val_loss: 8.0262e-04 - val_mse: 7.5092e-04 - val_NMSE: 0.0068\n",
      "Epoch 34/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1569e-04 - mse: 6.4131e-05 - NMSE: 5.7967e-04 - tot_time: 0h 5m 14.3s\n",
      "\n",
      "Epoch 34: val_NMSE improved from 0.00058 to 0.00051, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1569e-04 - mse: 6.4131e-05 - NMSE: 5.7967e-04 - val_loss: 1.0769e-04 - val_mse: 5.6560e-05 - val_NMSE: 5.1124e-04\n",
      "Epoch 35/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2824e-04 - mse: 7.7470e-05 - NMSE: 7.0026e-04 - tot_time: 0h 5m 23.4s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2815e-04 - mse: 7.7378e-05 - NMSE: 6.9943e-04 - val_loss: 1.2228e-04 - val_mse: 7.1732e-05 - val_NMSE: 6.4841e-04\n",
      "Epoch 36/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0884e-04 - mse: 5.8646e-05 - NMSE: 5.3008e-04 - tot_time: 0h 5m 32.4s\n",
      "\n",
      "Epoch 36: val_NMSE improved from 0.00051 to 0.00042, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0865e-04 - mse: 5.8457e-05 - NMSE: 5.2837e-04 - val_loss: 9.6029e-05 - val_mse: 4.6220e-05 - val_NMSE: 4.1778e-04\n",
      "Epoch 37/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.3007e-04 - mse: 8.0321e-05 - NMSE: 7.2610e-04 - tot_time: 0h 5m 41.5s\n",
      "\n",
      "Epoch 37: val_NMSE did not improve from 0.00042\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.3029e-04 - mse: 8.0537e-05 - NMSE: 7.2804e-04 - val_loss: 2.2591e-04 - val_mse: 1.7628e-04 - val_NMSE: 0.0016\n",
      "Epoch 38/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1598e-04 - mse: 6.6696e-05 - NMSE: 6.0282e-04 - tot_time: 0h 5m 50.2s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.00042\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.1598e-04 - mse: 6.6696e-05 - NMSE: 6.0282e-04 - val_loss: 9.5646e-05 - val_mse: 4.6782e-05 - val_NMSE: 4.2286e-04\n",
      "Epoch 39/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.6210e-05 - mse: 4.7719e-05 - NMSE: 4.3135e-04 - tot_time: 0h 5m 59.0s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.00042\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 9.6210e-05 - mse: 4.7719e-05 - NMSE: 4.3135e-04 - val_loss: 9.5243e-05 - val_mse: 4.7176e-05 - val_NMSE: 4.2644e-04\n",
      "Epoch 40/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1589e-04 - mse: 6.8162e-05 - NMSE: 6.1613e-04 - tot_time: 0h 6m 7.8s\n",
      "\n",
      "Epoch 40: val_NMSE improved from 0.00042 to 0.00038, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1564e-04 - mse: 6.7914e-05 - NMSE: 6.1389e-04 - val_loss: 8.9539e-05 - val_mse: 4.2201e-05 - val_NMSE: 3.8146e-04\n",
      "Epoch 41/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.1400e-05 - mse: 4.4439e-05 - NMSE: 4.0168e-04 - tot_time: 0h 6m 16.6s\n",
      "\n",
      "Epoch 41: val_NMSE improved from 0.00038 to 0.00038, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 9.1400e-05 - mse: 4.4439e-05 - NMSE: 4.0168e-04 - val_loss: 8.8005e-05 - val_mse: 4.1489e-05 - val_NMSE: 3.7501e-04\n",
      "Epoch 42/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0080e-04 - mse: 5.4584e-05 - NMSE: 4.9338e-04 - tot_time: 0h 6m 25.7s\n",
      "\n",
      "Epoch 42: val_NMSE did not improve from 0.00038\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0074e-04 - mse: 5.4521e-05 - NMSE: 4.9282e-04 - val_loss: 1.1016e-04 - val_mse: 6.4325e-05 - val_NMSE: 5.8137e-04\n",
      "Epoch 43/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3730e-04 - mse: 9.1423e-05 - NMSE: 8.2642e-04 - tot_time: 0h 6m 34.8s\n",
      "\n",
      "Epoch 43: val_NMSE did not improve from 0.00038\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.3730e-04 - mse: 9.1423e-05 - NMSE: 8.2642e-04 - val_loss: 9.0286e-05 - val_mse: 4.4405e-05 - val_NMSE: 4.0139e-04\n",
      "Epoch 44/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.4701e-05 - mse: 3.9185e-05 - NMSE: 3.5417e-04 - tot_time: 0h 6m 43.9s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.00038\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 8.4701e-05 - mse: 3.9185e-05 - NMSE: 3.5417e-04 - val_loss: 1.0489e-04 - val_mse: 5.9867e-05 - val_NMSE: 5.4106e-04\n",
      "Epoch 45/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.8922e-05 - mse: 5.4100e-05 - NMSE: 4.8902e-04 - tot_time: 0h 6m 53.1s\n",
      "\n",
      "Epoch 45: val_NMSE improved from 0.00038 to 0.00033, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 9.8922e-05 - mse: 5.4100e-05 - NMSE: 4.8902e-04 - val_loss: 8.1219e-05 - val_mse: 3.6807e-05 - val_NMSE: 3.3270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0204e-04 - mse: 5.7841e-05 - NMSE: 5.2285e-04 - tot_time: 0h 7m 1.8s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.0204e-04 - mse: 5.7841e-05 - NMSE: 5.2285e-04 - val_loss: 9.6593e-05 - val_mse: 5.2665e-05 - val_NMSE: 4.7600e-04\n",
      "Epoch 47/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.6040e-05 - mse: 5.2255e-05 - NMSE: 4.7231e-04 - tot_time: 0h 7m 10.5s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.6040e-05 - mse: 5.2255e-05 - NMSE: 4.7231e-04 - val_loss: 1.9524e-04 - val_mse: 1.5186e-04 - val_NMSE: 0.0014\n",
      "Epoch 48/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0021e-04 - mse: 5.7063e-05 - NMSE: 5.1579e-04 - tot_time: 0h 7m 19.3s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.0014e-04 - mse: 5.6997e-05 - NMSE: 5.1519e-04 - val_loss: 1.1369e-04 - val_mse: 7.0848e-05 - val_NMSE: 6.4039e-04\n",
      "Epoch 49/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.7506e-05 - mse: 4.4838e-05 - NMSE: 4.0530e-04 - tot_time: 0h 7m 28.0s\n",
      "\n",
      "Epoch 49: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.7363e-05 - mse: 4.4696e-05 - NMSE: 4.0402e-04 - val_loss: 8.0139e-05 - val_mse: 3.7824e-05 - val_NMSE: 3.4189e-04\n",
      "Epoch 50/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.5327e-05 - mse: 5.3170e-05 - NMSE: 4.8059e-04 - tot_time: 0h 7m 36.7s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.5200e-05 - mse: 5.3043e-05 - NMSE: 4.7945e-04 - val_loss: 8.8900e-05 - val_mse: 4.6977e-05 - val_NMSE: 4.2465e-04\n",
      "Epoch 51/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 9.4581e-05 - mse: 5.2816e-05 - NMSE: 4.7739e-04 - tot_time: 0h 7m 45.4s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.4581e-05 - mse: 5.2816e-05 - NMSE: 4.7739e-04 - val_loss: 1.1003e-04 - val_mse: 6.8515e-05 - val_NMSE: 6.1929e-04\n",
      "Epoch 52/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.3404e-05 - mse: 4.2117e-05 - NMSE: 3.8071e-04 - tot_time: 0h 7m 54.3s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.3276e-05 - mse: 4.1991e-05 - NMSE: 3.7957e-04 - val_loss: 8.0636e-05 - val_mse: 3.9698e-05 - val_NMSE: 3.5884e-04\n",
      "Epoch 53/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.7299e-05 - mse: 5.6451e-05 - NMSE: 5.1026e-04 - tot_time: 0h 8m 2.9s\n",
      "\n",
      "Epoch 53: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 9.8027e-05 - mse: 5.7181e-05 - NMSE: 5.1686e-04 - val_loss: 2.4829e-04 - val_mse: 2.0774e-04 - val_NMSE: 0.0019\n",
      "Epoch 54/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.7488e-05 - mse: 4.6940e-05 - NMSE: 4.2428e-04 - tot_time: 0h 8m 12.2s\n",
      "\n",
      "Epoch 54: val_NMSE did not improve from 0.00033\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 8.7488e-05 - mse: 4.6940e-05 - NMSE: 4.2428e-04 - val_loss: 8.9714e-05 - val_mse: 4.9471e-05 - val_NMSE: 4.4713e-04\n",
      "Epoch 55/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.7927e-05 - mse: 5.7653e-05 - NMSE: 5.2111e-04 - tot_time: 0h 8m 21.2s\n",
      "\n",
      "Epoch 55: val_NMSE improved from 0.00033 to 0.00031, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 9.7719e-05 - mse: 5.7446e-05 - NMSE: 5.1924e-04 - val_loss: 7.4166e-05 - val_mse: 3.4087e-05 - val_NMSE: 3.0811e-04\n",
      "Epoch 56/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.3203e-05 - mse: 4.3434e-05 - NMSE: 3.9260e-04 - tot_time: 0h 8m 30.1s\n",
      "\n",
      "Epoch 56: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.3137e-05 - mse: 4.3369e-05 - NMSE: 3.9202e-04 - val_loss: 9.1153e-05 - val_mse: 5.1674e-05 - val_NMSE: 4.6705e-04\n",
      "Epoch 57/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 7.7832e-05 - mse: 3.8514e-05 - NMSE: 3.4813e-04 - tot_time: 0h 8m 38.9s\n",
      "\n",
      "Epoch 57: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 7.7832e-05 - mse: 3.8514e-05 - NMSE: 3.4813e-04 - val_loss: 9.0380e-05 - val_mse: 5.1389e-05 - val_NMSE: 4.6448e-04\n",
      "Epoch 58/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.4909e-05 - mse: 5.5854e-05 - NMSE: 5.0487e-04 - tot_time: 0h 8m 47.9s\n",
      "\n",
      "Epoch 58: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 9.4719e-05 - mse: 5.5665e-05 - NMSE: 5.0316e-04 - val_loss: 7.4472e-05 - val_mse: 3.5637e-05 - val_NMSE: 3.2211e-04\n",
      "Epoch 59/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.1122e-05 - mse: 4.2450e-05 - NMSE: 3.8371e-04 - tot_time: 0h 8m 56.6s\n",
      "\n",
      "Epoch 59: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.1014e-05 - mse: 4.2343e-05 - NMSE: 3.8274e-04 - val_loss: 7.3283e-05 - val_mse: 3.4904e-05 - val_NMSE: 3.1550e-04\n",
      "Epoch 60/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.0120e-05 - mse: 4.1909e-05 - NMSE: 3.7882e-04 - tot_time: 0h 9m 5.4s\n",
      "\n",
      "Epoch 60: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.0120e-05 - mse: 4.1909e-05 - NMSE: 3.7882e-04 - val_loss: 1.6064e-04 - val_mse: 1.2270e-04 - val_NMSE: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.5477e-05 - mse: 4.7602e-05 - NMSE: 4.3027e-04 - tot_time: 0h 9m 14.2s\n",
      "\n",
      "Epoch 61: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.5477e-05 - mse: 4.7602e-05 - NMSE: 4.3027e-04 - val_loss: 7.9019e-05 - val_mse: 4.1435e-05 - val_NMSE: 3.7452e-04\n",
      "Epoch 62/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.6571e-05 - mse: 3.9162e-05 - NMSE: 3.5397e-04 - tot_time: 0h 9m 22.8s\n",
      "\n",
      "Epoch 62: val_NMSE did not improve from 0.00031\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 7.6550e-05 - mse: 3.9142e-05 - NMSE: 3.5380e-04 - val_loss: 8.5760e-05 - val_mse: 4.8597e-05 - val_NMSE: 4.3927e-04\n",
      "Epoch 63/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.0941e-05 - mse: 4.3876e-05 - NMSE: 3.9659e-04 - tot_time: 0h 9m 31.6s\n",
      "\n",
      "Epoch 63: val_NMSE improved from 0.00031 to 0.00030, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.0798e-05 - mse: 4.3734e-05 - NMSE: 3.9530e-04 - val_loss: 7.0203e-05 - val_mse: 3.3355e-05 - val_NMSE: 3.0149e-04\n",
      "Epoch 64/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.1111e-05 - mse: 4.4358e-05 - NMSE: 4.0097e-04 - tot_time: 0h 9m 40.3s\n",
      "\n",
      "Epoch 64: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.0981e-05 - mse: 4.4230e-05 - NMSE: 3.9981e-04 - val_loss: 9.6859e-05 - val_mse: 6.0393e-05 - val_NMSE: 5.4592e-04\n",
      "Epoch 65/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.8817e-05 - mse: 4.2447e-05 - NMSE: 3.8367e-04 - tot_time: 0h 9m 49.4s\n",
      "\n",
      "Epoch 65: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 7.8726e-05 - mse: 4.2357e-05 - NMSE: 3.8285e-04 - val_loss: 7.2926e-05 - val_mse: 3.6757e-05 - val_NMSE: 3.3225e-04\n",
      "Epoch 66/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.3376e-05 - mse: 4.7299e-05 - NMSE: 4.2754e-04 - tot_time: 0h 9m 58.4s\n",
      "\n",
      "Epoch 66: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.3376e-05 - mse: 4.7299e-05 - NMSE: 4.2754e-04 - val_loss: 1.5830e-04 - val_mse: 1.2252e-04 - val_NMSE: 0.0011\n",
      "Epoch 67/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.4315e-05 - mse: 3.8567e-05 - NMSE: 3.4861e-04 - tot_time: 0h 10m 7.3s\n",
      "\n",
      "Epoch 67: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 7.4215e-05 - mse: 3.8469e-05 - NMSE: 3.4772e-04 - val_loss: 7.8819e-05 - val_mse: 4.3356e-05 - val_NMSE: 3.9189e-04\n",
      "Epoch 68/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.7738e-05 - mse: 4.2433e-05 - NMSE: 3.8355e-04 - tot_time: 0h 10m 16.2s\n",
      "\n",
      "Epoch 68: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 7.8120e-05 - mse: 4.2817e-05 - NMSE: 3.8701e-04 - val_loss: 1.1385e-04 - val_mse: 7.8771e-05 - val_NMSE: 7.1192e-04\n",
      "Epoch 69/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 7.4692e-05 - mse: 3.9685e-05 - NMSE: 3.5872e-04 - tot_time: 0h 10m 25.2s\n",
      "\n",
      "Epoch 69: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 7.4692e-05 - mse: 3.9685e-05 - NMSE: 3.5872e-04 - val_loss: 7.1360e-05 - val_mse: 3.6545e-05 - val_NMSE: 3.3032e-04\n",
      "Epoch 70/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.7505e-05 - mse: 4.2817e-05 - NMSE: 3.8701e-04 - tot_time: 0h 10m 33.9s\n",
      "\n",
      "Epoch 70: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 7.7399e-05 - mse: 4.2712e-05 - NMSE: 3.8606e-04 - val_loss: 7.1824e-05 - val_mse: 3.7279e-05 - val_NMSE: 3.3694e-04\n",
      "Epoch 71/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.4696e-05 - mse: 4.0265e-05 - NMSE: 3.6395e-04 - tot_time: 0h 10m 42.6s\n",
      "\n",
      "Epoch 71: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 7.4774e-05 - mse: 4.0344e-05 - NMSE: 3.6467e-04 - val_loss: 1.0942e-04 - val_mse: 7.5224e-05 - val_NMSE: 6.7995e-04\n",
      "Epoch 72/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 7.9474e-05 - mse: 4.5309e-05 - NMSE: 4.0955e-04 - tot_time: 0h 10m 51.2s\n",
      "\n",
      "Epoch 72: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 7.9362e-05 - mse: 4.5197e-05 - NMSE: 4.0854e-04 - val_loss: 7.9750e-05 - val_mse: 4.5740e-05 - val_NMSE: 4.1340e-04\n",
      "Epoch 73/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.2769e-05 - mse: 4.8697e-05 - NMSE: 4.4015e-04Restoring model weights from the end of the best epoch: 63.\n",
      " - tot_time: 0h 10m 59.9s\n",
      "\n",
      "Epoch 73: val_NMSE did not improve from 0.00030\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.2981e-05 - mse: 4.8911e-05 - NMSE: 4.4209e-04 - val_loss: 1.5933e-04 - val_mse: 1.2553e-04 - val_NMSE: 0.0011\n",
      "Epoch 73: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.0585e-05 - mse: 1.3788e-05 - NMSE: 1.2464e-04 - tot_time: 0h 11m 8.8s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.00030 to 0.00025, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 5.0585e-05 - mse: 1.3788e-05 - NMSE: 1.2464e-04 - val_loss: 6.3944e-05 - val_mse: 2.7207e-05 - val_NMSE: 2.4592e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.9588e-05 - mse: 1.2918e-05 - NMSE: 1.1678e-04 - tot_time: 0h 11m 17.7s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00025 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.9588e-05 - mse: 1.2918e-05 - NMSE: 1.1678e-04 - val_loss: 6.3482e-05 - val_mse: 2.6880e-05 - val_NMSE: 2.4296e-04\n",
      "Epoch 3/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.9210e-05 - mse: 1.2680e-05 - NMSE: 1.1462e-04 - tot_time: 0h 11m 26.6s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.9210e-05 - mse: 1.2680e-05 - NMSE: 1.1462e-04 - val_loss: 6.3054e-05 - val_mse: 2.6597e-05 - val_NMSE: 2.4041e-04\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8849e-05 - mse: 1.2466e-05 - NMSE: 1.1269e-04 - tot_time: 0h 11m 35.4s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.8849e-05 - mse: 1.2466e-05 - NMSE: 1.1269e-04 - val_loss: 6.2807e-05 - val_mse: 2.6502e-05 - val_NMSE: 2.3954e-04\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8522e-05 - mse: 1.2294e-05 - NMSE: 1.1113e-04 - tot_time: 0h 11m 43.9s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 4.8522e-05 - mse: 1.2294e-05 - NMSE: 1.1113e-04 - val_loss: 6.2725e-05 - val_mse: 2.6577e-05 - val_NMSE: 2.4022e-04\n",
      "Epoch 6/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.8254e-05 - mse: 1.2185e-05 - NMSE: 1.1014e-04 - tot_time: 0h 11m 52.6s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.8243e-05 - mse: 1.2174e-05 - NMSE: 1.1004e-04 - val_loss: 6.2318e-05 - val_mse: 2.6331e-05 - val_NMSE: 2.3800e-04\n",
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.8026e-05 - mse: 1.2119e-05 - NMSE: 1.0955e-04 - tot_time: 0h 12m 1.4s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00024 to 0.00024, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.8014e-05 - mse: 1.2107e-05 - NMSE: 1.0944e-04 - val_loss: 6.1997e-05 - val_mse: 2.6173e-05 - val_NMSE: 2.3657e-04\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.7853e-05 - mse: 1.2109e-05 - NMSE: 1.0946e-04 - tot_time: 0h 12m 10.3s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7841e-05 - mse: 1.2097e-05 - NMSE: 1.0936e-04 - val_loss: 6.2060e-05 - val_mse: 2.6400e-05 - val_NMSE: 2.3862e-04\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.7712e-05 - mse: 1.2130e-05 - NMSE: 1.0965e-04 - tot_time: 0h 12m 19.2s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7700e-05 - mse: 1.2120e-05 - NMSE: 1.0956e-04 - val_loss: 6.1830e-05 - val_mse: 2.6333e-05 - val_NMSE: 2.3802e-04\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7674e-05 - mse: 1.2255e-05 - NMSE: 1.1078e-04 - tot_time: 0h 12m 27.9s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.7674e-05 - mse: 1.2255e-05 - NMSE: 1.1078e-04 - val_loss: 6.2224e-05 - val_mse: 2.6888e-05 - val_NMSE: 2.4303e-04\n",
      "Epoch 11/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7899e-05 - mse: 1.2639e-05 - NMSE: 1.1425e-04 - tot_time: 0h 12m 37.0s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.7899e-05 - mse: 1.2639e-05 - NMSE: 1.1425e-04 - val_loss: 6.2289e-05 - val_mse: 2.7112e-05 - val_NMSE: 2.4505e-04\n",
      "Epoch 12/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8077e-05 - mse: 1.2973e-05 - NMSE: 1.1727e-04 - tot_time: 0h 12m 45.7s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.8077e-05 - mse: 1.2973e-05 - NMSE: 1.1727e-04 - val_loss: 6.2749e-05 - val_mse: 2.7727e-05 - val_NMSE: 2.5061e-04\n",
      "Epoch 13/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8148e-05 - mse: 1.3199e-05 - NMSE: 1.1931e-04 - tot_time: 0h 12m 54.4s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.8148e-05 - mse: 1.3199e-05 - NMSE: 1.1931e-04 - val_loss: 6.1167e-05 - val_mse: 2.6298e-05 - val_NMSE: 2.3770e-04\n",
      "Epoch 14/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.8208e-05 - mse: 1.3408e-05 - NMSE: 1.2120e-04 - tot_time: 0h 13m 3.0s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.8196e-05 - mse: 1.3397e-05 - NMSE: 1.2110e-04 - val_loss: 6.1622e-05 - val_mse: 2.6902e-05 - val_NMSE: 2.4315e-04\n",
      "Epoch 15/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.8076e-05 - mse: 1.3424e-05 - NMSE: 1.2135e-04 - tot_time: 0h 13m 12.2s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 4.8076e-05 - mse: 1.3424e-05 - NMSE: 1.2135e-04 - val_loss: 6.1241e-05 - val_mse: 2.6669e-05 - val_NMSE: 2.4105e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7816e-05 - mse: 1.3313e-05 - NMSE: 1.2035e-04 - tot_time: 0h 13m 21.1s\n",
      "\n",
      "Epoch 16: val_NMSE did not improve from 0.00024\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7816e-05 - mse: 1.3313e-05 - NMSE: 1.2035e-04 - val_loss: 6.0728e-05 - val_mse: 2.6308e-05 - val_NMSE: 2.3779e-04\n",
      "Epoch 17/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7571e-05 - mse: 1.3221e-05 - NMSE: 1.1951e-04 - tot_time: 0h 13m 29.8s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.00024 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7571e-05 - mse: 1.3221e-05 - NMSE: 1.1951e-04 - val_loss: 5.9981e-05 - val_mse: 2.5716e-05 - val_NMSE: 2.3244e-04\n",
      "Epoch 18/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7303e-05 - mse: 1.3110e-05 - NMSE: 1.1851e-04 - tot_time: 0h 13m 38.6s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.7303e-05 - mse: 1.3110e-05 - NMSE: 1.1851e-04 - val_loss: 5.9508e-05 - val_mse: 2.5402e-05 - val_NMSE: 2.2960e-04\n",
      "Epoch 19/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.7031e-05 - mse: 1.2998e-05 - NMSE: 1.1749e-04 - tot_time: 0h 13m 47.3s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.00023\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.7031e-05 - mse: 1.2998e-05 - NMSE: 1.1749e-04 - val_loss: 5.9398e-05 - val_mse: 2.5453e-05 - val_NMSE: 2.3006e-04\n",
      "Epoch 20/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.6861e-05 - mse: 1.2990e-05 - NMSE: 1.1742e-04 - tot_time: 0h 13m 56.3s\n",
      "\n",
      "Epoch 20: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.6847e-05 - mse: 1.2977e-05 - NMSE: 1.1730e-04 - val_loss: 5.9122e-05 - val_mse: 2.5338e-05 - val_NMSE: 2.2902e-04\n",
      "Epoch 21/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.6478e-05 - mse: 1.2770e-05 - NMSE: 1.1543e-04 - tot_time: 0h 14m 5.0s\n",
      "\n",
      "Epoch 21: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.6478e-05 - mse: 1.2770e-05 - NMSE: 1.1543e-04 - val_loss: 5.8790e-05 - val_mse: 2.5170e-05 - val_NMSE: 2.2750e-04\n",
      "Epoch 22/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.6209e-05 - mse: 1.2664e-05 - NMSE: 1.1447e-04 - tot_time: 0h 14m 13.9s\n",
      "\n",
      "Epoch 22: val_NMSE improved from 0.00023 to 0.00023, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.6209e-05 - mse: 1.2664e-05 - NMSE: 1.1447e-04 - val_loss: 5.8362e-05 - val_mse: 2.4904e-05 - val_NMSE: 2.2510e-04\n",
      "Epoch 23/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5911e-05 - mse: 1.2528e-05 - NMSE: 1.1325e-04 - tot_time: 0h 14m 23.0s\n",
      "\n",
      "Epoch 23: val_NMSE improved from 0.00023 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.5911e-05 - mse: 1.2528e-05 - NMSE: 1.1325e-04 - val_loss: 5.8003e-05 - val_mse: 2.4707e-05 - val_NMSE: 2.2331e-04\n",
      "Epoch 24/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.5655e-05 - mse: 1.2432e-05 - NMSE: 1.1237e-04 - tot_time: 0h 14m 31.9s\n",
      "\n",
      "Epoch 24: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.5641e-05 - mse: 1.2418e-05 - NMSE: 1.1225e-04 - val_loss: 5.7682e-05 - val_mse: 2.4544e-05 - val_NMSE: 2.2185e-04\n",
      "Epoch 25/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5342e-05 - mse: 1.2276e-05 - NMSE: 1.1097e-04 - tot_time: 0h 14m 41.1s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 4.5342e-05 - mse: 1.2276e-05 - NMSE: 1.1097e-04 - val_loss: 5.7549e-05 - val_mse: 2.4566e-05 - val_NMSE: 2.2205e-04\n",
      "Epoch 26/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5129e-05 - mse: 1.2216e-05 - NMSE: 1.1043e-04 - tot_time: 0h 14m 50.0s\n",
      "\n",
      "Epoch 26: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.5129e-05 - mse: 1.2216e-05 - NMSE: 1.1043e-04 - val_loss: 5.7238e-05 - val_mse: 2.4408e-05 - val_NMSE: 2.2061e-04\n",
      "Epoch 27/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.4863e-05 - mse: 1.2101e-05 - NMSE: 1.0938e-04 - tot_time: 0h 14m 58.5s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 4.4850e-05 - mse: 1.2088e-05 - NMSE: 1.0927e-04 - val_loss: 5.7033e-05 - val_mse: 2.4351e-05 - val_NMSE: 2.2010e-04\n",
      "Epoch 28/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4627e-05 - mse: 1.2011e-05 - NMSE: 1.0858e-04 - tot_time: 0h 15m 7.3s\n",
      "\n",
      "Epoch 28: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.4627e-05 - mse: 1.2011e-05 - NMSE: 1.0858e-04 - val_loss: 5.6798e-05 - val_mse: 2.4261e-05 - val_NMSE: 2.1928e-04\n",
      "Epoch 29/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4356e-05 - mse: 1.1884e-05 - NMSE: 1.0742e-04 - tot_time: 0h 15m 15.9s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.4356e-05 - mse: 1.1884e-05 - NMSE: 1.0742e-04 - val_loss: 5.6667e-05 - val_mse: 2.4271e-05 - val_NMSE: 2.1937e-04\n",
      "Epoch 30/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4119e-05 - mse: 1.1786e-05 - NMSE: 1.0653e-04 - tot_time: 0h 15m 24.7s\n",
      "\n",
      "Epoch 30: val_NMSE improved from 0.00022 to 0.00022, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.4119e-05 - mse: 1.1786e-05 - NMSE: 1.0653e-04 - val_loss: 5.6492e-05 - val_mse: 2.4233e-05 - val_NMSE: 2.1903e-04\n",
      "Epoch 31/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.3868e-05 - mse: 1.1670e-05 - NMSE: 1.0549e-04 - tot_time: 0h 15m 33.6s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3855e-05 - mse: 1.1657e-05 - NMSE: 1.0537e-04 - val_loss: 5.6422e-05 - val_mse: 2.4297e-05 - val_NMSE: 2.1961e-04\n",
      "Epoch 32/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3620e-05 - mse: 1.1554e-05 - NMSE: 1.0444e-04 - tot_time: 0h 15m 42.4s\n",
      "\n",
      "Epoch 32: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3620e-05 - mse: 1.1554e-05 - NMSE: 1.0444e-04 - val_loss: 5.6737e-05 - val_mse: 2.4743e-05 - val_NMSE: 2.2364e-04\n",
      "Epoch 33/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3421e-05 - mse: 1.1485e-05 - NMSE: 1.0381e-04 - tot_time: 0h 15m 51.2s\n",
      "\n",
      "Epoch 33: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3421e-05 - mse: 1.1485e-05 - NMSE: 1.0381e-04 - val_loss: 5.6998e-05 - val_mse: 2.5131e-05 - val_NMSE: 2.2714e-04\n",
      "Epoch 34/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.3144e-05 - mse: 1.1333e-05 - NMSE: 1.0245e-04 - tot_time: 0h 16m 0.2s\n",
      "\n",
      "Epoch 34: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.3144e-05 - mse: 1.1333e-05 - NMSE: 1.0245e-04 - val_loss: 5.8680e-05 - val_mse: 2.6937e-05 - val_NMSE: 2.4347e-04\n",
      "Epoch 35/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.3104e-05 - mse: 1.1416e-05 - NMSE: 1.0320e-04 - tot_time: 0h 16m 8.8s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.3099e-05 - mse: 1.1412e-05 - NMSE: 1.0316e-04 - val_loss: 5.6974e-05 - val_mse: 2.5352e-05 - val_NMSE: 2.2915e-04\n",
      "Epoch 36/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2631e-05 - mse: 1.1063e-05 - NMSE: 1.0001e-04 - tot_time: 0h 16m 17.8s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.2631e-05 - mse: 1.1063e-05 - NMSE: 1.0001e-04 - val_loss: 5.8861e-05 - val_mse: 2.7358e-05 - val_NMSE: 2.4727e-04\n",
      "Epoch 37/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2728e-05 - mse: 1.1278e-05 - NMSE: 1.0195e-04 - tot_time: 0h 16m 26.6s\n",
      "\n",
      "Epoch 37: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.2728e-05 - mse: 1.1278e-05 - NMSE: 1.0195e-04 - val_loss: 5.7329e-05 - val_mse: 2.5942e-05 - val_NMSE: 2.3448e-04\n",
      "Epoch 38/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2344e-05 - mse: 1.1009e-05 - NMSE: 9.9514e-05Restoring model weights from the end of the best epoch: 28.\n",
      " - tot_time: 0h 16m 36.0s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.00022\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 4.2344e-05 - mse: 1.1009e-05 - NMSE: 9.9514e-05 - val_loss: 5.7532e-05 - val_mse: 2.6258e-05 - val_NMSE: 2.3734e-04\n",
      "Epoch 38: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2443e-05 - mse: 9.9125e-06 - NMSE: 8.9604e-05 - tot_time: 0h 16m 44.8s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.00022 to 0.00021, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.2443e-05 - mse: 9.9125e-06 - NMSE: 8.9604e-05 - val_loss: 5.6218e-05 - val_mse: 2.3694e-05 - val_NMSE: 2.1416e-04\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2177e-05 - mse: 9.6611e-06 - NMSE: 8.7333e-05 - tot_time: 0h 16m 53.6s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00021 to 0.00021, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.2177e-05 - mse: 9.6611e-06 - NMSE: 8.7333e-05 - val_loss: 5.6179e-05 - val_mse: 2.3672e-05 - val_NMSE: 2.1396e-04\n",
      "Epoch 3/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2152e-05 - mse: 9.6526e-06 - NMSE: 8.7256e-05 - tot_time: 0h 17m 2.4s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00021 to 0.00021, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.2152e-05 - mse: 9.6526e-06 - NMSE: 8.7256e-05 - val_loss: 5.6160e-05 - val_mse: 2.3669e-05 - val_NMSE: 2.1393e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.2136e-05 - mse: 9.6534e-06 - NMSE: 8.7263e-05 - tot_time: 0h 17m 11.2s\n",
      "\n",
      "Epoch 4: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.2130e-05 - mse: 9.6483e-06 - NMSE: 8.7217e-05 - val_loss: 5.6153e-05 - val_mse: 2.3681e-05 - val_NMSE: 2.1404e-04\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2109e-05 - mse: 9.6456e-06 - NMSE: 8.7192e-05 - tot_time: 0h 17m 20.1s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.2109e-05 - mse: 9.6456e-06 - NMSE: 8.7192e-05 - val_loss: 5.6148e-05 - val_mse: 2.3696e-05 - val_NMSE: 2.1417e-04\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2077e-05 - mse: 9.6337e-06 - NMSE: 8.7085e-05 - tot_time: 0h 17m 30.8s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 4.2077e-05 - mse: 9.6337e-06 - NMSE: 8.7085e-05 - val_loss: 5.6123e-05 - val_mse: 2.3691e-05 - val_NMSE: 2.1413e-04\n",
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.2048e-05 - mse: 9.6268e-06 - NMSE: 8.7022e-05 - tot_time: 0h 17m 43.0s\n",
      "\n",
      "Epoch 7: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 4.2043e-05 - mse: 9.6217e-06 - NMSE: 8.6976e-05 - val_loss: 5.6083e-05 - val_mse: 2.3673e-05 - val_NMSE: 2.1397e-04\n",
      "Epoch 8/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.2009e-05 - mse: 9.6111e-06 - NMSE: 8.6880e-05 - tot_time: 0h 17m 54.9s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 4.2009e-05 - mse: 9.6111e-06 - NMSE: 8.6880e-05 - val_loss: 5.6059e-05 - val_mse: 2.3673e-05 - val_NMSE: 2.1397e-04\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.1980e-05 - mse: 9.6067e-06 - NMSE: 8.6841e-05 - tot_time: 0h 18m 6.6s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 4.1975e-05 - mse: 9.6013e-06 - NMSE: 8.6792e-05 - val_loss: 5.6041e-05 - val_mse: 2.3681e-05 - val_NMSE: 2.1404e-04\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.1939e-05 - mse: 9.5917e-06 - NMSE: 8.6705e-05 - tot_time: 0h 18m 18.2s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 4.1939e-05 - mse: 9.5917e-06 - NMSE: 8.6705e-05 - val_loss: 5.6027e-05 - val_mse: 2.3694e-05 - val_NMSE: 2.1417e-04\n",
      "Epoch 11/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.1906e-05 - mse: 9.5860e-06 - NMSE: 8.6654e-05Restoring model weights from the end of the best epoch: 1.\n",
      " - tot_time: 0h 18m 29.9s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.00021\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_001/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 4.1900e-05 - mse: 9.5807e-06 - NMSE: 8.6605e-05 - val_loss: 5.5985e-05 - val_mse: 2.3681e-05 - val_NMSE: 2.1404e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 9.9403e-05 - mse: 6.6879e-05 - NMSE: 6.0453e-04\n",
      "tested_rnn/test_rnn_001\n",
      "num_runs : 25\n",
      "    1 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    2 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    3 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    4 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    5 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    6 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    7 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    8 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    9 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    10 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    11 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    12 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    13 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    14 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    15 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    16 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    17 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    18 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    19 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    20 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    21 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    22 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    23 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    24 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "    25 / 25 -- run_time : 0.00 s -- eta : 0h 0m 0s\n",
      "\n",
      "error_threshold = 0.5\n",
      "prediction_horizon : 1.1739195376036125, median : 1.2681229572878527\n",
      "ph_min : 0.0, ph_max : 1.9927646471666258\n",
      "stddev : 0.5146231617626358, IQR : 0.9058021123484662\n",
      "1st quartile : 0.724641689878773, 3rd quartile : 1.6304438022272392\n",
      "analysis time : 3.613497495651245 s\n",
      "\n",
      "compute_time : 0h 18m 37s\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------- LEARNING RATE : 0.01 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0982 - tot_time: 0h 0m 12.9s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.00938, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 13s 63ms/step - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0982 - val_loss: 0.0012 - val_mse: 0.0010 - val_NMSE: 0.0094\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.3255e-04 - mse: 6.3540e-04 - NMSE: 0.0057 - tot_time: 0h 0m 22.3s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00938 to 0.00587, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 8.3255e-04 - mse: 6.3540e-04 - NMSE: 0.0057 - val_loss: 8.4810e-04 - val_mse: 6.4966e-04 - val_NMSE: 0.0059\n",
      "Epoch 3/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.9271e-04 - mse: 3.9785e-04 - NMSE: 0.0036 - tot_time: 0h 0m 31.4s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00587 to 0.00367, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 5.9205e-04 - mse: 3.9721e-04 - NMSE: 0.0036 - val_loss: 5.9671e-04 - val_mse: 4.0609e-04 - val_NMSE: 0.0037\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 5.2710e-04 - mse: 3.4145e-04 - NMSE: 0.0031 - tot_time: 0h 0m 40.6s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00367 to 0.00277, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 5.2710e-04 - mse: 3.4145e-04 - NMSE: 0.0031 - val_loss: 4.8794e-04 - val_mse: 3.0677e-04 - val_NMSE: 0.0028\n",
      "Epoch 5/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.4046e-04 - mse: 2.6422e-04 - NMSE: 0.0024 - tot_time: 0h 0m 49.3s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.00277\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 4.4046e-04 - mse: 2.6422e-04 - NMSE: 0.0024 - val_loss: 4.8526e-04 - val_mse: 3.1368e-04 - val_NMSE: 0.0028\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.5166e-04 - mse: 2.8385e-04 - NMSE: 0.0026 - tot_time: 0h 0m 58.1s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00277 to 0.00209, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.5166e-04 - mse: 2.8385e-04 - NMSE: 0.0026 - val_loss: 3.9594e-04 - val_mse: 2.3158e-04 - val_NMSE: 0.0021\n",
      "Epoch 7/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 4.0314e-04 - mse: 2.4246e-04 - NMSE: 0.0022 - tot_time: 0h 1m 7.1s\n",
      "\n",
      "Epoch 7: val_NMSE did not improve from 0.00209\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 4.0314e-04 - mse: 2.4246e-04 - NMSE: 0.0022 - val_loss: 3.9499e-04 - val_mse: 2.3750e-04 - val_NMSE: 0.0021\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.9578e-04 - mse: 2.4118e-04 - NMSE: 0.0022 - tot_time: 0h 1m 15.9s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.00209 to 0.00172, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.9526e-04 - mse: 2.4067e-04 - NMSE: 0.0022 - val_loss: 3.4280e-04 - val_mse: 1.9061e-04 - val_NMSE: 0.0017\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 4.6539e-04 - mse: 3.1404e-04 - NMSE: 0.0028 - tot_time: 0h 1m 24.8s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.00172\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 4.6457e-04 - mse: 3.1323e-04 - NMSE: 0.0028 - val_loss: 4.8819e-04 - val_mse: 3.3869e-04 - val_NMSE: 0.0031\n",
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 3.8065e-04 - mse: 2.3331e-04 - NMSE: 0.0021 - tot_time: 0h 1m 33.8s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.00172\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 3.8065e-04 - mse: 2.3331e-04 - NMSE: 0.0021 - val_loss: 3.4839e-04 - val_mse: 2.0298e-04 - val_NMSE: 0.0018\n",
      "Epoch 11/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.7166e-04 - mse: 2.2807e-04 - NMSE: 0.0021 - tot_time: 0h 1m 42.9s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.00172 to 0.00161, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 3.7114e-04 - mse: 2.2756e-04 - NMSE: 0.0021 - val_loss: 3.2013e-04 - val_mse: 1.7819e-04 - val_NMSE: 0.0016\n",
      "Epoch 12/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.7163e-04 - mse: 2.3113e-04 - NMSE: 0.0021 - tot_time: 0h 1m 51.6s\n",
      "\n",
      "Epoch 12: val_NMSE improved from 0.00161 to 0.00158, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 3.7105e-04 - mse: 2.3056e-04 - NMSE: 0.0021 - val_loss: 3.1351e-04 - val_mse: 1.7430e-04 - val_NMSE: 0.0016\n",
      "Epoch 13/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 3.8881e-04 - mse: 2.5021e-04 - NMSE: 0.0023 - tot_time: 0h 2m 0.6s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.00158 to 0.00149, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 3.8881e-04 - mse: 2.5021e-04 - NMSE: 0.0023 - val_loss: 3.0293e-04 - val_mse: 1.6523e-04 - val_NMSE: 0.0015\n",
      "Epoch 14/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.3296e-04 - mse: 1.9664e-04 - NMSE: 0.0018 - tot_time: 0h 2m 9.5s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.00149\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 3.3266e-04 - mse: 1.9636e-04 - NMSE: 0.0018 - val_loss: 3.4722e-04 - val_mse: 2.1214e-04 - val_NMSE: 0.0019\n",
      "Epoch 15/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.6585e-04 - mse: 2.3139e-04 - NMSE: 0.0021 - tot_time: 0h 2m 18.3s\n",
      "\n",
      "Epoch 15: val_NMSE improved from 0.00149 to 0.00137, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.6529e-04 - mse: 2.3084e-04 - NMSE: 0.0021 - val_loss: 2.8546e-04 - val_mse: 1.5155e-04 - val_NMSE: 0.0014\n",
      "Epoch 16/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.2680e-04 - mse: 1.9394e-04 - NMSE: 0.0018 - tot_time: 0h 2m 27.1s\n",
      "\n",
      "Epoch 16: val_NMSE did not improve from 0.00137\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.2634e-04 - mse: 1.9348e-04 - NMSE: 0.0017 - val_loss: 3.0574e-04 - val_mse: 1.7385e-04 - val_NMSE: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 3.1670e-04 - mse: 1.8576e-04 - NMSE: 0.0017 - tot_time: 0h 2m 35.9s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.00137 to 0.00132, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.1670e-04 - mse: 1.8576e-04 - NMSE: 0.0017 - val_loss: 2.7633e-04 - val_mse: 1.4624e-04 - val_NMSE: 0.0013\n",
      "Epoch 18/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 3.5125e-04 - mse: 2.2112e-04 - NMSE: 0.0020 - tot_time: 0h 2m 44.6s\n",
      "\n",
      "Epoch 18: val_NMSE did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 3.5087e-04 - mse: 2.2075e-04 - NMSE: 0.0020 - val_loss: 3.8742e-04 - val_mse: 2.5766e-04 - val_NMSE: 0.0023\n",
      "Epoch 19/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.8393e-04 - mse: 1.5537e-04 - NMSE: 0.0014 - tot_time: 0h 2m 53.3s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.8393e-04 - mse: 1.5537e-04 - NMSE: 0.0014 - val_loss: 2.9498e-04 - val_mse: 1.6771e-04 - val_NMSE: 0.0015\n",
      "Epoch 20/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.7813e-04 - mse: 1.5176e-04 - NMSE: 0.0014 - tot_time: 0h 3m 2.4s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.7787e-04 - mse: 1.5151e-04 - NMSE: 0.0014 - val_loss: 2.7961e-04 - val_mse: 1.5410e-04 - val_NMSE: 0.0014\n",
      "Epoch 21/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.8865e-04 - mse: 1.6365e-04 - NMSE: 0.0015 - tot_time: 0h 3m 11.6s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 2.8848e-04 - mse: 1.6349e-04 - NMSE: 0.0015 - val_loss: 2.9700e-04 - val_mse: 1.7294e-04 - val_NMSE: 0.0016\n",
      "Epoch 22/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.7719e-04 - mse: 1.5374e-04 - NMSE: 0.0014 - tot_time: 0h 3m 20.5s\n",
      "\n",
      "Epoch 22: val_NMSE improved from 0.00132 to 0.00125, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.7719e-04 - mse: 1.5374e-04 - NMSE: 0.0014 - val_loss: 2.6146e-04 - val_mse: 1.3866e-04 - val_NMSE: 0.0013\n",
      "Epoch 23/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.8809e-04 - mse: 1.6578e-04 - NMSE: 0.0015 - tot_time: 0h 3m 29.4s\n",
      "\n",
      "Epoch 23: val_NMSE did not improve from 0.00125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.8809e-04 - mse: 1.6578e-04 - NMSE: 0.0015 - val_loss: 2.7585e-04 - val_mse: 1.5422e-04 - val_NMSE: 0.0014\n",
      "Epoch 24/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.6457e-04 - mse: 1.4361e-04 - NMSE: 0.0013 - tot_time: 0h 3m 38.1s\n",
      "\n",
      "Epoch 24: val_NMSE improved from 0.00125 to 0.00108, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.6457e-04 - mse: 1.4361e-04 - NMSE: 0.0013 - val_loss: 2.3969e-04 - val_mse: 1.1934e-04 - val_NMSE: 0.0011\n",
      "Epoch 25/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.8451e-04 - mse: 1.6473e-04 - NMSE: 0.0015 - tot_time: 0h 3m 46.7s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.8401e-04 - mse: 1.6423e-04 - NMSE: 0.0015 - val_loss: 3.1299e-04 - val_mse: 1.9346e-04 - val_NMSE: 0.0017\n",
      "Epoch 26/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.6123e-04 - mse: 1.4228e-04 - NMSE: 0.0013 - tot_time: 0h 3m 55.7s\n",
      "\n",
      "Epoch 26: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.6123e-04 - mse: 1.4228e-04 - NMSE: 0.0013 - val_loss: 2.5822e-04 - val_mse: 1.3991e-04 - val_NMSE: 0.0013\n",
      "Epoch 27/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.5963e-04 - mse: 1.4215e-04 - NMSE: 0.0013 - tot_time: 0h 4m 4.8s\n",
      "\n",
      "Epoch 27: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.5963e-04 - mse: 1.4215e-04 - NMSE: 0.0013 - val_loss: 2.8747e-04 - val_mse: 1.7070e-04 - val_NMSE: 0.0015\n",
      "Epoch 28/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.7595e-04 - mse: 1.5977e-04 - NMSE: 0.0014 - tot_time: 0h 4m 13.5s\n",
      "\n",
      "Epoch 28: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.7595e-04 - mse: 1.5977e-04 - NMSE: 0.0014 - val_loss: 2.7807e-04 - val_mse: 1.6213e-04 - val_NMSE: 0.0015\n",
      "Epoch 29/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.2591e-04 - mse: 1.1048e-04 - NMSE: 9.9869e-04 - tot_time: 0h 4m 22.5s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.2696e-04 - mse: 1.1154e-04 - NMSE: 0.0010 - val_loss: 5.2514e-04 - val_mse: 4.1060e-04 - val_NMSE: 0.0037\n",
      "Epoch 30/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.4648e-04 - mse: 1.3258e-04 - NMSE: 0.0012 - tot_time: 0h 4m 31.1s\n",
      "\n",
      "Epoch 30: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.4624e-04 - mse: 1.3234e-04 - NMSE: 0.0012 - val_loss: 2.4863e-04 - val_mse: 1.3541e-04 - val_NMSE: 0.0012\n",
      "Epoch 31/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.4683e-04 - mse: 1.3416e-04 - NMSE: 0.0012 - tot_time: 0h 4m 39.8s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.4683e-04 - mse: 1.3416e-04 - NMSE: 0.0012 - val_loss: 2.5656e-04 - val_mse: 1.4459e-04 - val_NMSE: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.3265e-04 - mse: 1.2134e-04 - NMSE: 0.0011 - tot_time: 0h 4m 48.8s\n",
      "\n",
      "Epoch 32: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.3265e-04 - mse: 1.2134e-04 - NMSE: 0.0011 - val_loss: 2.9931e-04 - val_mse: 1.8859e-04 - val_NMSE: 0.0017\n",
      "Epoch 33/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.2230e-04 - mse: 1.1227e-04 - NMSE: 0.0010 - tot_time: 0h 4m 57.5s\n",
      "\n",
      "Epoch 33: val_NMSE did not improve from 0.00108\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.2199e-04 - mse: 1.1197e-04 - NMSE: 0.0010 - val_loss: 2.4880e-04 - val_mse: 1.3961e-04 - val_NMSE: 0.0013\n",
      "Epoch 34/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.2160e-04 - mse: 1.1291e-04 - NMSE: 0.0010 - tot_time: 0h 5m 6.1s\n",
      "\n",
      "Epoch 34: val_NMSE improved from 0.00108 to 0.00092, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.2131e-04 - mse: 1.1263e-04 - NMSE: 0.0010 - val_loss: 2.0946e-04 - val_mse: 1.0148e-04 - val_NMSE: 9.1731e-04\n",
      "Epoch 35/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.1972e-04 - mse: 1.1214e-04 - NMSE: 0.0010 - tot_time: 0h 5m 14.8s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.1972e-04 - mse: 1.1214e-04 - NMSE: 0.0010 - val_loss: 3.3494e-04 - val_mse: 2.2807e-04 - val_NMSE: 0.0021\n",
      "Epoch 36/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.3184e-04 - mse: 1.2522e-04 - NMSE: 0.0011 - tot_time: 0h 5m 24.2s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 2.3184e-04 - mse: 1.2522e-04 - NMSE: 0.0011 - val_loss: 2.1646e-04 - val_mse: 1.0997e-04 - val_NMSE: 9.9412e-04\n",
      "Epoch 37/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.9322e-04 - mse: 8.7473e-05 - NMSE: 7.9071e-04 - tot_time: 0h 5m 32.8s\n",
      "\n",
      "Epoch 37: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.9322e-04 - mse: 8.7473e-05 - NMSE: 7.9071e-04 - val_loss: 2.1926e-04 - val_mse: 1.1425e-04 - val_NMSE: 0.0010\n",
      "Epoch 38/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.2396e-04 - mse: 1.1907e-04 - NMSE: 0.0011 - tot_time: 0h 5m 41.9s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 2.2396e-04 - mse: 1.1907e-04 - NMSE: 0.0011 - val_loss: 2.0731e-04 - val_mse: 1.0320e-04 - val_NMSE: 9.3286e-04\n",
      "Epoch 39/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.1160e-04 - mse: 1.0807e-04 - NMSE: 9.7691e-04 - tot_time: 0h 5m 51.6s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 2.1131e-04 - mse: 1.0779e-04 - NMSE: 9.7437e-04 - val_loss: 2.1352e-04 - val_mse: 1.1046e-04 - val_NMSE: 9.9847e-04\n",
      "Epoch 40/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 2.0936e-04 - mse: 1.0665e-04 - NMSE: 9.6402e-04 - tot_time: 0h 6m 0.4s\n",
      "\n",
      "Epoch 40: val_NMSE did not improve from 0.00092\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.0942e-04 - mse: 1.0671e-04 - NMSE: 9.6457e-04 - val_loss: 2.4094e-04 - val_mse: 1.3872e-04 - val_NMSE: 0.0013\n",
      "Epoch 41/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.8864e-04 - mse: 8.7111e-05 - NMSE: 7.8740e-04 - tot_time: 0h 6m 9.2s\n",
      "\n",
      "Epoch 41: val_NMSE improved from 0.00092 to 0.00090, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.8864e-04 - mse: 8.7111e-05 - NMSE: 7.8740e-04 - val_loss: 2.0058e-04 - val_mse: 9.9641e-05 - val_NMSE: 9.0069e-04\n",
      "Epoch 42/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.9289e-04 - mse: 9.2467e-05 - NMSE: 8.3585e-04 - tot_time: 0h 6m 17.8s\n",
      "\n",
      "Epoch 42: val_NMSE did not improve from 0.00090\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.9267e-04 - mse: 9.2247e-05 - NMSE: 8.3386e-04 - val_loss: 2.0406e-04 - val_mse: 1.0424e-04 - val_NMSE: 9.4229e-04\n",
      "Epoch 43/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.1426e-04 - mse: 1.1485e-04 - NMSE: 0.0010 - tot_time: 0h 6m 26.6s\n",
      "\n",
      "Epoch 43: val_NMSE improved from 0.00090 to 0.00079, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 2.1426e-04 - mse: 1.1485e-04 - NMSE: 0.0010 - val_loss: 1.8725e-04 - val_mse: 8.7860e-05 - val_NMSE: 7.9422e-04\n",
      "Epoch 44/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.7310e-04 - mse: 7.4734e-05 - NMSE: 6.7551e-04 - tot_time: 0h 6m 35.4s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.00079\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.7291e-04 - mse: 7.4551e-05 - NMSE: 6.7386e-04 - val_loss: 1.8913e-04 - val_mse: 9.1568e-05 - val_NMSE: 8.2771e-04\n",
      "Epoch 45/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.7141e-04 - mse: 7.4743e-05 - NMSE: 6.7560e-04 - tot_time: 0h 6m 44.0s\n",
      "\n",
      "Epoch 45: val_NMSE did not improve from 0.00079\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.7128e-04 - mse: 7.4623e-05 - NMSE: 6.7452e-04 - val_loss: 1.9673e-04 - val_mse: 1.0100e-04 - val_NMSE: 9.1297e-04\n",
      "Epoch 46/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.7322e-04 - mse: 7.8183e-05 - NMSE: 7.0673e-04 - tot_time: 0h 6m 52.9s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.00079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.7322e-04 - mse: 7.8183e-05 - NMSE: 7.0673e-04 - val_loss: 2.1744e-04 - val_mse: 1.2302e-04 - val_NMSE: 0.0011\n",
      "Epoch 47/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.7303e-04 - mse: 7.9244e-05 - NMSE: 7.1625e-04 - tot_time: 0h 7m 2.8s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.00079\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 1.7303e-04 - mse: 7.9244e-05 - NMSE: 7.1625e-04 - val_loss: 2.0019e-04 - val_mse: 1.0708e-04 - val_NMSE: 9.6792e-04\n",
      "Epoch 48/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6547e-04 - mse: 7.3066e-05 - NMSE: 6.6048e-04 - tot_time: 0h 7m 13.7s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.00079\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 1.6547e-04 - mse: 7.3066e-05 - NMSE: 6.6048e-04 - val_loss: 1.9191e-04 - val_mse: 1.0022e-04 - val_NMSE: 9.0600e-04\n",
      "Epoch 49/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.7505e-04 - mse: 8.3774e-05 - NMSE: 7.5725e-04 - tot_time: 0h 7m 24.9s\n",
      "\n",
      "Epoch 49: val_NMSE improved from 0.00079 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 1.7476e-04 - mse: 8.3483e-05 - NMSE: 7.5462e-04 - val_loss: 1.7261e-04 - val_mse: 8.1913e-05 - val_NMSE: 7.4044e-04\n",
      "Epoch 50/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6209e-04 - mse: 7.2294e-05 - NMSE: 6.5345e-04 - tot_time: 0h 7m 35.4s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 1.6209e-04 - mse: 7.2294e-05 - NMSE: 6.5345e-04 - val_loss: 2.3804e-04 - val_mse: 1.4907e-04 - val_NMSE: 0.0013\n",
      "Epoch 51/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5886e-04 - mse: 7.0615e-05 - NMSE: 6.3831e-04 - tot_time: 0h 7m 47.5s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 1.5886e-04 - mse: 7.0615e-05 - NMSE: 6.3831e-04 - val_loss: 1.8638e-04 - val_mse: 9.8792e-05 - val_NMSE: 8.9304e-04\n",
      "Epoch 52/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.5160e-04 - mse: 6.4711e-05 - NMSE: 5.8492e-04 - tot_time: 0h 7m 58.8s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 1.5160e-04 - mse: 6.4711e-05 - NMSE: 5.8492e-04 - val_loss: 2.1047e-04 - val_mse: 1.2432e-04 - val_NMSE: 0.0011\n",
      "Epoch 53/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4706e-04 - mse: 6.1601e-05 - NMSE: 5.5681e-04 - tot_time: 0h 8m 10.0s\n",
      "\n",
      "Epoch 53: val_NMSE improved from 0.00074 to 0.00069, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 1.4693e-04 - mse: 6.1469e-05 - NMSE: 5.5562e-04 - val_loss: 1.6069e-04 - val_mse: 7.6071e-05 - val_NMSE: 6.8762e-04\n",
      "Epoch 54/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.6896e-04 - mse: 8.4379e-05 - NMSE: 7.6273e-04 - tot_time: 0h 8m 21.6s\n",
      "\n",
      "Epoch 54: val_NMSE did not improve from 0.00069\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 1.6896e-04 - mse: 8.4379e-05 - NMSE: 7.6273e-04 - val_loss: 1.7135e-04 - val_mse: 8.7563e-05 - val_NMSE: 7.9152e-04\n",
      "Epoch 55/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4230e-04 - mse: 5.9154e-05 - NMSE: 5.3468e-04 - tot_time: 0h 8m 31.5s\n",
      "\n",
      "Epoch 55: val_NMSE did not improve from 0.00069\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 1.4230e-04 - mse: 5.9154e-05 - NMSE: 5.3468e-04 - val_loss: 1.7706e-04 - val_mse: 9.4657e-05 - val_NMSE: 8.5557e-04\n",
      "Epoch 56/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4362e-04 - mse: 6.1913e-05 - NMSE: 5.5962e-04 - tot_time: 0h 8m 40.0s\n",
      "\n",
      "Epoch 56: val_NMSE did not improve from 0.00069\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 1.4355e-04 - mse: 6.1855e-05 - NMSE: 5.5910e-04 - val_loss: 1.5710e-04 - val_mse: 7.6109e-05 - val_NMSE: 6.8794e-04\n",
      "Epoch 57/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4281e-04 - mse: 6.2352e-05 - NMSE: 5.6361e-04 - tot_time: 0h 8m 48.7s\n",
      "\n",
      "Epoch 57: val_NMSE did not improve from 0.00069\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.4281e-04 - mse: 6.2352e-05 - NMSE: 5.6361e-04 - val_loss: 2.5329e-04 - val_mse: 1.7357e-04 - val_NMSE: 0.0016\n",
      "Epoch 58/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4736e-04 - mse: 6.7796e-05 - NMSE: 6.1284e-04 - tot_time: 0h 8m 57.6s\n",
      "\n",
      "Epoch 58: val_NMSE improved from 0.00069 to 0.00067, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.4715e-04 - mse: 6.7587e-05 - NMSE: 6.1095e-04 - val_loss: 1.5328e-04 - val_mse: 7.4122e-05 - val_NMSE: 6.7004e-04\n",
      "Epoch 59/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4655e-04 - mse: 6.8068e-05 - NMSE: 6.1526e-04 - tot_time: 0h 9m 6.6s\n",
      "\n",
      "Epoch 59: val_NMSE did not improve from 0.00067\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.4655e-04 - mse: 6.8068e-05 - NMSE: 6.1526e-04 - val_loss: 1.5328e-04 - val_mse: 7.5204e-05 - val_NMSE: 6.7977e-04\n",
      "Epoch 60/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2873e-04 - mse: 5.1408e-05 - NMSE: 4.6468e-04 - tot_time: 0h 9m 15.5s\n",
      "\n",
      "Epoch 60: val_NMSE did not improve from 0.00067\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2873e-04 - mse: 5.1408e-05 - NMSE: 4.6468e-04 - val_loss: 1.6776e-04 - val_mse: 9.1115e-05 - val_NMSE: 8.2357e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4973e-04 - mse: 7.3417e-05 - NMSE: 6.6365e-04 - tot_time: 0h 9m 24.6s\n",
      "\n",
      "Epoch 61: val_NMSE improved from 0.00067 to 0.00060, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.4948e-04 - mse: 7.3169e-05 - NMSE: 6.6141e-04 - val_loss: 1.4297e-04 - val_mse: 6.6783e-05 - val_NMSE: 6.0365e-04\n",
      "Epoch 62/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.3166e-04 - mse: 5.6254e-05 - NMSE: 5.0847e-04 - tot_time: 0h 9m 33.5s\n",
      "\n",
      "Epoch 62: val_NMSE did not improve from 0.00060\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.3160e-04 - mse: 5.6194e-05 - NMSE: 5.0793e-04 - val_loss: 1.6081e-04 - val_mse: 8.5929e-05 - val_NMSE: 7.7668e-04\n",
      "Epoch 63/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2743e-04 - mse: 5.3076e-05 - NMSE: 4.7977e-04 - tot_time: 0h 9m 42.5s\n",
      "\n",
      "Epoch 63: val_NMSE did not improve from 0.00060\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2743e-04 - mse: 5.3076e-05 - NMSE: 4.7977e-04 - val_loss: 1.8655e-04 - val_mse: 1.1267e-04 - val_NMSE: 0.0010\n",
      "Epoch 64/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2654e-04 - mse: 5.3141e-05 - NMSE: 4.8034e-04 - tot_time: 0h 9m 51.5s\n",
      "\n",
      "Epoch 64: val_NMSE did not improve from 0.00060\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2654e-04 - mse: 5.3141e-05 - NMSE: 4.8034e-04 - val_loss: 1.8549e-04 - val_mse: 1.1266e-04 - val_NMSE: 0.0010\n",
      "Epoch 65/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3138e-04 - mse: 5.8905e-05 - NMSE: 5.3242e-04 - tot_time: 0h 10m 0.5s\n",
      "\n",
      "Epoch 65: val_NMSE did not improve from 0.00060\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.3138e-04 - mse: 5.8905e-05 - NMSE: 5.3242e-04 - val_loss: 2.1839e-04 - val_mse: 1.4637e-04 - val_NMSE: 0.0013\n",
      "Epoch 66/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3439e-04 - mse: 6.2377e-05 - NMSE: 5.6384e-04 - tot_time: 0h 10m 9.5s\n",
      "\n",
      "Epoch 66: val_NMSE improved from 0.00060 to 0.00054, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.3439e-04 - mse: 6.2377e-05 - NMSE: 5.6384e-04 - val_loss: 1.3120e-04 - val_mse: 5.9306e-05 - val_NMSE: 5.3609e-04\n",
      "Epoch 67/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2880e-04 - mse: 5.7502e-05 - NMSE: 5.1977e-04 - tot_time: 0h 10m 18.2s\n",
      "\n",
      "Epoch 67: val_NMSE did not improve from 0.00054\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2874e-04 - mse: 5.7442e-05 - NMSE: 5.1922e-04 - val_loss: 1.7368e-04 - val_mse: 1.0279e-04 - val_NMSE: 9.2895e-04\n",
      "Epoch 68/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.3234e-04 - mse: 6.1945e-05 - NMSE: 5.5994e-04 - tot_time: 0h 10m 26.9s\n",
      "\n",
      "Epoch 68: val_NMSE did not improve from 0.00054\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.3291e-04 - mse: 6.2517e-05 - NMSE: 5.6511e-04 - val_loss: 2.2727e-04 - val_mse: 1.5720e-04 - val_NMSE: 0.0014\n",
      "Epoch 69/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2979e-04 - mse: 5.9757e-05 - NMSE: 5.4012e-04 - tot_time: 0h 10m 36.0s\n",
      "\n",
      "Epoch 69: val_NMSE did not improve from 0.00054\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2979e-04 - mse: 5.9757e-05 - NMSE: 5.4012e-04 - val_loss: 1.3530e-04 - val_mse: 6.5466e-05 - val_NMSE: 5.9174e-04\n",
      "Epoch 70/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2694e-04 - mse: 5.7412e-05 - NMSE: 5.1897e-04 - tot_time: 0h 10m 44.9s\n",
      "\n",
      "Epoch 70: val_NMSE improved from 0.00054 to 0.00051, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.2694e-04 - mse: 5.7412e-05 - NMSE: 5.1897e-04 - val_loss: 1.2601e-04 - val_mse: 5.6608e-05 - val_NMSE: 5.1169e-04\n",
      "Epoch 71/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2111e-04 - mse: 5.2163e-05 - NMSE: 4.7150e-04 - tot_time: 0h 10m 53.9s\n",
      "\n",
      "Epoch 71: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.2111e-04 - mse: 5.2163e-05 - NMSE: 4.7150e-04 - val_loss: 1.3325e-04 - val_mse: 6.4666e-05 - val_NMSE: 5.8447e-04\n",
      "Epoch 72/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2478e-04 - mse: 5.6438e-05 - NMSE: 5.1016e-04 - tot_time: 0h 11m 2.8s\n",
      "\n",
      "Epoch 72: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.2478e-04 - mse: 5.6438e-05 - NMSE: 5.1016e-04 - val_loss: 1.3471e-04 - val_mse: 6.6558e-05 - val_NMSE: 6.0165e-04\n",
      "Epoch 73/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2951e-04 - mse: 6.1313e-05 - NMSE: 5.5422e-04 - tot_time: 0h 11m 11.5s\n",
      "\n",
      "Epoch 73: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 1.2951e-04 - mse: 6.1311e-05 - NMSE: 5.5420e-04 - val_loss: 1.5000e-04 - val_mse: 8.2018e-05 - val_NMSE: 7.4139e-04\n",
      "Epoch 74/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 5.9577e-04 - mse: 4.9434e-04 - NMSE: 0.0045 - tot_time: 0h 11m 21.9s\n",
      "\n",
      "Epoch 74: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 5.9362e-04 - mse: 4.9209e-04 - NMSE: 0.0044 - val_loss: 2.2986e-04 - val_mse: 1.0984e-04 - val_NMSE: 9.9293e-04\n",
      "Epoch 75/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 1.6512e-04 - mse: 5.6284e-05 - NMSE: 5.0876e-04 - tot_time: 0h 11m 36.4s\n",
      "\n",
      "Epoch 75: val_NMSE did not improve from 0.00051\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 1.6512e-04 - mse: 5.6284e-05 - NMSE: 5.0876e-04 - val_loss: 1.6511e-04 - val_mse: 6.5101e-05 - val_NMSE: 5.8847e-04\n",
      "Epoch 76/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.4135e-04 - mse: 4.7135e-05 - NMSE: 4.2603e-04 - tot_time: 0h 11m 46.1s\n",
      "\n",
      "Epoch 76: val_NMSE improved from 0.00051 to 0.00049, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 1.4135e-04 - mse: 4.7135e-05 - NMSE: 4.2603e-04 - val_loss: 1.4341e-04 - val_mse: 5.4269e-05 - val_NMSE: 4.9056e-04\n",
      "Epoch 77/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2473e-04 - mse: 3.9301e-05 - NMSE: 3.5522e-04 - tot_time: 0h 11m 55.4s\n",
      "\n",
      "Epoch 77: val_NMSE improved from 0.00049 to 0.00045, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.2464e-04 - mse: 3.9238e-05 - NMSE: 3.5465e-04 - val_loss: 1.3227e-04 - val_mse: 5.0235e-05 - val_NMSE: 4.5407e-04\n",
      "Epoch 78/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2253e-04 - mse: 4.2980e-05 - NMSE: 3.8847e-04 - tot_time: 0h 12m 4.7s\n",
      "\n",
      "Epoch 78: val_NMSE did not improve from 0.00045\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 1.2246e-04 - mse: 4.2922e-05 - NMSE: 3.8795e-04 - val_loss: 1.4346e-04 - val_mse: 6.6263e-05 - val_NMSE: 5.9896e-04\n",
      "Epoch 79/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1589e-04 - mse: 4.0652e-05 - NMSE: 3.6744e-04 - tot_time: 0h 12m 14.1s\n",
      "\n",
      "Epoch 79: val_NMSE did not improve from 0.00045\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 1.1589e-04 - mse: 4.0652e-05 - NMSE: 3.6744e-04 - val_loss: 1.2964e-04 - val_mse: 5.6130e-05 - val_NMSE: 5.0732e-04\n",
      "Epoch 80/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1441e-04 - mse: 4.2318e-05 - NMSE: 3.8251e-04 - tot_time: 0h 12m 23.2s\n",
      "\n",
      "Epoch 80: val_NMSE improved from 0.00045 to 0.00040, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.1441e-04 - mse: 4.2318e-05 - NMSE: 3.8251e-04 - val_loss: 1.1456e-04 - val_mse: 4.3769e-05 - val_NMSE: 3.9563e-04\n",
      "Epoch 81/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.3643e-04 - mse: 6.6407e-05 - NMSE: 6.0029e-04 - tot_time: 0h 12m 32.5s\n",
      "\n",
      "Epoch 81: val_NMSE improved from 0.00040 to 0.00039, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.3643e-04 - mse: 6.6407e-05 - NMSE: 6.0029e-04 - val_loss: 1.1323e-04 - val_mse: 4.3546e-05 - val_NMSE: 3.9362e-04\n",
      "Epoch 82/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0433e-04 - mse: 3.5853e-05 - NMSE: 3.2405e-04 - tot_time: 0h 12m 41.8s\n",
      "\n",
      "Epoch 82: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.0429e-04 - mse: 3.5815e-05 - NMSE: 3.2371e-04 - val_loss: 1.2668e-04 - val_mse: 5.9218e-05 - val_NMSE: 5.3521e-04\n",
      "Epoch 83/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1260e-04 - mse: 4.5946e-05 - NMSE: 4.1530e-04 - tot_time: 0h 12m 51.0s\n",
      "\n",
      "Epoch 83: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.1261e-04 - mse: 4.5958e-05 - NMSE: 4.1542e-04 - val_loss: 1.6655e-04 - val_mse: 1.0059e-04 - val_NMSE: 9.0911e-04\n",
      "Epoch 84/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.2335e-04 - mse: 5.7765e-05 - NMSE: 5.2215e-04 - tot_time: 0h 13m 0.2s\n",
      "\n",
      "Epoch 84: val_NMSE improved from 0.00039 to 0.00039, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.2335e-04 - mse: 5.7765e-05 - NMSE: 5.2215e-04 - val_loss: 1.0893e-04 - val_mse: 4.3475e-05 - val_NMSE: 3.9297e-04\n",
      "Epoch 85/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0734e-04 - mse: 4.2464e-05 - NMSE: 3.8383e-04 - tot_time: 0h 13m 9.4s\n",
      "\n",
      "Epoch 85: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 1.0734e-04 - mse: 4.2464e-05 - NMSE: 3.8383e-04 - val_loss: 1.5410e-04 - val_mse: 8.9762e-05 - val_NMSE: 8.1140e-04\n",
      "Epoch 86/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1899e-04 - mse: 5.5018e-05 - NMSE: 4.9733e-04 - tot_time: 0h 13m 18.3s\n",
      "\n",
      "Epoch 86: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1899e-04 - mse: 5.5018e-05 - NMSE: 4.9733e-04 - val_loss: 1.2637e-04 - val_mse: 6.2580e-05 - val_NMSE: 5.6566e-04\n",
      "Epoch 87/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0832e-04 - mse: 4.4929e-05 - NMSE: 4.0610e-04 - tot_time: 0h 13m 27.2s\n",
      "\n",
      "Epoch 87: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.0832e-04 - mse: 4.4929e-05 - NMSE: 4.0610e-04 - val_loss: 1.4079e-04 - val_mse: 7.7762e-05 - val_NMSE: 7.0294e-04\n",
      "Epoch 88/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.1158e-04 - mse: 4.8780e-05 - NMSE: 4.4095e-04 - tot_time: 0h 13m 36.1s\n",
      "\n",
      "Epoch 88: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1158e-04 - mse: 4.8780e-05 - NMSE: 4.4095e-04 - val_loss: 1.3016e-04 - val_mse: 6.7521e-05 - val_NMSE: 6.1026e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1446e-04 - mse: 5.2061e-05 - NMSE: 4.7056e-04 - tot_time: 0h 13m 44.9s\n",
      "\n",
      "Epoch 89: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1431e-04 - mse: 5.1910e-05 - NMSE: 4.6921e-04 - val_loss: 1.1920e-04 - val_mse: 5.6999e-05 - val_NMSE: 5.1516e-04\n",
      "Epoch 90/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1035e-04 - mse: 4.8368e-05 - NMSE: 4.3722e-04 - tot_time: 0h 13m 53.7s\n",
      "\n",
      "Epoch 90: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 1.1023e-04 - mse: 4.8248e-05 - NMSE: 4.3613e-04 - val_loss: 1.1395e-04 - val_mse: 5.2155e-05 - val_NMSE: 4.7145e-04\n",
      "Epoch 91/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1618e-04 - mse: 5.4479e-05 - NMSE: 4.9245e-04Restoring model weights from the end of the best epoch: 81.\n",
      " - tot_time: 0h 14m 2.7s\n",
      "\n",
      "Epoch 91: val_NMSE did not improve from 0.00039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 1.1600e-04 - mse: 5.4303e-05 - NMSE: 4.9087e-04 - val_loss: 1.0724e-04 - val_mse: 4.5432e-05 - val_NMSE: 4.1063e-04\n",
      "Epoch 91: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 9.0993e-05 - mse: 2.1558e-05 - NMSE: 1.9486e-04 - tot_time: 0h 14m 11.8s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.00039 to 0.00037, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 9.0973e-05 - mse: 2.1539e-05 - NMSE: 1.9469e-04 - val_loss: 1.0990e-04 - val_mse: 4.0703e-05 - val_NMSE: 3.6792e-04\n",
      "Epoch 2/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.8691e-05 - mse: 1.9729e-05 - NMSE: 1.7834e-04 - tot_time: 0h 14m 20.9s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.00037 to 0.00036, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.8691e-05 - mse: 1.9729e-05 - NMSE: 1.7834e-04 - val_loss: 1.0825e-04 - val_mse: 3.9526e-05 - val_NMSE: 3.5728e-04\n",
      "Epoch 3/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.7670e-05 - mse: 1.9184e-05 - NMSE: 1.7341e-04 - tot_time: 0h 14m 29.8s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.00036 to 0.00035, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.7657e-05 - mse: 1.9172e-05 - NMSE: 1.7330e-04 - val_loss: 1.0693e-04 - val_mse: 3.8681e-05 - val_NMSE: 3.4964e-04\n",
      "Epoch 4/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.6765e-05 - mse: 1.8761e-05 - NMSE: 1.6958e-04 - tot_time: 0h 14m 38.6s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.00035 to 0.00034, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.6765e-05 - mse: 1.8761e-05 - NMSE: 1.6958e-04 - val_loss: 1.0588e-04 - val_mse: 3.8116e-05 - val_NMSE: 3.4453e-04\n",
      "Epoch 5/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.5958e-05 - mse: 1.8437e-05 - NMSE: 1.6665e-04 - tot_time: 0h 14m 47.7s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.00034 to 0.00034, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.5947e-05 - mse: 1.8427e-05 - NMSE: 1.6657e-04 - val_loss: 1.0478e-04 - val_mse: 3.7498e-05 - val_NMSE: 3.3894e-04\n",
      "Epoch 6/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.5198e-05 - mse: 1.8165e-05 - NMSE: 1.6419e-04 - tot_time: 0h 14m 56.6s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.00034 to 0.00033, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.5198e-05 - mse: 1.8165e-05 - NMSE: 1.6419e-04 - val_loss: 1.0363e-04 - val_mse: 3.6837e-05 - val_NMSE: 3.3298e-04\n",
      "Epoch 7/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.4530e-05 - mse: 1.7975e-05 - NMSE: 1.6248e-04 - tot_time: 0h 15m 5.3s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.00033 to 0.00033, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.4519e-05 - mse: 1.7966e-05 - NMSE: 1.6239e-04 - val_loss: 1.0269e-04 - val_mse: 3.6368e-05 - val_NMSE: 3.2873e-04\n",
      "Epoch 8/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.4070e-05 - mse: 1.7987e-05 - NMSE: 1.6258e-04 - tot_time: 0h 15m 14.4s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.00033 to 0.00033, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.4059e-05 - mse: 1.7977e-05 - NMSE: 1.6249e-04 - val_loss: 1.0201e-04 - val_mse: 3.6157e-05 - val_NMSE: 3.2683e-04\n",
      "Epoch 9/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.3549e-05 - mse: 1.7926e-05 - NMSE: 1.6204e-04 - tot_time: 0h 15m 23.6s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.00033 to 0.00032, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 8.3537e-05 - mse: 1.7916e-05 - NMSE: 1.6194e-04 - val_loss: 1.0099e-04 - val_mse: 3.5590e-05 - val_NMSE: 3.2169e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.3226e-05 - mse: 1.8061e-05 - NMSE: 1.6325e-04 - tot_time: 0h 15m 32.3s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.00032 to 0.00032, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 8.3226e-05 - mse: 1.8061e-05 - NMSE: 1.6325e-04 - val_loss: 1.0043e-04 - val_mse: 3.5479e-05 - val_NMSE: 3.2069e-04\n",
      "Epoch 11/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.2404e-05 - mse: 1.7677e-05 - NMSE: 1.5978e-04 - tot_time: 0h 15m 41.0s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.00032 to 0.00032, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.2404e-05 - mse: 1.7677e-05 - NMSE: 1.5978e-04 - val_loss: 9.9546e-05 - val_mse: 3.5018e-05 - val_NMSE: 3.1652e-04\n",
      "Epoch 12/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.2300e-05 - mse: 1.8000e-05 - NMSE: 1.6270e-04 - tot_time: 0h 15m 49.8s\n",
      "\n",
      "Epoch 12: val_NMSE improved from 0.00032 to 0.00032, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.2300e-05 - mse: 1.8000e-05 - NMSE: 1.6270e-04 - val_loss: 9.8989e-05 - val_mse: 3.4879e-05 - val_NMSE: 3.1527e-04\n",
      "Epoch 13/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.1979e-05 - mse: 1.8089e-05 - NMSE: 1.6351e-04 - tot_time: 0h 15m 58.7s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.00032 to 0.00031, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.1964e-05 - mse: 1.8076e-05 - NMSE: 1.6339e-04 - val_loss: 9.8133e-05 - val_mse: 3.4427e-05 - val_NMSE: 3.1119e-04\n",
      "Epoch 14/125\n",
      "187/188 [============================>.] - ETA: 0s - loss: 8.1146e-05 - mse: 1.7641e-05 - NMSE: 1.5946e-04 - tot_time: 0h 16m 7.7s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.00031 to 0.00031, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 8.1133e-05 - mse: 1.7629e-05 - NMSE: 1.5935e-04 - val_loss: 9.7368e-05 - val_mse: 3.4037e-05 - val_NMSE: 3.0766e-04\n",
      "Epoch 15/125\n",
      "188/188 [==============================] - ETA: 0s - loss: 8.1427e-05 - mse: 1.8304e-05 - NMSE: 1.6545e-04 - tot_time: 0h 16m 16.5s\n",
      "\n",
      "Epoch 15: val_NMSE improved from 0.00031 to 0.00030, saving model to /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/new_lorenz/GRU_params_Search/params_search_000/tested_rnn/test_rnn_002/checkpoints/LossHistoriesCheckpoint\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 8.1427e-05 - mse: 1.8304e-05 - NMSE: 1.6545e-04 - val_loss: 9.6646e-05 - val_mse: 3.3695e-05 - val_NMSE: 3.0457e-04\n",
      "Epoch 16/125\n",
      "128/188 [===================>..........] - ETA: 2s - loss: 8.2001e-05 - mse: 1.9186e-05 - NMSE: 1.7343e-04"
     ]
    }
   ],
   "source": [
    "res = gp_minimize(\n",
    "    optim_func,\n",
    "    dimensions,\n",
    "    x0=x0,\n",
    "    n_calls=n_calls,\n",
    "    n_initial_points=n_initial_points,\n",
    "    random_state=prng_seed,\n",
    "    acq_func=acq_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1667873564544,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "nDv5D8APneQm",
    "outputId": "ee911dc8-4d36-48af-8ad0-07cef0dbaf81"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 11096,
     "status": "ok",
     "timestamp": 1667873575637,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "dbLa0AwlDBWh",
    "outputId": "d3f93f58-9ce7-4994-8d68-29520477e02d"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1667873575638,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "MDopQ4JMhRPV",
    "outputId": "f6480bb7-5837-4a80-9333-f9acd175b27a"
   },
   "outputs": [],
   "source": [
    "optim_x = np.array(res.x)\n",
    "x_iters = np.array(res.x_iters)\n",
    "func_iters = np.array(res.func_vals)\n",
    "optim_func = res.fun\n",
    "\n",
    "optim_idx = np.where(x_iters[:, 0] == optim_x[0])[0]\n",
    "for i in range(optim_x.shape[0]-1):\n",
    "    i = i+1\n",
    "    optim_idx_i = np.where(x_iters[optim_idx, i] == optim_x[i])[0]\n",
    "    optim_idx = optim_idx[optim_idx_i]\n",
    "optim_idx = optim_idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667873576097,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "2_fAlJz2Vdev"
   },
   "outputs": [],
   "source": [
    "optim_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667873576098,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -60
    },
    "id": "s5BNteRC7COC",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = n_initial_points + len(x0)\n",
    "# sorted_idx = np.argsort(x_iters[a:, 0])\n",
    "\n",
    "xplot = np.arange(func_iters.shape[0])\n",
    "\n",
    "if a > 0:\n",
    "    plt.plot(\n",
    "        -func_iters[0:a+1],\n",
    "        linestyle='--',\n",
    "        color='C2',\n",
    "        marker='^',\n",
    "        label='Initial Points',\n",
    "    )\n",
    "    xplot = np.arange(a, func_iters.shape[0])\n",
    "plt.plot(\n",
    "    xplot,\n",
    "    -func_iters[a:],\n",
    "    linestyle='--',\n",
    "    marker='^',\n",
    "    label='GP Minimization',#'__nolegend__',\n",
    ")\n",
    "plt.plot([optim_idx], [-func_iters[optim_idx]], 's', label='Optimal Value')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=15)\n",
    "plt.ylabel('Median Prediction Horizon', fontsize=15)\n",
    "plt.grid(True, which='major', axis='x')\n",
    "plt.grid(True, which='both', axis='y')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.savefig(dir_name_rnn_plots+'/median_PH.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "plot_convergence(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_vals_dict = {\n",
    "    'x_iters':x_iters,\n",
    "    'func_iters':func_iters,\n",
    "    'optim_x':optim_x,\n",
    "    'optim_idx':optim_idx,\n",
    "    'optim_fun':func_iters[optim_idx]\n",
    "}\n",
    "\n",
    "with open(dir_name_rnn+'/optimized_vals.txt', 'w') as f:\n",
    "    f.write(str(optimized_vals_dict))\n",
    "    \n",
    "np.savez(\n",
    "    dir_name_rnn+'/optimized_vals',\n",
    "    x_iters=x_iters,\n",
    "    func_iters=func_iters,\n",
    "    optim_x=optim_x,\n",
    "    optim_idx=optim_idx,\n",
    "    optim_fun=func_iters[optim_idx]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xoptim_names = [\n",
    "    [r'fRMS', 'fRMS', plt.semilogy],\n",
    "    [r'$\\Lambda_{reg}$', 'lambda_reg', plt.semilogy],\n",
    "]\n",
    "if vary_zoneout == True:\n",
    "    xoptim_names.append(\n",
    "        [r'$p^{zoneout}$', 'zoneout', plt.plot]\n",
    "    )\n",
    "\n",
    "for i in range(len(xoptim_names)):\n",
    "    a = n_initial_points + len(x0)\n",
    "    # sorted_idx = np.argsort(x_iters[a:, 0])\n",
    "\n",
    "    xplot = np.arange(x_iters.shape[0])\n",
    "    if a > 0:\n",
    "        xoptim_names[i][2](\n",
    "            x_iters[:, i][0:a+1],\n",
    "            linestyle='--',\n",
    "            color='C2',\n",
    "            marker='^',\n",
    "            label='Initial Points',\n",
    "        )\n",
    "        xplot = np.arange(a, x_iters.shape[0])\n",
    "    xoptim_names[i][2](\n",
    "        xplot,\n",
    "        x_iters[:, i][a:],\n",
    "        linestyle='--',\n",
    "        marker='^',\n",
    "        label='GP Minimization',#'__nolegend__',\n",
    "    )\n",
    "    xoptim_names[i][2]([optim_idx], [x_iters[optim_idx, i]], 's', label='Optimal Value')\n",
    "\n",
    "    plt.xlabel('Iteration', fontsize=15)\n",
    "    plt.ylabel(xoptim_names[i][0], fontsize=15)\n",
    "    plt.grid(True, which='major', axis='x')\n",
    "    plt.grid(True, which='both', axis='y')\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    plt.savefig(dir_name_rnn_plots+'/'+xoptim_names[i][1]+'.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(dir_name_rnn+'/tested_rnn')\n",
    "# dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_mean_lst = []\n",
    "for dir_name in dir_list:\n",
    "    with np.load(dir_name_rnn+'/tested_rnn/'+dir_name+'/prediction_horizons-testingdata--combinedAERNN--ZEROoutsteps.npz') as f:\n",
    "        ph_mean = np.mean(f['prediction_horizon_arr'])\n",
    "        ph_mean_lst.append(ph_mean)\n",
    "ph_mean_lst = np.array(ph_mean_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(ph_mean_lst == ph_mean_lst.max())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx, dir_list[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence plot\n",
    "convergence_f = np.empty_like(func_iters)\n",
    "min_val = np.inf\n",
    "for i in range(func_iters.shape[0]):\n",
    "    if func_iters[i] < min_val:\n",
    "        min_val = func_iters[i]\n",
    "    convergence_f[i] = min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = n_initial_points + len(x0)\n",
    "# sorted_idx = np.argsort(x_iters[a:, 0])\n",
    "\n",
    "xplot = np.arange(x_iters.shape[0])\n",
    "\n",
    "if a > 0:\n",
    "    plt.plot(\n",
    "        -convergence_f[0:a+1],\n",
    "        linestyle='--',\n",
    "        color='C2',\n",
    "        marker='^',\n",
    "        label='Initial Points',\n",
    "    )\n",
    "    xplot = np.arange(a, x_iters.shape[0])\n",
    "plt.plot(\n",
    "    xplot,\n",
    "    -convergence_f[a:],\n",
    "    linestyle='--',\n",
    "    marker='^',\n",
    "    label='GP Minimization',#'__nolegend__',\n",
    ")\n",
    "# plt.semilogy([optim_idx], [func_iters[optim_idx, 0]], 's', label='Optimal Value')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=15)\n",
    "plt.ylabel(\n",
    "#     r\"$$\\min_{0 \\leq j \\leq \\mathrm{present \\ iteration}} \\left( \\mathrm{Test \\ MSE} \\right)$$\",\n",
    "#     r\"$$\\min_{0 \\leq j \\leq \\mathrm{present \\atop iteration}} \\left( \\mathrm{Test \\ MSE} \\right)$$\",\n",
    "    r\"$$\\max_{0 \\leq j \\leq \\mathrm{present \\atop iteration}} \\left( \\mathrm{Median \\ PH} \\right)$$\",\n",
    "    fontsize=15,\n",
    ")\n",
    "plt.title('Convergence Plot', fontsize=18)\n",
    "plt.grid(True, which='major', axis='x')\n",
    "plt.grid(True, which='both', axis='y')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.savefig(dir_name_rnn_plots+'/convergence_plot.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction horizon computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
