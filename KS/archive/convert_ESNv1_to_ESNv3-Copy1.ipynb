{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674c3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d187405",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "array = np.array\n",
    "float32 = np.float32\n",
    "int32 = np.int32\n",
    "float64 = np.float64\n",
    "int64 = np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f340e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9ad324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/KS\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78d21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 23:53:43.180160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.180671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.294128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.294482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.294865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.295141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 23:53:43.297387: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 23:53:43.297891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.298537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:43.298935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:44.841553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:44.841914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:44.842216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 23:53:44.842480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3369 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if gpus:\n",
    "        gpu_to_use = 1\n",
    "        tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_devices = tf.config.list_logical_devices('GPU')\n",
    "        print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06704ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.misc_tools import create_data_for_RNN\n",
    "from tools.ae_v5 import Autoencoder\n",
    "from tools.ESN_v1 import ESN\n",
    "from tools.ESN_v3 import ESN as ESNv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b898192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365464d",
   "metadata": {},
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c41638",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_idx = '000'\n",
    "dir_name_gs_all = os.getcwd() + '/grid_search/gridsearch_' + gs_idx\n",
    "\n",
    "worker_id = 1\n",
    "\n",
    "# worker_dir_list = os.listdir(dir_name_gs_all)\n",
    "# worker_dir_list = [dir_name_gs_all+'/'+dname for dname in worker_dir_list if os.path.isdir(dir_name_gs_all+'/'+dname)]\n",
    "\n",
    "worker_dir_list = [dir_name_gs_all+'/worker_{}'.format(worker_id)]\n",
    "\n",
    "ESN_dir_list = []\n",
    "for dname in worker_dir_list:\n",
    "    temp = os.listdir(dname)\n",
    "    temp = [dname+'/'+esndir for esndir in temp if os.path.isdir(dname+'/'+esndir)]\n",
    "    ESN_dir_list.extend(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392eab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_rnn: /home/rkaushik/Documents/Thesis/MLROM/KS/grid_search/gridsearch_000/worker_1/ESN_030\n",
      "dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/KS/saved_ae/ae_046\n",
      "data_dir_idx: 005\n",
      "normalize_flag_ogdata: False\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "\n",
    "# RNN directory\n",
    "dir_name_rnn = ESN_dir_list[0]\n",
    "\n",
    "# reading AE directory\n",
    "with open(dir_name_rnn + '/sim_data_AE_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "params_dict = eval(''.join(lines))\n",
    "\n",
    "dir_name_ae = params_dict['dir_name_ae']\n",
    "ae_idx = dir_name_ae[-3:]\n",
    "dir_name_ae = os.getcwd()+'/saved_ae/ae_'+ae_idx\n",
    "try:\n",
    "    use_ae_data = params_dict['use_ae_data']\n",
    "except:\n",
    "    print(\"'use_ae_data' not present in sim_data_AE_params, set to True.\")\n",
    "    use_ae_data = True\n",
    "\n",
    "# reading RNN paramaters\n",
    "with open(dir_name_rnn + '/RNN_specific_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "params_rnn_dict = eval(''.join(lines))\n",
    "\n",
    "\n",
    "\n",
    "dt_rnn = params_rnn_dict['dt_rnn']\n",
    "T_sample_input = params_rnn_dict['T_sample_input']\n",
    "T_sample_output = params_rnn_dict['T_sample_output']\n",
    "T_offset = params_rnn_dict['T_offset']\n",
    "return_params_arr = params_rnn_dict['return_params_arr']\n",
    "params = params_rnn_dict['params']\n",
    "delta_t = params_rnn_dict['delta_t']\n",
    "normalize_dataset = params_rnn_dict['normalize_dataset']\n",
    "num_input_tsteps = params_rnn_dict['num_input_tsteps']\n",
    "skip_intermediate = params_rnn_dict['skip_intermediate']\n",
    "normalization_type = params_rnn_dict['normalization_type']\n",
    "\n",
    "normalization_arr_rnn = None\n",
    "if normalize_dataset == True:\n",
    "    temp = np.load(dir_name_rnn+'/normalization_data.npz', allow_pickle=True)\n",
    "    normalization_arr_rnn = temp['normalization_arr'][0]\n",
    "    \n",
    "# reading simulation parameters\n",
    "with open(dir_name_ae + '/ae_data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "data_dir_idx = params_dict['data_dir_idx']\n",
    "normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "\n",
    "temp = np.load(dir_name_ae+'/normalization_data.npz', allow_pickle=True)\n",
    "normalization_constant_arr_aedata = temp['normalization_constant_arr_aedata'][0]\n",
    "\n",
    "try:\n",
    "    ae_data_with_params = params_dict['ae_data_with_params']\n",
    "except:\n",
    "    print(\"'ae_data_with_params' not present in ae_data, set to 'True'.\")\n",
    "    ae_data_with_params = True\n",
    "\n",
    "print('dir_name_rnn:', dir_name_rnn)\n",
    "print('dir_name_ae:', dir_name_ae)\n",
    "print('data_dir_idx:', data_dir_idx)\n",
    "\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + '/saved_data/data_' + data_dir_idx\n",
    "    \n",
    "with open(dir_name_data + '/sim_data_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "params_dict = eval(''.join(lines))\n",
    "params_mat = params_dict['params_mat']\n",
    "# init_state_mat = params_dict['init_state_mat']\n",
    "t0 = params_dict['t0']\n",
    "T = params_dict['T']\n",
    "delta_t = params_dict['delta_t']\n",
    "numpoints_xgrid = params_dict['numpoints_xgrid']\n",
    "length = params_dict['length']\n",
    "return_params_arr = params_dict['return_params_arr']\n",
    "normalize_flag_ogdata = params_dict['normalize_flag']\n",
    "print('normalize_flag_ogdata:', normalize_flag_ogdata)\n",
    "alldata_withparams_flag = params_dict['alldata_withparams_flag']\n",
    "\n",
    "xgrid = length*np.linspace(0, 1, numpoints_xgrid)\n",
    "\n",
    "fl = np.load(dir_name_data+'/data.npz', allow_pickle=True)\n",
    "# all_data = fl['all_data']\n",
    "# boundary_idx_arr = fl['boundary_idx_arr']\n",
    "# normalization_constant_arr_ogdata = fl['normalization_constant_arr'][0]\n",
    "# initial_t0 = fl['initial_t0']\n",
    "# init_state_mat = fl['init_state_mat']\n",
    "lyapunov_spectrum_mat = fl['lyapunov_spectrum_mat']\n",
    "\n",
    "# training params\n",
    "with open(dir_name_rnn + '/training_specific_params.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tparams_dict = eval(''.join(lines))\n",
    "\n",
    "# learning_rate_dict = tparams_dict['learning_rate_dict']\n",
    "epochs = tparams_dict['epochs']\n",
    "patience = tparams_dict['patience']\n",
    "min_delta = tparams_dict['min_delta']\n",
    "prng_seed = tparams_dict['prng_seed']\n",
    "train_split = tparams_dict['train_split']\n",
    "val_split = tparams_dict['val_split']\n",
    "batch_size = tparams_dict['batch_size']\n",
    "\n",
    "test_split = 1 - train_split - val_split\n",
    "\n",
    "# setting seed for PRNGs\n",
    "np.random.seed(prng_seed)\n",
    "tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb5ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case : 1, lyapunov exponent : 0.06465670311438651, lyapunov time : 15.466300964355469s\n"
     ]
    }
   ],
   "source": [
    "lyapunov_time_arr = np.empty(shape=lyapunov_spectrum_mat.shape[0], dtype=FTYPE)\n",
    "for i in range(lyapunov_spectrum_mat.shape[0]):\n",
    "    lyapunov_time_arr[i] = 1/lyapunov_spectrum_mat[i, 0]\n",
    "    print('Case : {}, lyapunov exponent : {}, lyapunov time : {}s'.format(i+1, lyapunov_spectrum_mat[i, 0], lyapunov_time_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a968037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "        boundary_idx_arr,\n",
    "        delta_t,\n",
    "        all_data,\n",
    "        xgrid,\n",
    "        xticks_snapto=20,\n",
    "        num_yticks=11,\n",
    "    ):\n",
    "\n",
    "    n = len(boundary_idx_arr)\n",
    "    # '''\n",
    "    num_cols = 1\n",
    "    num_rows = 1\n",
    "    factor = 1\n",
    "    # fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n",
    "\n",
    "    num_modes = xgrid.shape[0]\n",
    "\n",
    "    prev_idx = 0\n",
    "    for i in range(len(boundary_idx_arr)):\n",
    "        next_idx = boundary_idx_arr[i]\n",
    "        fig, ax = plt.subplots(figsize=(factor*7.5*num_cols, factor*5.0*num_rows))\n",
    "        N = next_idx - prev_idx\n",
    "        input_time = np.arange(0, N)*delta_t\n",
    "\n",
    "        im = ax.imshow(all_data[prev_idx:next_idx, 0:num_modes].transpose(), aspect='auto', origin='lower')\n",
    "        num_xticks = 1 + int((N*delta_t + 0.5*xticks_snapto) // xticks_snapto)\n",
    "        # xticks = np.linspace(0, N, num_xticks, dtype=np.int32)\n",
    "        xticks = np.arange(0, N, int((xticks_snapto+0.5*delta_t)//delta_t))\n",
    "        ax.set_xticks(ticks=xticks)\n",
    "        ax.set_xticklabels(np.round(xticks*delta_t, 1))\n",
    "        ax.tick_params(axis='x', rotation=270+45)\n",
    "\n",
    "        yticks = np.linspace(0, 1, num_yticks)*(len(xgrid)-1)\n",
    "        yticklabels = np.round(np.linspace(0, 1, yticks.shape[0])*xgrid[-1], 2)\n",
    "        ax.set_yticks(ticks=yticks)\n",
    "        ax.set_yticklabels(yticklabels)\n",
    "\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel(r'$x$')\n",
    "        # ax.title.set_text(r'Latent States')\n",
    "\n",
    "        plt.colorbar(im)\n",
    "        plt.show()\n",
    "        print('')\n",
    "\n",
    "        prev_idx = next_idx\n",
    "\n",
    "    # '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5193664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dealing with normalizing the data before feeding into autoencoder\n",
    "# if normalizeforae_flag == True and use_ae_data == True:\n",
    "#     for i in range(numpoints_xgrid):\n",
    "#         all_data[:, i] -= normalization_constant_arr_aedata[0, i]\n",
    "#         all_data[:, i] /= normalization_constant_arr_aedata[1, i]\n",
    "# if ae_data_with_params == False:\n",
    "#     all_data = all_data[:, 0:numpoints_xgrid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0728354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75ee88b4",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87ebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_file = dir_name_ae+dir_sep+'new_class_data'+dir_sep+'ae_'+ae_idx+'_class_dict.txt'\n",
    "# wt_file = dir_name_ae+dir_sep+'new_class_data'+dir_sep+'ae_'+ae_idx+'_ae_weights.h5'\n",
    "# if use_ae_data == True:\n",
    "#     load_file = dir_name_ae+'/final_net/final_net_class_dict.txt'\n",
    "#     wt_file = dir_name_ae+'/final_net/final_net_ae_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ac2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_ae_data == True:\n",
    "#     ae_net = Autoencoder(all_data.shape[1], load_file=load_file)\n",
    "#     ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65415b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create data\n",
    "# if use_ae_data == True:\n",
    "#     latent_states_all = ae_net.encoder_net.predict(all_data)\n",
    "#     del(all_data)\n",
    "# else:\n",
    "#     latent_states_all = all_data[:, 0:xgrid.shape[0]]\n",
    "\n",
    "# num_latent_states = latent_states_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b48f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_latent_states_KS(\n",
    "#     boundary_idx_arr,\n",
    "#     latent_states_all,\n",
    "#     delta_t,\n",
    "#     dir_name_ae,\n",
    "#     xticks_snapto=int(40*np.round((T//10)/40)),\n",
    "#     num_yticks=11,\n",
    "#     save_figs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4319b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbcf0170",
   "metadata": {},
   "source": [
    "# ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27a6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_1/ESN_030\n",
      "    time taken : 154.82240915298462 s\n",
      "worker_1/ESN_002\n",
      "    time taken : 160.83131980895996 s\n",
      "worker_1/ESN_076\n",
      "    time taken : 179.15672206878662 s\n",
      "worker_1/ESN_044\n",
      "    time taken : 171.168874502182 s\n",
      "worker_1/ESN_029\n",
      "    time taken : 20.873427152633667 s\n",
      "worker_1/ESN_041\n",
      "    time taken : 19.87019443511963 s\n",
      "worker_1/ESN_007\n",
      "    time taken : 14.942042112350464 s\n",
      "worker_1/ESN_023\n",
      "    time taken : 12.445675373077393 s\n",
      "worker_1/ESN_045\n",
      "    time taken : 11.770596027374268 s\n",
      "worker_1/ESN_047\n",
      "    time taken : 22.14444375038147 s\n",
      "worker_1/ESN_055\n",
      "    time taken : 20.50893807411194 s\n",
      "worker_1/ESN_071\n",
      "    time taken : 13.835004091262817 s\n",
      "worker_1/ESN_054\n",
      "    time taken : 163.01694798469543 s\n",
      "worker_1/ESN_057\n",
      "    time taken : 18.637277841567993 s\n",
      "worker_1/ESN_042\n",
      "    time taken : 162.94983053207397 s\n",
      "worker_1/ESN_038\n",
      "    time taken : 164.66737961769104 s\n",
      "worker_1/ESN_075\n",
      "    time taken : 14.664850950241089 s\n",
      "worker_1/ESN_034\n",
      "    time taken : 164.25978827476501 s\n",
      "worker_1/ESN_051\n",
      "    time taken : 12.7330162525177 s\n",
      "worker_1/ESN_074\n",
      "    time taken : 157.3579602241516 s\n",
      "worker_1/ESN_010\n",
      "    time taken : 151.6751561164856 s\n",
      "worker_1/ESN_036\n",
      "    time taken : 176.04780960083008 s\n",
      "worker_1/ESN_031\n",
      "    time taken : 20.64726209640503 s\n",
      "worker_1/ESN_058\n",
      "    time taken : 167.37393474578857 s\n",
      "worker_1/ESN_008\n",
      "    time taken : 177.1696367263794 s\n",
      "worker_1/ESN_039\n",
      "    time taken : 17.34695053100586 s\n",
      "worker_1/ESN_006\n",
      "    time taken : 157.02470779418945 s\n",
      "worker_1/ESN_022\n",
      "    time taken : 180.92928743362427 s\n",
      "worker_1/ESN_032\n",
      "    time taken : 177.96845173835754 s\n",
      "worker_1/ESN_063\n",
      "    time taken : 13.793907403945923 s\n",
      "worker_1/ESN_011\n",
      "    time taken : 17.413302898406982 s\n",
      "worker_1/ESN_067\n",
      "    time taken : 16.03475570678711 s\n",
      "worker_1/ESN_059\n",
      "    time taken : 12.81205439567566 s\n",
      "worker_1/ESN_077\n",
      "    time taken : 16.471277952194214 s\n",
      "worker_1/ESN_060\n",
      "    time taken : 166.5324296951294 s\n",
      "worker_1/ESN_019\n",
      "    time taken : 19.39139223098755 s\n",
      "worker_1/ESN_021\n",
      "    time taken : 16.175103425979614 s\n",
      "worker_1/ESN_079\n",
      "    time taken : 17.07782006263733 s\n",
      "worker_1/ESN_061\n",
      "    time taken : 20.210857152938843 s\n",
      "worker_1/ESN_064\n",
      "    time taken : 149.2954683303833 s\n",
      "worker_1/ESN_018\n",
      "    time taken : 150.01139450073242 s\n",
      "worker_1/ESN_065\n",
      "    time taken : 15.249680995941162 s\n",
      "worker_1/ESN_000\n",
      "    time taken : 168.1089904308319 s\n",
      "worker_1/ESN_013\n",
      "    time taken : 13.969820976257324 s\n",
      "worker_1/ESN_012\n",
      "    time taken : 160.11778593063354 s\n",
      "worker_1/ESN_017\n",
      "    time taken : 16.504810094833374 s\n",
      "worker_1/ESN_028\n",
      "    time taken : 150.93714499473572 s\n",
      "worker_1/ESN_062\n",
      "    time taken : 162.15278697013855 s\n",
      "worker_1/ESN_080\n",
      "    time taken : 160.05465698242188 s\n",
      "worker_1/ESN_048\n",
      "    time taken : 166.04031682014465 s\n",
      "worker_1/ESN_003\n",
      "    time taken : 8.642911911010742 s\n",
      "worker_1/ESN_027\n",
      "    time taken : 9.085551977157593 s\n",
      "worker_1/ESN_043\n",
      "    time taken : 19.157492637634277 s\n",
      "worker_1/ESN_068\n",
      "    time taken : 155.84157872200012 s\n",
      "worker_1/ESN_004\n",
      "    time taken : 145.37255668640137 s\n",
      "worker_1/ESN_037\n",
      "    time taken : 19.484580516815186 s\n",
      "worker_1/ESN_026\n",
      "    time taken : 168.22257566452026 s\n",
      "worker_1/ESN_053\n",
      "    time taken : 17.707289695739746 s\n",
      "worker_1/ESN_009\n",
      "    time taken : 16.66329860687256 s\n",
      "worker_1/ESN_035\n",
      "    time taken : 21.86828589439392 s\n",
      "worker_1/ESN_069\n",
      "    time taken : 16.80158519744873 s\n",
      "worker_1/ESN_052\n",
      "    time taken : 168.83671975135803 s\n",
      "worker_1/ESN_005\n",
      "    time taken : 23.681818962097168 s\n",
      "worker_1/ESN_046\n",
      "    time taken : 172.531023979187 s\n",
      "worker_1/ESN_049\n",
      "    time taken : 20.07844376564026 s\n",
      "worker_1/ESN_066\n",
      "    time taken : 173.9082100391388 s\n",
      "worker_1/ESN_015\n",
      "    time taken : 13.495262861251831 s\n",
      "worker_1/ESN_001\n",
      "    time taken : 19.331698656082153 s\n",
      "worker_1/ESN_020\n",
      "    time taken : 150.44087290763855 s\n",
      "worker_1/ESN_072\n",
      "    time taken : 166.82740759849548 s\n",
      "worker_1/ESN_014\n",
      "    time taken : 148.01668572425842 s\n",
      "worker_1/ESN_078\n",
      "    time taken : 157.78514003753662 s\n",
      "worker_1/ESN_040\n",
      "    time taken : 165.28102326393127 s\n",
      "worker_1/ESN_024\n",
      "    time taken : 145.12887144088745 s\n",
      "worker_1/ESN_070\n",
      "    time taken : 146.52972626686096 s\n",
      "worker_1/ESN_033\n",
      "    time taken : 16.955384731292725 s\n",
      "worker_1/ESN_050\n",
      "    time taken : 125.96432948112488 s\n",
      "worker_1/ESN_073\n",
      "    time taken : 9.85324740409851 s\n",
      "worker_1/ESN_025\n",
      "    time taken : 10.17536187171936 s\n",
      "worker_1/ESN_016\n",
      "    time taken : 89.63632535934448 s\n",
      "worker_1/ESN_056\n",
      "    time taken : 95.9284098148346 s\n"
     ]
    }
   ],
   "source": [
    "for dname_idx in range(len(ESN_dir_list)):\n",
    "    computation_time = time.time()\n",
    "    dir_name_rnn = ESN_dir_list[dname_idx]\n",
    "\n",
    "    sidx1 = dir_name_rnn[::-1].index('/')\n",
    "    sidx2 = dir_name_rnn[-sidx1-2::-1].index('/')\n",
    "    print(dir_name_rnn[-(sidx1+sidx2+1):])\n",
    "\n",
    "    # Initialize ESN_v1 network\n",
    "    load_file = dir_name_rnn + '/final_net/final_net_class_dict.txt'\n",
    "    rnn_net = ESN(\n",
    "        load_file=load_file,\n",
    "        stddev=0.0,\n",
    "    )\n",
    "    rnn_net.build(input_shape=(1, 1, rnn_net.data_dim))\n",
    "\n",
    "    wt_file = dir_name_rnn+'/final_net/final_net_ESN_weights.h5'\n",
    "    rnn_net.load_weights_from_file(wt_file)\n",
    "\n",
    "    new_ESN = ESNv3(load_file=load_file)\n",
    "    new_ESN.build(input_shape=(1, 1, rnn_net.data_dim))\n",
    "\n",
    "    for i in range(len(rnn_net.ESN_layers)):\n",
    "        rnn_net_cell = rnn_net.ESN_layers[i].cell\n",
    "        input_size = rnn_net_cell.input_size\n",
    "        usebias_Win = rnn_net.usebias_Win[i]\n",
    "\n",
    "        new_ESN_cell = new_ESN.ESN_layers[i].cell\n",
    "\n",
    "        # setting Win\n",
    "        K.set_value(new_ESN_cell.Win.kernel, rnn_net_cell.Win_np[0:input_size, :])\n",
    "        if usebias_Win == True:\n",
    "            K.set_value(new_ESN_cell.Win.bias, rnn_net_cell.Win_np[-1, :])\n",
    "\n",
    "        # setting Wres\n",
    "        K.set_value(new_ESN_cell.Wres.kernel, rnn_net_cell.Wres_np)\n",
    "\n",
    "    # setting Wout\n",
    "    usebias_Wout = rnn_net.usebias_Wout\n",
    "    Wout_np = rnn_net.Wout.numpy()\n",
    "\n",
    "    K.set_value(new_ESN.Wout.kernel, Wout_np[0:rnn_net.ESN_layers_units[-1], :])\n",
    "    if usebias_Wout == True:\n",
    "        K.set_value(new_ESN.Wout.bias, Wout_np[-1, :])\n",
    "\n",
    "    new_ESN.save_model_weights(dir_name_rnn+'/final_net/final_net_ESN_weights')\n",
    "    \n",
    "    print('    time taken : {} s'.format(time.time()-computation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1e169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c00a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ESN(np.ones(shape=(1, 1, rnn_net.data_dim)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc1559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb674ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fc845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8f763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e38dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
