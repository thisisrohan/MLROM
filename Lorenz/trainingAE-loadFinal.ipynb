{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AVrZNGlZu4Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SxAd7iDL0Ami"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1696,
     "status": "ok",
     "timestamp": 1656593329168,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "JjNnPRuk0IIX",
    "outputId": "e46083d6-1bb3-4c23-ae46-c5a1e9dc216a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1656593329169,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "9REiGIIy0IzV",
    "outputId": "bdaa5f59-9a07-4a01-c2cb-6947e644a525"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import create_Lorenz_data, mytimecallback, SaveLosses, plot_losses, plot_reconstructed_data, plot_latent_states, readAndReturnLossHistories\n",
    "from tools.ae_v3 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-mIQj_v4gzMh"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QL5n-abCg0nI"
   },
   "outputs": [],
   "source": [
    "# setting seed for PRNGs\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    prng_seed = 42\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656593329463,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "93252cb5-d45b-4fa7-dcd1-418412a5c079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:07:00.716068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.716470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.716823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.717261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.717693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.718065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.718615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.719087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.719460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.719797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3359 MB memory:  -> device: 0, name: Quadro K2200, pci bus id: 0000:02:00.0, compute capability: 5.0\n",
      "2022-09-15 19:07:00."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "719903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:00.720169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 3369 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:07:45.412622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:45.413036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:45.413392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:45.413732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:45.414065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:07:45.414402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# Lorenz System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xcNgt4hqg6Xv"
   },
   "outputs": [],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "from numpy import *\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # simutlation paramaters\n",
    "    sigma_arr = np.array([10])\n",
    "    rho_arr = np.array([20])\n",
    "    beta_arr = np.array([4/3])\n",
    "\n",
    "    x0 = 1\n",
    "    y0 = 1\n",
    "    z0 = 1\n",
    "\n",
    "    t0 = 0.0\n",
    "    T = 100.0\n",
    "    delta_t = 0.01\n",
    "\n",
    "    return_params_arr = False\n",
    "    normalize_flag = True\n",
    "\n",
    "    # making ae save directory\n",
    "    dir_name_ae = os.getcwd() + dir_sep + 'saved_ae'\n",
    "    if not os.path.isdir(dir_name_ae):\n",
    "        os.makedirs(dir_name_ae)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        dir_check = 'ae_' + str(counter).zfill(3)\n",
    "        if os.path.isdir(dir_name_ae + dir_sep + dir_check):\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dir_name_ae = dir_name_ae + dir_sep + dir_check\n",
    "    os.makedirs(dir_name_ae)\n",
    "    os.makedirs(dir_name_ae+dir_sep+'plots')\n",
    "\n",
    "    # saving sim data\n",
    "    sim_data = {\n",
    "        'rho_arr':rho_arr,\n",
    "        'sigma_arr':sigma_arr,\n",
    "        'beta_arr':beta_arr,\n",
    "        'x0':x0,\n",
    "        'y0':y0,\n",
    "        'z0':z0,\n",
    "        't0':t0,\n",
    "        'T':T,\n",
    "        'delta_t':delta_t,\n",
    "        'return_params_arr':return_params_arr,\n",
    "        'normalize_flag':normalize_flag\n",
    "    }\n",
    "    with open(dir_name_ae+dir_sep+'sim_data_params.txt', 'w') as f:\n",
    "        f.write(str(sim_data))\n",
    "\n",
    "else:\n",
    "    # simutlation paramaters\n",
    "    dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_003'.format(ds=dir_sep)\n",
    "\n",
    "    with open(dir_name_ae + dir_sep + 'sim_data_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    params_dict = eval(''.join(lines))\n",
    "\n",
    "    rho_arr = params_dict['rho_arr']\n",
    "    sigma_arr = params_dict['sigma_arr']\n",
    "    beta_arr = params_dict['beta_arr']\n",
    "\n",
    "    x0 = params_dict['x0']\n",
    "    y0 = params_dict['y0']\n",
    "    z0 = params_dict['z0']\n",
    "\n",
    "    t0 = params_dict['t0']\n",
    "    T = params_dict['T']\n",
    "    delta_t = params_dict['delta_t']\n",
    "\n",
    "    return_params_arr = params_dict['return_params_arr']\n",
    "    normalize_flag = params_dict['normalize_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7sl7i5H5Dqz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySVDz_2U5FH5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uDhfYHU45IS8"
   },
   "outputs": [],
   "source": [
    "res_dict = create_Lorenz_data(\n",
    "    T, t0, delta_t,\n",
    "    rho_arr, sigma_arr, beta_arr,\n",
    "    x0, y0, z0, return_params_arr=return_params_arr,\n",
    "    normalize=normalize_flag\n",
    ")\n",
    "\n",
    "all_data = res_dict['all_data']\n",
    "N = res_dict['N']\n",
    "boundary_idx_arr = res_dict['boundary_idx_arr']\n",
    "\n",
    "if return_params_arr == True:\n",
    "    params_arr = res_dict['params_arr']\n",
    "\n",
    "if normalize_flag == True:\n",
    "    normalization_constant_arr = res_dict['normalization_constant_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59kkrSP1GvzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-MJa7P5t5KiC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(boundary_idx_arr)\n",
    "# # '''\n",
    "# num_cols = 1\n",
    "# num_rows = n\n",
    "\n",
    "# fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n",
    "\n",
    "# prev_idx = 0\n",
    "# for i in range(n):\n",
    "#     # ax = plt.axes(projection ='3d')\n",
    "#     next_idx = boundary_idx_arr[i]\n",
    "    \n",
    "#     ax_orig = fig.add_subplot(num_rows, num_cols, i+1, projection ='3d')\n",
    "#     ax_orig.plot(all_data[prev_idx:next_idx, 0], all_data[prev_idx:next_idx, 1], all_data[prev_idx:next_idx, 2])\n",
    "#     ax_orig.title.set_text(r'Actual Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:]))\n",
    "#     ax_orig.set_xlabel('x')\n",
    "#     ax_orig.set_ylabel('y')\n",
    "#     ax_orig.set_zlabel('z')\n",
    "    \n",
    "#     # ax_predict = fig.add_subplot(num_rows, num_cols, 2*i+2, projection ='3d')\n",
    "#     # ax_predict.plot(reconstructed_data[prev_idx:next_idx, 0], reconstructed_data[prev_idx:next_idx, 1], reconstructed_data[prev_idx:next_idx, 2])\n",
    "#     # ax_predict.title.set_text(r'NN Reconstructed Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:])\n",
    "#     # )\n",
    "#     # ax_predict.set_xlabel('x')\n",
    "#     # ax_predict.set_ylabel('y')\n",
    "#     # ax_predict.set_zlabel('z')\n",
    "\n",
    "#     prev_idx = next_idx\n",
    "# # '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c5cjQ1lnjcwt"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    learning_rate_list = [0.001, 0.0001, 0.00001]\n",
    "    epochs = 2000\n",
    "    patience = 200  # parameter for early stopping\n",
    "    min_delta = 1e-6  # parameter for early stopping\n",
    "    lambda_reg = 1e-5  # weight for regularizer\n",
    "    train_split = 0.8\n",
    "    val_split = 0.1\n",
    "    test_split = 1 - train_split - val_split\n",
    "    batch_size = 64\n",
    "\n",
    "    # saving training params\n",
    "    training_specific_params = {\n",
    "        'learning_rate_list':learning_rate_list,\n",
    "        'epochs':epochs,\n",
    "        'patience':patience,\n",
    "        'min_delta':min_delta,\n",
    "        'prng_seed':prng_seed,\n",
    "        'train_split':train_split,\n",
    "        'val_split':val_split,\n",
    "        'batch_size':batch_size\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ae+dir_sep+'training_specific_params.txt', 'w') as f:\n",
    "        f.write(str(training_specific_params))\n",
    "else:\n",
    "    with open(dir_name_ae + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    learning_rate_list = tparams_dict['learning_rate_list']\n",
    "    epochs = tparams_dict['epochs']\n",
    "    patience = tparams_dict['patience']\n",
    "    min_delta = tparams_dict['min_delta']\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "\n",
    "    test_split = 1 - train_split - val_split\n",
    "\n",
    "    # setting seed for PRNGs\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lovTI3zuhlX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IjsRi02g5ORG"
   },
   "outputs": [],
   "source": [
    "# setting up data\n",
    "idx = np.arange(all_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "boundary = int(np.round((1-test_split)*all_data.shape[0]))\n",
    "training_data = all_data[idx[0:boundary], :]\n",
    "testing_data = all_data[idx[boundary:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qwietg7eTG-s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ-28EnzJ4Ur"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xTsmS7lgpps"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7l5kI1tfMszJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:08:41.324899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.325285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.325624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.325952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.326266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.326590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.327018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.327358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.327702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.327977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3359 MB memory:  -> device: 0, name: Quadro K2200, pci bus id: 0000:02:00.0, compute capability: 5.0\n",
      "2022-09-15 19:08:41.328067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-15 19:08:41.328333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 3369 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize network\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    ae_net = Autoencoder(\n",
    "        data_dim=6,\n",
    "        enc_layers=[16,12,8,8,4,4,2],\n",
    "        dec_layers=[2,4,4,8,8,12,16],\n",
    "        latent_space_dim=2,\n",
    "        lambda_reg=lambda_reg,\n",
    "        reg_name='L2',\n",
    "        enc_layer_act_func='elu',\n",
    "        enc_final_layer_act_func='tanh',\n",
    "        dec_layer_act_func='elu',\n",
    "        dec_final_layer_act_func='linear',\n",
    "        load_file=None)\n",
    "    # saving the AE configuration\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    ae_net.save_class_dict(save_path+dir_sep+'final_net_class_dict.txt')\n",
    "else:\n",
    "    load_file = dir_name_ae + dir_sep + 'final_net' + 'final_net_class_dict.txt'\n",
    "    ae_net = Autoencoder(data_dim=6, load_file=load_file)\n",
    "    \n",
    "    if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "        wt_file = dir_name_ae+dir_sep+'checkpoints'+dir_sep+'checkpoint'\n",
    "        # ae_net.load_weights(wt_file)\n",
    "    elif behaviour == 'loadFinalNetAndPlot':\n",
    "        wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "    ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48tkgZxT0Amt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yUChBAKqIFtX"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    val_loss_hist = []\n",
    "    train_loss_hist = []\n",
    "    lr_change=[0, 0]\n",
    "    savelosses_cb_vallossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    savelosses_cb_trainlossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    starting_lr_idx = 0\n",
    "    num_epochs_left = epochs\n",
    "elif behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    val_loss_hist, train_loss_hist, lr_change, starting_lr_idx, num_epochs_left, val_loss_arr_fromckpt, train_loss_arr_fromckpt = readAndReturnLossHistories(\n",
    "        dir_name_ae=dir_name_ae,\n",
    "        dir_sep=dir_sep,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list)\n",
    "    savelosses_cb_vallossarr = val_loss_arr_fromckpt\n",
    "    savelosses_cb_trainlossarr = train_loss_arr_fromckpt\n",
    "elif behaviour == 'loadFinalNetAndPlot':\n",
    "    with open(dir_name_ae+'{ds}final_net{ds}losses.txt'.format(ds=dir_sep), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    losses_dict = eval(''.join(lines))\n",
    "\n",
    "    val_loss_hist = losses_dict['val_loss_hist']\n",
    "    train_loss_hist = losses_dict['train_loss_hist']\n",
    "    lr_change = losses_dict['lr_change']\n",
    "    test_loss = losses_dict['test_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0oEGp6WKGu2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 42891,
     "status": "error",
     "timestamp": 1656593375693,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gELga1WnQeMK",
    "outputId": "82d1c95c-9354-43ed-c640-dfe3ea8f6ade",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 42.8772 - tot_time: 0h 0m 2.3s\n",
      "124/124 [==============================] - 2s 8ms/step - loss: 42.1691 - val_loss: 0.2456\n",
      "Epoch 2/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0494 - tot_time: 0h 0m 3.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0494 - val_loss: 0.0340\n",
      "Epoch 3/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0341 - tot_time: 0h 0m 4.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0346\n",
      "Epoch 4/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0341 - tot_time: 0h 0m 4.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0341 - val_loss: 0.0334\n",
      "Epoch 5/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0340 - tot_time: 0h 0m 5.8s\n",
      "\n",
      "Epoch 5: val_loss improved from inf to 0.03364, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 6/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0339 - tot_time: 0h 0m 6.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 7/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0341 - tot_time: 0h 0m 7.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0340 - val_loss: 0.0344\n",
      "Epoch 8/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0340 - tot_time: 0h 0m 8.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0340 - val_loss: 0.0333\n",
      "Epoch 9/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0340 - tot_time: 0h 0m 9.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0340 - val_loss: 0.0334\n",
      "Epoch 10/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0340 - tot_time: 0h 0m 9.8s\n",
      "\n",
      "Epoch 10: val_loss improved from 0.03364 to 0.03317, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0332\n",
      "Epoch 11/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0339 - tot_time: 0h 0m 10.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0339 - val_loss: 0.0331\n",
      "Epoch 12/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 11.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0338 - val_loss: 0.0330\n",
      "Epoch 13/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0338 - tot_time: 0h 0m 12.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0337 - val_loss: 0.0333\n",
      "Epoch 14/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 13.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0336 - val_loss: 0.0332\n",
      "Epoch 15/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0340 - tot_time: 0h 0m 14.4s\n",
      "\n",
      "Epoch 15: val_loss improved from 0.03317 to 0.03305, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0340 - val_loss: 0.0331\n",
      "Epoch 16/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 15.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0337 - val_loss: 0.0333\n",
      "Epoch 17/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 16.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 18/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0338 - tot_time: 0h 0m 17.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0330\n",
      "Epoch 19/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 17.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0337 - val_loss: 0.0331\n",
      "Epoch 20/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 18.6s\n",
      "\n",
      "Epoch 20: val_loss improved from 0.03305 to 0.03303, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0337 - val_loss: 0.0330\n",
      "Epoch 21/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0335 - tot_time: 0h 0m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0336 - val_loss: 0.0329\n",
      "Epoch 22/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 20.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0337 - val_loss: 0.0332\n",
      "Epoch 23/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0336 - tot_time: 0h 0m 21.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0336 - val_loss: 0.0330\n",
      "Epoch 24/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0334 - tot_time: 0h 0m 22.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0334 - val_loss: 0.0340\n",
      "Epoch 25/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0334 - tot_time: 0h 0m 22.9s\n",
      "\n",
      "Epoch 25: val_loss improved from 0.03303 to 0.03288, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0329\n",
      "Epoch 26/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0335 - tot_time: 0h 0m 23.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0335 - val_loss: 0.0329\n",
      "Epoch 27/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0333 - tot_time: 0h 0m 24.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0337\n",
      "Epoch 28/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 25.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0337 - val_loss: 0.0334\n",
      "Epoch 29/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0333 - tot_time: 0h 0m 26.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0332 - val_loss: 0.0328\n",
      "Epoch 30/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0333 - tot_time: 0h 0m 27.3s\n",
      "\n",
      "Epoch 30: val_loss improved from 0.03288 to 0.03230, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0323\n",
      "Epoch 31/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0331 - tot_time: 0h 0m 28.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0331 - val_loss: 0.0383\n",
      "Epoch 32/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0341 - tot_time: 0h 0m 29.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0341 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0339 - tot_time: 0h 0m 29.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0338 - val_loss: 0.0331\n",
      "Epoch 34/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0339 - tot_time: 0h 0m 30.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0339 - val_loss: 0.0330\n",
      "Epoch 35/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0336 - tot_time: 0h 0m 31.7s\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.03230\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0336 - val_loss: 0.0333\n",
      "Epoch 36/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 32.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0338 - val_loss: 0.0338\n",
      "Epoch 37/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0337 - tot_time: 0h 0m 33.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0326\n",
      "Epoch 38/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0330 - tot_time: 0h 0m 34.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0329 - val_loss: 0.0318\n",
      "Epoch 39/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0324 - tot_time: 0h 0m 35.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0321 - val_loss: 0.0318\n",
      "Epoch 40/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0307 - tot_time: 0h 0m 36.1s\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.03230\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0307 - val_loss: 0.0332\n",
      "Epoch 41/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0280 - tot_time: 0h 0m 37.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0279 - val_loss: 0.0244\n",
      "Epoch 42/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0221 - tot_time: 0h 0m 37.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0221 - val_loss: 0.0188\n",
      "Epoch 43/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0181 - tot_time: 0h 0m 38.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0168\n",
      "Epoch 44/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0167 - tot_time: 0h 0m 39.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0159\n",
      "Epoch 45/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0163 - tot_time: 0h 0m 40.4s\n",
      "\n",
      "Epoch 45: val_loss improved from 0.03230 to 0.01578, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 46/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0160 - tot_time: 0h 0m 41.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 47/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0157 - tot_time: 0h 0m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 48/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0155 - tot_time: 0h 0m 43.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 49/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0154 - tot_time: 0h 0m 44.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 50/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0153 - tot_time: 0h 0m 45.0s\n",
      "\n",
      "Epoch 50: val_loss improved from 0.01578 to 0.01514, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 51/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0151 - tot_time: 0h 0m 45.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 52/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0151 - tot_time: 0h 0m 46.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 53/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0151 - tot_time: 0h 0m 47.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 54/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0152 - tot_time: 0h 0m 48.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 55/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0149 - tot_time: 0h 0m 49.4s\n",
      "\n",
      "Epoch 55: val_loss improved from 0.01514 to 0.01510, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 56/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0148 - tot_time: 0h 0m 50.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 57/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0150 - tot_time: 0h 0m 51.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 58/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0150 - tot_time: 0h 0m 52.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 59/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0147 - tot_time: 0h 0m 52.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 60/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0147 - tot_time: 0h 0m 53.6s\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.01510\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 61/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0147 - tot_time: 0h 0m 54.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 62/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0147 - tot_time: 0h 0m 55.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 63/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0145 - tot_time: 0h 0m 56.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 64/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0147 - tot_time: 0h 0m 57.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0142\n",
      "Epoch 65/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0146 - tot_time: 0h 0m 58.0s\n",
      "\n",
      "Epoch 65: val_loss improved from 0.01510 to 0.01490, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 66/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0145 - tot_time: 0h 0m 59.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0145 - tot_time: 0h 0m 59.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 68/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0144 - tot_time: 0h 1m 0.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 69/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0146 - tot_time: 0h 1m 1.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 70/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0144 - tot_time: 0h 1m 2.4s\n",
      "\n",
      "Epoch 70: val_loss improved from 0.01490 to 0.01384, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 71/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0141 - tot_time: 0h 1m 3.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 72/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0141 - tot_time: 0h 1m 4.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 73/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0139 - tot_time: 0h 1m 4.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 74/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0139 - tot_time: 0h 1m 5.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 75/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0137 - tot_time: 0h 1m 6.3s\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.01384\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 76/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0136 - tot_time: 0h 1m 7.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 77/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0135 - tot_time: 0h 1m 8.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 78/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0133 - tot_time: 0h 1m 9.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 79/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0133 - tot_time: 0h 1m 10.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 80/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0128 - tot_time: 0h 1m 10.7s\n",
      "\n",
      "Epoch 80: val_loss improved from 0.01384 to 0.01294, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 81/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0127 - tot_time: 0h 1m 11.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 82/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0127 - tot_time: 0h 1m 12.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 83/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0127 - tot_time: 0h 1m 13.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 84/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0122 - tot_time: 0h 1m 14.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0125\n",
      "Epoch 85/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0123 - tot_time: 0h 1m 15.3s\n",
      "\n",
      "Epoch 85: val_loss improved from 0.01294 to 0.01257, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 86/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0120 - tot_time: 0h 1m 16.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 87/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0119 - tot_time: 0h 1m 17.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 88/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0119 - tot_time: 0h 1m 18.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 89/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0118 - tot_time: 0h 1m 18.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 90/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0117 - tot_time: 0h 1m 19.7s\n",
      "\n",
      "Epoch 90: val_loss improved from 0.01257 to 0.01202, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 91/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0119 - tot_time: 0h 1m 20.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 92/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0116 - tot_time: 0h 1m 21.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 93/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0117 - tot_time: 0h 1m 22.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 94/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 23.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 95/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 23.7s\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.01202\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0159\n",
      "Epoch 96/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0122 - tot_time: 0h 1m 24.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 97/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 25.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 98/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0117 - tot_time: 0h 1m 26.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 99/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 26.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 100/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 27.8s\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.01202\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0150\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0118 - tot_time: 0h 1m 28.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 102/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0115 - tot_time: 0h 1m 29.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 103/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0114 - tot_time: 0h 1m 30.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 104/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 31.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 105/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0114 - tot_time: 0h 1m 31.9s\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.01202\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 106/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0114 - tot_time: 0h 1m 32.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 107/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 33.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 108/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0114 - tot_time: 0h 1m 34.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 109/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0116 - tot_time: 0h 1m 35.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 110/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 36.1s\n",
      "\n",
      "Epoch 110: val_loss improved from 0.01202 to 0.01170, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 111/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 37.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 112/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 38.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 113/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 38.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 114/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 39.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 115/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 40.2s\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.01170\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 116/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 41.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 117/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0114 - tot_time: 0h 1m 41.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 118/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 42.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 119/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 43.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 120/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0111 - tot_time: 0h 1m 44.5s\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.01170\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 121/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 45.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 122/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 46.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 123/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 47.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 124/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 48.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 125/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 48.8s\n",
      "\n",
      "Epoch 125: val_loss improved from 0.01170 to 0.01125, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 126/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 49.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0155\n",
      "Epoch 127/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0113 - tot_time: 0h 1m 50.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 128/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0111 - tot_time: 0h 1m 51.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 129/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 52.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 130/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0111 - tot_time: 0h 1m 53.0s\n",
      "\n",
      "Epoch 130: val_loss improved from 0.01125 to 0.01118, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 131/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 53.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 132/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0112 - tot_time: 0h 1m 54.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 133/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 55.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 134/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0110 - tot_time: 0h 1m 56.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 135/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0111 - tot_time: 0h 1m 57.2s\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.01118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0109 - tot_time: 0h 1m 58.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 137/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0108 - tot_time: 0h 1m 58.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 138/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 1m 59.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 139/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0111 - tot_time: 0h 2m 0.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 140/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 1.4s\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.01118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 141/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0112 - tot_time: 0h 2m 2.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 142/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 3.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 143/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0109 - tot_time: 0h 2m 4.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 144/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0107 - tot_time: 0h 2m 4.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 145/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 5.7s\n",
      "\n",
      "Epoch 145: val_loss improved from 0.01118 to 0.01083, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 146/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0107 - tot_time: 0h 2m 6.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 147/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 7.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 148/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 8.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 149/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0109 - tot_time: 0h 2m 9.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 150/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0106 - tot_time: 0h 2m 9.6s\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.01083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 151/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0107 - tot_time: 0h 2m 10.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 152/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 11.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 153/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0106 - tot_time: 0h 2m 11.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 154/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0108 - tot_time: 0h 2m 12.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 155/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0105 - tot_time: 0h 2m 13.7s\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.01083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 156/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0106 - tot_time: 0h 2m 14.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 157/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 15.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 158/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0107 - tot_time: 0h 2m 16.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 159/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0105 - tot_time: 0h 2m 16.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 160/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 17.6s\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.01083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 161/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 18.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 162/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 19.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 163/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0105 - tot_time: 0h 2m 20.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 164/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 21.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 165/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0128 - tot_time: 0h 2m 21.9s\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.01083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 166/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 22.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 167/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 23.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 168/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 24.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 169/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 25.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 170/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0107 - tot_time: 0h 2m 26.3s\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.01083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 171/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 27.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0104 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 28.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 173/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 29.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 174/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 29.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 175/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 30.7s\n",
      "\n",
      "Epoch 175: val_loss improved from 0.01083 to 0.01020, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 176/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 31.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 177/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 32.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 178/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 33.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 179/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 34.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 180/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 34.9s\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.01020\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 181/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 35.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 182/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 36.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 183/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 37.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 184/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 38.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 185/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 39.5s\n",
      "\n",
      "Epoch 185: val_loss improved from 0.01020 to 0.01002, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 186/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0103 - tot_time: 0h 2m 40.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 187/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 41.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 188/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 42.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 189/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 43.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 190/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0101 - tot_time: 0h 2m 43.9s\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.01002\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 191/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 44.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 192/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 45.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 193/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 46.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 194/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 47.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 195/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0104 - tot_time: 0h 2m 48.0s\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.01002\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 196/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 49.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 197/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0102 - tot_time: 0h 2m 49.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 198/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0099 - tot_time: 0h 2m 50.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 199/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0097 - tot_time: 0h 2m 51.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 200/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0099 - tot_time: 0h 2m 52.5s\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.01002\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 201/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0098 - tot_time: 0h 2m 53.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 202/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0099 - tot_time: 0h 2m 54.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 203/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0100 - tot_time: 0h 2m 55.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 204/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0099 - tot_time: 0h 2m 55.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 205/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0099 - tot_time: 0h 2m 56.9s\n",
      "\n",
      "Epoch 205: val_loss improved from 0.01002 to 0.00963, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 206/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0098 - tot_time: 0h 2m 57.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 207/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0096 - tot_time: 0h 2m 58.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 208/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0097 - tot_time: 0h 2m 59.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 209/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0096 - tot_time: 0h 3m 0.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 210/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0103 - tot_time: 0h 3m 1.3s\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00963\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 211/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0096 - tot_time: 0h 3m 2.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 212/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0099 - tot_time: 0h 3m 2.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 213/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0098 - tot_time: 0h 3m 3.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 214/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0096 - tot_time: 0h 3m 4.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 215/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0094 - tot_time: 0h 3m 5.5s\n",
      "\n",
      "Epoch 215: val_loss improved from 0.00963 to 0.00953, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 216/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0093 - tot_time: 0h 3m 6.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 217/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0095 - tot_time: 0h 3m 7.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 218/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0094 - tot_time: 0h 3m 8.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 219/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0096 - tot_time: 0h 3m 9.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 220/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0093 - tot_time: 0h 3m 10.0s\n",
      "\n",
      "Epoch 220: val_loss improved from 0.00953 to 0.00949, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 221/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0095 - tot_time: 0h 3m 10.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 222/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0092 - tot_time: 0h 3m 11.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 223/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0095 - tot_time: 0h 3m 12.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 224/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0093 - tot_time: 0h 3m 13.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 225/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0091 - tot_time: 0h 3m 14.6s\n",
      "\n",
      "Epoch 225: val_loss improved from 0.00949 to 0.00909, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 226/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0089 - tot_time: 0h 3m 15.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 227/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0089 - tot_time: 0h 3m 16.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 228/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0086 - tot_time: 0h 3m 17.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 229/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0079 - tot_time: 0h 3m 17.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 230/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0064 - tot_time: 0h 3m 18.9s\n",
      "\n",
      "Epoch 230: val_loss improved from 0.00909 to 0.00657, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 231/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0044 - tot_time: 0h 3m 20.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 232/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0031 - tot_time: 0h 3m 20.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 233/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0025 - tot_time: 0h 3m 21.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 234/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0024 - tot_time: 0h 3m 22.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 235/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0023 - tot_time: 0h 3m 23.1s\n",
      "\n",
      "Epoch 235: val_loss improved from 0.00657 to 0.00235, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 236/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0023 - tot_time: 0h 3m 24.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 237/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0022 - tot_time: 0h 3m 25.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 238/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0022 - tot_time: 0h 3m 25.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 239/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0022 - tot_time: 0h 3m 26.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 240/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0022 - tot_time: 0h 3m 27.7s\n",
      "\n",
      "Epoch 240: val_loss improved from 0.00235 to 0.00227, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 241/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0022 - tot_time: 0h 3m 28.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 242/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 29.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 243/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 30.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 244/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 31.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 245/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 32.3s\n",
      "\n",
      "Epoch 245: val_loss improved from 0.00227 to 0.00208, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 246/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 33.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 247/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0021 - tot_time: 0h 3m 33.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 248/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 34.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 249/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 35.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 250/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 36.7s\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00208\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 251/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 37.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 252/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 38.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 253/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 39.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 254/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0020 - tot_time: 0h 3m 40.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 255/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 40.9s\n",
      "\n",
      "Epoch 255: val_loss improved from 0.00208 to 0.00186, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 256/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 41.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 257/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 42.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 258/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 43.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 259/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 44.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 260/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 45.3s\n",
      "\n",
      "Epoch 260: val_loss improved from 0.00186 to 0.00182, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 261/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 46.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 262/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 46.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 263/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0019 - tot_time: 0h 3m 47.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 264/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 48.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 265/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 49.4s\n",
      "\n",
      "Epoch 265: val_loss improved from 0.00182 to 0.00175, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 266/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 50.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 267/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 51.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 268/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 52.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 269/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0018 - tot_time: 0h 3m 53.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 270/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 53.8s\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.00175\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 271/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 54.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 272/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 273/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 56.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 274/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 57.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 275/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 58.3s\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.00175\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 276/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 3m 59.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 277/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 0.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 278/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 0.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 279/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 1.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 280/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 2.5s\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.00175\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 281/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 3.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 282/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 4.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 283/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 5.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 284/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 5.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 285/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 6.6s\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.00175\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 286/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 7.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 287/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 8.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 288/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 9.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 289/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 10.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 290/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 11.0s\n",
      "\n",
      "Epoch 290: val_loss improved from 0.00175 to 0.00168, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 291/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 11.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 292/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 12.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 293/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 13.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 294/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 14.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 295/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 15.3s\n",
      "\n",
      "Epoch 295: val_loss improved from 0.00168 to 0.00159, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 296/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 16.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 297/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 16.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 298/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 17.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 299/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 18.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 300/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 19.3s\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.00159\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 301/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 20.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 302/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 21.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 303/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 21.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 304/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 22.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 305/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 23.7s\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.00159\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 306/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0017 - tot_time: 0h 4m 24.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 307/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 25.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 26.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 309/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 26.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 310/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 27.8s\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.00159\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 311/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 28.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 312/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 29.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 313/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 30.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 314/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 31.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 315/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 32.0s\n",
      "\n",
      "Epoch 315: val_loss improved from 0.00159 to 0.00155, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 316/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 32.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 317/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 33.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 318/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 34.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 319/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 35.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 320/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 36.3s\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.00155\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 321/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 37.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 322/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 38.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 323/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 38.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 324/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 39.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 325/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 40.4s\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.00155\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 326/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 41.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 327/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 42.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 328/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 43.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 329/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 330/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 44.6s\n",
      "\n",
      "Epoch 330: val_loss improved from 0.00155 to 0.00151, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 331/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 45.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 332/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 46.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 333/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 47.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 334/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 48.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 335/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 49.1s\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.00151\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 336/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 49.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 337/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 50.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 338/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 51.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 339/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 52.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 340/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 53.1s\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.00151\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 341/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 53.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 342/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 54.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 55.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 344/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 56.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 345/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 57.2s\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.00151\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 346/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 58.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 347/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 4m 59.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 348/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0016 - tot_time: 0h 4m 59.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 349/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 0.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 350/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 1.9s\n",
      "\n",
      "Epoch 350: val_loss improved from 0.00151 to 0.00148, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 351/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 2.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 352/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 3.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 353/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 4.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 354/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 5.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 355/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 6.0s\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 356/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 7.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 357/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 7.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 358/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 8.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 359/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 9.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 360/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 10.4s\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 361/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 11.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 362/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 12.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 363/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 12.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 364/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 13.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 365/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 14.7s\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 366/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 15.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 367/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 16.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 368/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 17.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 369/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 17.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 370/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 18.7s\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 371/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 19.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 372/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 20.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 373/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 21.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 374/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 22.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 375/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 22.8s\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 376/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0016 - tot_time: 0h 5m 23.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 377/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 24.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 378/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 25.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 26.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 380/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 27.2s\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 381/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 27.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 382/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 28.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 383/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 29.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 384/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 30.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 385/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 31.3s\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 386/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 32.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 387/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 32.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 388/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 33.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 389/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 34.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 390/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 35.3s\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 391/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 36.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 392/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 37.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 393/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 38.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 394/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 38.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 395/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 39.8s\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 396/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 40.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 397/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 41.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 398/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 42.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 399/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 43.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 400/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 44.0s\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 401/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 44.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 402/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 45.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 403/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 46.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 404/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 47.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 405/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 48.2s\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.00148\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 406/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 49.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 407/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 50.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 408/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 50.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 409/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 51.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 410/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 52.5s\n",
      "\n",
      "Epoch 410: val_loss improved from 0.00148 to 0.00145, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 411/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 53.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 412/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 54.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 413/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 55.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 55.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 415/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 56.8s\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.00145\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 416/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 57.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 417/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 58.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 418/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 5m 59.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 419/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 420/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 0.8s\n",
      "\n",
      "Epoch 420: val_loss improved from 0.00145 to 0.00144, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 421/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 1.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 422/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 2.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 423/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 3.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 424/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 4.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 425/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 5.4s\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 426/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 6.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 427/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 7.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 428/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 429/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 8.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 430/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 9.4s\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 431/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 10.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 432/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 11.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 433/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 12.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 434/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 13.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 435/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 13.6s\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 436/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 14.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 437/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 15.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 438/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 16.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 439/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 17.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 440/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 18.1s\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 441/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 18.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 442/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 19.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 443/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 20.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 444/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 21.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 445/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 22.3s\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 446/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 23.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 447/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 23.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 448/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 24.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 449/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 25.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 26.4s\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.00144\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 451/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 27.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 452/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 28.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 453/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 29.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 454/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 29.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 455/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 30.8s\n",
      "\n",
      "Epoch 455: val_loss improved from 0.00144 to 0.00141, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 456/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 31.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 457/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 32.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 458/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 33.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 459/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 34.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 460/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 34.9s\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.00141\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 461/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 35.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 462/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 36.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 463/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 37.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 464/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 38.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 465/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 39.1s\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.00141\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 466/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 39.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 467/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 40.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 468/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 41.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 469/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 470/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 43.4s\n",
      "\n",
      "Epoch 470: val_loss improved from 0.00141 to 0.00140, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 471/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 44.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 472/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 45.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 473/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 46.1s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 474/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 46.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 475/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 47.7s\n",
      "\n",
      "Epoch 475: val_loss improved from 0.00140 to 0.00139, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 476/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 477/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 49.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 478/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 50.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 479/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 480/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 51.9s\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.00139\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 481/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 52.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 482/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 53.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 483/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 54.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 484/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 55.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 485/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 56.2s\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.00139\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 486/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 56.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 487/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0015 - tot_time: 0h 6m 57.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 488/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 58.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 489/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 6m 59.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 490/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 0.5s\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.00139\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 491/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 1.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 492/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 2.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 493/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 3.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 494/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 4.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 495/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 4.8s\n",
      "\n",
      "Epoch 495: val_loss improved from 0.00139 to 0.00135, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 496/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 5.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 497/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 6.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 498/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 7.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 499/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 8.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 500/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 9.1s\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 501/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 9.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 502/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 10.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 503/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 11.7s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 504/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 12.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 505/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 13.2s\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 506/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 14.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 507/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 14.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 508/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 15.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 509/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 16.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 510/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 17.4s\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 511/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 18.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 512/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 19.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 513/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 19.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 514/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 20.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 515/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 21.8s\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 516/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 22.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 517/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 23.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 518/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 24.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 519/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 24.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 25.7s\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 521/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 26.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 522/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 27.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 523/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 28.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 524/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 29.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 525/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 30.0s\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.00135\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 526/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 30.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 527/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 31.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 528/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 32.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 529/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 33.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 530/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 34.2s\n",
      "\n",
      "Epoch 530: val_loss improved from 0.00135 to 0.00132, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 531/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 35.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 532/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 35.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 533/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 36.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 534/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 37.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 535/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 38.2s\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 536/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 39.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 537/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 40.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 538/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 40.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 539/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 41.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 540/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 42.6s\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 541/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 43.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 542/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 44.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 543/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 45.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 544/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 45.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 545/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 46.7s\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 546/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 47.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 547/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 48.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 548/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 49.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 549/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 50.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 550/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 50.7s\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 551/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 51.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 552/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 553/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 53.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 554/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 54.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 555/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 55.0s\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 556/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 55.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 557/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0015 - tot_time: 0h 7m 56.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 558/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 7m 57.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 559/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 7m 58.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 560/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 7m 59.1s\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 561/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 562/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 0.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 563/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 1.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 564/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 2.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 565/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 3.4s\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.00132\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 566/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 4.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 567/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 5.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 568/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 5.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 569/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 6.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 570/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 7.9s\n",
      "\n",
      "Epoch 570: val_loss improved from 0.00132 to 0.00131, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 571/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 8.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 572/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 9.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 573/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 10.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 574/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 11.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 575/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 11.8s\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.00131\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 576/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 12.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 577/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 13.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 578/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 14.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 579/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 15.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 580/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 15.9s\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.00131\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 581/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 16.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 582/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 17.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 583/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 18.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 584/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 19.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 585/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 20.3s\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.00131\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 586/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 21.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 587/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 21.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 588/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 589/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 23.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 590/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 24.5s\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.00131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 591/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 25.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 592/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 26.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 593/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 26.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 594/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 27.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 595/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 28.6s\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.00131\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 596/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 29.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 597/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 30.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 598/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 31.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 599/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 32.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 600/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 33.0s\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.00131\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 601/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 33.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 602/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 34.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 603/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 35.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 604/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 36.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 605/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 37.0s\n",
      "\n",
      "Epoch 605: val_loss improved from 0.00131 to 0.00127, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 606/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 38.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 607/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 38.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 608/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 39.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 609/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 40.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 610/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 41.3s\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 611/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 42.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 612/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 43.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 613/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 43.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 614/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 44.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 615/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 45.8s\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 616/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 46.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 617/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 47.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 618/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 48.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 619/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 48.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 620/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 49.8s\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 621/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 50.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 622/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 51.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 623/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 52.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 624/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 53.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 625/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 54.1s\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 8m 55.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 627/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 56.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 628/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 56.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 629/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 57.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 630/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 58.7s\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 631/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 8m 59.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 632/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 0.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 633/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 1.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 634/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 1.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 635/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 2.8s\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 636/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0014 - tot_time: 0h 9m 3.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 637/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 4.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 638/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 5.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 639/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 6.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 640/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 6.9s\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 641/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 7.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 642/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 8.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 643/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 9.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 644/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 10.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 645/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 11.3s\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 646/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0014 - tot_time: 0h 9m 11.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 647/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 12.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 648/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 13.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 649/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 14.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 650/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 15.6s\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 651/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 16.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 652/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 17.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 653/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 18.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 654/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 19.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 655/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 19.8s\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 656/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 20.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 657/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 21.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 658/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 22.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 659/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 23.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 660/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 24.2s\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.00127\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 661/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 24.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 662/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 25.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 663/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 26.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 664/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 27.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 665/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 28.4s\n",
      "\n",
      "Epoch 665: val_loss improved from 0.00127 to 0.00126, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 666/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 29.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 667/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 30.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 668/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 31.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 669/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 31.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 670/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 32.5s\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 671/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 33.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 672/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 34.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 673/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 35.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 674/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 36.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 675/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 37.0s\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 676/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 37.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 677/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 38.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 678/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 39.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 679/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 40.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 680/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 41.2s\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 681/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 42.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 682/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 42.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 683/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 43.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 684/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 44.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 685/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 45.4s\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 686/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 46.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 687/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 47.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 688/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 48.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 689/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 48.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 690/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 49.7s\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 691/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 50.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 692/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 51.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 693/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 52.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 694/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 53.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 695/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0014 - tot_time: 0h 9m 54.2s\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 696/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 55.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 697/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 55.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 698/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 56.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 699/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 57.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 700/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 58.5s\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.00126\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 701/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 9m 59.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 702/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 0.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 703/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 1.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 704/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 2.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 705/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 2.7s\n",
      "\n",
      "Epoch 705: val_loss improved from 0.00126 to 0.00124, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 706/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 3.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 707/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 4.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 708/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 5.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 709/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 6.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 710/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 7.1s\n",
      "\n",
      "Epoch 710: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 711/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 7.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 712/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 8.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 713/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 9.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 714/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 10.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 715/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 11.1s\n",
      "\n",
      "Epoch 715: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 716/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 12.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 717/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 12.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 718/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 13.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 719/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 14.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 720/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 15.3s\n",
      "\n",
      "Epoch 720: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 721/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 15.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 722/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 16.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 723/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 17.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 724/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 18.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 725/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 19.4s\n",
      "\n",
      "Epoch 725: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 726/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 20.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 727/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 20.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 728/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 21.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 729/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 22.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 730/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 23.4s\n",
      "\n",
      "Epoch 730: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 731/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 24.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 732/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 25.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 733/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 25.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 734/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 27.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 735/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 27.9s\n",
      "\n",
      "Epoch 735: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 736/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 28.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 737/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 29.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 738/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 30.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 739/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 31.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 740/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 32.2s\n",
      "\n",
      "Epoch 740: val_loss did not improve from 0.00124\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 741/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 33.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 742/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 33.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 743/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 34.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 744/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 35.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 745/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 36.3s\n",
      "\n",
      "Epoch 745: val_loss improved from 0.00124 to 0.00121, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 746/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 37.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 747/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 38.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 748/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 38.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 749/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 40.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 750/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 40.7s\n",
      "\n",
      "Epoch 750: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 751/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 41.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 752/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 42.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 753/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 43.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 754/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 44.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 755/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 45.0s\n",
      "\n",
      "Epoch 755: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 756/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 10m 45.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 757/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 46.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 758/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 47.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 759/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 48.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 760/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 49.2s\n",
      "\n",
      "Epoch 760: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 761/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 50.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 762/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 50.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 763/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 51.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 764/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 765/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 53.4s\n",
      "\n",
      "Epoch 765: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 766/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 54.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 767/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 55.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 768/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 56.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 769/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 10m 57.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 770/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 58.0s\n",
      "\n",
      "Epoch 770: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 771/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 58.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 772/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 10m 59.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 773/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 0.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 774/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 1.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 775/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 2.0s\n",
      "\n",
      "Epoch 775: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 776/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 3.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 777/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 3.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 778/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 4.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 779/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 5.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 780/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 6.3s\n",
      "\n",
      "Epoch 780: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 781/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 7.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 782/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 8.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 783/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 8.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 784/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 9.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 785/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 10.6s\n",
      "\n",
      "Epoch 785: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 786/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 11.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 787/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 12.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 788/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 13.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 789/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 14.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 790/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 14.9s\n",
      "\n",
      "Epoch 790: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 791/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 15.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 792/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 16.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 793/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 17.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 794/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 18.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 795/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 19.1s\n",
      "\n",
      "Epoch 795: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 796/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 20.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 797/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 20.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 798/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 21.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 799/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 22.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 800/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 23.2s\n",
      "\n",
      "Epoch 800: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 801/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 24.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 802/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 24.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 25.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 804/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 26.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 805/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 27.3s\n",
      "\n",
      "Epoch 805: val_loss did not improve from 0.00121\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 806/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 28.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 807/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 29.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 808/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 29.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 809/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 30.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 810/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 31.7s\n",
      "\n",
      "Epoch 810: val_loss improved from 0.00121 to 0.00119, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 811/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 32.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 812/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 33.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 813/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 34.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 814/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 35.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 815/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 36.0s\n",
      "\n",
      "Epoch 815: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 816/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 36.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 817/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 37.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 818/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 38.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 819/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 39.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 820/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 40.2s\n",
      "\n",
      "Epoch 820: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 821/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 41.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 822/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 41.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 823/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 42.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 824/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 43.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 825/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 44.5s\n",
      "\n",
      "Epoch 825: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 826/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 45.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 827/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 46.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 828/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 47.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 829/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 47.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 830/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 48.9s\n",
      "\n",
      "Epoch 830: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 831/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 49.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 832/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 50.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 833/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 51.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 834/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 52.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 835/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 53.1s\n",
      "\n",
      "Epoch 835: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 836/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 54.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 837/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 54.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 55.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 839/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 56.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 840/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 57.3s\n",
      "\n",
      "Epoch 840: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 841/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 58.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 842/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 11m 59.1s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 843/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 11m 59.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 844/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 0.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 845/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 1.6s\n",
      "\n",
      "Epoch 845: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 846/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 2.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 847/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 3.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 848/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 4.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 849/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 4.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 850/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 5.8s\n",
      "\n",
      "Epoch 850: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 851/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 6.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 852/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 7.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 853/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 8.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 854/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 9.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 855/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 10.1s\n",
      "\n",
      "Epoch 855: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 856/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 11.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 857/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 12.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 858/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 12.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 859/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 13.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 860/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 14.6s\n",
      "\n",
      "Epoch 860: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 861/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 15.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 862/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 16.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 863/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 17.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 864/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 17.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 865/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 18.7s\n",
      "\n",
      "Epoch 865: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 866/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 867/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 20.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 868/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 21.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 869/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 22.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 870/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 22.9s\n",
      "\n",
      "Epoch 870: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 871/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 23.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 872/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 24.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 873/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 25.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 26.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 875/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 27.3s\n",
      "\n",
      "Epoch 875: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 876/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 27.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 877/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 28.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 878/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 29.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 879/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 30.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 880/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 31.4s\n",
      "\n",
      "Epoch 880: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 881/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 32.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 882/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 33.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 883/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 33.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 884/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 34.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 885/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 35.5s\n",
      "\n",
      "Epoch 885: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 886/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 36.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 887/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 37.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 888/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 38.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 889/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 38.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 890/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 39.9s\n",
      "\n",
      "Epoch 890: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 891/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 40.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 892/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 41.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 893/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 42.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 894/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 43.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 895/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 44.0s\n",
      "\n",
      "Epoch 895: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 896/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 45.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 897/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 45.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 898/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 46.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 899/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 47.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 900/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 48.3s\n",
      "\n",
      "Epoch 900: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 901/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 49.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 902/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 50.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 903/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 50.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 904/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 51.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 905/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 52.8s\n",
      "\n",
      "Epoch 905: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 906/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 53.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 907/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 54.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 908/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 12m 55.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 909/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 56.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 57.0s\n",
      "\n",
      "Epoch 910: val_loss did not improve from 0.00119\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 911/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 57.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 912/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 58.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 913/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 12m 59.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 914/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 0.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 915/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 1.0s\n",
      "\n",
      "Epoch 915: val_loss improved from 0.00119 to 0.00118, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 916/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 1.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 917/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 3.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 918/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 3.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 919/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 4.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 920/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 5.5s\n",
      "\n",
      "Epoch 920: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 921/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 6.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 922/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 7.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 923/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 924/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 8.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 925/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 9.4s\n",
      "\n",
      "Epoch 925: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 926/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 13m 10.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 927/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 11.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 928/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 11.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 929/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 12.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 930/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 13.5s\n",
      "\n",
      "Epoch 930: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 931/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 14.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 932/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 15.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 933/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 16.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 934/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 17.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 935/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 18.0s\n",
      "\n",
      "Epoch 935: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 936/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 18.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 937/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 19.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 938/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 20.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 939/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 13m 21.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 940/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 22.0s\n",
      "\n",
      "Epoch 940: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 941/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 23.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 942/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 23.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 943/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 24.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 944/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 25.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 945/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 26.2s\n",
      "\n",
      "Epoch 945: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 946/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 26.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 947/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 28.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 948/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 28.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 949/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 29.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 950/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 30.5s\n",
      "\n",
      "Epoch 950: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 951/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 31.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 952/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 32.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 953/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 33.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 954/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 34.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 955/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 34.8s\n",
      "\n",
      "Epoch 955: val_loss did not improve from 0.00118\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 956/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 35.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 957/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 36.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 958/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 37.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 959/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 38.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 960/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 39.0s\n",
      "\n",
      "Epoch 960: val_loss improved from 0.00118 to 0.00117, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 961/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 39.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 962/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 40.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 963/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 41.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 964/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 965/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 43.4s\n",
      "\n",
      "Epoch 965: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 966/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 44.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 967/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 45.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 968/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 46.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 969/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 46.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 970/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 47.4s\n",
      "\n",
      "Epoch 970: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 971/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 48.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 972/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 49.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 973/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 50.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 974/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 51.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 975/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 51.8s\n",
      "\n",
      "Epoch 975: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 976/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 52.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 977/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 53.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 978/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 54.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 979/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 55.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 980/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 56.4s\n",
      "\n",
      "Epoch 980: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 981/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 57.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 982/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 57.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 983/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 58.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 984/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 13m 59.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 985/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 0.5s\n",
      "\n",
      "Epoch 985: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 986/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 1.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 987/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 2.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 988/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 2.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 989/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 3.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 990/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 4.6s\n",
      "\n",
      "Epoch 990: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 991/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 5.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 992/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 6.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 993/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 7.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 994/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 995/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 8.9s\n",
      "\n",
      "Epoch 995: val_loss did not improve from 0.00117\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 996/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 9.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 997/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 10.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 998/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 11.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 999/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 12.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1000/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 13.2s\n",
      "\n",
      "Epoch 1000: val_loss improved from 0.00117 to 0.00116, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1001/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 14.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1002/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 14.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1003/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 15.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1004/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 16.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1005/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 17.5s\n",
      "\n",
      "Epoch 1005: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1006/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 18.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1007/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 19.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1008/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 20.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1009/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 21.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1010/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 22.0s\n",
      "\n",
      "Epoch 1010: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1011/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 22.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1012/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 23.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1013/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 24.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1014/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 25.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1015/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/124 [============================>.] - ETA: 0s - loss: 0.0013 - tot_time: 0h 14m 26.0s\n",
      "\n",
      "Epoch 1015: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1016/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 26.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1017/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 27.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1018/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 28.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1019/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 29.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1020/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 30.1s\n",
      "\n",
      "Epoch 1020: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1021/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 31.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1022/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 32.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1023/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 32.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1024/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 33.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1025/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 34.6s\n",
      "\n",
      "Epoch 1025: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1026/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 35.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1027/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 36.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1028/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 37.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1029/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 37.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1030/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 38.8s\n",
      "\n",
      "Epoch 1030: val_loss did not improve from 0.00116\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1031/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 39.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1032/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 40.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1033/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 41.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1034/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1035/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 43.2s\n",
      "\n",
      "Epoch 1035: val_loss improved from 0.00116 to 0.00115, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1036/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 44.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1037/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 45.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1038/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 45.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1039/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 46.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1040/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 47.5s\n",
      "\n",
      "Epoch 1040: val_loss did not improve from 0.00115\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1041/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 48.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1042/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 49.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1043/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 50.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1044/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 50.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1045/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 51.9s\n",
      "\n",
      "Epoch 1045: val_loss did not improve from 0.00115\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1046/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 52.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1047/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 53.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1048/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 54.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1049/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 55.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1050/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 56.1s\n",
      "\n",
      "Epoch 1050: val_loss improved from 0.00115 to 0.00114, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1051/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 57.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1052/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 57.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1053/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 58.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1054/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 14m 59.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1055/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 0.4s\n",
      "\n",
      "Epoch 1055: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1056/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 1.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1057/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 2.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1058/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 2.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1059/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 3.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1060/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 4.7s\n",
      "\n",
      "Epoch 1060: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1061/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 5.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1062/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 6.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1063/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 7.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1064/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 8.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1065/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 8.7s\n",
      "\n",
      "Epoch 1065: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1066/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 9.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1067/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 10.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1068/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 11.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1069/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 12.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1070/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 13.1s\n",
      "\n",
      "Epoch 1070: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1071/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 13.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1072/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 14.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1073/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 15.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1074/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 16.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1075/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 17.4s\n",
      "\n",
      "Epoch 1075: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1076/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 18.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1077/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 19.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1078/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 19.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1079/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 20.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1080/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 21.5s\n",
      "\n",
      "Epoch 1080: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1081/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 22.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1082/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1083/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 24.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1084/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 25.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1085/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 25.9s\n",
      "\n",
      "Epoch 1085: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1086/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 26.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1087/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 27.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1088/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 28.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1089/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 29.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1090/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 30.1s\n",
      "\n",
      "Epoch 1090: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1091/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 30.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1092/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 31.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1093/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 32.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1094/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 33.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1095/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 34.3s\n",
      "\n",
      "Epoch 1095: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1096/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 35.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1097/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 36.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1098/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 37.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1099/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 38.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1100/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 38.9s\n",
      "\n",
      "Epoch 1100: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1101/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1102/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1103/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 41.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1104/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 42.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1105/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 43.5s\n",
      "\n",
      "Epoch 1105: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1106/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 44.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1107/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 45.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1108/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 45.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1109/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 46.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1110/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 47.5s\n",
      "\n",
      "Epoch 1110: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1111/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 48.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1112/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 49.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1113/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 50.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1114/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 51.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1115/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 51.7s\n",
      "\n",
      "Epoch 1115: val_loss did not improve from 0.00114\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1116/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 52.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1117/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 53.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1118/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 54.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1119/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 55.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1120/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 56.1s\n",
      "\n",
      "Epoch 1120: val_loss did not improve from 0.00114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1121/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 56.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1122/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 57.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1123/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 58.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1124/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 15m 59.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1125/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 0.2s\n",
      "\n",
      "Epoch 1125: val_loss improved from 0.00114 to 0.00113, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1126/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 1.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1127/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 1.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1128/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 2.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1129/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 3.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1130/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 4.3s\n",
      "\n",
      "Epoch 1130: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1131/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 5.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1132/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 6.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1133/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 6.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1134/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 7.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1135/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 8.9s\n",
      "\n",
      "Epoch 1135: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1136/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 9.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1137/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 10.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1138/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 11.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1139/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 12.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1140/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 13.2s\n",
      "\n",
      "Epoch 1140: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1141/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 14.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1142/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 14.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1143/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 15.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1144/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 16.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1145/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 17.4s\n",
      "\n",
      "Epoch 1145: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1146/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 18.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1147/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 19.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1148/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 20.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1149/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 20.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1150/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 21.8s\n",
      "\n",
      "Epoch 1150: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1151/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 22.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1152/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1153/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 24.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1154/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 25.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1155/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 26.0s\n",
      "\n",
      "Epoch 1155: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1156/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 26.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1157/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 27.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1158/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 28.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1159/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 29.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1160/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 30.1s\n",
      "\n",
      "Epoch 1160: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1161/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 31.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1162/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 32.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1163/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 32.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1164/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 33.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1165/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 34.5s\n",
      "\n",
      "Epoch 1165: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1166/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 35.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1167/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 36.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1168/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 37.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1169/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 37.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1170/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 38.8s\n",
      "\n",
      "Epoch 1170: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1171/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 39.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1172/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 40.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1173/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 41.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1174/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 42.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1175/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 42.9s\n",
      "\n",
      "Epoch 1175: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1176/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1177/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 44.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1178/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 45.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1179/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 46.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1180/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 47.4s\n",
      "\n",
      "Epoch 1180: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1181/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 48.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1182/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 49.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1183/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 50.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1184/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 50.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 1185/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 51.6s\n",
      "\n",
      "Epoch 1185: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1186/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 52.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1187/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 53.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1188/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 54.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1189/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 55.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1190/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 55.8s\n",
      "\n",
      "Epoch 1190: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1191/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 56.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1192/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 57.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1193/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 58.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1194/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 16m 59.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1195/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 0.2s\n",
      "\n",
      "Epoch 1195: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1196/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 1.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1197/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 17m 2.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1198/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 2.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1199/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 3.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1200/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 4.6s\n",
      "\n",
      "Epoch 1200: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1201/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 5.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1202/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 6.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1203/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 7.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1204/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 8.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1205/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 9.0s\n",
      "\n",
      "Epoch 1205: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1206/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 10.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1207/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0013 - tot_time: 0h 17m 10.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1208/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 11.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1209/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 12.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1210/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 17m 13.3s\n",
      "\n",
      "Epoch 1210: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1211/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 14.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1212/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 15.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1213/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 15.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1214/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 16.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1215/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 17.8s\n",
      "\n",
      "Epoch 1215: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1216/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 18.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1217/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 19.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1218/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 20.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1219/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 20.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1220/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 21.9s\n",
      "\n",
      "Epoch 1220: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1221/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1222/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 23.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1223/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 24.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1224/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 25.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1225/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 17m 26.0s\n",
      "\n",
      "Epoch 1225: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1226/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 26.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1227/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 28.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1228/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 28.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1229/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 29.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1230/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 30.5s\n",
      "\n",
      "Epoch 1230: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1231/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 31.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1232/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 32.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1233/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 33.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1234/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 33.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1235/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 34.8s\n",
      "\n",
      "Epoch 1235: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1236/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 35.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1237/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 36.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1238/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 37.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1239/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 38.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1240/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 39.0s\n",
      "\n",
      "Epoch 1240: val_loss did not improve from 0.00113\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1241/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 40.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1242/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 40.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1243/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 41.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1244/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 42.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1245/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 43.4s\n",
      "\n",
      "Epoch 1245: val_loss improved from 0.00113 to 0.00112, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1246/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 17m 44.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1247/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 17m 45.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1248/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 46.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1249/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 46.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1250/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 47.8s\n",
      "\n",
      "Epoch 1250: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1251/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 48.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1252/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 49.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1253/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 50.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1254/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 51.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1255/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 52.1s\n",
      "\n",
      "Epoch 1255: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1256/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 53.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1257/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 53.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1258/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 54.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1259/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 55.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1260/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 56.4s\n",
      "\n",
      "Epoch 1260: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1261/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 57.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1262/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 58.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1263/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 59.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1264/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 17m 59.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1265/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 0.9s\n",
      "\n",
      "Epoch 1265: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1266/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 1.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1267/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 2.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1268/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 3.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1269/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 4.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1270/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 5.3s\n",
      "\n",
      "Epoch 1270: val_loss improved from 0.00112 to 0.00112, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1271/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 6.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1272/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 7.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1273/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 8.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1274/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 8.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1275/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 9.5s\n",
      "\n",
      "Epoch 1275: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1276/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 10.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1277/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 11.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1278/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 12.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1279/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 13.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1280/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 14.0s\n",
      "\n",
      "Epoch 1280: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1281/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 14.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1282/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 15.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1283/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 16.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1284/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 17.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1285/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 18.4s\n",
      "\n",
      "Epoch 1285: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1286/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 19.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1287/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 20.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1288/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 21.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1289/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 21.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1290/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 22.8s\n",
      "\n",
      "Epoch 1290: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1291/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 23.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1292/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 24.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1293/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 25.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1294/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 26.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1295/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 26.9s\n",
      "\n",
      "Epoch 1295: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1296/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 27.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1297/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 28.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1298/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 29.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1299/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 30.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1300/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 31.5s\n",
      "\n",
      "Epoch 1300: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1301/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 32.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1302/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 33.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1303/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 34.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1304/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 34.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1305/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 35.8s\n",
      "\n",
      "Epoch 1305: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1306/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 36.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1307/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 37.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1308/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 38.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1309/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 39.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1310/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 39.9s\n",
      "\n",
      "Epoch 1310: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1311/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1312/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 41.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1313/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 42.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1314/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 43.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1315/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 44.3s\n",
      "\n",
      "Epoch 1315: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1316/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 45.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1317/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 46.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1318/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 46.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1319/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 47.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1320/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 48.6s\n",
      "\n",
      "Epoch 1320: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1321/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 49.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1322/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 50.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1323/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 51.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1324/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 52.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1325/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 52.8s\n",
      "\n",
      "Epoch 1325: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1326/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 53.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1327/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 54.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1328/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 55.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1329/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 56.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1330/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 57.3s\n",
      "\n",
      "Epoch 1330: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1331/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 58.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1332/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 18m 59.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1333/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 18m 59.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1334/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 0.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1335/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 1.5s\n",
      "\n",
      "Epoch 1335: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1336/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 2.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1337/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 3.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1338/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 4.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1339/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 5.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1340/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 5.9s\n",
      "\n",
      "Epoch 1340: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1341/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 7.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1342/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 7.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1343/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 8.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1344/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 9.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1345/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 10.2s\n",
      "\n",
      "Epoch 1345: val_loss did not improve from 0.00112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1346/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 11.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1347/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 12.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1348/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 12.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1349/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 13.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1350/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 14.7s\n",
      "\n",
      "Epoch 1350: val_loss improved from 0.00112 to 0.00111, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1351/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 15.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1352/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 16.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1353/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 17.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1354/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 17.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1355/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 18.8s\n",
      "\n",
      "Epoch 1355: val_loss improved from 0.00111 to 0.00110, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1356/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 19.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1357/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 20.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1358/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 21.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1359/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 22.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1360/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 23.1s\n",
      "\n",
      "Epoch 1360: val_loss did not improve from 0.00110\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1361/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 24.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1362/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 25.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1363/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 25.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1364/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 26.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1365/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 27.5s\n",
      "\n",
      "Epoch 1365: val_loss did not improve from 0.00110\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1366/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 28.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1367/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 29.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1368/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 30.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1369/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 30.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1370/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 31.4s\n",
      "\n",
      "Epoch 1370: val_loss did not improve from 0.00110\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1371/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 32.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1372/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 33.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1373/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 34.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1374/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 35.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1375/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 35.6s\n",
      "\n",
      "Epoch 1375: val_loss improved from 0.00110 to 0.00110, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1376/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 36.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1377/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 37.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1378/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 38.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1379/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 39.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1380/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 40.3s\n",
      "\n",
      "Epoch 1380: val_loss did not improve from 0.00110\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1381/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 41.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1382/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 41.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1383/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 42.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1384/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 43.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1385/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 44.5s\n",
      "\n",
      "Epoch 1385: val_loss did not improve from 0.00110\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1386/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 45.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1387/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 46.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1388/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 47.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1389/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 48.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1390/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 48.8s\n",
      "\n",
      "Epoch 1390: val_loss improved from 0.00110 to 0.00109, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1391/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 49.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1392/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 50.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1393/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 51.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1394/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 52.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1395/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 53.2s\n",
      "\n",
      "Epoch 1395: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1396/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 54.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1397/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 55.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1398/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 55.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1399/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 56.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1400/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 19m 57.6s\n",
      "\n",
      "Epoch 1400: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1401/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 58.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1402/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 19m 59.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1403/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 0.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1404/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 1.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1405/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 1.7s\n",
      "\n",
      "Epoch 1405: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1406/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 2.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1407/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 3.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1408/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0013 - tot_time: 0h 20m 4.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1409/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 5.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1410/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 6.0s\n",
      "\n",
      "Epoch 1410: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1411/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 6.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1412/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 7.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1413/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 8.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1414/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 9.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1415/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 10.4s\n",
      "\n",
      "Epoch 1415: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1416/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 11.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1417/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 12.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1418/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 12.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1419/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 13.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1420/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 14.5s\n",
      "\n",
      "Epoch 1420: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1421/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 15.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1422/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 16.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1423/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 17.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1424/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 17.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1425/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 18.7s\n",
      "\n",
      "Epoch 1425: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1426/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 19.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1427/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 20.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1428/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 21.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1429/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 22.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1430/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 23.1s\n",
      "\n",
      "Epoch 1430: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1431/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 23.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1432/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 24.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1433/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 25.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1434/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 26.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1435/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 27.2s\n",
      "\n",
      "Epoch 1435: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1436/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 28.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1437/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 28.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1438/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 29.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1439/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 30.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1440/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 31.4s\n",
      "\n",
      "Epoch 1440: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1441/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 32.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1442/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 33.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1443/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 33.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1444/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 34.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1445/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 35.5s\n",
      "\n",
      "Epoch 1445: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1446/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 36.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1447/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 37.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1448/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 38.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1449/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 38.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1450/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 39.4s\n",
      "\n",
      "Epoch 1450: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1451/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 40.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1452/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 41.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1453/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 41.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1454/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 42.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1455/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 43.7s\n",
      "\n",
      "Epoch 1455: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1456/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 44.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1457/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 45.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1458/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 46.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1459/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 46.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1460/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 47.8s\n",
      "\n",
      "Epoch 1460: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1461/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 48.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1462/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 49.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1463/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 50.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1464/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1465/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 52.0s\n",
      "\n",
      "Epoch 1465: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1466/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 52.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1467/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 53.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1468/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 54.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1469/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 55.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1470/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 56.5s\n",
      "\n",
      "Epoch 1470: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1471/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 57.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1472/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 58.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1473/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 20m 59.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1474/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 20m 59.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1475/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 0.5s\n",
      "\n",
      "Epoch 1475: val_loss did not improve from 0.00109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1476/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 1.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1477/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 2.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1478/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 3.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1479/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 4.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1480/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 4.7s\n",
      "\n",
      "Epoch 1480: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1481/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 5.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1482/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 6.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1483/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 7.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1484/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 8.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1485/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 9.4s\n",
      "\n",
      "Epoch 1485: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1486/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 10.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1487/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 11.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1488/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 12.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1489/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 12.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1490/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 13.7s\n",
      "\n",
      "Epoch 1490: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1491/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 14.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1492/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 15.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1493/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 16.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1494/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 17.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1495/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 17.8s\n",
      "\n",
      "Epoch 1495: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1496/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 18.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1497/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 19.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1498/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 20.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1499/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 21.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1500/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 22.2s\n",
      "\n",
      "Epoch 1500: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1501/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 22.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1502/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 23.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1503/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 24.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1504/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 25.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1505/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 26.1s\n",
      "\n",
      "Epoch 1505: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1506/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 26.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1507/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 27.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1508/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 28.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1509/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 29.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1510/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 30.0s\n",
      "\n",
      "Epoch 1510: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1511/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 30.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1512/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 31.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1513/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 32.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1514/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 33.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1515/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 34.4s\n",
      "\n",
      "Epoch 1515: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1516/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 35.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1517/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 36.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1518/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 37.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1519/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 37.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1520/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 38.6s\n",
      "\n",
      "Epoch 1520: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1521/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 39.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1522/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 40.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1523/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 41.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1524/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 42.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1525/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 42.8s\n",
      "\n",
      "Epoch 1525: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1526/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 43.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1527/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 44.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1528/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 45.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1529/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 46.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1530/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 47.2s\n",
      "\n",
      "Epoch 1530: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1531/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 47.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1532/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 48.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1533/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 49.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1534/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 50.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1535/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 51.4s\n",
      "\n",
      "Epoch 1535: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1536/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 52.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1537/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 53.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1538/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 53.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1539/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 54.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1540/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 55.7s\n",
      "\n",
      "Epoch 1540: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1541/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 21m 56.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1542/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 57.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1543/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 58.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1544/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 21m 59.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1545/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 0.2s\n",
      "\n",
      "Epoch 1545: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1546/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 0.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1547/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 1.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1548/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 2.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1549/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 3.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1550/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 4.2s\n",
      "\n",
      "Epoch 1550: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1551/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 5.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1552/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 5.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1553/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 6.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1554/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 7.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1555/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 8.5s\n",
      "\n",
      "Epoch 1555: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1556/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 9.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1557/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 10.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1558/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 11.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1559/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 12.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1560/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 13.2s\n",
      "\n",
      "Epoch 1560: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1561/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 14.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1562/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 14.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1563/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 15.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1564/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 16.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1565/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 17.5s\n",
      "\n",
      "Epoch 1565: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1566/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 18.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1567/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 19.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1568/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 20.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1569/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 20.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1570/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 21.5s\n",
      "\n",
      "Epoch 1570: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1571/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 22.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1572/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1573/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 24.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1574/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 25.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1575/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 26.0s\n",
      "\n",
      "Epoch 1575: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1576/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 26.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1577/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 27.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1578/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 28.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1579/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 29.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1580/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 30.2s\n",
      "\n",
      "Epoch 1580: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1581/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 31.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1582/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 31.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1583/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 32.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1584/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 33.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1585/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 34.5s\n",
      "\n",
      "Epoch 1585: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1586/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 35.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1587/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 36.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1588/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 37.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1589/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 38.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1590/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 38.9s\n",
      "\n",
      "Epoch 1590: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1591/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1592/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 40.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1593/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 22m 41.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1594/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 42.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1595/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 43.4s\n",
      "\n",
      "Epoch 1595: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1596/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 44.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1597/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 44.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1598/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 45.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1599/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 46.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1600/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 47.2s\n",
      "\n",
      "Epoch 1600: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1601/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1602/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 49.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1603/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 49.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1604/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 50.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1605/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 51.7s\n",
      "\n",
      "Epoch 1605: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1606/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 52.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1607/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 53.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1608/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 54.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1609/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 55.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1610/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 56.2s\n",
      "\n",
      "Epoch 1610: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1611/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 56.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1612/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 57.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1613/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 58.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1614/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 22m 59.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1615/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 0.5s\n",
      "\n",
      "Epoch 1615: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1616/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 1.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1617/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 2.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1618/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 3.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1619/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 4.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1620/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 4.7s\n",
      "\n",
      "Epoch 1620: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1621/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 5.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1622/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 6.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1623/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 7.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1624/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 8.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1625/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 23m 9.2s\n",
      "\n",
      "Epoch 1625: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1626/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 9.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1627/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 10.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1628/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 11.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1629/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 12.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1630/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 13.5s\n",
      "\n",
      "Epoch 1630: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1631/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 14.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1632/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 15.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1633/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 16.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1634/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 16.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1635/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 23m 17.6s\n",
      "\n",
      "Epoch 1635: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1636/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 18.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1637/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 19.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1638/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 20.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1639/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 21.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1640/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 22.1s\n",
      "\n",
      "Epoch 1640: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1641/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 23.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1642/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 24.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1643/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 24.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1644/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 25.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1645/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 23m 26.6s\n",
      "\n",
      "Epoch 1645: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1646/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 27.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1647/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 28.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1648/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 29.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1649/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0012 - tot_time: 0h 23m 29.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1650/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 30.8s\n",
      "\n",
      "Epoch 1650: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1651/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 31.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1652/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 32.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1653/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 33.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1654/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 34.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/2000\n",
      "111/124 [=========================>....] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 35.0s\n",
      "\n",
      "Epoch 1655: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1656/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 35.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1657/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 36.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1658/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 37.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1659/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 38.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1660/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 39.3s\n",
      "\n",
      "Epoch 1660: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1661/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 40.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1662/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 41.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1663/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 42.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1664/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 42.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1665/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 23m 43.6s\n",
      "\n",
      "Epoch 1665: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1666/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 44.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1667/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 45.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1668/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 46.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1669/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 47.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1670/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 47.8s\n",
      "\n",
      "Epoch 1670: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1671/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 48.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1672/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 49.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1673/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 50.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1674/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 51.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1675/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 52.4s\n",
      "\n",
      "Epoch 1675: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1676/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 53.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1677/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 54.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1678/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 55.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1679/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 55.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1680/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 56.7s\n",
      "\n",
      "Epoch 1680: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1681/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 57.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1682/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 58.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1683/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 23m 59.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1684/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 0.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1685/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 0.9s\n",
      "\n",
      "Epoch 1685: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1686/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 1.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1687/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 2.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1688/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 3.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1689/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 4.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1690/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 5.4s\n",
      "\n",
      "Epoch 1690: val_loss did not improve from 0.00109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1691/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 6.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1692/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 24m 7.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1693/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1694/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 8.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1695/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 9.6s\n",
      "\n",
      "Epoch 1695: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1696/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 10.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1697/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 11.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1698/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 12.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1699/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 13.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1700/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 13.8s\n",
      "\n",
      "Epoch 1700: val_loss improved from 0.00109 to 0.00109, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1701/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 14.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1702/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 15.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1703/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 16.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1704/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 17.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1705/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 18.2s\n",
      "\n",
      "Epoch 1705: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1706/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 19.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1707/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 20.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1708/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 20.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1709/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 21.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1710/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 22.5s\n",
      "\n",
      "Epoch 1710: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1711/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 23.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1712/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 24.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1713/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 25.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1714/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 26.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1715/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 26.9s\n",
      "\n",
      "Epoch 1715: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1716/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 28.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1717/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 28.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1718/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 29.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1719/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 30.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1720/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 31.3s\n",
      "\n",
      "Epoch 1720: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1721/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 32.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1722/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 33.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1723/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 33.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1724/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 34.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1725/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 24m 35.7s\n",
      "\n",
      "Epoch 1725: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1726/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 36.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1727/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 37.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1728/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 38.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1729/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 39.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1730/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 40.0s\n",
      "\n",
      "Epoch 1730: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1731/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 41.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1732/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 41.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1733/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 42.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1734/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 43.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1735/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 44.3s\n",
      "\n",
      "Epoch 1735: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1736/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 45.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1737/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 46.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1738/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 46.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1739/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 47.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1740/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 48.7s\n",
      "\n",
      "Epoch 1740: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1741/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 49.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1742/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 50.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1743/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 51.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1744/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 52.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1745/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 53.1s\n",
      "\n",
      "Epoch 1745: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1746/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 53.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1747/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 54.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1748/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1749/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 56.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1750/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 57.5s\n",
      "\n",
      "Epoch 1750: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1751/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 58.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1752/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 24m 59.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1753/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 0.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1754/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 1.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1755/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 1.8s\n",
      "\n",
      "Epoch 1755: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1756/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 2.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1757/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 3.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1758/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 4.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1759/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 5.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1760/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 6.4s\n",
      "\n",
      "Epoch 1760: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1761/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 7.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1762/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 8.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1763/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 9.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1764/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 9.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1765/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 10.8s\n",
      "\n",
      "Epoch 1765: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1766/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 11.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1767/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 12.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1768/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 13.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1769/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 14.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1770/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 15.0s\n",
      "\n",
      "Epoch 1770: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1771/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 16.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1772/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 16.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1773/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 17.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1774/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 18.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1775/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 19.4s\n",
      "\n",
      "Epoch 1775: val_loss did not improve from 0.00109\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1776/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 20.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1777/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 21.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1778/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 21.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1779/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 22.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1780/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 25m 23.9s\n",
      "\n",
      "Epoch 1780: val_loss improved from 0.00109 to 0.00107, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1781/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 24.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1782/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 25.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1783/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 25m 26.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1784/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 27.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1785/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 28.1s\n",
      "\n",
      "Epoch 1785: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1786/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 29.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1787/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 29.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1788/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 30.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1789/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 31.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1790/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 32.2s\n",
      "\n",
      "Epoch 1790: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1791/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 33.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1792/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 34.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1793/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 34.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1794/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 35.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1795/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 36.5s\n",
      "\n",
      "Epoch 1795: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1796/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 37.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1797/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 38.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1798/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 39.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1799/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 39.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1800/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 40.7s\n",
      "\n",
      "Epoch 1800: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1801/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 41.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1802/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 42.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1803/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 43.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1804/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 44.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1805/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 44.9s\n",
      "\n",
      "Epoch 1805: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1806/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 45.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1807/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 46.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1808/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 47.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1809/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 48.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1810/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 49.4s\n",
      "\n",
      "Epoch 1810: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1811/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 50.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1812/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 51.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1813/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 52.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1814/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 52.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1815/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 53.6s\n",
      "\n",
      "Epoch 1815: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1816/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 54.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1817/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 55.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1818/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 56.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1819/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 57.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1820/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 57.9s\n",
      "\n",
      "Epoch 1820: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1821/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 59.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1822/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 25m 59.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1823/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 0.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1824/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 1.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1825/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 2.3s\n",
      "\n",
      "Epoch 1825: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1826/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 3.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1827/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 3.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1828/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 4.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1829/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 5.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1830/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 6.4s\n",
      "\n",
      "Epoch 1830: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1831/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 7.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1832/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 8.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1833/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 8.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1834/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 9.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1835/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 10.4s\n",
      "\n",
      "Epoch 1835: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1836/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 11.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1837/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 12.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1838/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 13.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1839/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0012 - tot_time: 0h 26m 13.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1840/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 14.8s\n",
      "\n",
      "Epoch 1840: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1841/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 15.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1842/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 16.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1843/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 17.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1844/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 18.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1845/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 19.0s\n",
      "\n",
      "Epoch 1845: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1846/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 20.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1847/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 20.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1848/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 21.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1849/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 22.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1850/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 23.3s\n",
      "\n",
      "Epoch 1850: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1851/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 24.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1852/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 25.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1853/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 25.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1854/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 26.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1855/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 27.9s\n",
      "\n",
      "Epoch 1855: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1856/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 28.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1857/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 29.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1858/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 30.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1859/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 31.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1860/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 32.0s\n",
      "\n",
      "Epoch 1860: val_loss did not improve from 0.00107\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1861/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 33.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1862/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 33.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1863/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 34.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1864/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0012 - tot_time: 0h 26m 35.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1865/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 36.2s\n",
      "\n",
      "Epoch 1865: val_loss improved from 0.00107 to 0.00106, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1866/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 37.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1867/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 38.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1868/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 38.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1869/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 39.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1870/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 40.6s\n",
      "\n",
      "Epoch 1870: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1871/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 41.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1872/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 42.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1873/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 43.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1874/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 43.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1875/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 44.9s\n",
      "\n",
      "Epoch 1875: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1876/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 45.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1877/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 46.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1878/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 47.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1879/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 48.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1880/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 49.0s\n",
      "\n",
      "Epoch 1880: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1881/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 49.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1882/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 50.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1883/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 51.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1884/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1885/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 53.4s\n",
      "\n",
      "Epoch 1885: val_loss improved from 0.00106 to 0.00106, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1886/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 54.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1887/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 55.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1888/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 56.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1889/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 56.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1890/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 57.7s\n",
      "\n",
      "Epoch 1890: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1891/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 58.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1892/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 26m 59.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1893/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 0.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1894/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 1.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1895/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 1.9s\n",
      "\n",
      "Epoch 1895: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1896/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 3.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1897/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 3.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1898/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 4.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1899/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 5.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1900/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 6.4s\n",
      "\n",
      "Epoch 1900: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1901/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 7.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1902/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 8.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1903/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 9.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1904/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 9.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1905/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 10.8s\n",
      "\n",
      "Epoch 1905: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1906/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 11.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1907/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 12.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1908/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 13.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1909/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 14.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1910/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 15.0s\n",
      "\n",
      "Epoch 1910: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1911/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 16.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1912/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 16.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1913/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 17.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1914/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 18.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1915/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 19.2s\n",
      "\n",
      "Epoch 1915: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1916/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 20.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1917/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 21.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1918/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 21.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1919/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 22.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1920/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 23.6s\n",
      "\n",
      "Epoch 1920: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1921/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 24.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1922/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 25.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1923/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 26.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1924/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 26.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1925/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 27.7s\n",
      "\n",
      "Epoch 1925: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1926/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 28.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1927/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 29.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1928/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 30.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1929/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 31.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1930/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 31.9s\n",
      "\n",
      "Epoch 1930: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1931/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 32.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1932/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 33.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1933/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 34.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1934/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 35.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1935/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 36.4s\n",
      "\n",
      "Epoch 1935: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1936/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 37.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1937/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 38.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1938/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 38.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1939/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 39.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1940/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 40.5s\n",
      "\n",
      "Epoch 1940: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1941/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 41.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1942/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 42.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1943/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 43.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1944/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1945/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 44.7s\n",
      "\n",
      "Epoch 1945: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1946/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 45.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1947/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 46.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1948/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 47.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1949/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 48.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1950/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 48.9s\n",
      "\n",
      "Epoch 1950: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1951/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 49.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1952/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 50.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1953/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 51.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1954/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 52.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1955/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 53.1s\n",
      "\n",
      "Epoch 1955: val_loss improved from 0.00106 to 0.00106, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1956/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 54.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1957/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 54.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1958/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1959/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 56.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1960/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 57.4s\n",
      "\n",
      "Epoch 1960: val_loss did not improve from 0.00106\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1961/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 58.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1962/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 59.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1963/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 27m 60.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1964/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 0.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1965/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 1.9s\n",
      "\n",
      "Epoch 1965: val_loss improved from 0.00106 to 0.00105, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1966/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 2.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1967/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 3.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1968/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 4.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1969/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 5.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1970/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 6.1s\n",
      "\n",
      "Epoch 1970: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1971/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 7.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1972/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 7.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1973/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 8.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1974/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 9.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1975/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 10.2s\n",
      "\n",
      "Epoch 1975: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1976/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 11.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1977/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 12.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1978/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 12.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1979/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 13.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1980/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 14.8s\n",
      "\n",
      "Epoch 1980: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1981/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 15.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1982/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 16.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1983/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 17.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1984/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 18.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1985/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 19.1s\n",
      "\n",
      "Epoch 1985: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1986/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 20.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1987/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 20.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1988/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 21.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1989/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 22.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1990/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 23.4s\n",
      "\n",
      "Epoch 1990: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1991/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 24.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1992/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 25.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1993/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 25.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1994/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 26.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1995/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0012 - tot_time: 0h 28m 27.7s\n",
      "\n",
      "Epoch 1995: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1996/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 28.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1997/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 29.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1998/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 30.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1999/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 31.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2000/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 32.2s\n",
      "\n",
      "Epoch 2000: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 33.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 33.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 34.9s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 4/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 35.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 5/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 36.6s\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00105 to 0.00105, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 37.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 38.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 39.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 40.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 10/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 41.0s\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00105 to 0.00105, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 11/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 42.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 12/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 43.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 13/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 43.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 44.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 45.6s\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 46.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 47.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 48.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 49.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 50.0s\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 21/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 50.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 51.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 52.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 53.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 54.4s\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 55.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 56.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 28/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 29/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 58.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 58.6s\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 31/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 28m 59.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 32/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 0.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 1.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 34/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 2.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 3.3s\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 36/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 3.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 37/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 4.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 38/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 5.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 39/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 6.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 7.5s\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 41/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 8.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 42/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 9.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 43/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 10.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 11.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 45/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 11.7s\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 12.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 13.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 48/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 14.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 15.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 50/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 16.2s\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 51/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 17.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 52/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 17.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 53/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 18.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 54/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 55/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 20.5s\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 56/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 21.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 57/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 22.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 58/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 23.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 59/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 23.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 60/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 24.7s\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 61/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 25.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 62/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 26.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 63/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 27.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 64/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 28.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 65/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 29.0s\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 66/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 29.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 67/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 30.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 68/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 31.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 69/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 32.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 70/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 33.3s\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 71/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 34.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 72/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 34.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 73/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 36.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 74/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 36.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 75/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 37.6s\n",
      "\n",
      "Epoch 75: val_loss improved from 0.00105 to 0.00105, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 76/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 38.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 77/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 39.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 78/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 40.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 79/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 41.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 41.8s\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 81/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 42.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 43.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 83/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 44.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 84/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 45.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 85/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 46.5s\n",
      "\n",
      "Epoch 85: val_loss improved from 0.00105 to 0.00105, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 86/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 47.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 87/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 48.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 88/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 49.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 89/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 49.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 90/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 50.7s\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 91/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 51.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 92/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 52.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 93/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 53.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 94/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 54.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 95/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 54.9s\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 96/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 56.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 97/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 56.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 98/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 57.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 99/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 58.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 100/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 29m 59.3s\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 101/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 0.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 102/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 0.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 103/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 1.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 104/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 2.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 105/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 3.6s\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00105\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 106/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 4.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 107/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 5.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 108/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 6.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 109/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 7.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 110/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 7.8s\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00105 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 111/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 8.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 112/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 9.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 113/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 10.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 114/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 11.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 12.3s\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 116/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 13.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 117/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 14.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 118/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 14.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 119/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 15.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 120/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 16.8s\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 121/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 17.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 122/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 18.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 123/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 19.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 124/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 20.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 125/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 20.9s\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 126/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 21.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 127/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 22.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 128/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 129/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 24.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 130/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 25.0s\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 131/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 25.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 132/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 26.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 133/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 27.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 134/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 28.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 135/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 29.5s\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 136/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 30.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 137/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 31.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 138/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 31.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 139/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 32.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 140/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 33.4s\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 141/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 34.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 142/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 35.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 143/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 36.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 144/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 37.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 145/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 37.7s\n",
      "\n",
      "Epoch 145: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 146/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 38.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 147/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 39.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 148/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 40.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 149/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 41.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 42.3s\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 151/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 43.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 152/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 43.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 153/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 44.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 154/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 45.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 155/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 46.4s\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 156/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 47.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 157/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 48.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 158/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 49.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 159/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 50.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 160/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 50.6s\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 161/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 51.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 162/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 52.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 163/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 53.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 164/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 53.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 165/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 54.9s\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 166/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 55.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 167/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 56.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 168/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 57.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 169/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 58.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 170/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 30m 59.1s\n",
      "\n",
      "Epoch 170: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 171/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 172/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 0.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 173/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 1.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 174/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 2.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 175/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 3.3s\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 176/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 4.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 177/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 5.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 178/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 5.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 179/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 6.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 180/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 7.7s\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 181/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 8.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 182/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 9.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 183/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 10.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 184/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 10.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 185/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 11.8s\n",
      "\n",
      "Epoch 185: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 186/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 13.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 187/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 13.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 188/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 14.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 189/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 15.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 190/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 16.1s\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 191/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 17.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 192/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 18.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 193/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 18.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 194/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 195/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 20.4s\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 196/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 21.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 197/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 22.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 198/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 23.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 199/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 23.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 200/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 24.6s\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 201/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 25.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 202/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 26.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 203/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 27.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 204/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 28.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 205/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 28.8s\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 206/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 29.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 207/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 30.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 208/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 31.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 209/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 32.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 210/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 33.3s\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 211/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 34.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 212/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 35.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 213/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 36.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 214/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 36.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 215/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 37.6s\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 216/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 38.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 217/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 39.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 218/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 40.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 219/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 41.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 41.6s\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 221/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 42.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 222/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 43.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 223/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 44.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 224/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 44.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 225/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 45.7s\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 226/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 46.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 227/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 47.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 228/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 229/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 49.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 230/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 49.8s\n",
      "\n",
      "Epoch 230: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 231/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 50.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 232/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 51.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 233/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 31m 52.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 234/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 53.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 235/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 54.1s\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 236/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 31m 55.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 237/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 56.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 238/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 56.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 239/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 57.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 240/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 58.6s\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 241/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 31m 59.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 242/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 0.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 243/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 1.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 244/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 2.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 245/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 2.9s\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 246/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 3.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 247/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 4.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 248/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 5.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 249/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 6.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 250/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 7.2s\n",
      "\n",
      "Epoch 250: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 251/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 8.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 252/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 9.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 253/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 9.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 254/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 10.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 11.7s\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 256/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 12.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 257/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 13.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 258/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 14.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 259/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 15.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 260/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 16.0s\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 261/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 16.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 262/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 17.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 263/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 18.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 264/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 19.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 265/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 20.1s\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 266/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 21.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 267/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 21.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 268/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 22.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 269/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 23.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 270/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 24.4s\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 271/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 25.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 272/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 26.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 273/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 27.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 274/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 27.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 275/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 28.5s\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 276/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 29.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 277/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 30.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 278/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 31.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 279/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 32.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 280/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 32.7s\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 281/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 33.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 282/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 34.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 283/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 35.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 284/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 36.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 285/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 37.2s\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 286/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 37.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 287/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 38.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 288/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 289/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 40.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 290/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 41.5s\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.00104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 291/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 292/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 43.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 293/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 44.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 294/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 45.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 295/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 45.7s\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 296/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 46.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 297/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 47.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 298/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 48.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 299/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 49.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 300/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 50.0s\n",
      "\n",
      "Epoch 300: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 301/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 50.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 302/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 51.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 303/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 52.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 304/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 53.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 305/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 54.2s\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 306/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 55.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 307/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 32m 55.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 308/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 56.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 309/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 57.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 310/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 58.1s\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 311/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 59.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 312/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 32m 60.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 313/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 0.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 314/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 1.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 315/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 2.6s\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 316/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 3.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 317/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 4.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 318/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 5.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 319/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 5.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 320/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 6.7s\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 321/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 7.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 322/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 8.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 323/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 9.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 324/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 10.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 325/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 10.7s\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 11.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 327/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 12.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 328/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 13.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 329/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 14.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 330/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 15.0s\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 331/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 15.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 332/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 16.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 333/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 17.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 334/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 18.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 335/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 19.2s\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 336/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 20.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 337/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 20.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 338/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 21.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 339/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 340/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 23.4s\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 341/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 24.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 342/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 25.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 343/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 25.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 344/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 26.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 345/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 27.8s\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 346/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 28.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 347/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 29.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 348/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 30.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 349/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 31.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 350/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 31.8s\n",
      "\n",
      "Epoch 350: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 351/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 32.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 352/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 33.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 353/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 34.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 354/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 35.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 355/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 36.1s\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 356/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 37.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 357/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 38.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 358/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 38.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 359/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 39.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 360/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 40.6s\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 361/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 41.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 362/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 42.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 363/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 43.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 364/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 43.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 365/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 44.7s\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 366/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 45.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 367/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 46.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 368/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 47.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 369/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 370/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 48.8s\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 371/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 49.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 372/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 50.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 373/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 51.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 374/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 52.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 375/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 53.2s\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 376/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 54.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 377/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 55.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 378/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 55.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 379/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 33m 56.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 380/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 57.4s\n",
      "\n",
      "Epoch 380: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 381/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 58.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 382/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 33m 59.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 383/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 384/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 1.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 385/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 1.7s\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 386/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 2.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 387/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 3.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 388/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 4.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 389/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 5.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 390/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 6.1s\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 391/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 6.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 392/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 7.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 393/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 8.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 394/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 9.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 395/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 10.2s\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 396/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 11.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 397/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 11.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 398/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 12.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 399/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 13.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 400/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 14.5s\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 401/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 15.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 402/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 16.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 403/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 17.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 404/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 18.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 405/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 19.1s\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 406/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 19.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 407/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 20.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 408/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 21.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 409/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 22.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 410/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 23.3s\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.00104\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 411/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 24.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 412/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 25.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 413/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 26.1s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 414/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 26.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 415/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 27.8s\n",
      "\n",
      "Epoch 415: val_loss improved from 0.00104 to 0.00104, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 416/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 28.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 417/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 29.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 418/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 30.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 419/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 31.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 420/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 32.2s\n",
      "\n",
      "Epoch 420: val_loss improved from 0.00104 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 421/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 33.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 422/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 34.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 423/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 34.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 424/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 35.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 425/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 36.9s\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 426/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 37.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 427/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 38.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 428/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 39.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 429/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 40.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 430/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 41.2s\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 42.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 432/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 42.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 433/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 43.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 434/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 44.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 435/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 45.6s\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 436/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 46.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 437/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 47.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 438/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 48.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 439/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 49.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 440/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 49.9s\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 441/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 50.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 442/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 51.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 443/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 52.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 444/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 53.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 445/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 54.4s\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 446/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0011 - tot_time: 0h 34m 55.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 447/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 56.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 448/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 449/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 57.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 450/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 58.7s\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 451/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 34m 59.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 452/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 0.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 453/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 1.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 454/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 2.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 455/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 3.0s\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 456/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 4.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 457/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 4.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 458/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 5.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 459/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 6.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 460/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 7.6s\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 461/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 8.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 462/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 9.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 463/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 10.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 464/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 11.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 465/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 12.1s\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 466/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 12.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 13.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 468/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 14.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 469/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 15.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 470/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 16.4s\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 471/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 17.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 472/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 18.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 473/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 19.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 474/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 20.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 475/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 20.9s\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 476/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 21.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 477/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 478/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 23.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 479/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 24.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 480/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 25.4s\n",
      "\n",
      "Epoch 480: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 481/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 26.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 482/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 27.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 483/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 28.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 484/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 28.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 485/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 29.8s\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 486/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 30.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 487/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 31.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 488/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 32.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 489/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 33.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 490/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 34.2s\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 491/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 35.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 492/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 35.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 493/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 36.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 494/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 37.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 495/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 38.5s\n",
      "\n",
      "Epoch 495: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 496/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 39.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 497/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 40.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 498/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 41.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 499/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 42.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 500/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 43.1s\n",
      "\n",
      "Epoch 500: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 501/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 43.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 502/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 44.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 503/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 45.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 504/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 46.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 505/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 47.3s\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 506/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 507/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 48.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 508/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 49.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 509/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 50.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 510/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 51.3s\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 511/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 52.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 512/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 53.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 513/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 54.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 514/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 55.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 515/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 55.9s\n",
      "\n",
      "Epoch 515: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 516/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 56.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 517/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 57.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 518/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 58.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 519/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 35m 59.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 520/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 0.6s\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 521/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 1.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 522/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 2.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 523/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 3.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 524/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 3.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 525/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 4.9s\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 526/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 5.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 527/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 6.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 528/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 7.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 529/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 8.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 530/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 9.1s\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 531/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 10.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 532/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 11.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 533/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 11.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 534/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 12.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 535/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 13.7s\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 536/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 14.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 537/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 15.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 538/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 16.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 539/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 17.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 540/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 18.0s\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 541/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 18.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 542/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 19.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 543/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 20.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 544/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 21.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 545/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 22.3s\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 546/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 23.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 547/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 24.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 548/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 25.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 549/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 26.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 550/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 26.8s\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 551/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 27.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 552/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 28.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 553/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 29.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 554/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 30.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 555/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 31.4s\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 556/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 32.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 557/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 33.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 558/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 34.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 559/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 34.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 560/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 35.6s\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 561/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 36.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 562/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 37.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 563/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 38.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 564/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 38.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 565/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 39.6s\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 566/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 40.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 567/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 41.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 568/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 42.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 569/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 43.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 570/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 44.4s\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 571/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 45.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 46.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 573/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 46.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 574/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 47.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 575/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 48.5s\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 576/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 49.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 577/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 50.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 578/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 579/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 52.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 580/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 52.9s\n",
      "\n",
      "Epoch 580: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 581/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 53.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 582/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 54.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 583/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 55.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 584/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 56.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 585/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 57.3s\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 586/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 58.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 587/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 59.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 588/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 36m 60.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 589/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 0.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 590/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 1.9s\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 591/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 2.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 592/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 3.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 593/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 4.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 594/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 5.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 595/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 6.2s\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 596/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 7.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 597/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 8.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 598/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 9.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 599/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 9.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 600/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 10.5s\n",
      "\n",
      "Epoch 600: val_loss improved from 0.00103 to 0.00103, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 601/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 11.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 602/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 12.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 603/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 13.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 604/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 14.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 605/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 15.0s\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 606/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 15.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 16.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 608/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 17.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 609/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 18.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 610/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 19.5s\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 611/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 20.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 612/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 21.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 613/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 22.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 614/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 22.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 615/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 23.8s\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 616/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 24.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 617/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 25.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 618/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 26.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 619/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 27.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 620/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 28.0s\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 621/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 28.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 622/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 29.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 623/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 30.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 624/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 31.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 625/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 32.6s\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 626/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 33.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 627/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 34.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 628/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 35.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 629/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 35.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 630/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 36.8s\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 631/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 37.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 632/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 38.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 633/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 39.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 634/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 40.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 635/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 41.3s\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 636/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 42.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 637/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 43.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 638/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 43.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 639/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 44.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 640/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 45.7s\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 641/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 46.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 642/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 47.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 48.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 644/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 49.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 645/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 50.1s\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 646/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 50.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 647/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 51.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 648/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 649/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 53.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 650/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 54.3s\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 651/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 55.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 652/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 56.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 653/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 56.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 654/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 57.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 655/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 58.5s\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 656/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 37m 59.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 657/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 0.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 658/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 1.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 659/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 2.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 660/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 2.9s\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 661/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 3.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 662/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 4.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 663/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 5.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 664/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 6.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 665/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 7.3s\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 666/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 8.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 667/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 8.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 668/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 9.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 669/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 10.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 670/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 11.4s\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 671/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 12.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 672/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 13.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 673/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 13.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 674/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 14.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 675/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 15.9s\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 676/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 16.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 677/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 17.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 678/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 18.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 679/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 19.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 680/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 20.3s\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.00103\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 681/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 21.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 682/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 22.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 683/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 23.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 684/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 23.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 685/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 24.7s\n",
      "\n",
      "Epoch 685: val_loss improved from 0.00103 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 686/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 25.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 687/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 26.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 688/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 27.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 689/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 28.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 690/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 29.1s\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 691/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 30.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 692/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 31.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 693/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 31.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 694/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 32.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 695/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 33.7s\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 696/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 34.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 697/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 35.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 698/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 36.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 699/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 37.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 700/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 38.3s\n",
      "\n",
      "Epoch 700: val_loss improved from 0.00102 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 701/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 39.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 702/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 40.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 703/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 41.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 704/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 41.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 705/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 42.6s\n",
      "\n",
      "Epoch 705: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 706/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 43.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 707/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 44.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 708/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 45.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 709/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 46.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 710/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 47.0s\n",
      "\n",
      "Epoch 710: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 711/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 47.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 712/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 48.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 713/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 49.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 50.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 715/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 51.5s\n",
      "\n",
      "Epoch 715: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 716/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 52.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 717/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 53.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 718/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 54.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 719/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 55.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 720/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 56.0s\n",
      "\n",
      "Epoch 720: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 721/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 56.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 722/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 57.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 723/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 58.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 724/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 38m 59.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 725/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 0.2s\n",
      "\n",
      "Epoch 725: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 726/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 1.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 727/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 2.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 728/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 2.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 729/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 3.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 730/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 4.6s\n",
      "\n",
      "Epoch 730: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 731/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 5.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 732/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 6.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 733/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 7.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 734/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 8.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 735/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 9.3s\n",
      "\n",
      "Epoch 735: val_loss improved from 0.00102 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 736/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 10.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 737/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 11.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 738/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 12.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 739/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 12.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 740/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 13.8s\n",
      "\n",
      "Epoch 740: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 741/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 14.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 742/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 15.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 743/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 16.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 744/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 17.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 745/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 18.2s\n",
      "\n",
      "Epoch 745: val_loss improved from 0.00102 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 746/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 19.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 747/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 19.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 748/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 20.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 21.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 750/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 22.5s\n",
      "\n",
      "Epoch 750: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 751/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 23.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 752/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 24.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 753/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 25.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 754/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 26.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 755/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 27.2s\n",
      "\n",
      "Epoch 755: val_loss improved from 0.00102 to 0.00102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 756/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 28.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 757/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 29.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 758/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 29.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 759/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 30.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 760/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 31.6s\n",
      "\n",
      "Epoch 760: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 761/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 32.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 762/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 33.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 763/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 34.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 764/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 35.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 765/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 36.2s\n",
      "\n",
      "Epoch 765: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 766/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 37.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 767/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 37.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 768/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 38.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 769/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 39.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 770/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 40.4s\n",
      "\n",
      "Epoch 770: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 771/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 41.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 772/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 42.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 773/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 43.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 774/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 775/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 45.0s\n",
      "\n",
      "Epoch 775: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 776/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 45.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 777/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 46.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 778/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 47.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 779/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 48.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 780/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 49.4s\n",
      "\n",
      "Epoch 780: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 781/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 50.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 782/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 51.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 783/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 51.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 784/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 52.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 785/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 53.6s\n",
      "\n",
      "Epoch 785: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 786/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 54.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 787/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 55.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 788/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 56.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 789/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 57.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 790/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 58.3s\n",
      "\n",
      "Epoch 790: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 791/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 39m 59.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 792/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 0.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 793/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 1.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 794/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 1.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 795/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 3.0s\n",
      "\n",
      "Epoch 795: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 796/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 3.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 797/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 4.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 798/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 5.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 799/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 6.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 800/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 7.5s\n",
      "\n",
      "Epoch 800: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 801/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 8.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 802/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 9.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 803/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 10.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 804/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 11.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 805/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 11.8s\n",
      "\n",
      "Epoch 805: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 806/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 12.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 807/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 13.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 808/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 14.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 809/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 15.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 810/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 16.2s\n",
      "\n",
      "Epoch 810: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 811/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 17.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 812/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 18.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 813/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 18.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 814/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 19.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 815/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 20.9s\n",
      "\n",
      "Epoch 815: val_loss did not improve from 0.00102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 816/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 21.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 817/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 22.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 818/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 23.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 819/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 24.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 25.4s\n",
      "\n",
      "Epoch 820: val_loss improved from 0.00102 to 0.00101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 821/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 26.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 822/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 27.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 823/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 28.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 824/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 28.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 825/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 29.9s\n",
      "\n",
      "Epoch 825: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 826/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 30.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 827/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 31.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 828/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 32.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 829/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 33.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 830/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 34.3s\n",
      "\n",
      "Epoch 830: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 831/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 35.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 832/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 36.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 833/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 36.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 834/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 38.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 835/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 38.8s\n",
      "\n",
      "Epoch 835: val_loss improved from 0.00101 to 0.00101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 836/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 837/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 40.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 838/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 41.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 839/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 42.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 840/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 43.4s\n",
      "\n",
      "Epoch 840: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 841/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 44.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 842/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 45.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 843/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 46.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 844/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 46.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 845/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 47.7s\n",
      "\n",
      "Epoch 845: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 846/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 847/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 49.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 848/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 50.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 849/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 850/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 51.9s\n",
      "\n",
      "Epoch 850: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 851/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 52.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 852/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 53.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 853/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 54.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 854/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 55.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 56.4s\n",
      "\n",
      "Epoch 855: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 856/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 57.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 857/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 58.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 858/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 59.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 859/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 40m 59.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 860/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 0.8s\n",
      "\n",
      "Epoch 860: val_loss improved from 0.00101 to 0.00101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 861/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 1.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 862/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 2.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 863/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 3.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 864/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 4.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 865/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 5.1s\n",
      "\n",
      "Epoch 865: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 866/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 6.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 867/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 6.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 868/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 869/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 8.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 870/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 9.6s\n",
      "\n",
      "Epoch 870: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 871/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 10.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 872/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 11.7s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 873/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 12.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 874/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 13.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 875/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 14.3s\n",
      "\n",
      "Epoch 875: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 876/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 14.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 877/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 15.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 878/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 16.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 879/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 17.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 880/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 18.6s\n",
      "\n",
      "Epoch 880: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 881/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 19.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 882/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 20.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 883/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 21.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 884/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 22.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 885/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 23.1s\n",
      "\n",
      "Epoch 885: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 886/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 24.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 887/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 24.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 888/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 25.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 889/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 26.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 890/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 27.4s\n",
      "\n",
      "Epoch 890: val_loss improved from 0.00101 to 0.00101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 891/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 28.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 892/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 29.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 893/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 29.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 894/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 30.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 895/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 31.9s\n",
      "\n",
      "Epoch 895: val_loss improved from 0.00101 to 0.00101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 896/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 32.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 897/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 33.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 898/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 34.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 899/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 35.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 900/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 36.3s\n",
      "\n",
      "Epoch 900: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 901/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 37.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 902/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 37.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 903/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 38.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 904/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 39.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 905/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 40.5s\n",
      "\n",
      "Epoch 905: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 906/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 41.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 907/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 908/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 43.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 909/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 44.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 910/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 45.0s\n",
      "\n",
      "Epoch 910: val_loss did not improve from 0.00101\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 911/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 45.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 912/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 46.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 913/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 47.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 914/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 48.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 915/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 49.5s\n",
      "\n",
      "Epoch 915: val_loss improved from 0.00101 to 0.00100, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 916/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 50.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 917/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 51.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 918/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 52.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 919/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010   - tot_time: 0h 41m 52.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 920/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 53.7s\n",
      "\n",
      "Epoch 920: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 921/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 54.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 922/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 55.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 923/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 56.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 924/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 57.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 925/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 58.0s\n",
      "\n",
      "Epoch 925: val_loss improved from 0.00100 to 0.00100, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 926/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 41m 59.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 927/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 0.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 928/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 0.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 929/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 1.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 930/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 2.7s\n",
      "\n",
      "Epoch 930: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 931/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 3.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 932/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 4.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9880e-04\n",
      "Epoch 933/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 5.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 934/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 6.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 935/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 7.0s\n",
      "\n",
      "Epoch 935: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 936/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 937/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 8.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 938/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 9.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 939/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 10.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 940/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 11.2s\n",
      "\n",
      "Epoch 940: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 941/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 12.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 942/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 13.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 943/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 13.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 944/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 14.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 945/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 15.7s\n",
      "\n",
      "Epoch 945: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 946/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 16.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 947/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 42m 17.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 948/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 18.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 949/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 19.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 950/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 20.3s\n",
      "\n",
      "Epoch 950: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 951/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 21.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 952/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 21.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 953/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 22.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 954/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 23.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 955/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 24.6s\n",
      "\n",
      "Epoch 955: val_loss improved from 0.00100 to 0.00100, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 9.9722e-04\n",
      "Epoch 956/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010  - tot_time: 0h 42m 25.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 957/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 26.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9917e-04\n",
      "Epoch 958/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 27.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 28.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 960/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 29.0s\n",
      "\n",
      "Epoch 960: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 961/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 29.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 962/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 30.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9846e-04\n",
      "Epoch 963/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 31.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 964/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 32.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9896e-04\n",
      "Epoch 965/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 33.5s\n",
      "\n",
      "Epoch 965: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 966/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 34.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9958e-04\n",
      "Epoch 967/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 42m 35.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 968/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 36.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 969/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010     - tot_time: 0h 42m 37.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 970/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 37.9s\n",
      "\n",
      "Epoch 970: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 971/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 38.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 972/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 39.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9762e-04\n",
      "Epoch 973/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 40.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 974/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 41.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9753e-04\n",
      "Epoch 975/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 42.1s\n",
      "\n",
      "Epoch 975: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 976/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 43.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 977/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 43.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9480e-04\n",
      "Epoch 978/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 44.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9899e-04\n",
      "Epoch 979/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 45.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9547e-04\n",
      "Epoch 980/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 46.5s\n",
      "\n",
      "Epoch 980: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 981/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 47.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 982/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010  - tot_time: 0h 42m 48.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 983/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 49.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 984/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010    - tot_time: 0h 42m 50.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9815e-04\n",
      "Epoch 985/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 51.1s\n",
      "\n",
      "Epoch 985: val_loss did not improve from 0.00100\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 986/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 51.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 987/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 52.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 988/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 53.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9848e-04\n",
      "Epoch 989/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 42m 54.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9464e-04\n",
      "Epoch 990/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 55.5s\n",
      "\n",
      "Epoch 990: val_loss improved from 0.00100 to 0.00099, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 9.9129e-04\n",
      "Epoch 991/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 42m 56.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 992/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 57.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9344e-04\n",
      "Epoch 993/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010   - tot_time: 0h 42m 58.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9488e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 59.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9938e-04\n",
      "Epoch 995/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010 - tot_time: 0h 42m 60.0s\n",
      "\n",
      "Epoch 995: val_loss did not improve from 0.00099\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9685e-04\n",
      "Epoch 996/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 43m 1.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9381e-04\n",
      "Epoch 997/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.0010  - tot_time: 0h 43m 1.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 998/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 43m 2.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9079e-04\n",
      "Epoch 999/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010     - tot_time: 0h 43m 3.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1000/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.9979e-04 - tot_time: 0h 43m 4.4s\n",
      "\n",
      "Epoch 1000: val_loss improved from 0.00099 to 0.00099, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 9.9055e-04\n",
      "Epoch 1001/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9983e-04 - tot_time: 0h 43m 5.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9983e-04 - val_loss: 0.0010\n",
      "Epoch 1002/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 43m 6.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.8786e-04\n",
      "Epoch 1003/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9982e-04 - tot_time: 0h 43m 7.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1004/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 43m 8.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9744e-04\n",
      "Epoch 1005/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.9932e-04 - tot_time: 0h 43m 9.1s\n",
      "\n",
      "Epoch 1005: val_loss did not improve from 0.00099\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9499e-04\n",
      "Epoch 1006/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010     - tot_time: 0h 43m 9.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1007/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010     - tot_time: 0h 43m 10.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9337e-04\n",
      "Epoch 1008/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9927e-04 - tot_time: 0h 43m 11.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9918e-04 - val_loss: 9.9930e-04\n",
      "Epoch 1009/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 43m 12.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1010/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010 - tot_time: 0h 43m 13.6s\n",
      "\n",
      "Epoch 1010: val_loss did not improve from 0.00099\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 9.9242e-04\n",
      "Epoch 1011/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 0.0010     - tot_time: 0h 43m 14.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9989e-04 - val_loss: 9.9205e-04\n",
      "Epoch 1012/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0010 - tot_time: 0h 43m 15.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.9577e-04\n",
      "Epoch 1013/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9925e-04 - tot_time: 0h 43m 16.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9942e-04 - val_loss: 9.9606e-04\n",
      "Epoch 1014/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0010    - tot_time: 0h 43m 17.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1015/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0010   - tot_time: 0h 43m 17.9s\n",
      "\n",
      "Epoch 1015: val_loss did not improve from 0.00099\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 9.9098e-04\n",
      "Epoch 1016/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.9728e-04 - tot_time: 0h 43m 18.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9628e-04 - val_loss: 9.8618e-04\n",
      "Epoch 1017/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9790e-04 - tot_time: 0h 43m 19.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9790e-04 - val_loss: 9.9546e-04\n",
      "Epoch 1018/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.9603e-04 - tot_time: 0h 43m 20.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9653e-04 - val_loss: 9.9614e-04\n",
      "Epoch 1019/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9925e-04 - tot_time: 0h 43m 21.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9911e-04 - val_loss: 9.9346e-04\n",
      "Epoch 1020/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.9567e-04 - tot_time: 0h 43m 22.4s\n",
      "\n",
      "Epoch 1020: val_loss improved from 0.00099 to 0.00099, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9624e-04 - val_loss: 9.8772e-04\n",
      "Epoch 1021/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.0010   - tot_time: 0h 43m 23.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9822e-04 - val_loss: 9.8982e-04\n",
      "Epoch 1022/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.9728e-04 - tot_time: 0h 43m 24.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9618e-04 - val_loss: 9.8633e-04\n",
      "Epoch 1023/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.9969e-04 - tot_time: 0h 43m 25.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9644e-04 - val_loss: 9.8952e-04\n",
      "Epoch 1024/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9808e-04 - tot_time: 0h 43m 26.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9723e-04 - val_loss: 9.8914e-04\n",
      "Epoch 1025/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 9.9642e-04 - tot_time: 0h 43m 27.0s\n",
      "\n",
      "Epoch 1025: val_loss did not improve from 0.00099\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9661e-04 - val_loss: 9.9984e-04\n",
      "Epoch 1026/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9646e-04 - tot_time: 0h 43m 27.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9633e-04 - val_loss: 9.8410e-04\n",
      "Epoch 1027/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 9.9562e-04 - tot_time: 0h 43m 28.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9682e-04 - val_loss: 9.8992e-04\n",
      "Epoch 1028/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 9.9871e-04 - tot_time: 0h 43m 29.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9767e-04 - val_loss: 9.9292e-04\n",
      "Epoch 1029/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9612e-04 - tot_time: 0h 43m 30.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9612e-04 - val_loss: 9.8941e-04\n",
      "Epoch 1030/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9491e-04 - tot_time: 0h 43m 31.6s\n",
      "\n",
      "Epoch 1030: val_loss improved from 0.00099 to 0.00098, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.9499e-04 - val_loss: 9.8376e-04\n",
      "Epoch 1031/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.9302e-04 - tot_time: 0h 43m 32.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.9476e-04 - val_loss: 9.8819e-04\n",
      "Epoch 1032/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9253e-04 - tot_time: 0h 43m 33.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9295e-04 - val_loss: 0.0010\n",
      "Epoch 1033/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.9294e-04 - tot_time: 0h 43m 34.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9776e-04 - val_loss: 9.8991e-04\n",
      "Epoch 1034/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.9327e-04 - tot_time: 0h 43m 35.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.9540e-04 - val_loss: 9.8613e-04\n",
      "Epoch 1035/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.9426e-04 - tot_time: 0h 43m 36.0s\n",
      "\n",
      "Epoch 1035: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9236e-04 - val_loss: 9.8572e-04\n",
      "Epoch 1036/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9303e-04 - tot_time: 0h 43m 37.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9303e-04 - val_loss: 9.8598e-04\n",
      "Epoch 1037/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9544e-04 - tot_time: 0h 43m 37.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9536e-04 - val_loss: 9.9797e-04\n",
      "Epoch 1038/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.9362e-04 - tot_time: 0h 43m 38.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.9527e-04 - val_loss: 0.0010\n",
      "Epoch 1039/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9924e-04 - tot_time: 0h 43m 39.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9783e-04 - val_loss: 9.8585e-04\n",
      "Epoch 1040/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.9386e-04 - tot_time: 0h 43m 40.5s\n",
      "\n",
      "Epoch 1040: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9310e-04 - val_loss: 9.9037e-04\n",
      "Epoch 1041/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.9175e-04 - tot_time: 0h 43m 41.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.9381e-04 - val_loss: 9.8202e-04\n",
      "Epoch 1042/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9356e-04 - tot_time: 0h 43m 42.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9356e-04 - val_loss: 9.8686e-04\n",
      "Epoch 1043/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.9212e-04 - tot_time: 0h 43m 43.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9212e-04 - val_loss: 9.8961e-04\n",
      "Epoch 1044/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.8978e-04 - tot_time: 0h 43m 44.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9024e-04 - val_loss: 0.0010\n",
      "Epoch 1045/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8697e-04 - tot_time: 0h 43m 45.1s\n",
      "\n",
      "Epoch 1045: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.9125e-04 - val_loss: 0.0010\n",
      "Epoch 1046/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.8755e-04 - tot_time: 0h 43m 46.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9095e-04 - val_loss: 9.8524e-04\n",
      "Epoch 1047/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.8842e-04 - tot_time: 0h 43m 47.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8959e-04 - val_loss: 9.8423e-04\n",
      "Epoch 1048/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9035e-04 - tot_time: 0h 43m 47.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.9112e-04 - val_loss: 9.8527e-04\n",
      "Epoch 1049/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.9396e-04 - tot_time: 0h 43m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9245e-04 - val_loss: 9.9007e-04\n",
      "Epoch 1050/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8726e-04 - tot_time: 0h 43m 49.7s\n",
      "\n",
      "Epoch 1050: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8911e-04 - val_loss: 9.9329e-04\n",
      "Epoch 1051/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8763e-04 - tot_time: 0h 43m 50.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8908e-04 - val_loss: 9.8773e-04\n",
      "Epoch 1052/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8725e-04 - tot_time: 0h 43m 51.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.9079e-04 - val_loss: 9.7855e-04\n",
      "Epoch 1053/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9027e-04 - tot_time: 0h 43m 52.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8963e-04 - val_loss: 9.9577e-04\n",
      "Epoch 1054/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8870e-04 - tot_time: 0h 43m 53.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8870e-04 - val_loss: 0.0010\n",
      "Epoch 1055/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.9860e-04 - tot_time: 0h 43m 54.2s\n",
      "\n",
      "Epoch 1055: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.9957e-04 - val_loss: 0.0010\n",
      "Epoch 1056/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8854e-04 - tot_time: 0h 43m 55.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8859e-04 - val_loss: 9.8388e-04\n",
      "Epoch 1057/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8793e-04 - tot_time: 0h 43m 55.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8793e-04 - val_loss: 9.8807e-04\n",
      "Epoch 1058/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8896e-04 - tot_time: 0h 43m 56.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8829e-04 - val_loss: 9.7943e-04\n",
      "Epoch 1059/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8820e-04 - tot_time: 0h 43m 57.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8710e-04 - val_loss: 9.8032e-04\n",
      "Epoch 1060/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8766e-04 - tot_time: 0h 43m 58.3s\n",
      "\n",
      "Epoch 1060: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8776e-04 - val_loss: 9.9116e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1061/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8999e-04 - tot_time: 0h 43m 59.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8984e-04 - val_loss: 9.8004e-04\n",
      "Epoch 1062/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8563e-04 - tot_time: 0h 44m 0.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8570e-04 - val_loss: 0.0010\n",
      "Epoch 1063/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.9162e-04 - tot_time: 0h 44m 1.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8732e-04 - val_loss: 0.0010\n",
      "Epoch 1064/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8630e-04 - tot_time: 0h 44m 2.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8620e-04 - val_loss: 9.7945e-04\n",
      "Epoch 1065/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.8652e-04 - tot_time: 0h 44m 2.7s\n",
      "\n",
      "Epoch 1065: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8807e-04 - val_loss: 9.9073e-04\n",
      "Epoch 1066/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.8907e-04 - tot_time: 0h 44m 3.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8984e-04 - val_loss: 9.8760e-04\n",
      "Epoch 1067/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8893e-04 - tot_time: 0h 44m 4.7s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.8665e-04 - val_loss: 9.7541e-04\n",
      "Epoch 1068/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.8278e-04 - tot_time: 0h 44m 5.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8403e-04 - val_loss: 9.9855e-04\n",
      "Epoch 1069/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8797e-04 - tot_time: 0h 44m 6.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8752e-04 - val_loss: 9.7493e-04\n",
      "Epoch 1070/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8554e-04 - tot_time: 0h 44m 7.4s\n",
      "\n",
      "Epoch 1070: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8426e-04 - val_loss: 9.8902e-04\n",
      "Epoch 1071/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8380e-04 - tot_time: 0h 44m 8.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8388e-04 - val_loss: 9.7474e-04\n",
      "Epoch 1072/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8574e-04 - tot_time: 0h 44m 9.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8386e-04 - val_loss: 9.8510e-04\n",
      "Epoch 1073/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8552e-04 - tot_time: 0h 44m 10.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8510e-04 - val_loss: 9.8831e-04\n",
      "Epoch 1074/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8251e-04 - tot_time: 0h 44m 10.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8274e-04 - val_loss: 9.8477e-04\n",
      "Epoch 1075/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8480e-04 - tot_time: 0h 44m 11.9s\n",
      "\n",
      "Epoch 1075: val_loss improved from 0.00098 to 0.00098, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.8365e-04 - val_loss: 9.8230e-04\n",
      "Epoch 1076/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.8059e-04 - tot_time: 0h 44m 12.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8357e-04 - val_loss: 9.9615e-04\n",
      "Epoch 1077/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8186e-04 - tot_time: 0h 44m 13.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8349e-04 - val_loss: 9.7856e-04\n",
      "Epoch 1078/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.8154e-04 - tot_time: 0h 44m 14.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8036e-04 - val_loss: 9.8918e-04\n",
      "Epoch 1079/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.8179e-04 - tot_time: 0h 44m 15.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8180e-04 - val_loss: 9.7499e-04\n",
      "Epoch 1080/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.8236e-04 - tot_time: 0h 44m 16.3s\n",
      "\n",
      "Epoch 1080: val_loss did not improve from 0.00098\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8181e-04 - val_loss: 9.8858e-04\n",
      "Epoch 1081/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8523e-04 - tot_time: 0h 44m 17.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8293e-04 - val_loss: 9.8269e-04\n",
      "Epoch 1082/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8346e-04 - tot_time: 0h 44m 18.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.8319e-04 - val_loss: 9.8351e-04\n",
      "Epoch 1083/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.8042e-04 - tot_time: 0h 44m 18.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7924e-04 - val_loss: 9.7261e-04\n",
      "Epoch 1084/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.7994e-04 - tot_time: 0h 44m 19.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8009e-04 - val_loss: 9.9418e-04\n",
      "Epoch 1085/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.8261e-04 - tot_time: 0h 44m 20.7s\n",
      "\n",
      "Epoch 1085: val_loss improved from 0.00098 to 0.00098, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8177e-04 - val_loss: 9.7544e-04\n",
      "Epoch 1086/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.8082e-04 - tot_time: 0h 44m 21.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8052e-04 - val_loss: 9.7822e-04\n",
      "Epoch 1087/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.7836e-04 - tot_time: 0h 44m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7893e-04 - val_loss: 9.7389e-04\n",
      "Epoch 1088/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.7843e-04 - tot_time: 0h 44m 23.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.7857e-04 - val_loss: 9.7631e-04\n",
      "Epoch 1089/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.8371e-04 - tot_time: 0h 44m 24.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.8158e-04 - val_loss: 9.7236e-04\n",
      "Epoch 1090/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.7640e-04 - tot_time: 0h 44m 25.4s\n",
      "\n",
      "Epoch 1090: val_loss improved from 0.00098 to 0.00097, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7942e-04 - val_loss: 9.7473e-04\n",
      "Epoch 1091/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7873e-04 - tot_time: 0h 44m 26.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7873e-04 - val_loss: 9.9335e-04\n",
      "Epoch 1092/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7938e-04 - tot_time: 0h 44m 27.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7938e-04 - val_loss: 9.6681e-04\n",
      "Epoch 1093/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.7560e-04 - tot_time: 0h 44m 28.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7743e-04 - val_loss: 9.6781e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1094/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.7611e-04 - tot_time: 0h 44m 29.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7718e-04 - val_loss: 9.7321e-04\n",
      "Epoch 1095/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.8000e-04 - tot_time: 0h 44m 30.1s\n",
      "\n",
      "Epoch 1095: val_loss improved from 0.00097 to 0.00097, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.8024e-04 - val_loss: 9.6945e-04\n",
      "Epoch 1096/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 9.7615e-04 - tot_time: 0h 44m 30.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7737e-04 - val_loss: 9.6667e-04\n",
      "Epoch 1097/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.7554e-04 - tot_time: 0h 44m 31.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7560e-04 - val_loss: 9.8485e-04\n",
      "Epoch 1098/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.7421e-04 - tot_time: 0h 44m 32.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7408e-04 - val_loss: 9.8254e-04\n",
      "Epoch 1099/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.7747e-04 - tot_time: 0h 44m 33.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7514e-04 - val_loss: 9.6349e-04\n",
      "Epoch 1100/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.7503e-04 - tot_time: 0h 44m 34.5s\n",
      "\n",
      "Epoch 1100: val_loss did not improve from 0.00097\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7482e-04 - val_loss: 9.7402e-04\n",
      "Epoch 1101/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.7495e-04 - tot_time: 0h 44m 35.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7474e-04 - val_loss: 9.6366e-04\n",
      "Epoch 1102/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.7110e-04 - tot_time: 0h 44m 36.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.7256e-04 - val_loss: 9.6275e-04\n",
      "Epoch 1103/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.7299e-04 - tot_time: 0h 44m 37.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7235e-04 - val_loss: 9.6354e-04\n",
      "Epoch 1104/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.7253e-04 - tot_time: 0h 44m 38.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7386e-04 - val_loss: 9.6841e-04\n",
      "Epoch 1105/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.7179e-04 - tot_time: 0h 44m 38.7s\n",
      "\n",
      "Epoch 1105: val_loss did not improve from 0.00097\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7231e-04 - val_loss: 9.7539e-04\n",
      "Epoch 1106/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.7356e-04 - tot_time: 0h 44m 39.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7243e-04 - val_loss: 9.8553e-04\n",
      "Epoch 1107/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.7167e-04 - tot_time: 0h 44m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7097e-04 - val_loss: 9.7288e-04\n",
      "Epoch 1108/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7137e-04 - tot_time: 0h 44m 41.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7137e-04 - val_loss: 9.6527e-04\n",
      "Epoch 1109/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.7214e-04 - tot_time: 0h 44m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7209e-04 - val_loss: 9.7419e-04\n",
      "Epoch 1110/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.7010e-04 - tot_time: 0h 44m 43.3s\n",
      "\n",
      "Epoch 1110: val_loss did not improve from 0.00097\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7019e-04 - val_loss: 9.7485e-04\n",
      "Epoch 1111/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.7214e-04 - tot_time: 0h 44m 44.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.7232e-04 - val_loss: 9.6628e-04\n",
      "Epoch 1112/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.7133e-04 - tot_time: 0h 44m 45.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.7228e-04 - val_loss: 9.6231e-04\n",
      "Epoch 1113/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.6743e-04 - tot_time: 0h 44m 46.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6866e-04 - val_loss: 9.5999e-04\n",
      "Epoch 1114/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.6978e-04 - tot_time: 0h 44m 46.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7002e-04 - val_loss: 9.7100e-04\n",
      "Epoch 1115/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.7156e-04 - tot_time: 0h 44m 48.0s\n",
      "\n",
      "Epoch 1115: val_loss improved from 0.00097 to 0.00096, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.7160e-04 - val_loss: 9.6182e-04\n",
      "Epoch 1116/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.6676e-04 - tot_time: 0h 44m 48.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.6702e-04 - val_loss: 9.6619e-04\n",
      "Epoch 1117/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6917e-04 - tot_time: 0h 44m 49.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6917e-04 - val_loss: 9.6364e-04\n",
      "Epoch 1118/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.6955e-04 - tot_time: 0h 44m 50.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6759e-04 - val_loss: 9.6681e-04\n",
      "Epoch 1119/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.6831e-04 - tot_time: 0h 44m 51.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.6774e-04 - val_loss: 9.7076e-04\n",
      "Epoch 1120/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.6741e-04 - tot_time: 0h 44m 52.2s\n",
      "\n",
      "Epoch 1120: val_loss did not improve from 0.00096\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6731e-04 - val_loss: 9.7765e-04\n",
      "Epoch 1121/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.6570e-04 - tot_time: 0h 44m 53.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6526e-04 - val_loss: 9.5793e-04\n",
      "Epoch 1122/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.6431e-04 - tot_time: 0h 44m 53.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.6439e-04 - val_loss: 9.5969e-04\n",
      "Epoch 1123/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.6341e-04 - tot_time: 0h 44m 54.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6425e-04 - val_loss: 9.6202e-04\n",
      "Epoch 1124/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.6143e-04 - tot_time: 0h 44m 55.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6329e-04 - val_loss: 9.6280e-04\n",
      "Epoch 1125/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.6638e-04 - tot_time: 0h 44m 56.7s\n",
      "\n",
      "Epoch 1125: val_loss improved from 0.00096 to 0.00096, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.6366e-04 - val_loss: 9.5783e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1126/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.6449e-04 - tot_time: 0h 44m 57.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6443e-04 - val_loss: 9.6186e-04\n",
      "Epoch 1127/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.6268e-04 - tot_time: 0h 44m 58.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6187e-04 - val_loss: 9.5751e-04\n",
      "Epoch 1128/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.6242e-04 - tot_time: 0h 44m 59.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6101e-04 - val_loss: 9.5652e-04\n",
      "Epoch 1129/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.6023e-04 - tot_time: 0h 45m 0.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6073e-04 - val_loss: 9.5804e-04\n",
      "Epoch 1130/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 9.6436e-04 - tot_time: 0h 45m 1.2s\n",
      "\n",
      "Epoch 1130: val_loss improved from 0.00096 to 0.00096, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6201e-04 - val_loss: 9.5777e-04\n",
      "Epoch 1131/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6241e-04 - tot_time: 0h 45m 2.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6241e-04 - val_loss: 9.5244e-04\n",
      "Epoch 1132/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.5982e-04 - tot_time: 0h 45m 3.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5984e-04 - val_loss: 9.5138e-04\n",
      "Epoch 1133/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 9.6191e-04 - tot_time: 0h 45m 4.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.5895e-04 - val_loss: 9.5965e-04\n",
      "Epoch 1134/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.5804e-04 - tot_time: 0h 45m 4.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5790e-04 - val_loss: 9.6394e-04\n",
      "Epoch 1135/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.5984e-04 - tot_time: 0h 45m 5.9s\n",
      "\n",
      "Epoch 1135: val_loss improved from 0.00096 to 0.00096, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.5824e-04 - val_loss: 9.5572e-04\n",
      "Epoch 1136/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.5970e-04 - tot_time: 0h 45m 6.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.5859e-04 - val_loss: 9.4981e-04\n",
      "Epoch 1137/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.5652e-04 - tot_time: 0h 45m 7.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5675e-04 - val_loss: 9.6830e-04\n",
      "Epoch 1138/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.5511e-04 - tot_time: 0h 45m 8.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5534e-04 - val_loss: 9.7317e-04\n",
      "Epoch 1139/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.5694e-04 - tot_time: 0h 45m 9.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.5643e-04 - val_loss: 9.5438e-04\n",
      "Epoch 1140/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5815e-04 - tot_time: 0h 45m 10.4s\n",
      "\n",
      "Epoch 1140: val_loss improved from 0.00096 to 0.00095, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.5815e-04 - val_loss: 9.4598e-04\n",
      "Epoch 1141/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.5359e-04 - tot_time: 0h 45m 11.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5444e-04 - val_loss: 9.4665e-04\n",
      "Epoch 1142/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.5270e-04 - tot_time: 0h 45m 12.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.5278e-04 - val_loss: 9.4810e-04\n",
      "Epoch 1143/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.5443e-04 - tot_time: 0h 45m 13.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5448e-04 - val_loss: 9.5491e-04\n",
      "Epoch 1144/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.5316e-04 - tot_time: 0h 45m 14.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5215e-04 - val_loss: 9.4497e-04\n",
      "Epoch 1145/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.5150e-04 - tot_time: 0h 45m 14.8s\n",
      "\n",
      "Epoch 1145: val_loss did not improve from 0.00095\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5208e-04 - val_loss: 9.4693e-04\n",
      "Epoch 1146/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.4927e-04 - tot_time: 0h 45m 15.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5064e-04 - val_loss: 9.5677e-04\n",
      "Epoch 1147/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.5253e-04 - tot_time: 0h 45m 16.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.5125e-04 - val_loss: 9.7685e-04\n",
      "Epoch 1148/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.5228e-04 - tot_time: 0h 45m 17.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5195e-04 - val_loss: 9.4285e-04\n",
      "Epoch 1149/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.4845e-04 - tot_time: 0h 45m 18.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4950e-04 - val_loss: 9.4636e-04\n",
      "Epoch 1150/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4796e-04 - tot_time: 0h 45m 19.3s\n",
      "\n",
      "Epoch 1150: val_loss did not improve from 0.00095\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.4796e-04 - val_loss: 9.6853e-04\n",
      "Epoch 1151/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5158e-04 - tot_time: 0h 45m 20.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.5158e-04 - val_loss: 9.4940e-04\n",
      "Epoch 1152/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.4771e-04 - tot_time: 0h 45m 21.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4764e-04 - val_loss: 9.4626e-04\n",
      "Epoch 1153/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.4842e-04 - tot_time: 0h 45m 21.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.4701e-04 - val_loss: 9.8565e-04\n",
      "Epoch 1154/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.4927e-04 - tot_time: 0h 45m 22.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4812e-04 - val_loss: 9.4007e-04\n",
      "Epoch 1155/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.4680e-04 - tot_time: 0h 45m 23.9s\n",
      "\n",
      "Epoch 1155: val_loss improved from 0.00095 to 0.00094, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4524e-04 - val_loss: 9.3931e-04\n",
      "Epoch 1156/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.4732e-04 - tot_time: 0h 45m 24.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.4720e-04 - val_loss: 9.3812e-04\n",
      "Epoch 1157/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.4604e-04 - tot_time: 0h 45m 25.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4511e-04 - val_loss: 9.4515e-04\n",
      "Epoch 1158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/124 [==========================>...] - ETA: 0s - loss: 9.4662e-04 - tot_time: 0h 45m 26.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4436e-04 - val_loss: 9.4943e-04\n",
      "Epoch 1159/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.4304e-04 - tot_time: 0h 45m 27.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.4369e-04 - val_loss: 9.4176e-04\n",
      "Epoch 1160/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.3948e-04 - tot_time: 0h 45m 28.4s\n",
      "\n",
      "Epoch 1160: val_loss improved from 0.00094 to 0.00094, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.4094e-04 - val_loss: 9.3620e-04\n",
      "Epoch 1161/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.4295e-04 - tot_time: 0h 45m 29.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.4297e-04 - val_loss: 9.3470e-04\n",
      "Epoch 1162/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.4229e-04 - tot_time: 0h 45m 30.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4199e-04 - val_loss: 9.4067e-04\n",
      "Epoch 1163/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.3962e-04 - tot_time: 0h 45m 31.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4006e-04 - val_loss: 9.4592e-04\n",
      "Epoch 1164/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.3729e-04 - tot_time: 0h 45m 31.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4001e-04 - val_loss: 9.5807e-04\n",
      "Epoch 1165/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.4346e-04 - tot_time: 0h 45m 32.8s\n",
      "\n",
      "Epoch 1165: val_loss improved from 0.00094 to 0.00093, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.4338e-04 - val_loss: 9.3041e-04\n",
      "Epoch 1166/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.4041e-04 - tot_time: 0h 45m 33.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3912e-04 - val_loss: 9.3494e-04\n",
      "Epoch 1167/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 9.3976e-04 - tot_time: 0h 45m 34.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.3929e-04 - val_loss: 9.4273e-04\n",
      "Epoch 1168/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3678e-04 - tot_time: 0h 45m 35.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3678e-04 - val_loss: 9.3423e-04\n",
      "Epoch 1169/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.3549e-04 - tot_time: 0h 45m 36.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3501e-04 - val_loss: 9.3650e-04\n",
      "Epoch 1170/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3612e-04 - tot_time: 0h 45m 37.1s\n",
      "\n",
      "Epoch 1170: val_loss improved from 0.00093 to 0.00093, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.3612e-04 - val_loss: 9.2974e-04\n",
      "Epoch 1171/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.3967e-04 - tot_time: 0h 45m 38.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3814e-04 - val_loss: 9.3907e-04\n",
      "Epoch 1172/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.3521e-04 - tot_time: 0h 45m 39.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3516e-04 - val_loss: 9.2647e-04\n",
      "Epoch 1173/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.3487e-04 - tot_time: 0h 45m 39.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.3342e-04 - val_loss: 9.2869e-04\n",
      "Epoch 1174/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.3630e-04 - tot_time: 0h 45m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3398e-04 - val_loss: 9.3766e-04\n",
      "Epoch 1175/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3185e-04 - tot_time: 0h 45m 41.8s\n",
      "\n",
      "Epoch 1175: val_loss did not improve from 0.00093\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.3185e-04 - val_loss: 9.3042e-04\n",
      "Epoch 1176/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.2996e-04 - tot_time: 0h 45m 42.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.3179e-04 - val_loss: 9.3128e-04\n",
      "Epoch 1177/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.2900e-04 - tot_time: 0h 45m 43.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.2921e-04 - val_loss: 9.3246e-04\n",
      "Epoch 1178/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.3010e-04 - tot_time: 0h 45m 44.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2918e-04 - val_loss: 9.2081e-04\n",
      "Epoch 1179/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.3102e-04 - tot_time: 0h 45m 45.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.2933e-04 - val_loss: 9.2425e-04\n",
      "Epoch 1180/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2781e-04 - tot_time: 0h 45m 46.1s\n",
      "\n",
      "Epoch 1180: val_loss improved from 0.00093 to 0.00093, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.2781e-04 - val_loss: 9.2668e-04\n",
      "Epoch 1181/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.2654e-04 - tot_time: 0h 45m 47.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2736e-04 - val_loss: 9.2798e-04\n",
      "Epoch 1182/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.2678e-04 - tot_time: 0h 45m 47.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.2481e-04 - val_loss: 9.3592e-04\n",
      "Epoch 1183/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.2777e-04 - tot_time: 0h 45m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.2776e-04 - val_loss: 9.3084e-04\n",
      "Epoch 1184/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.2606e-04 - tot_time: 0h 45m 49.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2500e-04 - val_loss: 9.6518e-04\n",
      "Epoch 1185/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.2518e-04 - tot_time: 0h 45m 50.4s\n",
      "\n",
      "Epoch 1185: val_loss improved from 0.00093 to 0.00092, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2462e-04 - val_loss: 9.1623e-04\n",
      "Epoch 1186/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.2262e-04 - tot_time: 0h 45m 51.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.2291e-04 - val_loss: 9.1706e-04\n",
      "Epoch 1187/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 9.2061e-04 - tot_time: 0h 45m 52.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2054e-04 - val_loss: 9.6057e-04\n",
      "Epoch 1188/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.2344e-04 - tot_time: 0h 45m 53.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2333e-04 - val_loss: 9.1451e-04\n",
      "Epoch 1189/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.2068e-04 - tot_time: 0h 45m 54.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.1934e-04 - val_loss: 9.4140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1190/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.2427e-04 - tot_time: 0h 45m 55.1s\n",
      "\n",
      "Epoch 1190: val_loss improved from 0.00092 to 0.00092, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.2343e-04 - val_loss: 9.1587e-04\n",
      "Epoch 1191/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.1882e-04 - tot_time: 0h 45m 56.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.1874e-04 - val_loss: 9.1079e-04\n",
      "Epoch 1192/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.1754e-04 - tot_time: 0h 45m 57.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.1631e-04 - val_loss: 9.1133e-04\n",
      "Epoch 1193/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.1710e-04 - tot_time: 0h 45m 57.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.1630e-04 - val_loss: 9.3802e-04\n",
      "Epoch 1194/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.1419e-04 - tot_time: 0h 45m 58.9s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.1588e-04 - val_loss: 9.1608e-04\n",
      "Epoch 1195/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 9.1716e-04 - tot_time: 0h 45m 59.8s\n",
      "\n",
      "Epoch 1195: val_loss improved from 0.00092 to 0.00091, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1446e-04 - val_loss: 9.1171e-04\n",
      "Epoch 1196/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1371e-04 - tot_time: 0h 46m 0.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1371e-04 - val_loss: 9.0354e-04\n",
      "Epoch 1197/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 9.1481e-04 - tot_time: 0h 46m 1.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.1428e-04 - val_loss: 9.1162e-04\n",
      "Epoch 1198/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.1347e-04 - tot_time: 0h 46m 2.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.1117e-04 - val_loss: 9.1149e-04\n",
      "Epoch 1199/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 9.1221e-04 - tot_time: 0h 46m 3.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1202e-04 - val_loss: 9.1798e-04\n",
      "Epoch 1200/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.1190e-04 - tot_time: 0h 46m 4.5s\n",
      "\n",
      "Epoch 1200: val_loss did not improve from 0.00091\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.1079e-04 - val_loss: 9.1512e-04\n",
      "Epoch 1201/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 9.0889e-04 - tot_time: 0h 46m 5.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.0985e-04 - val_loss: 9.0535e-04\n",
      "Epoch 1202/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.0764e-04 - tot_time: 0h 46m 6.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0861e-04 - val_loss: 8.9833e-04\n",
      "Epoch 1203/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.0616e-04 - tot_time: 0h 46m 7.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0728e-04 - val_loss: 9.1132e-04\n",
      "Epoch 1204/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0882e-04 - tot_time: 0h 46m 7.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 9.0882e-04 - val_loss: 9.1095e-04\n",
      "Epoch 1205/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.0351e-04 - tot_time: 0h 46m 8.7s\n",
      "\n",
      "Epoch 1205: val_loss improved from 0.00091 to 0.00091, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0375e-04 - val_loss: 9.0611e-04\n",
      "Epoch 1206/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 9.0318e-04 - tot_time: 0h 46m 9.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0368e-04 - val_loss: 9.4082e-04\n",
      "Epoch 1207/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0767e-04 - tot_time: 0h 46m 10.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 9.0767e-04 - val_loss: 8.9182e-04\n",
      "Epoch 1208/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 9.0159e-04 - tot_time: 0h 46m 11.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.0159e-04 - val_loss: 8.9914e-04\n",
      "Epoch 1209/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.9992e-04 - tot_time: 0h 46m 12.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0122e-04 - val_loss: 8.9584e-04\n",
      "Epoch 1210/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 9.0029e-04 - tot_time: 0h 46m 13.3s\n",
      "\n",
      "Epoch 1210: val_loss improved from 0.00091 to 0.00090, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9984e-04 - val_loss: 8.9829e-04\n",
      "Epoch 1211/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.9760e-04 - tot_time: 0h 46m 14.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9777e-04 - val_loss: 8.9613e-04\n",
      "Epoch 1212/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9757e-04 - tot_time: 0h 46m 15.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9757e-04 - val_loss: 9.3202e-04\n",
      "Epoch 1213/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.9724e-04 - tot_time: 0h 46m 16.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9945e-04 - val_loss: 9.2311e-04\n",
      "Epoch 1214/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.9616e-04 - tot_time: 0h 46m 17.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9717e-04 - val_loss: 8.9163e-04\n",
      "Epoch 1215/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 8.9680e-04 - tot_time: 0h 46m 17.8s\n",
      "\n",
      "Epoch 1215: val_loss improved from 0.00090 to 0.00090, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9537e-04 - val_loss: 8.9530e-04\n",
      "Epoch 1216/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9479e-04 - tot_time: 0h 46m 18.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9479e-04 - val_loss: 8.9554e-04\n",
      "Epoch 1217/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.9427e-04 - tot_time: 0h 46m 19.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9361e-04 - val_loss: 9.0053e-04\n",
      "Epoch 1218/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.9204e-04 - tot_time: 0h 46m 20.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.9142e-04 - val_loss: 8.9949e-04\n",
      "Epoch 1219/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.9089e-04 - tot_time: 0h 46m 21.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9085e-04 - val_loss: 8.9053e-04\n",
      "Epoch 1220/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.9098e-04 - tot_time: 0h 46m 22.6s\n",
      "\n",
      "Epoch 1220: val_loss improved from 0.00090 to 0.00089, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.9006e-04 - val_loss: 8.8694e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1221/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.8965e-04 - tot_time: 0h 46m 23.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.8973e-04 - val_loss: 8.9600e-04\n",
      "Epoch 1222/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.9070e-04 - tot_time: 0h 46m 24.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9012e-04 - val_loss: 8.9615e-04\n",
      "Epoch 1223/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 8.8674e-04 - tot_time: 0h 46m 25.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8738e-04 - val_loss: 9.0914e-04\n",
      "Epoch 1224/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.8628e-04 - tot_time: 0h 46m 26.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.8761e-04 - val_loss: 9.2630e-04\n",
      "Epoch 1225/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.9104e-04 - tot_time: 0h 46m 27.1s\n",
      "\n",
      "Epoch 1225: val_loss improved from 0.00089 to 0.00088, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.9104e-04 - val_loss: 8.7892e-04\n",
      "Epoch 1226/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 8.8405e-04 - tot_time: 0h 46m 27.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.8512e-04 - val_loss: 8.8142e-04\n",
      "Epoch 1227/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8354e-04 - tot_time: 0h 46m 28.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.8354e-04 - val_loss: 8.8843e-04\n",
      "Epoch 1228/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.8217e-04 - tot_time: 0h 46m 29.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8259e-04 - val_loss: 8.9729e-04\n",
      "Epoch 1229/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.8041e-04 - tot_time: 0h 46m 30.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.8035e-04 - val_loss: 8.7905e-04\n",
      "Epoch 1230/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 8.7999e-04 - tot_time: 0h 46m 31.4s\n",
      "\n",
      "Epoch 1230: val_loss improved from 0.00088 to 0.00087, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8006e-04 - val_loss: 8.7370e-04\n",
      "Epoch 1231/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.7925e-04 - tot_time: 0h 46m 32.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7963e-04 - val_loss: 8.9002e-04\n",
      "Epoch 1232/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.8129e-04 - tot_time: 0h 46m 33.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.8048e-04 - val_loss: 8.7662e-04\n",
      "Epoch 1233/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.7725e-04 - tot_time: 0h 46m 34.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7635e-04 - val_loss: 8.8171e-04\n",
      "Epoch 1234/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.7753e-04 - tot_time: 0h 46m 35.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7810e-04 - val_loss: 9.0088e-04\n",
      "Epoch 1235/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 8.7816e-04 - tot_time: 0h 46m 35.8s\n",
      "\n",
      "Epoch 1235: val_loss improved from 0.00087 to 0.00087, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.7688e-04 - val_loss: 8.6620e-04\n",
      "Epoch 1236/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.7276e-04 - tot_time: 0h 46m 36.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7349e-04 - val_loss: 8.7100e-04\n",
      "Epoch 1237/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.7323e-04 - tot_time: 0h 46m 37.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7342e-04 - val_loss: 8.6655e-04\n",
      "Epoch 1238/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.7318e-04 - tot_time: 0h 46m 38.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.7307e-04 - val_loss: 8.7191e-04\n",
      "Epoch 1239/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.7320e-04 - tot_time: 0h 46m 39.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7404e-04 - val_loss: 8.6758e-04\n",
      "Epoch 1240/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6870e-04 - tot_time: 0h 46m 40.5s\n",
      "\n",
      "Epoch 1240: val_loss did not improve from 0.00087\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6870e-04 - val_loss: 8.9073e-04\n",
      "Epoch 1241/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.6796e-04 - tot_time: 0h 46m 41.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.7003e-04 - val_loss: 8.7380e-04\n",
      "Epoch 1242/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6921e-04 - tot_time: 0h 46m 42.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6921e-04 - val_loss: 8.8253e-04\n",
      "Epoch 1243/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.6865e-04 - tot_time: 0h 46m 43.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6877e-04 - val_loss: 8.6256e-04\n",
      "Epoch 1244/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.6359e-04 - tot_time: 0h 46m 43.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.6504e-04 - val_loss: 9.0428e-04\n",
      "Epoch 1245/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.6683e-04 - tot_time: 0h 46m 44.9s\n",
      "\n",
      "Epoch 1245: val_loss improved from 0.00087 to 0.00086, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.6679e-04 - val_loss: 8.5814e-04\n",
      "Epoch 1246/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.6709e-04 - tot_time: 0h 46m 45.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6701e-04 - val_loss: 8.6554e-04\n",
      "Epoch 1247/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.6311e-04 - tot_time: 0h 46m 46.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6197e-04 - val_loss: 8.7572e-04\n",
      "Epoch 1248/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.6270e-04 - tot_time: 0h 46m 47.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6272e-04 - val_loss: 8.6572e-04\n",
      "Epoch 1249/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.6131e-04 - tot_time: 0h 46m 48.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6016e-04 - val_loss: 8.5668e-04\n",
      "Epoch 1250/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.5975e-04 - tot_time: 0h 46m 49.3s\n",
      "\n",
      "Epoch 1250: val_loss did not improve from 0.00086\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6076e-04 - val_loss: 8.6001e-04\n",
      "Epoch 1251/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.5900e-04 - tot_time: 0h 46m 50.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6050e-04 - val_loss: 8.5365e-04\n",
      "Epoch 1252/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 8.5869e-04 - tot_time: 0h 46m 51.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.5994e-04 - val_loss: 8.5629e-04\n",
      "Epoch 1253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/124 [===========================>..] - ETA: 0s - loss: 8.6133e-04 - tot_time: 0h 46m 52.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6020e-04 - val_loss: 8.5154e-04\n",
      "Epoch 1254/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.5342e-04 - tot_time: 0h 46m 53.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.5616e-04 - val_loss: 8.5148e-04\n",
      "Epoch 1255/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.5572e-04 - tot_time: 0h 46m 53.7s\n",
      "\n",
      "Epoch 1255: val_loss improved from 0.00086 to 0.00085, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.5571e-04 - val_loss: 8.4986e-04\n",
      "Epoch 1256/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.5700e-04 - tot_time: 0h 46m 54.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.5667e-04 - val_loss: 8.8714e-04\n",
      "Epoch 1257/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.5637e-04 - tot_time: 0h 46m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.5494e-04 - val_loss: 8.5481e-04\n",
      "Epoch 1258/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.5485e-04 - tot_time: 0h 46m 56.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.5393e-04 - val_loss: 8.4679e-04\n",
      "Epoch 1259/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.5611e-04 - tot_time: 0h 46m 57.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.5342e-04 - val_loss: 8.4548e-04\n",
      "Epoch 1260/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.5200e-04 - tot_time: 0h 46m 58.4s\n",
      "\n",
      "Epoch 1260: val_loss did not improve from 0.00085\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5280e-04 - val_loss: 8.5031e-04\n",
      "Epoch 1261/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.5032e-04 - tot_time: 0h 46m 59.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.5020e-04 - val_loss: 8.5059e-04\n",
      "Epoch 1262/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4803e-04 - tot_time: 0h 47m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.4803e-04 - val_loss: 8.5501e-04\n",
      "Epoch 1263/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 8.4796e-04 - tot_time: 0h 47m 1.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4690e-04 - val_loss: 8.4098e-04\n",
      "Epoch 1264/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.4815e-04 - tot_time: 0h 47m 1.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.4806e-04 - val_loss: 8.4711e-04\n",
      "Epoch 1265/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4877e-04 - tot_time: 0h 47m 2.8s\n",
      "\n",
      "Epoch 1265: val_loss improved from 0.00085 to 0.00084, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.4877e-04 - val_loss: 8.4129e-04\n",
      "Epoch 1266/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 8.4488e-04 - tot_time: 0h 47m 3.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.4522e-04 - val_loss: 8.4218e-04\n",
      "Epoch 1267/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.4564e-04 - tot_time: 0h 47m 4.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4402e-04 - val_loss: 8.4596e-04\n",
      "Epoch 1268/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.4416e-04 - tot_time: 0h 47m 5.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.4512e-04 - val_loss: 8.6093e-04\n",
      "Epoch 1269/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.4397e-04 - tot_time: 0h 47m 6.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.4465e-04 - val_loss: 8.3914e-04\n",
      "Epoch 1270/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.4051e-04 - tot_time: 0h 47m 7.3s\n",
      "\n",
      "Epoch 1270: val_loss improved from 0.00084 to 0.00083, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.4020e-04 - val_loss: 8.3195e-04\n",
      "Epoch 1271/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.4235e-04 - tot_time: 0h 47m 8.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.4072e-04 - val_loss: 8.3987e-04\n",
      "Epoch 1272/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.3894e-04 - tot_time: 0h 47m 9.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.4074e-04 - val_loss: 8.4379e-04\n",
      "Epoch 1273/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.4210e-04 - tot_time: 0h 47m 10.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.4302e-04 - val_loss: 8.3042e-04\n",
      "Epoch 1274/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.3777e-04 - tot_time: 0h 47m 11.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.3848e-04 - val_loss: 8.3063e-04\n",
      "Epoch 1275/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.3625e-04 - tot_time: 0h 47m 11.9s\n",
      "\n",
      "Epoch 1275: val_loss did not improve from 0.00083\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.3606e-04 - val_loss: 8.3331e-04\n",
      "Epoch 1276/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.3618e-04 - tot_time: 0h 47m 12.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.3585e-04 - val_loss: 8.3335e-04\n",
      "Epoch 1277/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3665e-04 - tot_time: 0h 47m 13.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3665e-04 - val_loss: 8.3416e-04\n",
      "Epoch 1278/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.3409e-04 - tot_time: 0h 47m 14.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3401e-04 - val_loss: 8.3859e-04\n",
      "Epoch 1279/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.3550e-04 - tot_time: 0h 47m 15.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.3508e-04 - val_loss: 8.6993e-04\n",
      "Epoch 1280/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.3700e-04 - tot_time: 0h 47m 16.4s\n",
      "\n",
      "Epoch 1280: val_loss improved from 0.00083 to 0.00083, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.3697e-04 - val_loss: 8.2921e-04\n",
      "Epoch 1281/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.3245e-04 - tot_time: 0h 47m 17.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3255e-04 - val_loss: 8.2502e-04\n",
      "Epoch 1282/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.3177e-04 - tot_time: 0h 47m 18.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.3187e-04 - val_loss: 8.3456e-04\n",
      "Epoch 1283/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.3113e-04 - tot_time: 0h 47m 19.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.3183e-04 - val_loss: 8.2673e-04\n",
      "Epoch 1284/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2875e-04 - tot_time: 0h 47m 20.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2875e-04 - val_loss: 8.2676e-04\n",
      "Epoch 1285/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.3139e-04 - tot_time: 0h 47m 21.1s\n",
      "\n",
      "Epoch 1285: val_loss improved from 0.00083 to 0.00082, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2971e-04 - val_loss: 8.2421e-04\n",
      "Epoch 1286/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.2760e-04 - tot_time: 0h 47m 21.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.2771e-04 - val_loss: 8.2766e-04\n",
      "Epoch 1287/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.2681e-04 - tot_time: 0h 47m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2674e-04 - val_loss: 8.1919e-04\n",
      "Epoch 1288/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.2555e-04 - tot_time: 0h 47m 23.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2565e-04 - val_loss: 8.3964e-04\n",
      "Epoch 1289/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.2777e-04 - tot_time: 0h 47m 24.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.2678e-04 - val_loss: 8.2984e-04\n",
      "Epoch 1290/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2333e-04 - tot_time: 0h 47m 25.6s\n",
      "\n",
      "Epoch 1290: val_loss improved from 0.00082 to 0.00082, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.2333e-04 - val_loss: 8.1968e-04\n",
      "Epoch 1291/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 8.2544e-04 - tot_time: 0h 47m 26.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2527e-04 - val_loss: 8.2139e-04\n",
      "Epoch 1292/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.2398e-04 - tot_time: 0h 47m 27.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2207e-04 - val_loss: 8.1747e-04\n",
      "Epoch 1293/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.2365e-04 - tot_time: 0h 47m 28.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2307e-04 - val_loss: 8.1946e-04\n",
      "Epoch 1294/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.2461e-04 - tot_time: 0h 47m 29.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.2250e-04 - val_loss: 8.3687e-04\n",
      "Epoch 1295/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.2273e-04 - tot_time: 0h 47m 30.1s\n",
      "\n",
      "Epoch 1295: val_loss did not improve from 0.00082\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2269e-04 - val_loss: 8.2834e-04\n",
      "Epoch 1296/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.2476e-04 - tot_time: 0h 47m 31.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2326e-04 - val_loss: 8.2450e-04\n",
      "Epoch 1297/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.1939e-04 - tot_time: 0h 47m 31.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.2034e-04 - val_loss: 8.2534e-04\n",
      "Epoch 1298/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.2028e-04 - tot_time: 0h 47m 32.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1925e-04 - val_loss: 8.1006e-04\n",
      "Epoch 1299/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1815e-04 - tot_time: 0h 47m 33.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1815e-04 - val_loss: 8.2598e-04\n",
      "Epoch 1300/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.1960e-04 - tot_time: 0h 47m 34.3s\n",
      "\n",
      "Epoch 1300: val_loss improved from 0.00082 to 0.00081, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.2015e-04 - val_loss: 8.0923e-04\n",
      "Epoch 1301/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.1793e-04 - tot_time: 0h 47m 35.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1783e-04 - val_loss: 8.1382e-04\n",
      "Epoch 1302/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.1438e-04 - tot_time: 0h 47m 36.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1510e-04 - val_loss: 8.1152e-04\n",
      "Epoch 1303/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 8.1630e-04 - tot_time: 0h 47m 36.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.1453e-04 - val_loss: 8.2355e-04\n",
      "Epoch 1304/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.1480e-04 - tot_time: 0h 47m 37.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1466e-04 - val_loss: 8.1245e-04\n",
      "Epoch 1305/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.1311e-04 - tot_time: 0h 47m 38.8s\n",
      "\n",
      "Epoch 1305: val_loss did not improve from 0.00081\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1430e-04 - val_loss: 8.1333e-04\n",
      "Epoch 1306/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1374e-04 - tot_time: 0h 47m 39.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.1374e-04 - val_loss: 8.2285e-04\n",
      "Epoch 1307/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.1422e-04 - tot_time: 0h 47m 40.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1425e-04 - val_loss: 8.1067e-04\n",
      "Epoch 1308/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 8.1151e-04 - tot_time: 0h 47m 41.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1258e-04 - val_loss: 8.0916e-04\n",
      "Epoch 1309/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 8.1140e-04 - tot_time: 0h 47m 42.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.1078e-04 - val_loss: 8.0829e-04\n",
      "Epoch 1310/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.1001e-04 - tot_time: 0h 47m 43.0s\n",
      "\n",
      "Epoch 1310: val_loss improved from 0.00081 to 0.00081, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1092e-04 - val_loss: 8.0915e-04\n",
      "Epoch 1311/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.1060e-04 - tot_time: 0h 47m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.1079e-04 - val_loss: 8.2026e-04\n",
      "Epoch 1312/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.1110e-04 - tot_time: 0h 47m 44.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.1226e-04 - val_loss: 8.2366e-04\n",
      "Epoch 1313/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1033e-04 - tot_time: 0h 47m 45.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 8.1033e-04 - val_loss: 8.1248e-04\n",
      "Epoch 1314/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 8.0687e-04 - tot_time: 0h 47m 46.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0695e-04 - val_loss: 8.0218e-04\n",
      "Epoch 1315/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0737e-04 - tot_time: 0h 47m 47.5s\n",
      "\n",
      "Epoch 1315: val_loss improved from 0.00081 to 0.00080, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0737e-04 - val_loss: 8.0203e-04\n",
      "Epoch 1316/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0755e-04 - tot_time: 0h 47m 48.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0755e-04 - val_loss: 8.0183e-04\n",
      "Epoch 1317/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 8.0628e-04 - tot_time: 0h 47m 49.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0564e-04 - val_loss: 8.0072e-04\n",
      "Epoch 1318/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.0542e-04 - tot_time: 0h 47m 50.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0486e-04 - val_loss: 8.1352e-04\n",
      "Epoch 1319/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.0637e-04 - tot_time: 0h 47m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0634e-04 - val_loss: 8.0340e-04\n",
      "Epoch 1320/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.0666e-04 - tot_time: 0h 47m 52.1s\n",
      "\n",
      "Epoch 1320: val_loss improved from 0.00080 to 0.00080, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0687e-04 - val_loss: 7.9825e-04\n",
      "Epoch 1321/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.0343e-04 - tot_time: 0h 47m 53.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0338e-04 - val_loss: 8.0663e-04\n",
      "Epoch 1322/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 8.0297e-04 - tot_time: 0h 47m 54.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0325e-04 - val_loss: 8.0007e-04\n",
      "Epoch 1323/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.0149e-04 - tot_time: 0h 47m 54.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 8.0145e-04 - val_loss: 8.1454e-04\n",
      "Epoch 1324/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 8.0181e-04 - tot_time: 0h 47m 55.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0170e-04 - val_loss: 8.0852e-04\n",
      "Epoch 1325/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.0170e-04 - tot_time: 0h 47m 56.9s\n",
      "\n",
      "Epoch 1325: val_loss improved from 0.00080 to 0.00080, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0136e-04 - val_loss: 7.9523e-04\n",
      "Epoch 1326/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.0153e-04 - tot_time: 0h 47m 57.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 8.0149e-04 - val_loss: 7.9607e-04\n",
      "Epoch 1327/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 8.0005e-04 - tot_time: 0h 47m 58.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0102e-04 - val_loss: 7.9333e-04\n",
      "Epoch 1328/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 8.0145e-04 - tot_time: 0h 47m 59.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0158e-04 - val_loss: 7.9315e-04\n",
      "Epoch 1329/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 8.0014e-04 - tot_time: 0h 48m 0.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0007e-04 - val_loss: 7.9760e-04\n",
      "Epoch 1330/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9889e-04 - tot_time: 0h 48m 1.4s\n",
      "\n",
      "Epoch 1330: val_loss did not improve from 0.00080\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9889e-04 - val_loss: 7.9677e-04\n",
      "Epoch 1331/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.9738e-04 - tot_time: 0h 48m 2.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9732e-04 - val_loss: 7.9386e-04\n",
      "Epoch 1332/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.9846e-04 - tot_time: 0h 48m 3.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9767e-04 - val_loss: 8.0218e-04\n",
      "Epoch 1333/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.9892e-04 - tot_time: 0h 48m 4.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9897e-04 - val_loss: 7.9210e-04\n",
      "Epoch 1334/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.9958e-04 - tot_time: 0h 48m 4.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9755e-04 - val_loss: 7.9655e-04\n",
      "Epoch 1335/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9696e-04 - tot_time: 0h 48m 5.6s\n",
      "\n",
      "Epoch 1335: val_loss did not improve from 0.00080\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9696e-04 - val_loss: 7.9994e-04\n",
      "Epoch 1336/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9624e-04 - tot_time: 0h 48m 6.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9624e-04 - val_loss: 8.0183e-04\n",
      "Epoch 1337/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.9439e-04 - tot_time: 0h 48m 7.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9429e-04 - val_loss: 7.9965e-04\n",
      "Epoch 1338/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.9623e-04 - tot_time: 0h 48m 8.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9621e-04 - val_loss: 7.9820e-04\n",
      "Epoch 1339/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.9110e-04 - tot_time: 0h 48m 9.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9427e-04 - val_loss: 8.1206e-04\n",
      "Epoch 1340/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.9831e-04 - tot_time: 0h 48m 9.8s\n",
      "\n",
      "Epoch 1340: val_loss did not improve from 0.00080\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9786e-04 - val_loss: 8.0293e-04\n",
      "Epoch 1341/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.9316e-04 - tot_time: 0h 48m 10.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9321e-04 - val_loss: 7.9466e-04\n",
      "Epoch 1342/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.9403e-04 - tot_time: 0h 48m 11.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9396e-04 - val_loss: 8.0140e-04\n",
      "Epoch 1343/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.9068e-04 - tot_time: 0h 48m 12.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9263e-04 - val_loss: 8.0705e-04\n",
      "Epoch 1344/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.9082e-04 - tot_time: 0h 48m 13.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9155e-04 - val_loss: 7.9962e-04\n",
      "Epoch 1345/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.9332e-04 - tot_time: 0h 48m 14.2s\n",
      "\n",
      "Epoch 1345: val_loss improved from 0.00080 to 0.00079, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.9326e-04 - val_loss: 7.9006e-04\n",
      "Epoch 1346/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.9189e-04 - tot_time: 0h 48m 15.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9124e-04 - val_loss: 7.8988e-04\n",
      "Epoch 1347/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.9187e-04 - tot_time: 0h 48m 15.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9078e-04 - val_loss: 7.9132e-04\n",
      "Epoch 1348/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.9169e-04 - tot_time: 0h 48m 16.9s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.9101e-04 - val_loss: 8.0132e-04\n",
      "Epoch 1349/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.9079e-04 - tot_time: 0h 48m 17.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9184e-04 - val_loss: 7.9143e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1350/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.9239e-04 - tot_time: 0h 48m 18.6s\n",
      "\n",
      "Epoch 1350: val_loss improved from 0.00079 to 0.00079, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9130e-04 - val_loss: 7.8512e-04\n",
      "Epoch 1351/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.9240e-04 - tot_time: 0h 48m 19.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9168e-04 - val_loss: 8.1012e-04\n",
      "Epoch 1352/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.9169e-04 - tot_time: 0h 48m 20.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.9261e-04 - val_loss: 7.9556e-04\n",
      "Epoch 1353/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.8797e-04 - tot_time: 0h 48m 21.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8790e-04 - val_loss: 7.8787e-04\n",
      "Epoch 1354/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8751e-04 - tot_time: 0h 48m 22.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8796e-04 - val_loss: 7.8634e-04\n",
      "Epoch 1355/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8836e-04 - tot_time: 0h 48m 23.0s\n",
      "\n",
      "Epoch 1355: val_loss improved from 0.00079 to 0.00078, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8804e-04 - val_loss: 7.8329e-04\n",
      "Epoch 1356/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.8615e-04 - tot_time: 0h 48m 24.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8821e-04 - val_loss: 7.9389e-04\n",
      "Epoch 1357/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8831e-04 - tot_time: 0h 48m 25.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8842e-04 - val_loss: 7.8597e-04\n",
      "Epoch 1358/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8820e-04 - tot_time: 0h 48m 25.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8755e-04 - val_loss: 7.8650e-04\n",
      "Epoch 1359/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.8679e-04 - tot_time: 0h 48m 26.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8679e-04 - val_loss: 7.8922e-04\n",
      "Epoch 1360/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.8562e-04 - tot_time: 0h 48m 27.6s\n",
      "\n",
      "Epoch 1360: val_loss improved from 0.00078 to 0.00078, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8513e-04 - val_loss: 7.8319e-04\n",
      "Epoch 1361/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8630e-04 - tot_time: 0h 48m 28.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8583e-04 - val_loss: 7.8143e-04\n",
      "Epoch 1362/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.8610e-04 - tot_time: 0h 48m 29.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8616e-04 - val_loss: 7.9235e-04\n",
      "Epoch 1363/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.8532e-04 - tot_time: 0h 48m 30.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8551e-04 - val_loss: 7.9084e-04\n",
      "Epoch 1364/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8518e-04 - tot_time: 0h 48m 31.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8518e-04 - val_loss: 7.9176e-04\n",
      "Epoch 1365/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.8605e-04 - tot_time: 0h 48m 32.0s\n",
      "\n",
      "Epoch 1365: val_loss did not improve from 0.00078\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8610e-04 - val_loss: 7.8514e-04\n",
      "Epoch 1366/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.8494e-04 - tot_time: 0h 48m 32.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8464e-04 - val_loss: 7.8806e-04\n",
      "Epoch 1367/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8539e-04 - tot_time: 0h 48m 33.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8429e-04 - val_loss: 7.9262e-04\n",
      "Epoch 1368/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8435e-04 - tot_time: 0h 48m 34.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8435e-04 - val_loss: 7.9031e-04\n",
      "Epoch 1369/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.8051e-04 - tot_time: 0h 48m 35.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8246e-04 - val_loss: 7.8487e-04\n",
      "Epoch 1370/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8391e-04 - tot_time: 0h 48m 36.2s\n",
      "\n",
      "Epoch 1370: val_loss did not improve from 0.00078\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8391e-04 - val_loss: 7.8496e-04\n",
      "Epoch 1371/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.8211e-04 - tot_time: 0h 48m 37.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.8253e-04 - val_loss: 7.8296e-04\n",
      "Epoch 1372/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.8170e-04 - tot_time: 0h 48m 38.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.8078e-04 - val_loss: 8.0493e-04\n",
      "Epoch 1373/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.8193e-04 - tot_time: 0h 48m 38.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8176e-04 - val_loss: 7.8027e-04\n",
      "Epoch 1374/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.8250e-04 - tot_time: 0h 48m 39.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8317e-04 - val_loss: 7.8280e-04\n",
      "Epoch 1375/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8251e-04 - tot_time: 0h 48m 40.7s\n",
      "\n",
      "Epoch 1375: val_loss improved from 0.00078 to 0.00078, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8166e-04 - val_loss: 7.7949e-04\n",
      "Epoch 1376/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.8214e-04 - tot_time: 0h 48m 41.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.8210e-04 - val_loss: 7.7856e-04\n",
      "Epoch 1377/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.8125e-04 - tot_time: 0h 48m 42.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8083e-04 - val_loss: 7.8744e-04\n",
      "Epoch 1378/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.8218e-04 - tot_time: 0h 48m 43.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8182e-04 - val_loss: 7.8272e-04\n",
      "Epoch 1379/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.7914e-04 - tot_time: 0h 48m 44.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7919e-04 - val_loss: 7.8197e-04\n",
      "Epoch 1380/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.8064e-04 - tot_time: 0h 48m 45.4s\n",
      "\n",
      "Epoch 1380: val_loss did not improve from 0.00078\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8093e-04 - val_loss: 8.0268e-04\n",
      "Epoch 1381/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.8297e-04 - tot_time: 0h 48m 46.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8292e-04 - val_loss: 7.7905e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7991e-04 - tot_time: 0h 48m 47.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7991e-04 - val_loss: 7.7847e-04\n",
      "Epoch 1383/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.7818e-04 - tot_time: 0h 48m 48.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7813e-04 - val_loss: 7.7943e-04\n",
      "Epoch 1384/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7831e-04 - tot_time: 0h 48m 49.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7855e-04 - val_loss: 7.8297e-04\n",
      "Epoch 1385/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7930e-04 - tot_time: 0h 48m 49.9s\n",
      "\n",
      "Epoch 1385: val_loss did not improve from 0.00078\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7953e-04 - val_loss: 9.0904e-04\n",
      "Epoch 1386/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.8662e-04 - tot_time: 0h 48m 50.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.8574e-04 - val_loss: 7.8667e-04\n",
      "Epoch 1387/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7785e-04 - tot_time: 0h 48m 51.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7777e-04 - val_loss: 7.8611e-04\n",
      "Epoch 1388/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7778e-04 - tot_time: 0h 48m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7803e-04 - val_loss: 7.7929e-04\n",
      "Epoch 1389/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7585e-04 - tot_time: 0h 48m 53.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.7664e-04 - val_loss: 7.7504e-04\n",
      "Epoch 1390/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.7809e-04 - tot_time: 0h 48m 54.1s\n",
      "\n",
      "Epoch 1390: val_loss improved from 0.00078 to 0.00078, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7719e-04 - val_loss: 7.7504e-04\n",
      "Epoch 1391/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7703e-04 - tot_time: 0h 48m 55.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7698e-04 - val_loss: 7.7870e-04\n",
      "Epoch 1392/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7613e-04 - tot_time: 0h 48m 55.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7614e-04 - val_loss: 7.7912e-04\n",
      "Epoch 1393/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7597e-04 - tot_time: 0h 48m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7612e-04 - val_loss: 7.9199e-04\n",
      "Epoch 1394/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7732e-04 - tot_time: 0h 48m 57.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7780e-04 - val_loss: 7.7307e-04\n",
      "Epoch 1395/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7779e-04 - tot_time: 0h 48m 58.6s\n",
      "\n",
      "Epoch 1395: val_loss did not improve from 0.00078\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7655e-04 - val_loss: 7.8239e-04\n",
      "Epoch 1396/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7694e-04 - tot_time: 0h 48m 59.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7695e-04 - val_loss: 8.0210e-04\n",
      "Epoch 1397/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.7706e-04 - tot_time: 0h 49m 0.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7704e-04 - val_loss: 7.8210e-04\n",
      "Epoch 1398/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7725e-04 - tot_time: 0h 49m 1.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7732e-04 - val_loss: 7.8215e-04\n",
      "Epoch 1399/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7490e-04 - tot_time: 0h 49m 2.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7513e-04 - val_loss: 7.8204e-04\n",
      "Epoch 1400/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.7512e-04 - tot_time: 0h 49m 3.2s\n",
      "\n",
      "Epoch 1400: val_loss improved from 0.00078 to 0.00077, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7497e-04 - val_loss: 7.7174e-04\n",
      "Epoch 1401/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7416e-04 - tot_time: 0h 49m 4.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7416e-04 - val_loss: 7.7310e-04\n",
      "Epoch 1402/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7595e-04 - tot_time: 0h 49m 4.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7503e-04 - val_loss: 7.8202e-04\n",
      "Epoch 1403/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.8018e-04 - tot_time: 0h 49m 5.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7796e-04 - val_loss: 7.8552e-04\n",
      "Epoch 1404/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7306e-04 - tot_time: 0h 49m 6.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7306e-04 - val_loss: 7.7794e-04\n",
      "Epoch 1405/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.7488e-04 - tot_time: 0h 49m 7.6s\n",
      "\n",
      "Epoch 1405: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7513e-04 - val_loss: 7.7566e-04\n",
      "Epoch 1406/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.7488e-04 - tot_time: 0h 49m 8.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7509e-04 - val_loss: 7.8787e-04\n",
      "Epoch 1407/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.7441e-04 - tot_time: 0h 49m 9.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7439e-04 - val_loss: 8.3562e-04\n",
      "Epoch 1408/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7566e-04 - tot_time: 0h 49m 10.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.7566e-04 - val_loss: 7.7271e-04\n",
      "Epoch 1409/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7248e-04 - tot_time: 0h 49m 11.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7273e-04 - val_loss: 7.7770e-04\n",
      "Epoch 1410/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7504e-04 - tot_time: 0h 49m 12.1s\n",
      "\n",
      "Epoch 1410: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7449e-04 - val_loss: 7.8023e-04\n",
      "Epoch 1411/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7373e-04 - tot_time: 0h 49m 13.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7372e-04 - val_loss: 7.8272e-04\n",
      "Epoch 1412/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7322e-04 - tot_time: 0h 49m 13.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7322e-04 - val_loss: 7.7471e-04\n",
      "Epoch 1413/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7069e-04 - tot_time: 0h 49m 15.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.7160e-04 - val_loss: 7.7137e-04\n",
      "Epoch 1414/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7377e-04 - tot_time: 0h 49m 15.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7178e-04 - val_loss: 7.7248e-04\n",
      "Epoch 1415/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/124 [===========================>..] - ETA: 0s - loss: 7.7323e-04 - tot_time: 0h 49m 16.6s\n",
      "\n",
      "Epoch 1415: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7207e-04 - val_loss: 7.7484e-04\n",
      "Epoch 1416/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7235e-04 - tot_time: 0h 49m 17.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7235e-04 - val_loss: 7.7411e-04\n",
      "Epoch 1417/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.6996e-04 - tot_time: 0h 49m 18.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7244e-04 - val_loss: 7.9067e-04\n",
      "Epoch 1418/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.7415e-04 - tot_time: 0h 49m 19.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7410e-04 - val_loss: 7.6964e-04\n",
      "Epoch 1419/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.7247e-04 - tot_time: 0h 49m 20.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7249e-04 - val_loss: 7.6931e-04\n",
      "Epoch 1420/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7357e-04 - tot_time: 0h 49m 21.2s\n",
      "\n",
      "Epoch 1420: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.7275e-04 - val_loss: 7.8896e-04\n",
      "Epoch 1421/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.7038e-04 - tot_time: 0h 49m 22.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7268e-04 - val_loss: 7.7429e-04\n",
      "Epoch 1422/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6862e-04 - tot_time: 0h 49m 23.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6953e-04 - val_loss: 7.7940e-04\n",
      "Epoch 1423/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.7036e-04 - tot_time: 0h 49m 23.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.7068e-04 - val_loss: 7.8041e-04\n",
      "Epoch 1424/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7139e-04 - tot_time: 0h 49m 24.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7156e-04 - val_loss: 7.7946e-04\n",
      "Epoch 1425/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.7094e-04 - tot_time: 0h 49m 25.7s\n",
      "\n",
      "Epoch 1425: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7024e-04 - val_loss: 7.7682e-04\n",
      "Epoch 1426/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.7022e-04 - tot_time: 0h 49m 26.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.6986e-04 - val_loss: 7.7065e-04\n",
      "Epoch 1427/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6996e-04 - tot_time: 0h 49m 27.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6980e-04 - val_loss: 7.7276e-04\n",
      "Epoch 1428/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6934e-04 - tot_time: 0h 49m 28.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6945e-04 - val_loss: 7.7956e-04\n",
      "Epoch 1429/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6909e-04 - tot_time: 0h 49m 29.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.6995e-04 - val_loss: 7.7246e-04\n",
      "Epoch 1430/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6824e-04 - tot_time: 0h 49m 30.0s\n",
      "\n",
      "Epoch 1430: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6827e-04 - val_loss: 7.7179e-04\n",
      "Epoch 1431/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6748e-04 - tot_time: 0h 49m 31.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6857e-04 - val_loss: 7.7064e-04\n",
      "Epoch 1432/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6870e-04 - tot_time: 0h 49m 31.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6815e-04 - val_loss: 7.7054e-04\n",
      "Epoch 1433/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6772e-04 - tot_time: 0h 49m 32.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6772e-04 - val_loss: 7.7214e-04\n",
      "Epoch 1434/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.6803e-04 - tot_time: 0h 49m 33.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6879e-04 - val_loss: 7.6710e-04\n",
      "Epoch 1435/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.6683e-04 - tot_time: 0h 49m 34.6s\n",
      "\n",
      "Epoch 1435: val_loss improved from 0.00077 to 0.00077, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6678e-04 - val_loss: 7.7142e-04\n",
      "Epoch 1436/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6735e-04 - tot_time: 0h 49m 35.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6735e-04 - val_loss: 7.7556e-04\n",
      "Epoch 1437/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6913e-04 - tot_time: 0h 49m 36.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6763e-04 - val_loss: 7.7328e-04\n",
      "Epoch 1438/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6749e-04 - tot_time: 0h 49m 37.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6769e-04 - val_loss: 7.6603e-04\n",
      "Epoch 1439/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6708e-04 - tot_time: 0h 49m 38.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6708e-04 - val_loss: 7.7688e-04\n",
      "Epoch 1440/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6717e-04 - tot_time: 0h 49m 39.1s\n",
      "\n",
      "Epoch 1440: val_loss improved from 0.00077 to 0.00077, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6717e-04 - val_loss: 7.7106e-04\n",
      "Epoch 1441/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6655e-04 - tot_time: 0h 49m 40.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6728e-04 - val_loss: 7.7003e-04\n",
      "Epoch 1442/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6768e-04 - tot_time: 0h 49m 41.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6814e-04 - val_loss: 7.6852e-04\n",
      "Epoch 1443/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6708e-04 - tot_time: 0h 49m 41.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.6636e-04 - val_loss: 7.8099e-04\n",
      "Epoch 1444/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6762e-04 - tot_time: 0h 49m 42.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6756e-04 - val_loss: 7.6574e-04\n",
      "Epoch 1445/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6717e-04 - tot_time: 0h 49m 43.9s\n",
      "\n",
      "Epoch 1445: val_loss improved from 0.00077 to 0.00077, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6717e-04 - val_loss: 7.6729e-04\n",
      "Epoch 1446/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6727e-04 - tot_time: 0h 49m 44.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6725e-04 - val_loss: 7.6747e-04\n",
      "Epoch 1447/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6504e-04 - tot_time: 0h 49m 45.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6486e-04 - val_loss: 7.8148e-04\n",
      "Epoch 1448/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.6512e-04 - tot_time: 0h 49m 46.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6568e-04 - val_loss: 7.6574e-04\n",
      "Epoch 1449/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6591e-04 - tot_time: 0h 49m 47.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6591e-04 - val_loss: 7.7623e-04\n",
      "Epoch 1450/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6632e-04 - tot_time: 0h 49m 48.4s\n",
      "\n",
      "Epoch 1450: val_loss improved from 0.00077 to 0.00077, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6524e-04 - val_loss: 7.6554e-04\n",
      "Epoch 1451/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.6454e-04 - tot_time: 0h 49m 49.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6448e-04 - val_loss: 7.7065e-04\n",
      "Epoch 1452/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6606e-04 - tot_time: 0h 49m 50.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6606e-04 - val_loss: 7.6765e-04\n",
      "Epoch 1453/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6675e-04 - tot_time: 0h 49m 51.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6640e-04 - val_loss: 7.8697e-04\n",
      "Epoch 1454/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6527e-04 - tot_time: 0h 49m 52.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6631e-04 - val_loss: 7.7133e-04\n",
      "Epoch 1455/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6262e-04 - tot_time: 0h 49m 53.0s\n",
      "\n",
      "Epoch 1455: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6374e-04 - val_loss: 7.8095e-04\n",
      "Epoch 1456/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6698e-04 - tot_time: 0h 49m 54.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6717e-04 - val_loss: 7.7627e-04\n",
      "Epoch 1457/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6474e-04 - tot_time: 0h 49m 54.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6472e-04 - val_loss: 7.7250e-04\n",
      "Epoch 1458/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6643e-04 - tot_time: 0h 49m 55.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6505e-04 - val_loss: 7.7845e-04\n",
      "Epoch 1459/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6424e-04 - tot_time: 0h 49m 56.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6419e-04 - val_loss: 7.6566e-04\n",
      "Epoch 1460/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6297e-04 - tot_time: 0h 49m 57.3s\n",
      "\n",
      "Epoch 1460: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6331e-04 - val_loss: 7.7968e-04\n",
      "Epoch 1461/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7029e-04 - tot_time: 0h 49m 58.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7029e-04 - val_loss: 7.7140e-04\n",
      "Epoch 1462/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.6786e-04 - tot_time: 0h 49m 59.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6650e-04 - val_loss: 7.6508e-04\n",
      "Epoch 1463/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6310e-04 - tot_time: 0h 49m 59.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6310e-04 - val_loss: 7.6539e-04\n",
      "Epoch 1464/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6242e-04 - tot_time: 0h 50m 0.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6340e-04 - val_loss: 8.6284e-04\n",
      "Epoch 1465/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.6866e-04 - tot_time: 0h 50m 1.8s\n",
      "\n",
      "Epoch 1465: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7062e-04 - val_loss: 7.7782e-04\n",
      "Epoch 1466/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6350e-04 - tot_time: 0h 50m 2.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6346e-04 - val_loss: 7.6289e-04\n",
      "Epoch 1467/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6397e-04 - tot_time: 0h 50m 3.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6396e-04 - val_loss: 7.6097e-04\n",
      "Epoch 1468/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.6444e-04 - tot_time: 0h 50m 4.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6434e-04 - val_loss: 7.7322e-04\n",
      "Epoch 1469/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6210e-04 - tot_time: 0h 50m 5.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6210e-04 - val_loss: 7.8076e-04\n",
      "Epoch 1470/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6288e-04 - tot_time: 0h 50m 6.3s\n",
      "\n",
      "Epoch 1470: val_loss did not improve from 0.00077\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6293e-04 - val_loss: 7.8484e-04\n",
      "Epoch 1471/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6408e-04 - tot_time: 0h 50m 7.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6408e-04 - val_loss: 7.6158e-04\n",
      "Epoch 1472/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6209e-04 - tot_time: 0h 50m 8.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6156e-04 - val_loss: 7.7105e-04\n",
      "Epoch 1473/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6225e-04 - tot_time: 0h 50m 9.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6203e-04 - val_loss: 7.6281e-04\n",
      "Epoch 1474/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.6179e-04 - tot_time: 0h 50m 9.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6060e-04 - val_loss: 7.6154e-04\n",
      "Epoch 1475/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6114e-04 - tot_time: 0h 50m 10.7s\n",
      "\n",
      "Epoch 1475: val_loss improved from 0.00077 to 0.00076, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6195e-04 - val_loss: 7.6195e-04\n",
      "Epoch 1476/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6171e-04 - tot_time: 0h 50m 11.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6070e-04 - val_loss: 7.7070e-04\n",
      "Epoch 1477/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6261e-04 - tot_time: 0h 50m 12.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.6171e-04 - val_loss: 7.6535e-04\n",
      "Epoch 1478/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6288e-04 - tot_time: 0h 50m 13.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6298e-04 - val_loss: 7.7185e-04\n",
      "Epoch 1479/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6168e-04 - tot_time: 0h 50m 14.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6160e-04 - val_loss: 7.6117e-04\n",
      "Epoch 1480/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.6067e-04 - tot_time: 0h 50m 15.2s\n",
      "\n",
      "Epoch 1480: val_loss did not improve from 0.00076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6077e-04 - val_loss: 7.6615e-04\n",
      "Epoch 1481/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6084e-04 - tot_time: 0h 50m 16.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6084e-04 - val_loss: 7.6294e-04\n",
      "Epoch 1482/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6120e-04 - tot_time: 0h 50m 17.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6118e-04 - val_loss: 7.6930e-04\n",
      "Epoch 1483/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.6225e-04 - tot_time: 0h 50m 18.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6039e-04 - val_loss: 7.6331e-04\n",
      "Epoch 1484/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.6208e-04 - tot_time: 0h 50m 18.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6246e-04 - val_loss: 7.6249e-04\n",
      "Epoch 1485/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.6148e-04 - tot_time: 0h 50m 19.7s\n",
      "\n",
      "Epoch 1485: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5900e-04 - val_loss: 7.6208e-04\n",
      "Epoch 1486/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5933e-04 - tot_time: 0h 50m 20.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5927e-04 - val_loss: 7.6178e-04\n",
      "Epoch 1487/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6024e-04 - tot_time: 0h 50m 21.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6020e-04 - val_loss: 7.6315e-04\n",
      "Epoch 1488/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.6149e-04 - tot_time: 0h 50m 22.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6007e-04 - val_loss: 7.7070e-04\n",
      "Epoch 1489/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.6392e-04 - tot_time: 0h 50m 23.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6267e-04 - val_loss: 7.6773e-04\n",
      "Epoch 1490/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6094e-04 - tot_time: 0h 50m 24.3s\n",
      "\n",
      "Epoch 1490: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6043e-04 - val_loss: 7.6410e-04\n",
      "Epoch 1491/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5872e-04 - tot_time: 0h 50m 25.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5879e-04 - val_loss: 7.6847e-04\n",
      "Epoch 1492/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5832e-04 - tot_time: 0h 50m 26.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5948e-04 - val_loss: 7.7093e-04\n",
      "Epoch 1493/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6034e-04 - tot_time: 0h 50m 27.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6031e-04 - val_loss: 7.6296e-04\n",
      "Epoch 1494/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5913e-04 - tot_time: 0h 50m 27.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5964e-04 - val_loss: 7.6578e-04\n",
      "Epoch 1495/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5968e-04 - tot_time: 0h 50m 28.8s\n",
      "\n",
      "Epoch 1495: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5969e-04 - val_loss: 7.7005e-04\n",
      "Epoch 1496/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.6098e-04 - tot_time: 0h 50m 29.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6093e-04 - val_loss: 7.6284e-04\n",
      "Epoch 1497/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6043e-04 - tot_time: 0h 50m 30.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.6043e-04 - val_loss: 7.6500e-04\n",
      "Epoch 1498/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5810e-04 - tot_time: 0h 50m 31.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5806e-04 - val_loss: 7.6315e-04\n",
      "Epoch 1499/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5665e-04 - tot_time: 0h 50m 32.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5772e-04 - val_loss: 7.6035e-04\n",
      "Epoch 1500/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5936e-04 - tot_time: 0h 50m 33.2s\n",
      "\n",
      "Epoch 1500: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5817e-04 - val_loss: 7.6822e-04\n",
      "Epoch 1501/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5645e-04 - tot_time: 0h 50m 34.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5805e-04 - val_loss: 7.7992e-04\n",
      "Epoch 1502/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5944e-04 - tot_time: 0h 50m 35.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5944e-04 - val_loss: 7.6078e-04\n",
      "Epoch 1503/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5854e-04 - tot_time: 0h 50m 35.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5784e-04 - val_loss: 7.8214e-04\n",
      "Epoch 1504/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.6391e-04 - tot_time: 0h 50m 36.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6307e-04 - val_loss: 7.6639e-04\n",
      "Epoch 1505/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6101e-04 - tot_time: 0h 50m 37.6s\n",
      "\n",
      "Epoch 1505: val_loss improved from 0.00076 to 0.00076, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5970e-04 - val_loss: 7.6190e-04\n",
      "Epoch 1506/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5738e-04 - tot_time: 0h 50m 38.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5738e-04 - val_loss: 7.6354e-04\n",
      "Epoch 1507/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5653e-04 - tot_time: 0h 50m 39.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5746e-04 - val_loss: 7.6397e-04\n",
      "Epoch 1508/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5567e-04 - tot_time: 0h 50m 40.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5750e-04 - val_loss: 7.6204e-04\n",
      "Epoch 1509/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5839e-04 - tot_time: 0h 50m 41.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5871e-04 - val_loss: 9.1478e-04\n",
      "Epoch 1510/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6610e-04 - tot_time: 0h 50m 42.2s\n",
      "\n",
      "Epoch 1510: val_loss improved from 0.00076 to 0.00076, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.6582e-04 - val_loss: 7.5953e-04\n",
      "Epoch 1511/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5724e-04 - tot_time: 0h 50m 43.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5747e-04 - val_loss: 7.6585e-04\n",
      "Epoch 1512/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5729e-04 - tot_time: 0h 50m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5751e-04 - val_loss: 7.7207e-04\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/124 [============================>.] - ETA: 0s - loss: 7.5843e-04 - tot_time: 0h 50m 45.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5839e-04 - val_loss: 7.5783e-04\n",
      "Epoch 1514/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5717e-04 - tot_time: 0h 50m 45.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5695e-04 - val_loss: 7.5782e-04\n",
      "Epoch 1515/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5790e-04 - tot_time: 0h 50m 46.8s\n",
      "\n",
      "Epoch 1515: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5643e-04 - val_loss: 7.6064e-04\n",
      "Epoch 1516/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.5601e-04 - tot_time: 0h 50m 47.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5643e-04 - val_loss: 7.6017e-04\n",
      "Epoch 1517/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5561e-04 - tot_time: 0h 50m 48.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5561e-04 - val_loss: 7.7033e-04\n",
      "Epoch 1518/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5584e-04 - tot_time: 0h 50m 49.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5584e-04 - val_loss: 7.6275e-04\n",
      "Epoch 1519/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5777e-04 - tot_time: 0h 50m 50.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5764e-04 - val_loss: 7.5949e-04\n",
      "Epoch 1520/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5707e-04 - tot_time: 0h 50m 51.1s\n",
      "\n",
      "Epoch 1520: val_loss improved from 0.00076 to 0.00076, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5649e-04 - val_loss: 7.5813e-04\n",
      "Epoch 1521/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5612e-04 - tot_time: 0h 50m 52.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5607e-04 - val_loss: 7.5656e-04\n",
      "Epoch 1522/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5663e-04 - tot_time: 0h 50m 53.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5634e-04 - val_loss: 7.6319e-04\n",
      "Epoch 1523/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5579e-04 - tot_time: 0h 50m 53.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5616e-04 - val_loss: 7.6421e-04\n",
      "Epoch 1524/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5693e-04 - tot_time: 0h 50m 54.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5656e-04 - val_loss: 7.5662e-04\n",
      "Epoch 1525/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5479e-04 - tot_time: 0h 50m 55.6s\n",
      "\n",
      "Epoch 1525: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5534e-04 - val_loss: 7.6923e-04\n",
      "Epoch 1526/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5530e-04 - tot_time: 0h 50m 56.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5530e-04 - val_loss: 7.5959e-04\n",
      "Epoch 1527/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5604e-04 - tot_time: 0h 50m 57.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5603e-04 - val_loss: 7.5679e-04\n",
      "Epoch 1528/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5356e-04 - tot_time: 0h 50m 58.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5519e-04 - val_loss: 7.6206e-04\n",
      "Epoch 1529/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5515e-04 - tot_time: 0h 50m 59.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5510e-04 - val_loss: 7.7703e-04\n",
      "Epoch 1530/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5646e-04 - tot_time: 0h 51m 0.1s\n",
      "\n",
      "Epoch 1530: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5721e-04 - val_loss: 7.7217e-04\n",
      "Epoch 1531/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5634e-04 - tot_time: 0h 51m 0.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5723e-04 - val_loss: 7.6646e-04\n",
      "Epoch 1532/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5424e-04 - tot_time: 0h 51m 1.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5420e-04 - val_loss: 7.5529e-04\n",
      "Epoch 1533/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5599e-04 - tot_time: 0h 51m 2.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5593e-04 - val_loss: 7.5628e-04\n",
      "Epoch 1534/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5393e-04 - tot_time: 0h 51m 3.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5403e-04 - val_loss: 7.7546e-04\n",
      "Epoch 1535/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5851e-04 - tot_time: 0h 51m 4.4s\n",
      "\n",
      "Epoch 1535: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5775e-04 - val_loss: 7.6130e-04\n",
      "Epoch 1536/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5443e-04 - tot_time: 0h 51m 5.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5439e-04 - val_loss: 7.5877e-04\n",
      "Epoch 1537/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.5429e-04 - tot_time: 0h 51m 5.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5394e-04 - val_loss: 7.5697e-04\n",
      "Epoch 1538/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5429e-04 - tot_time: 0h 51m 6.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5429e-04 - val_loss: 7.5897e-04\n",
      "Epoch 1539/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5428e-04 - tot_time: 0h 51m 7.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5428e-04 - val_loss: 7.6086e-04\n",
      "Epoch 1540/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.5234e-04 - tot_time: 0h 51m 8.3s\n",
      "\n",
      "Epoch 1540: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5427e-04 - val_loss: 7.7247e-04\n",
      "Epoch 1541/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5622e-04 - tot_time: 0h 51m 9.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5618e-04 - val_loss: 7.5432e-04\n",
      "Epoch 1542/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5437e-04 - tot_time: 0h 51m 10.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5381e-04 - val_loss: 7.6858e-04\n",
      "Epoch 1543/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5503e-04 - tot_time: 0h 51m 11.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5338e-04 - val_loss: 7.5763e-04\n",
      "Epoch 1544/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5184e-04 - tot_time: 0h 51m 11.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5415e-04 - val_loss: 7.5494e-04\n",
      "Epoch 1545/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5584e-04 - tot_time: 0h 51m 12.9s\n",
      "\n",
      "Epoch 1545: val_loss improved from 0.00076 to 0.00076, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.5639e-04 - val_loss: 7.5704e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1546/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5409e-04 - tot_time: 0h 51m 13.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5343e-04 - val_loss: 7.6436e-04\n",
      "Epoch 1547/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5325e-04 - tot_time: 0h 51m 14.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5383e-04 - val_loss: 7.6078e-04\n",
      "Epoch 1548/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5303e-04 - tot_time: 0h 51m 15.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5251e-04 - val_loss: 7.5665e-04\n",
      "Epoch 1549/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4971e-04 - tot_time: 0h 51m 16.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5259e-04 - val_loss: 7.5406e-04\n",
      "Epoch 1550/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5350e-04 - tot_time: 0h 51m 17.2s\n",
      "\n",
      "Epoch 1550: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5345e-04 - val_loss: 7.6631e-04\n",
      "Epoch 1551/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5374e-04 - tot_time: 0h 51m 18.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5273e-04 - val_loss: 7.6433e-04\n",
      "Epoch 1552/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5304e-04 - tot_time: 0h 51m 18.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5247e-04 - val_loss: 7.5414e-04\n",
      "Epoch 1553/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5305e-04 - tot_time: 0h 51m 19.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5304e-04 - val_loss: 7.7792e-04\n",
      "Epoch 1554/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.5403e-04 - tot_time: 0h 51m 20.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5562e-04 - val_loss: 7.5695e-04\n",
      "Epoch 1555/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5394e-04 - tot_time: 0h 51m 21.5s\n",
      "\n",
      "Epoch 1555: val_loss did not improve from 0.00076\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5389e-04 - val_loss: 7.6108e-04\n",
      "Epoch 1556/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5271e-04 - tot_time: 0h 51m 22.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5220e-04 - val_loss: 7.5496e-04\n",
      "Epoch 1557/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5168e-04 - tot_time: 0h 51m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5145e-04 - val_loss: 7.6147e-04\n",
      "Epoch 1558/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5485e-04 - tot_time: 0h 51m 24.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5480e-04 - val_loss: 7.5428e-04\n",
      "Epoch 1559/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5389e-04 - tot_time: 0h 51m 25.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5258e-04 - val_loss: 7.5724e-04\n",
      "Epoch 1560/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.5228e-04 - tot_time: 0h 51m 25.9s\n",
      "\n",
      "Epoch 1560: val_loss improved from 0.00076 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5214e-04 - val_loss: 7.5483e-04\n",
      "Epoch 1561/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5286e-04 - tot_time: 0h 51m 26.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5286e-04 - val_loss: 7.5551e-04\n",
      "Epoch 1562/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5294e-04 - tot_time: 0h 51m 27.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5152e-04 - val_loss: 7.5894e-04\n",
      "Epoch 1563/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.5284e-04 - tot_time: 0h 51m 28.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5303e-04 - val_loss: 7.5303e-04\n",
      "Epoch 1564/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5250e-04 - tot_time: 0h 51m 29.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5250e-04 - val_loss: 7.5467e-04\n",
      "Epoch 1565/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5321e-04 - tot_time: 0h 51m 30.2s\n",
      "\n",
      "Epoch 1565: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5239e-04 - val_loss: 8.7702e-04\n",
      "Epoch 1566/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.6046e-04 - tot_time: 0h 51m 31.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6133e-04 - val_loss: 7.5397e-04\n",
      "Epoch 1567/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5114e-04 - tot_time: 0h 51m 31.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5139e-04 - val_loss: 7.5445e-04\n",
      "Epoch 1568/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5121e-04 - tot_time: 0h 51m 32.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5117e-04 - val_loss: 7.5598e-04\n",
      "Epoch 1569/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5076e-04 - tot_time: 0h 51m 33.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5183e-04 - val_loss: 7.6494e-04\n",
      "Epoch 1570/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4970e-04 - tot_time: 0h 51m 34.3s\n",
      "\n",
      "Epoch 1570: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5062e-04 - val_loss: 7.5691e-04\n",
      "Epoch 1571/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5112e-04 - tot_time: 0h 51m 35.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5150e-04 - val_loss: 7.5730e-04\n",
      "Epoch 1572/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5235e-04 - tot_time: 0h 51m 36.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5227e-04 - val_loss: 7.5533e-04\n",
      "Epoch 1573/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5007e-04 - tot_time: 0h 51m 36.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.5001e-04 - val_loss: 7.6441e-04\n",
      "Epoch 1574/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5170e-04 - tot_time: 0h 51m 37.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5178e-04 - val_loss: 7.6405e-04\n",
      "Epoch 1575/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5302e-04 - tot_time: 0h 51m 38.6s\n",
      "\n",
      "Epoch 1575: val_loss improved from 0.00075 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5193e-04 - val_loss: 7.5369e-04\n",
      "Epoch 1576/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5034e-04 - tot_time: 0h 51m 39.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5029e-04 - val_loss: 7.5300e-04\n",
      "Epoch 1577/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.5255e-04 - tot_time: 0h 51m 40.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5184e-04 - val_loss: 7.5589e-04\n",
      "Epoch 1578/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5113e-04 - tot_time: 0h 51m 41.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5022e-04 - val_loss: 7.6359e-04\n",
      "Epoch 1579/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/124 [============================>.] - ETA: 0s - loss: 7.4950e-04 - tot_time: 0h 51m 42.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4947e-04 - val_loss: 7.5660e-04\n",
      "Epoch 1580/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5001e-04 - tot_time: 0h 51m 43.1s\n",
      "\n",
      "Epoch 1580: val_loss improved from 0.00075 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.5001e-04 - val_loss: 7.5203e-04\n",
      "Epoch 1581/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4940e-04 - tot_time: 0h 51m 43.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4936e-04 - val_loss: 7.6974e-04\n",
      "Epoch 1582/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5087e-04 - tot_time: 0h 51m 44.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5103e-04 - val_loss: 7.5252e-04\n",
      "Epoch 1583/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5030e-04 - tot_time: 0h 51m 45.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5026e-04 - val_loss: 7.5340e-04\n",
      "Epoch 1584/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5026e-04 - tot_time: 0h 51m 46.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5022e-04 - val_loss: 7.5154e-04\n",
      "Epoch 1585/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.5058e-04 - tot_time: 0h 51m 47.4s\n",
      "\n",
      "Epoch 1585: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4956e-04 - val_loss: 7.6250e-04\n",
      "Epoch 1586/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5014e-04 - tot_time: 0h 51m 48.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5009e-04 - val_loss: 7.5959e-04\n",
      "Epoch 1587/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5041e-04 - tot_time: 0h 51m 49.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5041e-04 - val_loss: 7.5702e-04\n",
      "Epoch 1588/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5029e-04 - tot_time: 0h 51m 50.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5033e-04 - val_loss: 7.5623e-04\n",
      "Epoch 1589/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4934e-04 - tot_time: 0h 51m 50.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5031e-04 - val_loss: 7.5722e-04\n",
      "Epoch 1590/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4910e-04 - tot_time: 0h 51m 51.6s\n",
      "\n",
      "Epoch 1590: val_loss improved from 0.00075 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4910e-04 - val_loss: 7.5026e-04\n",
      "Epoch 1591/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4963e-04 - tot_time: 0h 51m 52.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4963e-04 - val_loss: 7.4985e-04\n",
      "Epoch 1592/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5011e-04 - tot_time: 0h 51m 53.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5011e-04 - val_loss: 7.7430e-04\n",
      "Epoch 1593/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.4844e-04 - tot_time: 0h 51m 54.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4993e-04 - val_loss: 7.5335e-04\n",
      "Epoch 1594/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.5111e-04 - tot_time: 0h 51m 55.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5105e-04 - val_loss: 7.5433e-04\n",
      "Epoch 1595/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5132e-04 - tot_time: 0h 51m 56.0s\n",
      "\n",
      "Epoch 1595: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5059e-04 - val_loss: 7.5207e-04\n",
      "Epoch 1596/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4756e-04 - tot_time: 0h 51m 56.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4779e-04 - val_loss: 7.5357e-04\n",
      "Epoch 1597/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.5020e-04 - tot_time: 0h 51m 57.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4977e-04 - val_loss: 7.5227e-04\n",
      "Epoch 1598/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4718e-04 - tot_time: 0h 51m 58.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4871e-04 - val_loss: 7.5058e-04\n",
      "Epoch 1599/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4883e-04 - tot_time: 0h 51m 59.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4802e-04 - val_loss: 7.5215e-04\n",
      "Epoch 1600/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.5029e-04 - tot_time: 0h 52m 0.3s\n",
      "\n",
      "Epoch 1600: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5030e-04 - val_loss: 7.5308e-04\n",
      "Epoch 1601/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4815e-04 - tot_time: 0h 52m 1.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4811e-04 - val_loss: 7.5418e-04\n",
      "Epoch 1602/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4988e-04 - tot_time: 0h 52m 1.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4959e-04 - val_loss: 7.5414e-04\n",
      "Epoch 1603/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4902e-04 - tot_time: 0h 52m 2.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4883e-04 - val_loss: 7.5132e-04\n",
      "Epoch 1604/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4807e-04 - tot_time: 0h 52m 3.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4802e-04 - val_loss: 7.5761e-04\n",
      "Epoch 1605/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.4727e-04 - tot_time: 0h 52m 4.4s\n",
      "\n",
      "Epoch 1605: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4857e-04 - val_loss: 7.5470e-04\n",
      "Epoch 1606/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4885e-04 - tot_time: 0h 52m 5.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4868e-04 - val_loss: 7.5562e-04\n",
      "Epoch 1607/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4876e-04 - tot_time: 0h 52m 6.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4837e-04 - val_loss: 7.5480e-04\n",
      "Epoch 1608/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 7.4658e-04 - tot_time: 0h 52m 7.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4752e-04 - val_loss: 7.7158e-04\n",
      "Epoch 1609/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.5228e-04 - tot_time: 0h 52m 7.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5122e-04 - val_loss: 7.5754e-04\n",
      "Epoch 1610/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4787e-04 - tot_time: 0h 52m 8.8s\n",
      "\n",
      "Epoch 1610: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4765e-04 - val_loss: 7.6149e-04\n",
      "Epoch 1611/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4708e-04 - tot_time: 0h 52m 9.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4711e-04 - val_loss: 7.5212e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1612/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4893e-04 - tot_time: 0h 52m 10.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4739e-04 - val_loss: 7.5273e-04\n",
      "Epoch 1613/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4878e-04 - tot_time: 0h 52m 11.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4873e-04 - val_loss: 7.5609e-04\n",
      "Epoch 1614/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4960e-04 - tot_time: 0h 52m 12.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4899e-04 - val_loss: 7.4825e-04\n",
      "Epoch 1615/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4717e-04 - tot_time: 0h 52m 13.2s\n",
      "\n",
      "Epoch 1615: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4714e-04 - val_loss: 7.7325e-04\n",
      "Epoch 1616/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.4713e-04 - tot_time: 0h 52m 14.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4803e-04 - val_loss: 7.5068e-04\n",
      "Epoch 1617/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4771e-04 - tot_time: 0h 52m 15.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4736e-04 - val_loss: 7.5285e-04\n",
      "Epoch 1618/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4780e-04 - tot_time: 0h 52m 16.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4763e-04 - val_loss: 7.5472e-04\n",
      "Epoch 1619/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4629e-04 - tot_time: 0h 52m 16.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4634e-04 - val_loss: 7.5377e-04\n",
      "Epoch 1620/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4605e-04 - tot_time: 0h 52m 17.5s\n",
      "\n",
      "Epoch 1620: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4606e-04 - val_loss: 7.6716e-04\n",
      "Epoch 1621/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4929e-04 - tot_time: 0h 52m 18.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4838e-04 - val_loss: 7.7883e-04\n",
      "Epoch 1622/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4636e-04 - tot_time: 0h 52m 19.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4751e-04 - val_loss: 7.5843e-04\n",
      "Epoch 1623/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4873e-04 - tot_time: 0h 52m 20.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4750e-04 - val_loss: 7.5286e-04\n",
      "Epoch 1624/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4725e-04 - tot_time: 0h 52m 21.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4743e-04 - val_loss: 7.5380e-04\n",
      "Epoch 1625/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4627e-04 - tot_time: 0h 52m 21.9s\n",
      "\n",
      "Epoch 1625: val_loss improved from 0.00075 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4758e-04 - val_loss: 7.4843e-04\n",
      "Epoch 1626/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4683e-04 - tot_time: 0h 52m 22.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4683e-04 - val_loss: 7.5090e-04\n",
      "Epoch 1627/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4488e-04 - tot_time: 0h 52m 23.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4537e-04 - val_loss: 7.5050e-04\n",
      "Epoch 1628/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4566e-04 - tot_time: 0h 52m 24.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4604e-04 - val_loss: 7.6478e-04\n",
      "Epoch 1629/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4859e-04 - tot_time: 0h 52m 25.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4789e-04 - val_loss: 7.4899e-04\n",
      "Epoch 1630/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4595e-04 - tot_time: 0h 52m 26.5s\n",
      "\n",
      "Epoch 1630: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4624e-04 - val_loss: 7.5620e-04\n",
      "Epoch 1631/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.4779e-04 - tot_time: 0h 52m 27.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4843e-04 - val_loss: 7.5575e-04\n",
      "Epoch 1632/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4660e-04 - tot_time: 0h 52m 27.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4661e-04 - val_loss: 7.6555e-04\n",
      "Epoch 1633/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4603e-04 - tot_time: 0h 52m 28.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4614e-04 - val_loss: 7.5006e-04\n",
      "Epoch 1634/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4661e-04 - tot_time: 0h 52m 29.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4680e-04 - val_loss: 8.4824e-04\n",
      "Epoch 1635/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5342e-04 - tot_time: 0h 52m 30.5s\n",
      "\n",
      "Epoch 1635: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.5342e-04 - val_loss: 7.6362e-04\n",
      "Epoch 1636/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4696e-04 - tot_time: 0h 52m 31.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4608e-04 - val_loss: 7.4957e-04\n",
      "Epoch 1637/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4712e-04 - tot_time: 0h 52m 32.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4595e-04 - val_loss: 7.4919e-04\n",
      "Epoch 1638/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4595e-04 - tot_time: 0h 52m 32.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4532e-04 - val_loss: 7.4904e-04\n",
      "Epoch 1639/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4560e-04 - tot_time: 0h 52m 33.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4565e-04 - val_loss: 7.5051e-04\n",
      "Epoch 1640/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4616e-04 - tot_time: 0h 52m 34.7s\n",
      "\n",
      "Epoch 1640: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4616e-04 - val_loss: 7.5404e-04\n",
      "Epoch 1641/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4528e-04 - tot_time: 0h 52m 35.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4534e-04 - val_loss: 7.4906e-04\n",
      "Epoch 1642/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4595e-04 - tot_time: 0h 52m 36.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4591e-04 - val_loss: 7.5124e-04\n",
      "Epoch 1643/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4744e-04 - tot_time: 0h 52m 37.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4644e-04 - val_loss: 7.5401e-04\n",
      "Epoch 1644/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4380e-04 - tot_time: 0h 52m 38.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4502e-04 - val_loss: 8.8130e-04\n",
      "Epoch 1645/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.6441e-04 - tot_time: 0h 52m 38.9s\n",
      "\n",
      "Epoch 1645: val_loss did not improve from 0.00075\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6302e-04 - val_loss: 7.4997e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1646/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4556e-04 - tot_time: 0h 52m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4537e-04 - val_loss: 7.5077e-04\n",
      "Epoch 1647/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4084e-04 - tot_time: 0h 52m 40.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4414e-04 - val_loss: 7.4606e-04\n",
      "Epoch 1648/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4424e-04 - tot_time: 0h 52m 41.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4450e-04 - val_loss: 7.5634e-04\n",
      "Epoch 1649/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.4814e-04 - tot_time: 0h 52m 42.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4585e-04 - val_loss: 7.5169e-04\n",
      "Epoch 1650/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4454e-04 - tot_time: 0h 52m 43.1s\n",
      "\n",
      "Epoch 1650: val_loss improved from 0.00075 to 0.00075, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4366e-04 - val_loss: 7.4809e-04\n",
      "Epoch 1651/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4498e-04 - tot_time: 0h 52m 44.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4498e-04 - val_loss: 7.6295e-04\n",
      "Epoch 1652/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4446e-04 - tot_time: 0h 52m 44.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4446e-04 - val_loss: 7.5998e-04\n",
      "Epoch 1653/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4571e-04 - tot_time: 0h 52m 45.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4706e-04 - val_loss: 7.4748e-04\n",
      "Epoch 1654/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4386e-04 - tot_time: 0h 52m 46.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4399e-04 - val_loss: 7.5169e-04\n",
      "Epoch 1655/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4543e-04 - tot_time: 0h 52m 47.5s\n",
      "\n",
      "Epoch 1655: val_loss improved from 0.00075 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4479e-04 - val_loss: 7.4491e-04\n",
      "Epoch 1656/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4486e-04 - tot_time: 0h 52m 48.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4437e-04 - val_loss: 7.4691e-04\n",
      "Epoch 1657/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4368e-04 - tot_time: 0h 52m 49.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4359e-04 - val_loss: 7.8794e-04\n",
      "Epoch 1658/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4658e-04 - tot_time: 0h 52m 50.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4658e-04 - val_loss: 7.4629e-04\n",
      "Epoch 1659/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4427e-04 - tot_time: 0h 52m 51.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4431e-04 - val_loss: 7.5613e-04\n",
      "Epoch 1660/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4498e-04 - tot_time: 0h 52m 52.0s\n",
      "\n",
      "Epoch 1660: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4495e-04 - val_loss: 7.5298e-04\n",
      "Epoch 1661/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4414e-04 - tot_time: 0h 52m 52.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4414e-04 - val_loss: 7.4632e-04\n",
      "Epoch 1662/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4402e-04 - tot_time: 0h 52m 53.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4336e-04 - val_loss: 7.4827e-04\n",
      "Epoch 1663/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4386e-04 - tot_time: 0h 52m 54.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4368e-04 - val_loss: 7.5266e-04\n",
      "Epoch 1664/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.4841e-04 - tot_time: 0h 52m 55.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4605e-04 - val_loss: 8.0942e-04\n",
      "Epoch 1665/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4768e-04 - tot_time: 0h 52m 56.0s\n",
      "\n",
      "Epoch 1665: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4768e-04 - val_loss: 7.4510e-04\n",
      "Epoch 1666/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4431e-04 - tot_time: 0h 52m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4431e-04 - val_loss: 7.4526e-04\n",
      "Epoch 1667/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4350e-04 - tot_time: 0h 52m 57.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4352e-04 - val_loss: 7.5099e-04\n",
      "Epoch 1668/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4392e-04 - tot_time: 0h 52m 58.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4392e-04 - val_loss: 7.6734e-04\n",
      "Epoch 1669/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4493e-04 - tot_time: 0h 52m 59.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4511e-04 - val_loss: 7.5308e-04\n",
      "Epoch 1670/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.4138e-04 - tot_time: 0h 53m 0.2s\n",
      "\n",
      "Epoch 1670: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4337e-04 - val_loss: 7.7117e-04\n",
      "Epoch 1671/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4976e-04 - tot_time: 0h 53m 1.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4804e-04 - val_loss: 7.5195e-04\n",
      "Epoch 1672/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4281e-04 - tot_time: 0h 53m 2.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4277e-04 - val_loss: 7.4616e-04\n",
      "Epoch 1673/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4298e-04 - tot_time: 0h 53m 2.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4279e-04 - val_loss: 7.4852e-04\n",
      "Epoch 1674/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4395e-04 - tot_time: 0h 53m 3.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4371e-04 - val_loss: 7.4771e-04\n",
      "Epoch 1675/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4366e-04 - tot_time: 0h 53m 4.7s\n",
      "\n",
      "Epoch 1675: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4320e-04 - val_loss: 7.5416e-04\n",
      "Epoch 1676/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4443e-04 - tot_time: 0h 53m 5.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4420e-04 - val_loss: 7.5011e-04\n",
      "Epoch 1677/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4278e-04 - tot_time: 0h 53m 6.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4318e-04 - val_loss: 7.7721e-04\n",
      "Epoch 1678/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4718e-04 - tot_time: 0h 53m 7.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4696e-04 - val_loss: 7.4808e-04\n",
      "Epoch 1679/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 7.4305e-04 - tot_time: 0h 53m 8.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4319e-04 - val_loss: 7.4486e-04\n",
      "Epoch 1680/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4325e-04 - tot_time: 0h 53m 9.0s\n",
      "\n",
      "Epoch 1680: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4242e-04 - val_loss: 7.5213e-04\n",
      "Epoch 1681/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4206e-04 - tot_time: 0h 53m 10.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4318e-04 - val_loss: 7.6539e-04\n",
      "Epoch 1682/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.4684e-04 - tot_time: 0h 53m 10.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4555e-04 - val_loss: 7.6988e-04\n",
      "Epoch 1683/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4518e-04 - tot_time: 0h 53m 11.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4518e-04 - val_loss: 7.4959e-04\n",
      "Epoch 1684/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4469e-04 - tot_time: 0h 53m 12.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4438e-04 - val_loss: 7.4646e-04\n",
      "Epoch 1685/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4138e-04 - tot_time: 0h 53m 13.4s\n",
      "\n",
      "Epoch 1685: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4134e-04 - val_loss: 7.4902e-04\n",
      "Epoch 1686/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4325e-04 - tot_time: 0h 53m 14.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4325e-04 - val_loss: 7.4661e-04\n",
      "Epoch 1687/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4260e-04 - tot_time: 0h 53m 15.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4241e-04 - val_loss: 7.6202e-04\n",
      "Epoch 1688/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4250e-04 - tot_time: 0h 53m 16.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4290e-04 - val_loss: 7.7620e-04\n",
      "Epoch 1689/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4511e-04 - tot_time: 0h 53m 17.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4449e-04 - val_loss: 7.4658e-04\n",
      "Epoch 1690/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4236e-04 - tot_time: 0h 53m 18.0s\n",
      "\n",
      "Epoch 1690: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4232e-04 - val_loss: 7.4732e-04\n",
      "Epoch 1691/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4189e-04 - tot_time: 0h 53m 18.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4187e-04 - val_loss: 7.4516e-04\n",
      "Epoch 1692/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4202e-04 - tot_time: 0h 53m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4199e-04 - val_loss: 7.4946e-04\n",
      "Epoch 1693/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4222e-04 - tot_time: 0h 53m 20.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4222e-04 - val_loss: 7.4906e-04\n",
      "Epoch 1694/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4354e-04 - tot_time: 0h 53m 21.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4256e-04 - val_loss: 7.4363e-04\n",
      "Epoch 1695/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4178e-04 - tot_time: 0h 53m 22.1s\n",
      "\n",
      "Epoch 1695: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4181e-04 - val_loss: 7.5808e-04\n",
      "Epoch 1696/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4210e-04 - tot_time: 0h 53m 23.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4188e-04 - val_loss: 7.4457e-04\n",
      "Epoch 1697/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4094e-04 - tot_time: 0h 53m 23.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4111e-04 - val_loss: 7.4685e-04\n",
      "Epoch 1698/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4230e-04 - tot_time: 0h 53m 24.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4129e-04 - val_loss: 7.4309e-04\n",
      "Epoch 1699/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4158e-04 - tot_time: 0h 53m 25.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4128e-04 - val_loss: 7.4522e-04\n",
      "Epoch 1700/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4184e-04 - tot_time: 0h 53m 26.3s\n",
      "\n",
      "Epoch 1700: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4183e-04 - val_loss: 7.5629e-04\n",
      "Epoch 1701/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4321e-04 - tot_time: 0h 53m 27.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4354e-04 - val_loss: 7.4499e-04\n",
      "Epoch 1702/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4216e-04 - tot_time: 0h 53m 28.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4216e-04 - val_loss: 7.5394e-04\n",
      "Epoch 1703/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4271e-04 - tot_time: 0h 53m 28.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4270e-04 - val_loss: 7.5003e-04\n",
      "Epoch 1704/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4157e-04 - tot_time: 0h 53m 29.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4247e-04 - val_loss: 7.4598e-04\n",
      "Epoch 1705/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4198e-04 - tot_time: 0h 53m 30.6s\n",
      "\n",
      "Epoch 1705: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4222e-04 - val_loss: 7.4682e-04\n",
      "Epoch 1706/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4052e-04 - tot_time: 0h 53m 31.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4052e-04 - val_loss: 7.8263e-04\n",
      "Epoch 1707/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4746e-04 - tot_time: 0h 53m 32.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4554e-04 - val_loss: 7.4509e-04\n",
      "Epoch 1708/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.4260e-04 - tot_time: 0h 53m 33.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4137e-04 - val_loss: 7.4764e-04\n",
      "Epoch 1709/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4316e-04 - tot_time: 0h 53m 33.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4163e-04 - val_loss: 7.4608e-04\n",
      "Epoch 1710/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4189e-04 - tot_time: 0h 53m 34.9s\n",
      "\n",
      "Epoch 1710: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4191e-04 - val_loss: 7.4575e-04\n",
      "Epoch 1711/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.3791e-04 - tot_time: 0h 53m 35.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4013e-04 - val_loss: 7.4881e-04\n",
      "Epoch 1712/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4236e-04 - tot_time: 0h 53m 36.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4276e-04 - val_loss: 7.5264e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1713/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4092e-04 - tot_time: 0h 53m 37.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4092e-04 - val_loss: 7.4330e-04\n",
      "Epoch 1714/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3990e-04 - tot_time: 0h 53m 38.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4019e-04 - val_loss: 7.4992e-04\n",
      "Epoch 1715/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4049e-04 - tot_time: 0h 53m 39.1s\n",
      "\n",
      "Epoch 1715: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4103e-04 - val_loss: 7.4340e-04\n",
      "Epoch 1716/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4079e-04 - tot_time: 0h 53m 40.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4079e-04 - val_loss: 7.4468e-04\n",
      "Epoch 1717/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3808e-04 - tot_time: 0h 53m 40.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4004e-04 - val_loss: 7.4325e-04\n",
      "Epoch 1718/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4148e-04 - tot_time: 0h 53m 41.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4028e-04 - val_loss: 7.4619e-04\n",
      "Epoch 1719/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4004e-04 - tot_time: 0h 53m 42.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4077e-04 - val_loss: 7.4431e-04\n",
      "Epoch 1720/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3781e-04 - tot_time: 0h 53m 43.5s\n",
      "\n",
      "Epoch 1720: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3980e-04 - val_loss: 7.4487e-04\n",
      "Epoch 1721/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3936e-04 - tot_time: 0h 53m 44.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3944e-04 - val_loss: 7.6774e-04\n",
      "Epoch 1722/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3962e-04 - tot_time: 0h 53m 45.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4229e-04 - val_loss: 7.4725e-04\n",
      "Epoch 1723/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4318e-04 - tot_time: 0h 53m 46.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4318e-04 - val_loss: 7.5226e-04\n",
      "Epoch 1724/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.4046e-04 - tot_time: 0h 53m 46.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4059e-04 - val_loss: 7.5676e-04\n",
      "Epoch 1725/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3982e-04 - tot_time: 0h 53m 47.9s\n",
      "\n",
      "Epoch 1725: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4178e-04 - val_loss: 7.4424e-04\n",
      "Epoch 1726/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3934e-04 - tot_time: 0h 53m 48.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3933e-04 - val_loss: 7.4529e-04\n",
      "Epoch 1727/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3984e-04 - tot_time: 0h 53m 49.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3987e-04 - val_loss: 7.4350e-04\n",
      "Epoch 1728/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4264e-04 - tot_time: 0h 53m 50.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4275e-04 - val_loss: 7.6383e-04\n",
      "Epoch 1729/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4188e-04 - tot_time: 0h 53m 51.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4163e-04 - val_loss: 7.4539e-04\n",
      "Epoch 1730/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4078e-04 - tot_time: 0h 53m 52.2s\n",
      "\n",
      "Epoch 1730: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4023e-04 - val_loss: 7.4507e-04\n",
      "Epoch 1731/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3990e-04 - tot_time: 0h 53m 53.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3993e-04 - val_loss: 7.4452e-04\n",
      "Epoch 1732/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.4148e-04 - tot_time: 0h 53m 53.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4045e-04 - val_loss: 7.4598e-04\n",
      "Epoch 1733/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4283e-04 - tot_time: 0h 53m 54.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4183e-04 - val_loss: 7.6377e-04\n",
      "Epoch 1734/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4147e-04 - tot_time: 0h 53m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4146e-04 - val_loss: 7.4744e-04\n",
      "Epoch 1735/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.4007e-04 - tot_time: 0h 53m 56.4s\n",
      "\n",
      "Epoch 1735: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3908e-04 - val_loss: 7.5321e-04\n",
      "Epoch 1736/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4065e-04 - tot_time: 0h 53m 57.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4051e-04 - val_loss: 7.4967e-04\n",
      "Epoch 1737/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4120e-04 - tot_time: 0h 53m 58.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4103e-04 - val_loss: 7.4298e-04\n",
      "Epoch 1738/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.3937e-04 - tot_time: 0h 53m 59.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3946e-04 - val_loss: 7.5248e-04\n",
      "Epoch 1739/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4202e-04 - tot_time: 0h 53m 59.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4202e-04 - val_loss: 7.4211e-04\n",
      "Epoch 1740/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4016e-04 - tot_time: 0h 54m 0.9s\n",
      "\n",
      "Epoch 1740: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3940e-04 - val_loss: 7.4562e-04\n",
      "Epoch 1741/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4092e-04 - tot_time: 0h 54m 1.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.4088e-04 - val_loss: 7.5091e-04\n",
      "Epoch 1742/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3991e-04 - tot_time: 0h 54m 2.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3934e-04 - val_loss: 7.4487e-04\n",
      "Epoch 1743/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4024e-04 - tot_time: 0h 54m 3.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4024e-04 - val_loss: 7.5403e-04\n",
      "Epoch 1744/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.4066e-04 - tot_time: 0h 54m 4.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3969e-04 - val_loss: 7.4130e-04\n",
      "Epoch 1745/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3878e-04 - tot_time: 0h 54m 5.2s\n",
      "\n",
      "Epoch 1745: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3854e-04 - val_loss: 7.4183e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1746/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3771e-04 - tot_time: 0h 54m 6.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3895e-04 - val_loss: 7.5399e-04\n",
      "Epoch 1747/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3962e-04 - tot_time: 0h 54m 7.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3967e-04 - val_loss: 7.5435e-04\n",
      "Epoch 1748/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3990e-04 - tot_time: 0h 54m 7.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3990e-04 - val_loss: 7.4038e-04\n",
      "Epoch 1749/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.3899e-04 - tot_time: 0h 54m 8.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3892e-04 - val_loss: 7.4268e-04\n",
      "Epoch 1750/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3872e-04 - tot_time: 0h 54m 9.6s\n",
      "\n",
      "Epoch 1750: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3875e-04 - val_loss: 7.4484e-04\n",
      "Epoch 1751/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4179e-04 - tot_time: 0h 54m 10.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4136e-04 - val_loss: 7.5033e-04\n",
      "Epoch 1752/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3840e-04 - tot_time: 0h 54m 11.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4004e-04 - val_loss: 7.5625e-04\n",
      "Epoch 1753/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3833e-04 - tot_time: 0h 54m 12.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3854e-04 - val_loss: 7.6213e-04\n",
      "Epoch 1754/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3801e-04 - tot_time: 0h 54m 13.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3867e-04 - val_loss: 7.5549e-04\n",
      "Epoch 1755/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.4021e-04 - tot_time: 0h 54m 14.1s\n",
      "\n",
      "Epoch 1755: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4043e-04 - val_loss: 7.5156e-04\n",
      "Epoch 1756/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.4082e-04 - tot_time: 0h 54m 14.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3955e-04 - val_loss: 7.3956e-04\n",
      "Epoch 1757/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3887e-04 - tot_time: 0h 54m 15.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3860e-04 - val_loss: 7.4708e-04\n",
      "Epoch 1758/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3878e-04 - tot_time: 0h 54m 16.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3883e-04 - val_loss: 7.4211e-04\n",
      "Epoch 1759/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3923e-04 - tot_time: 0h 54m 17.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3896e-04 - val_loss: 7.4122e-04\n",
      "Epoch 1760/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3892e-04 - tot_time: 0h 54m 18.6s\n",
      "\n",
      "Epoch 1760: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3892e-04 - val_loss: 7.3971e-04\n",
      "Epoch 1761/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3791e-04 - tot_time: 0h 54m 19.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3807e-04 - val_loss: 7.4655e-04\n",
      "Epoch 1762/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3891e-04 - tot_time: 0h 54m 20.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3889e-04 - val_loss: 7.4559e-04\n",
      "Epoch 1763/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3902e-04 - tot_time: 0h 54m 21.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3884e-04 - val_loss: 7.4465e-04\n",
      "Epoch 1764/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.3962e-04 - tot_time: 0h 54m 21.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3895e-04 - val_loss: 7.4461e-04\n",
      "Epoch 1765/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3935e-04 - tot_time: 0h 54m 22.8s\n",
      "\n",
      "Epoch 1765: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3889e-04 - val_loss: 7.4602e-04\n",
      "Epoch 1766/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3827e-04 - tot_time: 0h 54m 23.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3893e-04 - val_loss: 7.5434e-04\n",
      "Epoch 1767/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.3966e-04 - tot_time: 0h 54m 24.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3988e-04 - val_loss: 7.5696e-04\n",
      "Epoch 1768/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3780e-04 - tot_time: 0h 54m 25.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3837e-04 - val_loss: 7.4578e-04\n",
      "Epoch 1769/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3745e-04 - tot_time: 0h 54m 26.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3802e-04 - val_loss: 7.5479e-04\n",
      "Epoch 1770/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.3884e-04 - tot_time: 0h 54m 27.1s\n",
      "\n",
      "Epoch 1770: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3824e-04 - val_loss: 7.4390e-04\n",
      "Epoch 1771/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3778e-04 - tot_time: 0h 54m 28.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3780e-04 - val_loss: 7.4281e-04\n",
      "Epoch 1772/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3786e-04 - tot_time: 0h 54m 29.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3729e-04 - val_loss: 7.4807e-04\n",
      "Epoch 1773/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3826e-04 - tot_time: 0h 54m 29.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3826e-04 - val_loss: 7.4830e-04\n",
      "Epoch 1774/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3794e-04 - tot_time: 0h 54m 30.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3792e-04 - val_loss: 7.4840e-04\n",
      "Epoch 1775/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3896e-04 - tot_time: 0h 54m 31.6s\n",
      "\n",
      "Epoch 1775: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3773e-04 - val_loss: 7.4353e-04\n",
      "Epoch 1776/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3762e-04 - tot_time: 0h 54m 32.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3753e-04 - val_loss: 7.4725e-04\n",
      "Epoch 1777/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3778e-04 - tot_time: 0h 54m 33.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3766e-04 - val_loss: 7.5075e-04\n",
      "Epoch 1778/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3837e-04 - tot_time: 0h 54m 34.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3749e-04 - val_loss: 7.4296e-04\n",
      "Epoch 1779/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3714e-04 - tot_time: 0h 54m 34.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3791e-04 - val_loss: 7.5467e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1780/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3783e-04 - tot_time: 0h 54m 35.7s\n",
      "\n",
      "Epoch 1780: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3754e-04 - val_loss: 7.4065e-04\n",
      "Epoch 1781/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3921e-04 - tot_time: 0h 54m 36.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3914e-04 - val_loss: 7.4318e-04\n",
      "Epoch 1782/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.3962e-04 - tot_time: 0h 54m 37.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3984e-04 - val_loss: 7.4126e-04\n",
      "Epoch 1783/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3968e-04 - tot_time: 0h 54m 38.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3856e-04 - val_loss: 7.4113e-04\n",
      "Epoch 1784/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3842e-04 - tot_time: 0h 54m 39.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3838e-04 - val_loss: 7.4101e-04\n",
      "Epoch 1785/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3646e-04 - tot_time: 0h 54m 40.0s\n",
      "\n",
      "Epoch 1785: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3646e-04 - val_loss: 7.4491e-04\n",
      "Epoch 1786/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3704e-04 - tot_time: 0h 54m 41.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3699e-04 - val_loss: 7.4111e-04\n",
      "Epoch 1787/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3315e-04 - tot_time: 0h 54m 41.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3607e-04 - val_loss: 7.4490e-04\n",
      "Epoch 1788/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3801e-04 - tot_time: 0h 54m 42.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3703e-04 - val_loss: 7.4179e-04\n",
      "Epoch 1789/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3618e-04 - tot_time: 0h 54m 43.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3752e-04 - val_loss: 7.3878e-04\n",
      "Epoch 1790/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.3509e-04 - tot_time: 0h 54m 44.5s\n",
      "\n",
      "Epoch 1790: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3656e-04 - val_loss: 7.7154e-04\n",
      "Epoch 1791/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.4328e-04 - tot_time: 0h 54m 45.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.4324e-04 - val_loss: 7.3840e-04\n",
      "Epoch 1792/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3798e-04 - tot_time: 0h 54m 46.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3778e-04 - val_loss: 7.5491e-04\n",
      "Epoch 1793/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.3768e-04 - tot_time: 0h 54m 47.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3758e-04 - val_loss: 7.4168e-04\n",
      "Epoch 1794/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3672e-04 - tot_time: 0h 54m 47.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3671e-04 - val_loss: 7.4809e-04\n",
      "Epoch 1795/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3711e-04 - tot_time: 0h 54m 48.7s\n",
      "\n",
      "Epoch 1795: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3690e-04 - val_loss: 7.4269e-04\n",
      "Epoch 1796/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3874e-04 - tot_time: 0h 54m 49.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3864e-04 - val_loss: 7.5295e-04\n",
      "Epoch 1797/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3708e-04 - tot_time: 0h 54m 50.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3694e-04 - val_loss: 7.4160e-04\n",
      "Epoch 1798/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3615e-04 - tot_time: 0h 54m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3611e-04 - val_loss: 7.4156e-04\n",
      "Epoch 1799/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3671e-04 - tot_time: 0h 54m 52.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3621e-04 - val_loss: 7.3803e-04\n",
      "Epoch 1800/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3591e-04 - tot_time: 0h 54m 52.9s\n",
      "\n",
      "Epoch 1800: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3588e-04 - val_loss: 7.4813e-04\n",
      "Epoch 1801/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3455e-04 - tot_time: 0h 54m 53.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3602e-04 - val_loss: 7.4198e-04\n",
      "Epoch 1802/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3689e-04 - tot_time: 0h 54m 54.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3688e-04 - val_loss: 7.4645e-04\n",
      "Epoch 1803/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3694e-04 - tot_time: 0h 54m 55.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3689e-04 - val_loss: 7.4258e-04\n",
      "Epoch 1804/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3729e-04 - tot_time: 0h 54m 56.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3702e-04 - val_loss: 7.3893e-04\n",
      "Epoch 1805/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.3504e-04 - tot_time: 0h 54m 57.4s\n",
      "\n",
      "Epoch 1805: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3663e-04 - val_loss: 7.4030e-04\n",
      "Epoch 1806/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3740e-04 - tot_time: 0h 54m 58.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3741e-04 - val_loss: 7.4322e-04\n",
      "Epoch 1807/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3767e-04 - tot_time: 0h 54m 59.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3773e-04 - val_loss: 7.3886e-04\n",
      "Epoch 1808/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.3749e-04 - tot_time: 0h 55m 0.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3629e-04 - val_loss: 7.4039e-04\n",
      "Epoch 1809/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3599e-04 - tot_time: 0h 55m 0.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3629e-04 - val_loss: 7.6339e-04\n",
      "Epoch 1810/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3782e-04 - tot_time: 0h 55m 1.9s\n",
      "\n",
      "Epoch 1810: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3803e-04 - val_loss: 7.5841e-04\n",
      "Epoch 1811/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3687e-04 - tot_time: 0h 55m 2.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3693e-04 - val_loss: 7.4163e-04\n",
      "Epoch 1812/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3540e-04 - tot_time: 0h 55m 3.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3591e-04 - val_loss: 7.5019e-04\n",
      "Epoch 1813/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3683e-04 - tot_time: 0h 55m 4.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3634e-04 - val_loss: 7.4358e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1814/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3508e-04 - tot_time: 0h 55m 5.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3508e-04 - val_loss: 7.5039e-04\n",
      "Epoch 1815/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3665e-04 - tot_time: 0h 55m 6.1s\n",
      "\n",
      "Epoch 1815: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3727e-04 - val_loss: 7.4250e-04\n",
      "Epoch 1816/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3542e-04 - tot_time: 0h 55m 7.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3731e-04 - val_loss: 7.3763e-04\n",
      "Epoch 1817/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3554e-04 - tot_time: 0h 55m 8.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3551e-04 - val_loss: 7.4322e-04\n",
      "Epoch 1818/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3599e-04 - tot_time: 0h 55m 9.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3671e-04 - val_loss: 7.4249e-04\n",
      "Epoch 1819/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3631e-04 - tot_time: 0h 55m 9.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3642e-04 - val_loss: 7.4640e-04\n",
      "Epoch 1820/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3654e-04 - tot_time: 0h 55m 10.6s\n",
      "\n",
      "Epoch 1820: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3633e-04 - val_loss: 7.4041e-04\n",
      "Epoch 1821/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3540e-04 - tot_time: 0h 55m 11.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3537e-04 - val_loss: 7.4596e-04\n",
      "Epoch 1822/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3508e-04 - tot_time: 0h 55m 12.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3508e-04 - val_loss: 7.3700e-04\n",
      "Epoch 1823/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3647e-04 - tot_time: 0h 55m 13.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3647e-04 - val_loss: 7.4242e-04\n",
      "Epoch 1824/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3743e-04 - tot_time: 0h 55m 14.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3719e-04 - val_loss: 7.4108e-04\n",
      "Epoch 1825/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3368e-04 - tot_time: 0h 55m 15.2s\n",
      "\n",
      "Epoch 1825: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3430e-04 - val_loss: 7.3952e-04\n",
      "Epoch 1826/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3707e-04 - tot_time: 0h 55m 16.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3549e-04 - val_loss: 7.4500e-04\n",
      "Epoch 1827/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3411e-04 - tot_time: 0h 55m 17.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3595e-04 - val_loss: 7.3920e-04\n",
      "Epoch 1828/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3528e-04 - tot_time: 0h 55m 17.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3516e-04 - val_loss: 7.6421e-04\n",
      "Epoch 1829/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3560e-04 - tot_time: 0h 55m 18.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3578e-04 - val_loss: 7.4383e-04\n",
      "Epoch 1830/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3526e-04 - tot_time: 0h 55m 19.7s\n",
      "\n",
      "Epoch 1830: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3479e-04 - val_loss: 7.3883e-04\n",
      "Epoch 1831/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3397e-04 - tot_time: 0h 55m 20.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3380e-04 - val_loss: 7.4848e-04\n",
      "Epoch 1832/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3597e-04 - tot_time: 0h 55m 21.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3661e-04 - val_loss: 7.4675e-04\n",
      "Epoch 1833/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3617e-04 - tot_time: 0h 55m 22.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3573e-04 - val_loss: 7.3879e-04\n",
      "Epoch 1834/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.3458e-04 - tot_time: 0h 55m 23.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3532e-04 - val_loss: 7.3849e-04\n",
      "Epoch 1835/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3405e-04 - tot_time: 0h 55m 24.3s\n",
      "\n",
      "Epoch 1835: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3405e-04 - val_loss: 7.4584e-04\n",
      "Epoch 1836/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3134e-04 - tot_time: 0h 55m 25.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3516e-04 - val_loss: 7.4252e-04\n",
      "Epoch 1837/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3501e-04 - tot_time: 0h 55m 25.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3479e-04 - val_loss: 7.4004e-04\n",
      "Epoch 1838/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3501e-04 - tot_time: 0h 55m 26.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3499e-04 - val_loss: 7.3959e-04\n",
      "Epoch 1839/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3572e-04 - tot_time: 0h 55m 27.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3534e-04 - val_loss: 7.4392e-04\n",
      "Epoch 1840/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3553e-04 - tot_time: 0h 55m 28.5s\n",
      "\n",
      "Epoch 1840: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3550e-04 - val_loss: 7.4382e-04\n",
      "Epoch 1841/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3487e-04 - tot_time: 0h 55m 29.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3454e-04 - val_loss: 7.4572e-04\n",
      "Epoch 1842/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.3427e-04 - tot_time: 0h 55m 30.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3427e-04 - val_loss: 7.4428e-04\n",
      "Epoch 1843/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3546e-04 - tot_time: 0h 55m 31.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3482e-04 - val_loss: 7.3903e-04\n",
      "Epoch 1844/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3251e-04 - tot_time: 0h 55m 32.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3420e-04 - val_loss: 7.3641e-04\n",
      "Epoch 1845/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3389e-04 - tot_time: 0h 55m 33.1s\n",
      "\n",
      "Epoch 1845: val_loss improved from 0.00074 to 0.00074, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3388e-04 - val_loss: 7.3666e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1846/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3356e-04 - tot_time: 0h 55m 33.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3419e-04 - val_loss: 7.4250e-04\n",
      "Epoch 1847/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3563e-04 - tot_time: 0h 55m 35.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3505e-04 - val_loss: 7.5791e-04\n",
      "Epoch 1848/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3647e-04 - tot_time: 0h 55m 35.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3645e-04 - val_loss: 7.3670e-04\n",
      "Epoch 1849/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3488e-04 - tot_time: 0h 55m 36.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3459e-04 - val_loss: 8.2180e-04\n",
      "Epoch 1850/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4044e-04 - tot_time: 0h 55m 37.7s\n",
      "\n",
      "Epoch 1850: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4044e-04 - val_loss: 7.7817e-04\n",
      "Epoch 1851/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3637e-04 - tot_time: 0h 55m 38.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3679e-04 - val_loss: 7.3831e-04\n",
      "Epoch 1852/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3574e-04 - tot_time: 0h 55m 39.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3574e-04 - val_loss: 7.3949e-04\n",
      "Epoch 1853/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3109e-04 - tot_time: 0h 55m 40.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3256e-04 - val_loss: 7.3574e-04\n",
      "Epoch 1854/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3437e-04 - tot_time: 0h 55m 41.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3437e-04 - val_loss: 7.3911e-04\n",
      "Epoch 1855/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3284e-04 - tot_time: 0h 55m 42.0s\n",
      "\n",
      "Epoch 1855: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3282e-04 - val_loss: 7.4889e-04\n",
      "Epoch 1856/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3390e-04 - tot_time: 0h 55m 43.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3394e-04 - val_loss: 7.3655e-04\n",
      "Epoch 1857/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3506e-04 - tot_time: 0h 55m 43.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3396e-04 - val_loss: 7.4651e-04\n",
      "Epoch 1858/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3423e-04 - tot_time: 0h 55m 44.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3423e-04 - val_loss: 7.3707e-04\n",
      "Epoch 1859/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.3225e-04 - tot_time: 0h 55m 45.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3274e-04 - val_loss: 7.4327e-04\n",
      "Epoch 1860/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3345e-04 - tot_time: 0h 55m 46.3s\n",
      "\n",
      "Epoch 1860: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3328e-04 - val_loss: 7.6055e-04\n",
      "Epoch 1861/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3548e-04 - tot_time: 0h 55m 47.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3502e-04 - val_loss: 7.3627e-04\n",
      "Epoch 1862/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3586e-04 - tot_time: 0h 55m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3499e-04 - val_loss: 7.3666e-04\n",
      "Epoch 1863/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3170e-04 - tot_time: 0h 55m 49.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3396e-04 - val_loss: 7.4608e-04\n",
      "Epoch 1864/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3256e-04 - tot_time: 0h 55m 49.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3295e-04 - val_loss: 7.3643e-04\n",
      "Epoch 1865/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3387e-04 - tot_time: 0h 55m 50.8s\n",
      "\n",
      "Epoch 1865: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3435e-04 - val_loss: 7.3685e-04\n",
      "Epoch 1866/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3439e-04 - tot_time: 0h 55m 51.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3435e-04 - val_loss: 7.4277e-04\n",
      "Epoch 1867/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3440e-04 - tot_time: 0h 55m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3423e-04 - val_loss: 7.3864e-04\n",
      "Epoch 1868/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3350e-04 - tot_time: 0h 55m 53.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3350e-04 - val_loss: 7.3899e-04\n",
      "Epoch 1869/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3209e-04 - tot_time: 0h 55m 54.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3212e-04 - val_loss: 7.3811e-04\n",
      "Epoch 1870/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3329e-04 - tot_time: 0h 55m 55.3s\n",
      "\n",
      "Epoch 1870: val_loss did not improve from 0.00074\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3364e-04 - val_loss: 7.6678e-04\n",
      "Epoch 1871/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.4059e-04 - tot_time: 0h 55m 56.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3941e-04 - val_loss: 7.4842e-04\n",
      "Epoch 1872/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3297e-04 - tot_time: 0h 55m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3297e-04 - val_loss: 7.3867e-04\n",
      "Epoch 1873/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3274e-04 - tot_time: 0h 55m 58.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3274e-04 - val_loss: 7.3927e-04\n",
      "Epoch 1874/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3500e-04 - tot_time: 0h 55m 58.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3455e-04 - val_loss: 7.3677e-04\n",
      "Epoch 1875/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3348e-04 - tot_time: 0h 55m 59.5s\n",
      "\n",
      "Epoch 1875: val_loss improved from 0.00074 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3346e-04 - val_loss: 7.3450e-04\n",
      "Epoch 1876/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3335e-04 - tot_time: 0h 56m 0.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3312e-04 - val_loss: 7.3882e-04\n",
      "Epoch 1877/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3395e-04 - tot_time: 0h 56m 1.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3393e-04 - val_loss: 7.3810e-04\n",
      "Epoch 1878/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3350e-04 - tot_time: 0h 56m 2.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3402e-04 - val_loss: 7.4668e-04\n",
      "Epoch 1879/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3403e-04 - tot_time: 0h 56m 3.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3368e-04 - val_loss: 7.3442e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.3452e-04 - tot_time: 0h 56m 3.9s\n",
      "\n",
      "Epoch 1880: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3285e-04 - val_loss: 7.3488e-04\n",
      "Epoch 1881/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3298e-04 - tot_time: 0h 56m 4.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3298e-04 - val_loss: 7.5096e-04\n",
      "Epoch 1882/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3516e-04 - tot_time: 0h 56m 5.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3511e-04 - val_loss: 7.3995e-04\n",
      "Epoch 1883/2000\n",
      "111/124 [=========================>....] - ETA: 0s - loss: 7.3483e-04 - tot_time: 0h 56m 6.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3380e-04 - val_loss: 7.3518e-04\n",
      "Epoch 1884/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3306e-04 - tot_time: 0h 56m 7.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3319e-04 - val_loss: 7.3522e-04\n",
      "Epoch 1885/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3393e-04 - tot_time: 0h 56m 8.4s\n",
      "\n",
      "Epoch 1885: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3301e-04 - val_loss: 7.4589e-04\n",
      "Epoch 1886/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3274e-04 - tot_time: 0h 56m 9.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3316e-04 - val_loss: 7.3842e-04\n",
      "Epoch 1887/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3263e-04 - tot_time: 0h 56m 10.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3268e-04 - val_loss: 7.3860e-04\n",
      "Epoch 1888/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3285e-04 - tot_time: 0h 56m 10.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3281e-04 - val_loss: 7.3973e-04\n",
      "Epoch 1889/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3114e-04 - tot_time: 0h 56m 11.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3200e-04 - val_loss: 7.3881e-04\n",
      "Epoch 1890/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3325e-04 - tot_time: 0h 56m 12.5s\n",
      "\n",
      "Epoch 1890: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3322e-04 - val_loss: 7.3346e-04\n",
      "Epoch 1891/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3297e-04 - tot_time: 0h 56m 13.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3276e-04 - val_loss: 7.3383e-04\n",
      "Epoch 1892/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3321e-04 - tot_time: 0h 56m 14.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3315e-04 - val_loss: 7.6057e-04\n",
      "Epoch 1893/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3439e-04 - tot_time: 0h 56m 15.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3395e-04 - val_loss: 7.3861e-04\n",
      "Epoch 1894/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3237e-04 - tot_time: 0h 56m 16.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3326e-04 - val_loss: 7.3875e-04\n",
      "Epoch 1895/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3317e-04 - tot_time: 0h 56m 16.8s\n",
      "\n",
      "Epoch 1895: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3260e-04 - val_loss: 7.4227e-04\n",
      "Epoch 1896/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3223e-04 - tot_time: 0h 56m 17.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3193e-04 - val_loss: 7.7056e-04\n",
      "Epoch 1897/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3840e-04 - tot_time: 0h 56m 18.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3840e-04 - val_loss: 7.3518e-04\n",
      "Epoch 1898/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3151e-04 - tot_time: 0h 56m 19.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3151e-04 - val_loss: 7.3814e-04\n",
      "Epoch 1899/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3196e-04 - tot_time: 0h 56m 20.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3192e-04 - val_loss: 7.3821e-04\n",
      "Epoch 1900/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3233e-04 - tot_time: 0h 56m 21.3s\n",
      "\n",
      "Epoch 1900: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3211e-04 - val_loss: 7.4526e-04\n",
      "Epoch 1901/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3373e-04 - tot_time: 0h 56m 22.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3338e-04 - val_loss: 7.4787e-04\n",
      "Epoch 1902/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3257e-04 - tot_time: 0h 56m 22.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3258e-04 - val_loss: 7.3671e-04\n",
      "Epoch 1903/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3265e-04 - tot_time: 0h 56m 23.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3278e-04 - val_loss: 7.4603e-04\n",
      "Epoch 1904/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3193e-04 - tot_time: 0h 56m 24.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3193e-04 - val_loss: 7.3937e-04\n",
      "Epoch 1905/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3247e-04 - tot_time: 0h 56m 25.4s\n",
      "\n",
      "Epoch 1905: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3245e-04 - val_loss: 7.3939e-04\n",
      "Epoch 1906/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3107e-04 - tot_time: 0h 56m 26.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3103e-04 - val_loss: 7.3554e-04\n",
      "Epoch 1907/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3316e-04 - tot_time: 0h 56m 27.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3259e-04 - val_loss: 7.5374e-04\n",
      "Epoch 1908/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3381e-04 - tot_time: 0h 56m 28.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3308e-04 - val_loss: 7.3472e-04\n",
      "Epoch 1909/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3156e-04 - tot_time: 0h 56m 28.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3152e-04 - val_loss: 7.4388e-04\n",
      "Epoch 1910/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3200e-04 - tot_time: 0h 56m 29.5s\n",
      "\n",
      "Epoch 1910: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3166e-04 - val_loss: 7.3595e-04\n",
      "Epoch 1911/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3199e-04 - tot_time: 0h 56m 30.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3171e-04 - val_loss: 7.6151e-04\n",
      "Epoch 1912/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3322e-04 - tot_time: 0h 56m 31.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3295e-04 - val_loss: 7.3751e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1913/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3172e-04 - tot_time: 0h 56m 32.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3170e-04 - val_loss: 7.3610e-04\n",
      "Epoch 1914/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2924e-04 - tot_time: 0h 56m 33.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3170e-04 - val_loss: 7.3996e-04\n",
      "Epoch 1915/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3368e-04 - tot_time: 0h 56m 33.9s\n",
      "\n",
      "Epoch 1915: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3385e-04 - val_loss: 7.6454e-04\n",
      "Epoch 1916/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.4030e-04 - tot_time: 0h 56m 34.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3855e-04 - val_loss: 7.4037e-04\n",
      "Epoch 1917/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3138e-04 - tot_time: 0h 56m 35.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3138e-04 - val_loss: 7.3887e-04\n",
      "Epoch 1918/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2913e-04 - tot_time: 0h 56m 36.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3111e-04 - val_loss: 7.3778e-04\n",
      "Epoch 1919/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3215e-04 - tot_time: 0h 56m 37.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3247e-04 - val_loss: 7.4292e-04\n",
      "Epoch 1920/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3196e-04 - tot_time: 0h 56m 38.2s\n",
      "\n",
      "Epoch 1920: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3207e-04 - val_loss: 7.3360e-04\n",
      "Epoch 1921/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.3201e-04 - tot_time: 0h 56m 39.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3222e-04 - val_loss: 7.3689e-04\n",
      "Epoch 1922/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3195e-04 - tot_time: 0h 56m 39.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3105e-04 - val_loss: 7.4555e-04\n",
      "Epoch 1923/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3159e-04 - tot_time: 0h 56m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3159e-04 - val_loss: 7.4205e-04\n",
      "Epoch 1924/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3168e-04 - tot_time: 0h 56m 41.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3127e-04 - val_loss: 7.3617e-04\n",
      "Epoch 1925/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3089e-04 - tot_time: 0h 56m 42.5s\n",
      "\n",
      "Epoch 1925: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3077e-04 - val_loss: 7.3411e-04\n",
      "Epoch 1926/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3153e-04 - tot_time: 0h 56m 43.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.3100e-04 - val_loss: 7.3681e-04\n",
      "Epoch 1927/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3221e-04 - tot_time: 0h 56m 44.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3221e-04 - val_loss: 7.3327e-04\n",
      "Epoch 1928/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3161e-04 - tot_time: 0h 56m 45.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3158e-04 - val_loss: 7.4372e-04\n",
      "Epoch 1929/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3251e-04 - tot_time: 0h 56m 46.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3198e-04 - val_loss: 7.4320e-04\n",
      "Epoch 1930/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3363e-04 - tot_time: 0h 56m 46.9s\n",
      "\n",
      "Epoch 1930: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3263e-04 - val_loss: 7.5159e-04\n",
      "Epoch 1931/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3237e-04 - tot_time: 0h 56m 47.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3228e-04 - val_loss: 7.3408e-04\n",
      "Epoch 1932/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3164e-04 - tot_time: 0h 56m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3119e-04 - val_loss: 7.3378e-04\n",
      "Epoch 1933/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3093e-04 - tot_time: 0h 56m 49.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3089e-04 - val_loss: 7.3467e-04\n",
      "Epoch 1934/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3152e-04 - tot_time: 0h 56m 50.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3069e-04 - val_loss: 7.3258e-04\n",
      "Epoch 1935/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3071e-04 - tot_time: 0h 56m 51.2s\n",
      "\n",
      "Epoch 1935: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3190e-04 - val_loss: 7.3367e-04\n",
      "Epoch 1936/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3267e-04 - tot_time: 0h 56m 52.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3283e-04 - val_loss: 7.3504e-04\n",
      "Epoch 1937/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3409e-04 - tot_time: 0h 56m 52.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3362e-04 - val_loss: 7.4056e-04\n",
      "Epoch 1938/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3081e-04 - tot_time: 0h 56m 53.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3088e-04 - val_loss: 7.3783e-04\n",
      "Epoch 1939/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3086e-04 - tot_time: 0h 56m 54.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3005e-04 - val_loss: 7.3878e-04\n",
      "Epoch 1940/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.3145e-04 - tot_time: 0h 56m 55.2s\n",
      "\n",
      "Epoch 1940: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3106e-04 - val_loss: 7.3426e-04\n",
      "Epoch 1941/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2963e-04 - tot_time: 0h 56m 56.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3026e-04 - val_loss: 7.4624e-04\n",
      "Epoch 1942/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3175e-04 - tot_time: 0h 56m 57.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3185e-04 - val_loss: 7.5536e-04\n",
      "Epoch 1943/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3304e-04 - tot_time: 0h 56m 57.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3212e-04 - val_loss: 7.3356e-04\n",
      "Epoch 1944/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2987e-04 - tot_time: 0h 56m 58.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2955e-04 - val_loss: 7.3420e-04\n",
      "Epoch 1945/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2879e-04 - tot_time: 0h 56m 59.6s\n",
      "\n",
      "Epoch 1945: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3143e-04 - val_loss: 7.5934e-04\n",
      "Epoch 1946/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3343e-04 - tot_time: 0h 57m 0.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3309e-04 - val_loss: 7.6126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1947/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3107e-04 - tot_time: 0h 57m 1.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3153e-04 - val_loss: 7.3328e-04\n",
      "Epoch 1948/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2899e-04 - tot_time: 0h 57m 2.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2899e-04 - val_loss: 7.3236e-04\n",
      "Epoch 1949/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2862e-04 - tot_time: 0h 57m 3.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2998e-04 - val_loss: 7.4500e-04\n",
      "Epoch 1950/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3205e-04 - tot_time: 0h 57m 4.1s\n",
      "\n",
      "Epoch 1950: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3224e-04 - val_loss: 7.3976e-04\n",
      "Epoch 1951/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3123e-04 - tot_time: 0h 57m 4.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3109e-04 - val_loss: 7.3788e-04\n",
      "Epoch 1952/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2979e-04 - tot_time: 0h 57m 5.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2979e-04 - val_loss: 7.4091e-04\n",
      "Epoch 1953/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3052e-04 - tot_time: 0h 57m 6.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3052e-04 - val_loss: 7.3117e-04\n",
      "Epoch 1954/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2781e-04 - tot_time: 0h 57m 7.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2945e-04 - val_loss: 7.3424e-04\n",
      "Epoch 1955/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3005e-04 - tot_time: 0h 57m 8.2s\n",
      "\n",
      "Epoch 1955: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3016e-04 - val_loss: 7.5231e-04\n",
      "Epoch 1956/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3170e-04 - tot_time: 0h 57m 9.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3166e-04 - val_loss: 7.4052e-04\n",
      "Epoch 1957/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2897e-04 - tot_time: 0h 57m 10.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3033e-04 - val_loss: 7.4235e-04\n",
      "Epoch 1958/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3257e-04 - tot_time: 0h 57m 11.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3184e-04 - val_loss: 7.4707e-04\n",
      "Epoch 1959/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.3052e-04 - tot_time: 0h 57m 12.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3172e-04 - val_loss: 7.3283e-04\n",
      "Epoch 1960/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2852e-04 - tot_time: 0h 57m 12.7s\n",
      "\n",
      "Epoch 1960: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3035e-04 - val_loss: 7.3343e-04\n",
      "Epoch 1961/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2922e-04 - tot_time: 0h 57m 13.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2954e-04 - val_loss: 7.3246e-04\n",
      "Epoch 1962/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3224e-04 - tot_time: 0h 57m 14.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3224e-04 - val_loss: 7.5117e-04\n",
      "Epoch 1963/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3059e-04 - tot_time: 0h 57m 15.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3034e-04 - val_loss: 7.3265e-04\n",
      "Epoch 1964/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3057e-04 - tot_time: 0h 57m 16.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3057e-04 - val_loss: 7.4510e-04\n",
      "Epoch 1965/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3048e-04 - tot_time: 0h 57m 17.0s\n",
      "\n",
      "Epoch 1965: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3044e-04 - val_loss: 7.4436e-04\n",
      "Epoch 1966/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3046e-04 - tot_time: 0h 57m 17.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3067e-04 - val_loss: 7.3852e-04\n",
      "Epoch 1967/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2956e-04 - tot_time: 0h 57m 18.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2956e-04 - val_loss: 7.3577e-04\n",
      "Epoch 1968/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3136e-04 - tot_time: 0h 57m 19.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3054e-04 - val_loss: 7.3952e-04\n",
      "Epoch 1969/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.3191e-04 - tot_time: 0h 57m 20.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3122e-04 - val_loss: 7.3105e-04\n",
      "Epoch 1970/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3045e-04 - tot_time: 0h 57m 21.3s\n",
      "\n",
      "Epoch 1970: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2972e-04 - val_loss: 7.3144e-04\n",
      "Epoch 1971/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2899e-04 - tot_time: 0h 57m 22.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2908e-04 - val_loss: 7.3677e-04\n",
      "Epoch 1972/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2895e-04 - tot_time: 0h 57m 22.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3018e-04 - val_loss: 7.4017e-04\n",
      "Epoch 1973/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3065e-04 - tot_time: 0h 57m 23.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3060e-04 - val_loss: 7.3661e-04\n",
      "Epoch 1974/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3168e-04 - tot_time: 0h 57m 24.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3130e-04 - val_loss: 7.3431e-04\n",
      "Epoch 1975/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2839e-04 - tot_time: 0h 57m 25.4s\n",
      "\n",
      "Epoch 1975: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2984e-04 - val_loss: 7.3820e-04\n",
      "Epoch 1976/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3061e-04 - tot_time: 0h 57m 26.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3060e-04 - val_loss: 7.3528e-04\n",
      "Epoch 1977/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3011e-04 - tot_time: 0h 57m 27.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2984e-04 - val_loss: 7.3450e-04\n",
      "Epoch 1978/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3191e-04 - tot_time: 0h 57m 27.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.3137e-04 - val_loss: 7.3234e-04\n",
      "Epoch 1979/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2920e-04 - tot_time: 0h 57m 28.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2885e-04 - val_loss: 7.3213e-04\n",
      "Epoch 1980/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 7.3082e-04 - tot_time: 0h 57m 29.7s\n",
      "\n",
      "Epoch 1980: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3082e-04 - val_loss: 7.4116e-04\n",
      "Epoch 1981/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2876e-04 - tot_time: 0h 57m 30.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2890e-04 - val_loss: 7.3430e-04\n",
      "Epoch 1982/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.3076e-04 - tot_time: 0h 57m 31.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3014e-04 - val_loss: 7.4108e-04\n",
      "Epoch 1983/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2880e-04 - tot_time: 0h 57m 32.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3069e-04 - val_loss: 7.3630e-04\n",
      "Epoch 1984/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2885e-04 - tot_time: 0h 57m 33.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2914e-04 - val_loss: 7.3281e-04\n",
      "Epoch 1985/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2867e-04 - tot_time: 0h 57m 34.0s\n",
      "\n",
      "Epoch 1985: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2952e-04 - val_loss: 7.4467e-04\n",
      "Epoch 1986/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.3266e-04 - tot_time: 0h 57m 34.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3055e-04 - val_loss: 7.3811e-04\n",
      "Epoch 1987/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2789e-04 - tot_time: 0h 57m 35.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2832e-04 - val_loss: 7.4202e-04\n",
      "Epoch 1988/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2888e-04 - tot_time: 0h 57m 36.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2888e-04 - val_loss: 7.3632e-04\n",
      "Epoch 1989/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2872e-04 - tot_time: 0h 57m 37.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2857e-04 - val_loss: 7.4123e-04\n",
      "Epoch 1990/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2914e-04 - tot_time: 0h 57m 38.1s\n",
      "\n",
      "Epoch 1990: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2909e-04 - val_loss: 7.3735e-04\n",
      "Epoch 1991/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2913e-04 - tot_time: 0h 57m 39.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2953e-04 - val_loss: 7.3363e-04\n",
      "Epoch 1992/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2912e-04 - tot_time: 0h 57m 40.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2856e-04 - val_loss: 7.4903e-04\n",
      "Epoch 1993/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2947e-04 - tot_time: 0h 57m 40.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.3044e-04 - val_loss: 7.3015e-04\n",
      "Epoch 1994/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2712e-04 - tot_time: 0h 57m 41.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2880e-04 - val_loss: 7.9698e-04\n",
      "Epoch 1995/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.3463e-04 - tot_time: 0h 57m 42.7s\n",
      "\n",
      "Epoch 1995: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3458e-04 - val_loss: 7.3986e-04\n",
      "Epoch 1996/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2773e-04 - tot_time: 0h 57m 43.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2844e-04 - val_loss: 7.5612e-04\n",
      "Epoch 1997/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3007e-04 - tot_time: 0h 57m 44.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3007e-04 - val_loss: 7.3018e-04\n",
      "Epoch 1998/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.3118e-04 - tot_time: 0h 57m 45.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3116e-04 - val_loss: 7.3406e-04\n",
      "Epoch 1999/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2784e-04 - tot_time: 0h 57m 46.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2839e-04 - val_loss: 7.4071e-04\n",
      "Epoch 2000/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2993e-04 - tot_time: 0h 57m 47.1s\n",
      "\n",
      "Epoch 2000: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.3079e-04 - val_loss: 7.3455e-04\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2692e-04 - tot_time: 0h 57m 48.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2592e-04 - val_loss: 7.3003e-04\n",
      "Epoch 2/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2547e-04 - tot_time: 0h 57m 48.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2549e-04 - val_loss: 7.3004e-04\n",
      "Epoch 3/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2414e-04 - tot_time: 0h 57m 49.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2546e-04 - val_loss: 7.3057e-04\n",
      "Epoch 4/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2492e-04 - tot_time: 0h 57m 50.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2544e-04 - val_loss: 7.3067e-04\n",
      "Epoch 5/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2628e-04 - tot_time: 0h 57m 51.5s\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2624e-04 - val_loss: 7.2953e-04\n",
      "Epoch 6/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2535e-04 - tot_time: 0h 57m 52.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2535e-04 - val_loss: 7.2961e-04\n",
      "Epoch 7/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2613e-04 - tot_time: 0h 57m 53.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2548e-04 - val_loss: 7.2937e-04\n",
      "Epoch 8/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2528e-04 - tot_time: 0h 57m 54.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2528e-04 - val_loss: 7.3012e-04\n",
      "Epoch 9/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2551e-04 - tot_time: 0h 57m 55.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2551e-04 - val_loss: 7.3067e-04\n",
      "Epoch 10/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2604e-04 - tot_time: 0h 57m 55.8s\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2559e-04 - val_loss: 7.2979e-04\n",
      "Epoch 11/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2607e-04 - tot_time: 0h 57m 56.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2547e-04 - val_loss: 7.2956e-04\n",
      "Epoch 12/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/124 [============================>.] - ETA: 0s - loss: 7.2601e-04 - tot_time: 0h 57m 57.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2545e-04 - val_loss: 7.2990e-04\n",
      "Epoch 13/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2087e-04 - tot_time: 0h 57m 58.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2541e-04 - val_loss: 7.2934e-04\n",
      "Epoch 14/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2569e-04 - tot_time: 0h 57m 59.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2536e-04 - val_loss: 7.3046e-04\n",
      "Epoch 15/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2569e-04 - tot_time: 0h 58m 0.3s\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2567e-04 - val_loss: 7.3011e-04\n",
      "Epoch 16/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2630e-04 - tot_time: 0h 58m 1.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2543e-04 - val_loss: 7.3037e-04\n",
      "Epoch 17/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2561e-04 - tot_time: 0h 58m 1.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2561e-04 - val_loss: 7.2975e-04\n",
      "Epoch 18/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2543e-04 - tot_time: 0h 58m 2.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2543e-04 - val_loss: 7.2966e-04\n",
      "Epoch 19/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2583e-04 - tot_time: 0h 58m 3.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2553e-04 - val_loss: 7.3045e-04\n",
      "Epoch 20/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2547e-04 - tot_time: 0h 58m 4.5s\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2555e-04 - val_loss: 7.2964e-04\n",
      "Epoch 21/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2337e-04 - tot_time: 0h 58m 5.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2540e-04 - val_loss: 7.2912e-04\n",
      "Epoch 22/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2545e-04 - tot_time: 0h 58m 6.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2542e-04 - val_loss: 7.3078e-04\n",
      "Epoch 23/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2639e-04 - tot_time: 0h 58m 7.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2539e-04 - val_loss: 7.2979e-04\n",
      "Epoch 24/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2726e-04 - tot_time: 0h 58m 8.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2558e-04 - val_loss: 7.3057e-04\n",
      "Epoch 25/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2667e-04 - tot_time: 0h 58m 8.7s\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2563e-04 - val_loss: 7.2977e-04\n",
      "Epoch 26/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2528e-04 - tot_time: 0h 58m 9.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2549e-04 - val_loss: 7.2960e-04\n",
      "Epoch 27/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2541e-04 - tot_time: 0h 58m 10.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2541e-04 - val_loss: 7.2966e-04\n",
      "Epoch 28/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 7.2477e-04 - tot_time: 0h 58m 11.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2537e-04 - val_loss: 7.2920e-04\n",
      "Epoch 29/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2554e-04 - tot_time: 0h 58m 11.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2550e-04 - val_loss: 7.2993e-04\n",
      "Epoch 30/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2516e-04 - tot_time: 0h 58m 12.9s\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2545e-04 - val_loss: 7.3011e-04\n",
      "Epoch 31/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2657e-04 - tot_time: 0h 58m 13.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2548e-04 - val_loss: 7.3226e-04\n",
      "Epoch 32/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2666e-04 - tot_time: 0h 58m 14.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2587e-04 - val_loss: 7.2954e-04\n",
      "Epoch 33/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2533e-04 - tot_time: 0h 58m 15.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2533e-04 - val_loss: 7.3110e-04\n",
      "Epoch 34/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 7.2824e-04 - tot_time: 0h 58m 16.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2575e-04 - val_loss: 7.2963e-04\n",
      "Epoch 35/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2544e-04 - tot_time: 0h 58m 17.1s\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2544e-04 - val_loss: 7.3008e-04\n",
      "Epoch 36/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2508e-04 - tot_time: 0h 58m 18.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2525e-04 - val_loss: 7.2895e-04\n",
      "Epoch 37/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2611e-04 - tot_time: 0h 58m 18.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2542e-04 - val_loss: 7.2937e-04\n",
      "Epoch 38/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2612e-04 - tot_time: 0h 58m 19.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2574e-04 - val_loss: 7.2910e-04\n",
      "Epoch 39/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2562e-04 - tot_time: 0h 58m 20.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2530e-04 - val_loss: 7.2980e-04\n",
      "Epoch 40/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2157e-04 - tot_time: 0h 58m 21.4s\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2538e-04 - val_loss: 7.3085e-04\n",
      "Epoch 41/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2579e-04 - tot_time: 0h 58m 22.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2533e-04 - val_loss: 7.3085e-04\n",
      "Epoch 42/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2607e-04 - tot_time: 0h 58m 23.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2531e-04 - val_loss: 7.2903e-04\n",
      "Epoch 43/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2505e-04 - tot_time: 0h 58m 24.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2546e-04 - val_loss: 7.2950e-04\n",
      "Epoch 44/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2583e-04 - tot_time: 0h 58m 24.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2542e-04 - val_loss: 7.2940e-04\n",
      "Epoch 45/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2649e-04 - tot_time: 0h 58m 25.9s\n",
      "\n",
      "Epoch 45: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2530e-04 - val_loss: 7.2945e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2556e-04 - tot_time: 0h 58m 26.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2520e-04 - val_loss: 7.2985e-04\n",
      "Epoch 47/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2584e-04 - tot_time: 0h 58m 27.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2532e-04 - val_loss: 7.3000e-04\n",
      "Epoch 48/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2556e-04 - tot_time: 0h 58m 28.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2535e-04 - val_loss: 7.2966e-04\n",
      "Epoch 49/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2506e-04 - tot_time: 0h 58m 29.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2573e-04 - val_loss: 7.2926e-04\n",
      "Epoch 50/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2619e-04 - tot_time: 0h 58m 30.2s\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2573e-04 - val_loss: 7.3013e-04\n",
      "Epoch 51/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2519e-04 - tot_time: 0h 58m 31.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2519e-04 - val_loss: 7.2986e-04\n",
      "Epoch 52/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2642e-04 - tot_time: 0h 58m 31.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2520e-04 - val_loss: 7.2932e-04\n",
      "Epoch 53/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2519e-04 - tot_time: 0h 58m 32.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2531e-04 - val_loss: 7.2960e-04\n",
      "Epoch 54/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.2508e-04 - tot_time: 0h 58m 33.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2538e-04 - val_loss: 7.2946e-04\n",
      "Epoch 55/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2546e-04 - tot_time: 0h 58m 34.5s\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2550e-04 - val_loss: 7.2991e-04\n",
      "Epoch 56/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2474e-04 - tot_time: 0h 58m 35.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2534e-04 - val_loss: 7.2994e-04\n",
      "Epoch 57/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.2627e-04 - tot_time: 0h 58m 36.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2513e-04 - val_loss: 7.2984e-04\n",
      "Epoch 58/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2560e-04 - tot_time: 0h 58m 37.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2516e-04 - val_loss: 7.2951e-04\n",
      "Epoch 59/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2529e-04 - tot_time: 0h 58m 38.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2529e-04 - val_loss: 7.3052e-04\n",
      "Epoch 60/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2487e-04 - tot_time: 0h 58m 39.0s\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2530e-04 - val_loss: 7.3199e-04\n",
      "Epoch 61/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2555e-04 - tot_time: 0h 58m 39.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2554e-04 - val_loss: 7.2947e-04\n",
      "Epoch 62/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2497e-04 - tot_time: 0h 58m 40.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2524e-04 - val_loss: 7.3091e-04\n",
      "Epoch 63/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2590e-04 - tot_time: 0h 58m 41.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2561e-04 - val_loss: 7.2899e-04\n",
      "Epoch 64/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2642e-04 - tot_time: 0h 58m 42.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2547e-04 - val_loss: 7.2953e-04\n",
      "Epoch 65/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2530e-04 - tot_time: 0h 58m 43.5s\n",
      "\n",
      "Epoch 65: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2533e-04 - val_loss: 7.2916e-04\n",
      "Epoch 66/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2521e-04 - tot_time: 0h 58m 44.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2521e-04 - val_loss: 7.2933e-04\n",
      "Epoch 67/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2698e-04 - tot_time: 0h 58m 45.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2532e-04 - val_loss: 7.2908e-04\n",
      "Epoch 68/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2523e-04 - tot_time: 0h 58m 46.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2512e-04 - val_loss: 7.3047e-04\n",
      "Epoch 69/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2553e-04 - tot_time: 0h 58m 46.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2518e-04 - val_loss: 7.2908e-04\n",
      "Epoch 70/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2558e-04 - tot_time: 0h 58m 47.7s\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2531e-04 - val_loss: 7.2924e-04\n",
      "Epoch 71/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2508e-04 - tot_time: 0h 58m 48.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2504e-04 - val_loss: 7.3066e-04\n",
      "Epoch 72/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2524e-04 - tot_time: 0h 58m 49.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2509e-04 - val_loss: 7.2954e-04\n",
      "Epoch 73/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2581e-04 - tot_time: 0h 58m 50.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2516e-04 - val_loss: 7.2944e-04\n",
      "Epoch 74/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2543e-04 - tot_time: 0h 58m 51.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2539e-04 - val_loss: 7.2955e-04\n",
      "Epoch 75/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2641e-04 - tot_time: 0h 58m 52.0s\n",
      "\n",
      "Epoch 75: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2545e-04 - val_loss: 7.2903e-04\n",
      "Epoch 76/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2580e-04 - tot_time: 0h 58m 53.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2521e-04 - val_loss: 7.2917e-04\n",
      "Epoch 77/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2524e-04 - tot_time: 0h 58m 54.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2520e-04 - val_loss: 7.3015e-04\n",
      "Epoch 78/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2565e-04 - tot_time: 0h 58m 54.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2524e-04 - val_loss: 7.2925e-04\n",
      "Epoch 79/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2489e-04 - tot_time: 0h 58m 55.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2501e-04 - val_loss: 7.2884e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2560e-04 - tot_time: 0h 58m 56.7s\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2532e-04 - val_loss: 7.2950e-04\n",
      "Epoch 81/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2526e-04 - tot_time: 0h 58m 57.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2523e-04 - val_loss: 7.2959e-04\n",
      "Epoch 82/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2507e-04 - tot_time: 0h 58m 58.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2509e-04 - val_loss: 7.2965e-04\n",
      "Epoch 83/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2589e-04 - tot_time: 0h 58m 59.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2517e-04 - val_loss: 7.2951e-04\n",
      "Epoch 84/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2542e-04 - tot_time: 0h 58m 59.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2506e-04 - val_loss: 7.2962e-04\n",
      "Epoch 85/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2536e-04 - tot_time: 0h 59m 0.9s\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2514e-04 - val_loss: 7.2986e-04\n",
      "Epoch 86/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2557e-04 - tot_time: 0h 59m 1.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2524e-04 - val_loss: 7.3073e-04\n",
      "Epoch 87/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2667e-04 - tot_time: 0h 59m 2.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2524e-04 - val_loss: 7.3038e-04\n",
      "Epoch 88/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2479e-04 - tot_time: 0h 59m 3.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2525e-04 - val_loss: 7.2998e-04\n",
      "Epoch 89/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2476e-04 - tot_time: 0h 59m 4.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2516e-04 - val_loss: 7.3068e-04\n",
      "Epoch 90/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2506e-04 - tot_time: 0h 59m 4.9s\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2506e-04 - val_loss: 7.2939e-04\n",
      "Epoch 91/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2470e-04 - tot_time: 0h 59m 5.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2495e-04 - val_loss: 7.2953e-04\n",
      "Epoch 92/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2522e-04 - tot_time: 0h 59m 6.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2522e-04 - val_loss: 7.2981e-04\n",
      "Epoch 93/2000\n",
      "111/124 [=========================>....] - ETA: 0s - loss: 7.2601e-04 - tot_time: 0h 59m 7.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2528e-04 - val_loss: 7.2962e-04\n",
      "Epoch 94/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2474e-04 - tot_time: 0h 59m 8.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2514e-04 - val_loss: 7.2899e-04\n",
      "Epoch 95/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2495e-04 - tot_time: 0h 59m 9.4s\n",
      "\n",
      "Epoch 95: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2495e-04 - val_loss: 7.2881e-04\n",
      "Epoch 96/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2479e-04 - tot_time: 0h 59m 10.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2519e-04 - val_loss: 7.2944e-04\n",
      "Epoch 97/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2509e-04 - tot_time: 0h 59m 11.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2505e-04 - val_loss: 7.2944e-04\n",
      "Epoch 98/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2449e-04 - tot_time: 0h 59m 12.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2487e-04 - val_loss: 7.2923e-04\n",
      "Epoch 99/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2512e-04 - tot_time: 0h 59m 12.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2512e-04 - val_loss: 7.2966e-04\n",
      "Epoch 100/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2350e-04 - tot_time: 0h 59m 13.8s\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2492e-04 - val_loss: 7.2962e-04\n",
      "Epoch 101/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2531e-04 - tot_time: 0h 59m 14.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2526e-04 - val_loss: 7.2976e-04\n",
      "Epoch 102/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2518e-04 - tot_time: 0h 59m 15.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2518e-04 - val_loss: 7.3029e-04\n",
      "Epoch 103/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2271e-04 - tot_time: 0h 59m 16.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2502e-04 - val_loss: 7.2992e-04\n",
      "Epoch 104/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2499e-04 - tot_time: 0h 59m 17.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2520e-04 - val_loss: 7.2880e-04\n",
      "Epoch 105/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2390e-04 - tot_time: 0h 59m 18.0s\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2493e-04 - val_loss: 7.3071e-04\n",
      "Epoch 106/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2515e-04 - tot_time: 0h 59m 19.1s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2499e-04 - val_loss: 7.2875e-04\n",
      "Epoch 107/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2522e-04 - tot_time: 0h 59m 19.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2515e-04 - val_loss: 7.2903e-04\n",
      "Epoch 108/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2517e-04 - tot_time: 0h 59m 20.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2514e-04 - val_loss: 7.2919e-04\n",
      "Epoch 109/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2559e-04 - tot_time: 0h 59m 21.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2494e-04 - val_loss: 7.2858e-04\n",
      "Epoch 110/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2490e-04 - tot_time: 0h 59m 22.5s\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2497e-04 - val_loss: 7.2880e-04\n",
      "Epoch 111/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2503e-04 - tot_time: 0h 59m 23.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2496e-04 - val_loss: 7.2936e-04\n",
      "Epoch 112/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2573e-04 - tot_time: 0h 59m 24.4s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2501e-04 - val_loss: 7.2877e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2445e-04 - tot_time: 0h 59m 25.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2489e-04 - val_loss: 7.2915e-04\n",
      "Epoch 114/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2463e-04 - tot_time: 0h 59m 26.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2504e-04 - val_loss: 7.3049e-04\n",
      "Epoch 115/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2590e-04 - tot_time: 0h 59m 27.0s\n",
      "\n",
      "Epoch 115: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2502e-04 - val_loss: 7.2870e-04\n",
      "Epoch 116/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2471e-04 - tot_time: 0h 59m 27.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2507e-04 - val_loss: 7.2869e-04\n",
      "Epoch 117/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2447e-04 - tot_time: 0h 59m 28.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.2978e-04\n",
      "Epoch 118/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2491e-04 - tot_time: 0h 59m 29.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2491e-04 - val_loss: 7.2930e-04\n",
      "Epoch 119/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2483e-04 - tot_time: 0h 59m 30.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2478e-04 - val_loss: 7.3251e-04\n",
      "Epoch 120/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2439e-04 - tot_time: 0h 59m 31.3s\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2503e-04 - val_loss: 7.2908e-04\n",
      "Epoch 121/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2460e-04 - tot_time: 0h 59m 32.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2500e-04 - val_loss: 7.3062e-04\n",
      "Epoch 122/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2481e-04 - tot_time: 0h 59m 33.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2493e-04 - val_loss: 7.2883e-04\n",
      "Epoch 123/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2557e-04 - tot_time: 0h 59m 34.1s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2500e-04 - val_loss: 7.2888e-04\n",
      "Epoch 124/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2495e-04 - tot_time: 0h 59m 35.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2485e-04 - val_loss: 7.3000e-04\n",
      "Epoch 125/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2543e-04 - tot_time: 0h 59m 35.7s\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2499e-04 - val_loss: 7.2954e-04\n",
      "Epoch 126/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2544e-04 - tot_time: 0h 59m 36.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2485e-04 - val_loss: 7.2896e-04\n",
      "Epoch 127/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.2414e-04 - tot_time: 0h 59m 37.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2485e-04 - val_loss: 7.2965e-04\n",
      "Epoch 128/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2614e-04 - tot_time: 0h 59m 38.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2501e-04 - val_loss: 7.2875e-04\n",
      "Epoch 129/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2465e-04 - tot_time: 0h 59m 39.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2475e-04 - val_loss: 7.2869e-04\n",
      "Epoch 130/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2519e-04 - tot_time: 0h 59m 40.3s\n",
      "\n",
      "Epoch 130: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2484e-04 - val_loss: 7.2854e-04\n",
      "Epoch 131/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2473e-04 - tot_time: 0h 59m 41.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2473e-04 - val_loss: 7.3076e-04\n",
      "Epoch 132/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2681e-04 - tot_time: 0h 59m 42.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2598e-04 - val_loss: 7.2979e-04\n",
      "Epoch 133/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2557e-04 - tot_time: 0h 59m 43.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2498e-04 - val_loss: 7.2924e-04\n",
      "Epoch 134/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2286e-04 - tot_time: 0h 59m 44.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2482e-04 - val_loss: 7.2874e-04\n",
      "Epoch 135/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2477e-04 - tot_time: 0h 59m 44.9s\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2475e-04 - val_loss: 7.2916e-04\n",
      "Epoch 136/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2576e-04 - tot_time: 0h 59m 45.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2497e-04 - val_loss: 7.2930e-04\n",
      "Epoch 137/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2376e-04 - tot_time: 0h 59m 46.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2484e-04 - val_loss: 7.2884e-04\n",
      "Epoch 138/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2469e-04 - tot_time: 0h 59m 47.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2467e-04 - val_loss: 7.2820e-04\n",
      "Epoch 139/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2652e-04 - tot_time: 0h 59m 48.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2473e-04 - val_loss: 7.2962e-04\n",
      "Epoch 140/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2493e-04 - tot_time: 0h 59m 49.2s\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2489e-04 - val_loss: 7.2946e-04\n",
      "Epoch 141/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2497e-04 - tot_time: 0h 59m 50.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2466e-04 - val_loss: 7.2892e-04\n",
      "Epoch 142/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2618e-04 - tot_time: 0h 59m 50.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2473e-04 - val_loss: 7.2841e-04\n",
      "Epoch 143/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2533e-04 - tot_time: 0h 59m 51.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2479e-04 - val_loss: 7.2929e-04\n",
      "Epoch 144/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2488e-04 - tot_time: 0h 59m 52.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2486e-04 - val_loss: 7.2958e-04\n",
      "Epoch 145/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2472e-04 - tot_time: 0h 59m 53.4s\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2472e-04 - val_loss: 7.2891e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2570e-04 - tot_time: 0h 59m 54.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2479e-04 - val_loss: 7.2897e-04\n",
      "Epoch 147/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2684e-04 - tot_time: 0h 59m 55.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2491e-04 - val_loss: 7.2966e-04\n",
      "Epoch 148/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2328e-04 - tot_time: 0h 59m 56.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2471e-04 - val_loss: 7.2898e-04\n",
      "Epoch 149/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2483e-04 - tot_time: 0h 59m 57.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2480e-04 - val_loss: 7.2934e-04\n",
      "Epoch 150/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2430e-04 - tot_time: 0h 59m 58.0s\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2451e-04 - val_loss: 7.2951e-04\n",
      "Epoch 151/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2526e-04 - tot_time: 0h 59m 58.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2481e-04 - val_loss: 7.2953e-04\n",
      "Epoch 152/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2591e-04 - tot_time: 0h 59m 59.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2459e-04 - val_loss: 7.2994e-04\n",
      "Epoch 153/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2537e-04 - tot_time: 1h 0m 0.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2506e-04 - val_loss: 7.2918e-04\n",
      "Epoch 154/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2439e-04 - tot_time: 1h 0m 1.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.2886e-04\n",
      "Epoch 155/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2471e-04 - tot_time: 1h 0m 2.6s\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.3044e-04\n",
      "Epoch 156/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2585e-04 - tot_time: 1h 0m 3.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2539e-04 - val_loss: 7.2914e-04\n",
      "Epoch 157/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2480e-04 - tot_time: 1h 0m 4.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2502e-04 - val_loss: 7.2866e-04\n",
      "Epoch 158/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2446e-04 - tot_time: 1h 0m 5.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2486e-04 - val_loss: 7.2920e-04\n",
      "Epoch 159/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2588e-04 - tot_time: 1h 0m 6.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2488e-04 - val_loss: 7.3147e-04\n",
      "Epoch 160/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2339e-04 - tot_time: 1h 0m 7.0s\n",
      "\n",
      "Epoch 160: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2476e-04 - val_loss: 7.2854e-04\n",
      "Epoch 161/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2606e-04 - tot_time: 1h 0m 8.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2475e-04 - val_loss: 7.2968e-04\n",
      "Epoch 162/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2532e-04 - tot_time: 1h 0m 8.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2467e-04 - val_loss: 7.2866e-04\n",
      "Epoch 163/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2425e-04 - tot_time: 1h 0m 9.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2469e-04 - val_loss: 7.2863e-04\n",
      "Epoch 164/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2365e-04 - tot_time: 1h 0m 10.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2458e-04 - val_loss: 7.2912e-04\n",
      "Epoch 165/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2462e-04 - tot_time: 1h 0m 11.4s\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2476e-04 - val_loss: 7.2904e-04\n",
      "Epoch 166/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2469e-04 - tot_time: 1h 0m 12.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.3007e-04\n",
      "Epoch 167/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2447e-04 - tot_time: 1h 0m 13.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2462e-04 - val_loss: 7.2952e-04\n",
      "Epoch 168/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2507e-04 - tot_time: 1h 0m 14.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2478e-04 - val_loss: 7.2955e-04\n",
      "Epoch 169/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2468e-04 - tot_time: 1h 0m 15.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.2856e-04\n",
      "Epoch 170/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2497e-04 - tot_time: 1h 0m 15.9s\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2447e-04 - val_loss: 7.2874e-04\n",
      "Epoch 171/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2475e-04 - tot_time: 1h 0m 16.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2471e-04 - val_loss: 7.2852e-04\n",
      "Epoch 172/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2449e-04 - tot_time: 1h 0m 17.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2445e-04 - val_loss: 7.2879e-04\n",
      "Epoch 173/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2587e-04 - tot_time: 1h 0m 18.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2483e-04 - val_loss: 7.2968e-04\n",
      "Epoch 174/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2452e-04 - tot_time: 1h 0m 19.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2461e-04 - val_loss: 7.2864e-04\n",
      "Epoch 175/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2464e-04 - tot_time: 1h 0m 20.5s\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2471e-04 - val_loss: 7.2930e-04\n",
      "Epoch 176/2000\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 7.2433e-04 - tot_time: 1h 0m 21.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2466e-04 - val_loss: 7.2890e-04\n",
      "Epoch 177/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2529e-04 - tot_time: 1h 0m 22.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2440e-04 - val_loss: 7.2908e-04\n",
      "Epoch 178/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2468e-04 - tot_time: 1h 0m 23.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2468e-04 - val_loss: 7.2859e-04\n",
      "Epoch 179/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2477e-04 - tot_time: 1h 0m 23.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2473e-04 - val_loss: 7.2826e-04\n",
      "Epoch 180/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 7.2450e-04 - tot_time: 1h 0m 24.7s\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2450e-04 - val_loss: 7.2908e-04\n",
      "Epoch 181/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2566e-04 - tot_time: 1h 0m 25.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2518e-04 - val_loss: 7.2828e-04\n",
      "Epoch 182/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2454e-04 - tot_time: 1h 0m 26.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2454e-04 - val_loss: 7.2892e-04\n",
      "Epoch 183/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2500e-04 - tot_time: 1h 0m 27.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2456e-04 - val_loss: 7.2886e-04\n",
      "Epoch 184/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2499e-04 - tot_time: 1h 0m 28.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2446e-04 - val_loss: 7.2909e-04\n",
      "Epoch 185/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2282e-04 - tot_time: 1h 0m 29.1s\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2460e-04 - val_loss: 7.2935e-04\n",
      "Epoch 186/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2529e-04 - tot_time: 1h 0m 30.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2467e-04 - val_loss: 7.2922e-04\n",
      "Epoch 187/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2472e-04 - tot_time: 1h 0m 30.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2463e-04 - val_loss: 7.2875e-04\n",
      "Epoch 188/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2458e-04 - tot_time: 1h 0m 31.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2458e-04 - val_loss: 7.2925e-04\n",
      "Epoch 189/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2480e-04 - tot_time: 1h 0m 32.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2464e-04 - val_loss: 7.2882e-04\n",
      "Epoch 190/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2440e-04 - tot_time: 1h 0m 33.5s\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2436e-04 - val_loss: 7.3015e-04\n",
      "Epoch 191/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2456e-04 - tot_time: 1h 0m 34.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2461e-04 - val_loss: 7.2904e-04\n",
      "Epoch 192/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2498e-04 - tot_time: 1h 0m 35.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2475e-04 - val_loss: 7.2866e-04\n",
      "Epoch 193/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2473e-04 - tot_time: 1h 0m 36.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2446e-04 - val_loss: 7.2847e-04\n",
      "Epoch 194/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2445e-04 - tot_time: 1h 0m 37.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2442e-04 - val_loss: 7.2947e-04\n",
      "Epoch 195/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2458e-04 - tot_time: 1h 0m 38.0s\n",
      "\n",
      "Epoch 195: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2454e-04 - val_loss: 7.2817e-04\n",
      "Epoch 196/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2443e-04 - tot_time: 1h 0m 38.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2446e-04 - val_loss: 7.3011e-04\n",
      "Epoch 197/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2496e-04 - tot_time: 1h 0m 39.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2454e-04 - val_loss: 7.2881e-04\n",
      "Epoch 198/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2371e-04 - tot_time: 1h 0m 40.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2453e-04 - val_loss: 7.2867e-04\n",
      "Epoch 199/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2439e-04 - tot_time: 1h 0m 41.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2455e-04 - val_loss: 7.2836e-04\n",
      "Epoch 200/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2589e-04 - tot_time: 1h 0m 42.4s\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2495e-04 - val_loss: 7.2838e-04\n",
      "Epoch 201/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2475e-04 - tot_time: 1h 0m 43.5s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2437e-04 - val_loss: 7.2851e-04\n",
      "Epoch 202/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2444e-04 - tot_time: 1h 0m 44.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2451e-04 - val_loss: 7.2812e-04\n",
      "Epoch 203/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2512e-04 - tot_time: 1h 0m 45.3s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2448e-04 - val_loss: 7.2852e-04\n",
      "Epoch 204/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2452e-04 - tot_time: 1h 0m 46.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2452e-04 - val_loss: 7.2833e-04\n",
      "Epoch 205/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2495e-04 - tot_time: 1h 0m 47.1s\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2470e-04 - val_loss: 7.2841e-04\n",
      "Epoch 206/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2459e-04 - tot_time: 1h 0m 48.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2436e-04 - val_loss: 7.3011e-04\n",
      "Epoch 207/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2447e-04 - tot_time: 1h 0m 49.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2447e-04 - val_loss: 7.2900e-04\n",
      "Epoch 208/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2521e-04 - tot_time: 1h 0m 50.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2426e-04 - val_loss: 7.2872e-04\n",
      "Epoch 209/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2503e-04 - tot_time: 1h 0m 51.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2441e-04 - val_loss: 7.3041e-04\n",
      "Epoch 210/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2572e-04 - tot_time: 1h 0m 51.6s\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2465e-04 - val_loss: 7.2861e-04\n",
      "Epoch 211/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2434e-04 - tot_time: 1h 0m 52.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2434e-04 - val_loss: 7.2909e-04\n",
      "Epoch 212/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2518e-04 - tot_time: 1h 0m 53.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2429e-04 - val_loss: 7.2851e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/124 [============================>.] - ETA: 0s - loss: 7.2423e-04 - tot_time: 1h 0m 54.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2442e-04 - val_loss: 7.2841e-04\n",
      "Epoch 214/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2557e-04 - tot_time: 1h 0m 55.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2411e-04 - val_loss: 7.2869e-04\n",
      "Epoch 215/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2486e-04 - tot_time: 1h 0m 56.2s\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2444e-04 - val_loss: 7.2857e-04\n",
      "Epoch 216/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2280e-04 - tot_time: 1h 0m 56.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2457e-04 - val_loss: 7.2816e-04\n",
      "Epoch 217/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2431e-04 - tot_time: 1h 0m 57.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2419e-04 - val_loss: 7.2782e-04\n",
      "Epoch 218/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2437e-04 - tot_time: 1h 0m 58.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2433e-04 - val_loss: 7.2930e-04\n",
      "Epoch 219/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2462e-04 - tot_time: 1h 0m 59.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2427e-04 - val_loss: 7.2835e-04\n",
      "Epoch 220/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2404e-04 - tot_time: 1h 1m 0.5s\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2440e-04 - val_loss: 7.2858e-04\n",
      "Epoch 221/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2583e-04 - tot_time: 1h 1m 1.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2433e-04 - val_loss: 7.2865e-04\n",
      "Epoch 222/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2450e-04 - tot_time: 1h 1m 2.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2458e-04 - val_loss: 7.3003e-04\n",
      "Epoch 223/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2329e-04 - tot_time: 1h 1m 3.2s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2472e-04 - val_loss: 7.2853e-04\n",
      "Epoch 224/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2441e-04 - tot_time: 1h 1m 4.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2436e-04 - val_loss: 7.3036e-04\n",
      "Epoch 225/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2440e-04 - tot_time: 1h 1m 4.9s\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2438e-04 - val_loss: 7.2850e-04\n",
      "Epoch 226/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2371e-04 - tot_time: 1h 1m 5.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2412e-04 - val_loss: 7.2984e-04\n",
      "Epoch 227/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2422e-04 - tot_time: 1h 1m 6.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2445e-04 - val_loss: 7.2888e-04\n",
      "Epoch 228/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2443e-04 - tot_time: 1h 1m 7.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2437e-04 - val_loss: 7.2794e-04\n",
      "Epoch 229/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2443e-04 - tot_time: 1h 1m 8.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2418e-04 - val_loss: 7.3203e-04\n",
      "Epoch 230/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2494e-04 - tot_time: 1h 1m 9.3s\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2494e-04 - val_loss: 7.2845e-04\n",
      "Epoch 231/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2423e-04 - tot_time: 1h 1m 10.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2423e-04 - val_loss: 7.2836e-04\n",
      "Epoch 232/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2460e-04 - tot_time: 1h 1m 11.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2417e-04 - val_loss: 7.2914e-04\n",
      "Epoch 233/2000\n",
      "111/124 [=========================>....] - ETA: 0s - loss: 7.2549e-04 - tot_time: 1h 1m 11.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2450e-04 - val_loss: 7.2851e-04\n",
      "Epoch 234/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2298e-04 - tot_time: 1h 1m 12.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2426e-04 - val_loss: 7.2960e-04\n",
      "Epoch 235/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2415e-04 - tot_time: 1h 1m 13.9s\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2415e-04 - val_loss: 7.2906e-04\n",
      "Epoch 236/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2416e-04 - tot_time: 1h 1m 14.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2416e-04 - val_loss: 7.2936e-04\n",
      "Epoch 237/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2522e-04 - tot_time: 1h 1m 15.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2422e-04 - val_loss: 7.2849e-04\n",
      "Epoch 238/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2371e-04 - tot_time: 1h 1m 16.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2415e-04 - val_loss: 7.2825e-04\n",
      "Epoch 239/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2401e-04 - tot_time: 1h 1m 17.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2424e-04 - val_loss: 7.2861e-04\n",
      "Epoch 240/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2501e-04 - tot_time: 1h 1m 18.1s\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2408e-04 - val_loss: 7.2825e-04\n",
      "Epoch 241/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2438e-04 - tot_time: 1h 1m 19.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2438e-04 - val_loss: 7.2796e-04\n",
      "Epoch 242/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2313e-04 - tot_time: 1h 1m 19.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2399e-04 - val_loss: 7.2812e-04\n",
      "Epoch 243/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2416e-04 - tot_time: 1h 1m 20.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2437e-04 - val_loss: 7.2827e-04\n",
      "Epoch 244/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2488e-04 - tot_time: 1h 1m 21.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2430e-04 - val_loss: 7.2873e-04\n",
      "Epoch 245/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2436e-04 - tot_time: 1h 1m 22.5s\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2407e-04 - val_loss: 7.2824e-04\n",
      "Epoch 246/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2460e-04 - tot_time: 1h 1m 23.6s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2414e-04 - val_loss: 7.2824e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2328e-04 - tot_time: 1h 1m 24.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2411e-04 - val_loss: 7.3016e-04\n",
      "Epoch 248/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2438e-04 - tot_time: 1h 1m 25.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2442e-04 - val_loss: 7.2897e-04\n",
      "Epoch 249/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2435e-04 - tot_time: 1h 1m 26.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2435e-04 - val_loss: 7.2874e-04\n",
      "Epoch 250/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2520e-04 - tot_time: 1h 1m 27.1s\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2431e-04 - val_loss: 7.2824e-04\n",
      "Epoch 251/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2473e-04 - tot_time: 1h 1m 28.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2441e-04 - val_loss: 7.2875e-04\n",
      "Epoch 252/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2399e-04 - tot_time: 1h 1m 29.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2399e-04 - val_loss: 7.2781e-04\n",
      "Epoch 253/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2369e-04 - tot_time: 1h 1m 29.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2405e-04 - val_loss: 7.2925e-04\n",
      "Epoch 254/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2411e-04 - tot_time: 1h 1m 30.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2411e-04 - val_loss: 7.2824e-04\n",
      "Epoch 255/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2413e-04 - tot_time: 1h 1m 31.7s\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2409e-04 - val_loss: 7.2974e-04\n",
      "Epoch 256/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2550e-04 - tot_time: 1h 1m 32.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2421e-04 - val_loss: 7.2852e-04\n",
      "Epoch 257/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2405e-04 - tot_time: 1h 1m 33.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2416e-04 - val_loss: 7.2880e-04\n",
      "Epoch 258/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2333e-04 - tot_time: 1h 1m 34.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2424e-04 - val_loss: 7.2961e-04\n",
      "Epoch 259/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2450e-04 - tot_time: 1h 1m 35.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2450e-04 - val_loss: 7.2867e-04\n",
      "Epoch 260/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2405e-04 - tot_time: 1h 1m 35.9s\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2406e-04 - val_loss: 7.2868e-04\n",
      "Epoch 261/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2259e-04 - tot_time: 1h 1m 37.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2404e-04 - val_loss: 7.3084e-04\n",
      "Epoch 262/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2449e-04 - tot_time: 1h 1m 37.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2449e-04 - val_loss: 7.2871e-04\n",
      "Epoch 263/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2420e-04 - tot_time: 1h 1m 38.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2420e-04 - val_loss: 7.2860e-04\n",
      "Epoch 264/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2407e-04 - tot_time: 1h 1m 39.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2397e-04 - val_loss: 7.2788e-04\n",
      "Epoch 265/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2396e-04 - tot_time: 1h 1m 40.2s\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2396e-04 - val_loss: 7.2905e-04\n",
      "Epoch 266/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2477e-04 - tot_time: 1h 1m 41.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2393e-04 - val_loss: 7.2931e-04\n",
      "Epoch 267/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2484e-04 - tot_time: 1h 1m 42.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2402e-04 - val_loss: 7.2927e-04\n",
      "Epoch 268/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2406e-04 - tot_time: 1h 1m 42.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2400e-04 - val_loss: 7.2844e-04\n",
      "Epoch 269/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2409e-04 - tot_time: 1h 1m 43.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2409e-04 - val_loss: 7.2781e-04\n",
      "Epoch 270/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.2618e-04 - tot_time: 1h 1m 44.7s\n",
      "\n",
      "Epoch 270: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2417e-04 - val_loss: 7.2800e-04\n",
      "Epoch 271/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2403e-04 - tot_time: 1h 1m 45.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2403e-04 - val_loss: 7.2865e-04\n",
      "Epoch 272/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2318e-04 - tot_time: 1h 1m 46.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2411e-04 - val_loss: 7.2939e-04\n",
      "Epoch 273/2000\n",
      "113/124 [==========================>...] - ETA: 0s - loss: 7.2658e-04 - tot_time: 1h 1m 47.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2428e-04 - val_loss: 7.2851e-04\n",
      "Epoch 274/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2513e-04 - tot_time: 1h 1m 48.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2438e-04 - val_loss: 7.2794e-04\n",
      "Epoch 275/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2394e-04 - tot_time: 1h 1m 49.1s\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2402e-04 - val_loss: 7.2966e-04\n",
      "Epoch 276/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2406e-04 - tot_time: 1h 1m 49.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2402e-04 - val_loss: 7.2812e-04\n",
      "Epoch 277/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2429e-04 - tot_time: 1h 1m 50.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2410e-04 - val_loss: 7.2867e-04\n",
      "Epoch 278/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2408e-04 - tot_time: 1h 1m 51.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2408e-04 - val_loss: 7.2811e-04\n",
      "Epoch 279/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2521e-04 - tot_time: 1h 1m 52.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2412e-04 - val_loss: 7.2841e-04\n",
      "Epoch 280/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2394e-04 - tot_time: 1h 1m 53.4s\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2394e-04 - val_loss: 7.2831e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2417e-04 - tot_time: 1h 1m 54.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2402e-04 - val_loss: 7.2882e-04\n",
      "Epoch 282/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2329e-04 - tot_time: 1h 1m 55.1s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2399e-04 - val_loss: 7.2801e-04\n",
      "Epoch 283/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2453e-04 - tot_time: 1h 1m 56.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2411e-04 - val_loss: 7.2799e-04\n",
      "Epoch 284/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2388e-04 - tot_time: 1h 1m 57.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2398e-04 - val_loss: 7.2862e-04\n",
      "Epoch 285/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2449e-04 - tot_time: 1h 1m 57.7s\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2390e-04 - val_loss: 7.2886e-04\n",
      "Epoch 286/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2404e-04 - tot_time: 1h 1m 58.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2404e-04 - val_loss: 7.2847e-04\n",
      "Epoch 287/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2410e-04 - tot_time: 1h 1m 59.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2407e-04 - val_loss: 7.2807e-04\n",
      "Epoch 288/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2328e-04 - tot_time: 1h 2m 0.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2427e-04 - val_loss: 7.2886e-04\n",
      "Epoch 289/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2454e-04 - tot_time: 1h 2m 1.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2421e-04 - val_loss: 7.2830e-04\n",
      "Epoch 290/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2492e-04 - tot_time: 1h 2m 2.3s\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2400e-04 - val_loss: 7.2874e-04\n",
      "Epoch 291/2000\n",
      "111/124 [=========================>....] - ETA: 0s - loss: 7.2506e-04 - tot_time: 1h 2m 2.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2413e-04 - val_loss: 7.2836e-04\n",
      "Epoch 292/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2415e-04 - tot_time: 1h 2m 4.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2409e-04 - val_loss: 7.2910e-04\n",
      "Epoch 293/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2376e-04 - tot_time: 1h 2m 5.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2383e-04 - val_loss: 7.2825e-04\n",
      "Epoch 294/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2414e-04 - tot_time: 1h 2m 5.6s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2409e-04 - val_loss: 7.2782e-04\n",
      "Epoch 295/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2421e-04 - tot_time: 1h 2m 6.6s\n",
      "\n",
      "Epoch 295: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2393e-04 - val_loss: 7.2785e-04\n",
      "Epoch 296/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2394e-04 - tot_time: 1h 2m 7.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2394e-04 - val_loss: 7.2861e-04\n",
      "Epoch 297/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2396e-04 - tot_time: 1h 2m 8.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2400e-04 - val_loss: 7.2783e-04\n",
      "Epoch 298/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2395e-04 - tot_time: 1h 2m 9.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2393e-04 - val_loss: 7.2805e-04\n",
      "Epoch 299/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2427e-04 - tot_time: 1h 2m 10.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2396e-04 - val_loss: 7.2905e-04\n",
      "Epoch 300/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2449e-04 - tot_time: 1h 2m 11.0s\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2452e-04 - val_loss: 7.2845e-04\n",
      "Epoch 301/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2467e-04 - tot_time: 1h 2m 12.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2395e-04 - val_loss: 7.2898e-04\n",
      "Epoch 302/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2275e-04 - tot_time: 1h 2m 12.8s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2392e-04 - val_loss: 7.2834e-04\n",
      "Epoch 303/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2411e-04 - tot_time: 1h 2m 13.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2411e-04 - val_loss: 7.2802e-04\n",
      "Epoch 304/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2462e-04 - tot_time: 1h 2m 14.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2379e-04 - val_loss: 7.2826e-04\n",
      "Epoch 305/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2406e-04 - tot_time: 1h 2m 15.5s\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2398e-04 - val_loss: 7.2910e-04\n",
      "Epoch 306/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2383e-04 - tot_time: 1h 2m 16.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2421e-04 - val_loss: 7.2890e-04\n",
      "Epoch 307/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2227e-04 - tot_time: 1h 2m 17.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2379e-04 - val_loss: 7.2987e-04\n",
      "Epoch 308/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2590e-04 - tot_time: 1h 2m 18.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2452e-04 - val_loss: 7.2831e-04\n",
      "Epoch 309/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2372e-04 - tot_time: 1h 2m 19.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2368e-04 - val_loss: 7.2789e-04\n",
      "Epoch 310/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2510e-04 - tot_time: 1h 2m 20.1s\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2393e-04 - val_loss: 7.2802e-04\n",
      "Epoch 311/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2367e-04 - tot_time: 1h 2m 20.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2409e-04 - val_loss: 7.2818e-04\n",
      "Epoch 312/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2405e-04 - tot_time: 1h 2m 21.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2390e-04 - val_loss: 7.2781e-04\n",
      "Epoch 313/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2391e-04 - tot_time: 1h 2m 22.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2391e-04 - val_loss: 7.2744e-04\n",
      "Epoch 314/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2353e-04 - tot_time: 1h 2m 23.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2378e-04 - val_loss: 7.2803e-04\n",
      "Epoch 315/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2481e-04 - tot_time: 1h 2m 24.2s\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2378e-04 - val_loss: 7.2881e-04\n",
      "Epoch 316/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2375e-04 - tot_time: 1h 2m 25.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2375e-04 - val_loss: 7.2767e-04\n",
      "Epoch 317/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2373e-04 - tot_time: 1h 2m 25.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2373e-04 - val_loss: 7.2828e-04\n",
      "Epoch 318/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2499e-04 - tot_time: 1h 2m 26.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2381e-04 - val_loss: 7.2838e-04\n",
      "Epoch 319/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2424e-04 - tot_time: 1h 2m 27.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2390e-04 - val_loss: 7.2752e-04\n",
      "Epoch 320/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2379e-04 - tot_time: 1h 2m 28.5s\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2379e-04 - val_loss: 7.2797e-04\n",
      "Epoch 321/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2426e-04 - tot_time: 1h 2m 29.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2389e-04 - val_loss: 7.2823e-04\n",
      "Epoch 322/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2562e-04 - tot_time: 1h 2m 30.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2421e-04 - val_loss: 7.2853e-04\n",
      "Epoch 323/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2382e-04 - tot_time: 1h 2m 31.2s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2378e-04 - val_loss: 7.2839e-04\n",
      "Epoch 324/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2323e-04 - tot_time: 1h 2m 32.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2367e-04 - val_loss: 7.2780e-04\n",
      "Epoch 325/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2471e-04 - tot_time: 1h 2m 33.1s\n",
      "\n",
      "Epoch 325: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2370e-04 - val_loss: 7.2761e-04\n",
      "Epoch 326/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2378e-04 - tot_time: 1h 2m 33.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2378e-04 - val_loss: 7.2812e-04\n",
      "Epoch 327/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2291e-04 - tot_time: 1h 2m 35.0s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2364e-04 - val_loss: 7.2793e-04\n",
      "Epoch 328/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2432e-04 - tot_time: 1h 2m 35.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2378e-04 - val_loss: 7.2802e-04\n",
      "Epoch 329/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2375e-04 - tot_time: 1h 2m 36.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2375e-04 - val_loss: 7.2769e-04\n",
      "Epoch 330/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2366e-04 - tot_time: 1h 2m 37.6s\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2401e-04 - val_loss: 7.2842e-04\n",
      "Epoch 331/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.2454e-04 - tot_time: 1h 2m 38.4s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2374e-04 - val_loss: 7.2765e-04\n",
      "Epoch 332/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2355e-04 - tot_time: 1h 2m 39.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2382e-04 - val_loss: 7.2811e-04\n",
      "Epoch 333/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2268e-04 - tot_time: 1h 2m 40.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2362e-04 - val_loss: 7.2835e-04\n",
      "Epoch 334/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2632e-04 - tot_time: 1h 2m 40.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2359e-04 - val_loss: 7.2774e-04\n",
      "Epoch 335/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2373e-04 - tot_time: 1h 2m 41.8s\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2373e-04 - val_loss: 7.2770e-04\n",
      "Epoch 336/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2359e-04 - tot_time: 1h 2m 42.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2359e-04 - val_loss: 7.2798e-04\n",
      "Epoch 337/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2406e-04 - tot_time: 1h 2m 43.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2373e-04 - val_loss: 7.2760e-04\n",
      "Epoch 338/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2405e-04 - tot_time: 1h 2m 44.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2375e-04 - val_loss: 7.2840e-04\n",
      "Epoch 339/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2385e-04 - tot_time: 1h 2m 45.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2385e-04 - val_loss: 7.2814e-04\n",
      "Epoch 340/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2358e-04 - tot_time: 1h 2m 46.1s\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2354e-04 - val_loss: 7.2782e-04\n",
      "Epoch 341/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2356e-04 - tot_time: 1h 2m 47.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2356e-04 - val_loss: 7.2763e-04\n",
      "Epoch 342/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2389e-04 - tot_time: 1h 2m 48.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2361e-04 - val_loss: 7.2741e-04\n",
      "Epoch 343/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2459e-04 - tot_time: 1h 2m 48.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2378e-04 - val_loss: 7.2845e-04\n",
      "Epoch 344/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2374e-04 - tot_time: 1h 2m 49.9s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2384e-04 - val_loss: 7.2733e-04\n",
      "Epoch 345/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2367e-04 - tot_time: 1h 2m 50.8s\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2373e-04 - val_loss: 7.2782e-04\n",
      "Epoch 346/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2457e-04 - tot_time: 1h 2m 51.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2380e-04 - val_loss: 7.2790e-04\n",
      "Epoch 347/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2367e-04 - tot_time: 1h 2m 52.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2364e-04 - val_loss: 7.2760e-04\n",
      "Epoch 348/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2405e-04 - tot_time: 1h 2m 53.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2355e-04 - val_loss: 7.2836e-04\n",
      "Epoch 349/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2164e-04 - tot_time: 1h 2m 54.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2359e-04 - val_loss: 7.2807e-04\n",
      "Epoch 350/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2339e-04 - tot_time: 1h 2m 55.0s\n",
      "\n",
      "Epoch 350: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2372e-04 - val_loss: 7.2742e-04\n",
      "Epoch 351/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2388e-04 - tot_time: 1h 2m 55.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2383e-04 - val_loss: 7.2819e-04\n",
      "Epoch 352/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2360e-04 - tot_time: 1h 2m 56.6s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2360e-04 - val_loss: 7.2779e-04\n",
      "Epoch 353/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2073e-04 - tot_time: 1h 2m 57.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2355e-04 - val_loss: 7.2796e-04\n",
      "Epoch 354/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2410e-04 - tot_time: 1h 2m 58.4s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2376e-04 - val_loss: 7.2803e-04\n",
      "Epoch 355/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2361e-04 - tot_time: 1h 2m 59.2s\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2361e-04 - val_loss: 7.2763e-04\n",
      "Epoch 356/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2433e-04 - tot_time: 1h 3m 0.1s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2373e-04 - val_loss: 7.2814e-04\n",
      "Epoch 357/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2595e-04 - tot_time: 1h 3m 1.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2364e-04 - val_loss: 7.2784e-04\n",
      "Epoch 358/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2353e-04 - tot_time: 1h 3m 1.8s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2354e-04 - val_loss: 7.2741e-04\n",
      "Epoch 359/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2389e-04 - tot_time: 1h 3m 2.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2389e-04 - val_loss: 7.2785e-04\n",
      "Epoch 360/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2343e-04 - tot_time: 1h 3m 3.6s\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2371e-04 - val_loss: 7.2775e-04\n",
      "Epoch 361/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2390e-04 - tot_time: 1h 3m 4.3s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2386e-04 - val_loss: 7.2833e-04\n",
      "Epoch 362/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2395e-04 - tot_time: 1h 3m 5.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2385e-04 - val_loss: 7.2873e-04\n",
      "Epoch 363/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2134e-04 - tot_time: 1h 3m 6.2s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2365e-04 - val_loss: 7.2770e-04\n",
      "Epoch 364/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2531e-04 - tot_time: 1h 3m 7.0s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2354e-04 - val_loss: 7.2785e-04\n",
      "Epoch 365/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2207e-04 - tot_time: 1h 3m 7.9s\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2351e-04 - val_loss: 7.2891e-04\n",
      "Epoch 366/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2269e-04 - tot_time: 1h 3m 8.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2429e-04 - val_loss: 7.2749e-04\n",
      "Epoch 367/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2352e-04 - tot_time: 1h 3m 9.5s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2354e-04 - val_loss: 7.2805e-04\n",
      "Epoch 368/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2435e-04 - tot_time: 1h 3m 10.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2370e-04 - val_loss: 7.2810e-04\n",
      "Epoch 369/2000\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 7.2452e-04 - tot_time: 1h 3m 11.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2336e-04 - val_loss: 7.2806e-04\n",
      "Epoch 370/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2389e-04 - tot_time: 1h 3m 12.2s\n",
      "\n",
      "Epoch 370: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2348e-04 - val_loss: 7.2732e-04\n",
      "Epoch 371/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2348e-04 - tot_time: 1h 3m 13.1s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2348e-04 - val_loss: 7.2746e-04\n",
      "Epoch 372/2000\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 7.2420e-04 - tot_time: 1h 3m 13.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2352e-04 - val_loss: 7.2759e-04\n",
      "Epoch 373/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2310e-04 - tot_time: 1h 3m 14.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2360e-04 - val_loss: 7.2743e-04\n",
      "Epoch 374/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2352e-04 - tot_time: 1h 3m 15.8s\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 7.2352e-04 - val_loss: 7.2974e-04\n",
      "Epoch 375/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2186e-04 - tot_time: 1h 3m 16.6s\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2337e-04 - val_loss: 7.2905e-04\n",
      "Epoch 376/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2603e-04 - tot_time: 1h 3m 17.5s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2573e-04 - val_loss: 7.2783e-04\n",
      "Epoch 377/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2332e-04 - tot_time: 1h 3m 18.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2337e-04 - val_loss: 7.2720e-04\n",
      "Epoch 378/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2369e-04 - tot_time: 1h 3m 19.2s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2369e-04 - val_loss: 7.2786e-04\n",
      "Epoch 379/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2404e-04 - tot_time: 1h 3m 20.0s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2339e-04 - val_loss: 7.2732e-04\n",
      "Epoch 380/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2397e-04 - tot_time: 1h 3m 21.0s\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2334e-04 - val_loss: 7.2758e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2394e-04 - tot_time: 1h 3m 21.7s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2317e-04 - val_loss: 7.2764e-04\n",
      "Epoch 382/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2364e-04 - tot_time: 1h 3m 22.6s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2358e-04 - val_loss: 7.2774e-04\n",
      "Epoch 383/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2357e-04 - tot_time: 1h 3m 23.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2364e-04 - val_loss: 7.2812e-04\n",
      "Epoch 384/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2415e-04 - tot_time: 1h 3m 24.3s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2351e-04 - val_loss: 7.2782e-04\n",
      "Epoch 385/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2308e-04 - tot_time: 1h 3m 25.2s\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2349e-04 - val_loss: 7.2754e-04\n",
      "Epoch 386/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2437e-04 - tot_time: 1h 3m 26.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2325e-04 - val_loss: 7.2764e-04\n",
      "Epoch 387/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2358e-04 - tot_time: 1h 3m 26.8s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2355e-04 - val_loss: 7.2801e-04\n",
      "Epoch 388/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2384e-04 - tot_time: 1h 3m 27.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2346e-04 - val_loss: 7.2812e-04\n",
      "Epoch 389/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2319e-04 - tot_time: 1h 3m 28.7s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2336e-04 - val_loss: 7.2721e-04\n",
      "Epoch 390/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2280e-04 - tot_time: 1h 3m 29.3s\n",
      "\n",
      "Epoch 390: val_loss improved from 0.00073 to 0.00073, saving model to /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2381e-04 - val_loss: 7.2728e-04\n",
      "Epoch 391/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2286e-04 - tot_time: 1h 3m 30.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2343e-04 - val_loss: 7.2841e-04\n",
      "Epoch 392/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2445e-04 - tot_time: 1h 3m 31.3s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2385e-04 - val_loss: 7.2819e-04\n",
      "Epoch 393/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2384e-04 - tot_time: 1h 3m 32.0s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2352e-04 - val_loss: 7.2765e-04\n",
      "Epoch 394/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2356e-04 - tot_time: 1h 3m 32.9s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2348e-04 - val_loss: 7.2795e-04\n",
      "Epoch 395/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2339e-04 - tot_time: 1h 3m 33.8s\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2339e-04 - val_loss: 7.2748e-04\n",
      "Epoch 396/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2409e-04 - tot_time: 1h 3m 34.5s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2330e-04 - val_loss: 7.2733e-04\n",
      "Epoch 397/2000\n",
      "121/124 [============================>.] - ETA: 0s - loss: 7.2390e-04 - tot_time: 1h 3m 35.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2348e-04 - val_loss: 7.2797e-04\n",
      "Epoch 398/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2449e-04 - tot_time: 1h 3m 36.5s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2329e-04 - val_loss: 7.2853e-04\n",
      "Epoch 399/2000\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 7.2371e-04 - tot_time: 1h 3m 37.1s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2352e-04 - val_loss: 7.2740e-04\n",
      "Epoch 400/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2384e-04 - tot_time: 1h 3m 38.1s\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2344e-04 - val_loss: 7.2752e-04\n",
      "Epoch 401/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2412e-04 - tot_time: 1h 3m 39.0s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2324e-04 - val_loss: 7.2751e-04\n",
      "Epoch 402/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2339e-04 - tot_time: 1h 3m 39.7s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2325e-04 - val_loss: 7.2830e-04\n",
      "Epoch 403/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2333e-04 - tot_time: 1h 3m 40.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2354e-04 - val_loss: 7.2767e-04\n",
      "Epoch 404/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2295e-04 - tot_time: 1h 3m 41.6s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2356e-04 - val_loss: 7.2706e-04\n",
      "Epoch 405/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2326e-04 - tot_time: 1h 3m 42.2s\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2325e-04 - val_loss: 7.2753e-04\n",
      "Epoch 406/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2383e-04 - tot_time: 1h 3m 43.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2345e-04 - val_loss: 7.2795e-04\n",
      "Epoch 407/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2343e-04 - tot_time: 1h 3m 44.2s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2338e-04 - val_loss: 7.2787e-04\n",
      "Epoch 408/2000\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 7.2151e-04 - tot_time: 1h 3m 44.9s\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 7.2322e-04 - val_loss: 7.2758e-04\n",
      "Epoch 409/2000\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 7.2281e-04 - tot_time: 1h 3m 45.8s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2340e-04 - val_loss: 7.2771e-04\n",
      "Epoch 410/2000\n",
      "117/124 [===========================>..] - ETA: 0s - loss: 7.2447e-04 - tot_time: 1h 3m 46.8s\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2345e-04 - val_loss: 7.2852e-04\n",
      "Epoch 411/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2424e-04 - tot_time: 1h 3m 47.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2332e-04 - val_loss: 7.2721e-04\n",
      "Epoch 412/2000\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2317e-04 - tot_time: 1h 3m 48.4s\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.2317e-04 - val_loss: 7.2762e-04\n",
      "Epoch 413/2000\n",
      "120/124 [============================>.] - ETA: 0s - loss: 7.2297e-04 - tot_time: 1h 3m 49.3s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2326e-04 - val_loss: 7.2760e-04\n",
      "Epoch 414/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2336e-04 - tot_time: 1h 3m 49.9s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2334e-04 - val_loss: 7.2710e-04\n",
      "Epoch 415/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - ETA: 0s - loss: 7.2318e-04 - tot_time: 1h 3m 50.8s\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.00073\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Lorenz/saved_ae/ae_003/checkpoints/LossHistoriesCheckpoint\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2318e-04 - val_loss: 7.2754e-04\n",
      "Epoch 416/2000\n",
      "123/124 [============================>.] - ETA: 0s - loss: 7.2350e-04 - tot_time: 1h 3m 51.7s\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2347e-04 - val_loss: 7.2803e-04\n",
      "Epoch 417/2000\n",
      "122/124 [============================>.] - ETA: 0s - loss: 7.2229e-04Restoring model weights from the end of the best epoch: 217.\n",
      " - tot_time: 1h 3m 52.4s\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 7.2336e-04 - val_loss: 7.2732e-04\n",
      "Epoch 417: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compiling the network\n",
    "ae_net.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_list[0]),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "    run_eagerly=False\n",
    ")\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # implementing early stopping\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=True,\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "\n",
    "    # time callback for each epoch\n",
    "    timekeeper_cb = mytimecallback()\n",
    "\n",
    "    # model checkpoint callback\n",
    "    dir_name_ckpt = dir_name_ae+dir_sep+'checkpoints'\n",
    "    if not os.path.isdir(dir_name_ckpt):\n",
    "        os.makedirs(dir_name_ckpt)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=dir_name_ckpt+dir_sep+'checkpoint',#+'/checkpoint--loss={loss:.4f}--vall_loss={val_loss:.4f}',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=2,\n",
    "        period=5  # saves every 5 epochs\n",
    "    )\n",
    "\n",
    "    # save losses callback\n",
    "    savelosses_cb = SaveLosses(\n",
    "        filepath=dir_name_ckpt+dir_sep+'LossHistoriesCheckpoint',\n",
    "        val_loss_arr=savelosses_cb_vallossarr,\n",
    "        train_loss_arr=savelosses_cb_trainlossarr,\n",
    "        total_epochs=epochs,\n",
    "        period=5)\n",
    "\n",
    "    # training the network\n",
    "    for i in range(starting_lr_idx, len(learning_rate_list)):\n",
    "        learning_rate = learning_rate_list[i]\n",
    "        K.set_value(ae_net.optimizer.lr, learning_rate)\n",
    "\n",
    "        savelosses_cb.update_lr_idx(i)\n",
    "\n",
    "        if i == starting_lr_idx:\n",
    "            EPOCHS = num_epochs_left\n",
    "            savelosses_cb.update_offset(epochs-num_epochs_left)\n",
    "        else:\n",
    "            EPOCHS = epochs\n",
    "            savelosses_cb.update_offset(0)\n",
    "\n",
    "        total_s_len = 80\n",
    "        sep_lr_s = ' LEARNING RATE : {} '.format(learning_rate)\n",
    "        sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'-' + sep_lr_s\n",
    "        sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'-'\n",
    "        print('\\n\\n' + '-'*len(sep_lr_s))\n",
    "        print('\\n' + sep_lr_s+'\\n')\n",
    "        print('-'*len(sep_lr_s) + '\\n\\n')\n",
    "        \n",
    "        history = ae_net.fit(training_data, training_data,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=val_split/train_split,\n",
    "            callbacks=[early_stopping_cb, timekeeper_cb, checkpoint_cb, savelosses_cb],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss_hist.extend(history.history['val_loss'])\n",
    "        train_loss_hist.extend(history.history['loss'])\n",
    "        \n",
    "        if i == starting_lr_idx:\n",
    "            lr_change[i+1] += len(history.history['val_loss'])\n",
    "        else:\n",
    "            lr_change.append(lr_change[i]+len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "d_Od0ul4P9bK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0646e-04\n"
     ]
    }
   ],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    test_loss = ae_net.evaluate(\n",
    "        testing_data, testing_data,\n",
    "    )\n",
    "\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "\n",
    "    with open(save_path+dir_sep+'losses.txt', 'w') as f:\n",
    "        f.write(str({\n",
    "            'val_loss_hist':val_loss_hist,\n",
    "            'train_loss_hist':train_loss_hist,\n",
    "            'lr_change':lr_change,\n",
    "            'test_loss':test_loss\n",
    "        }))\n",
    "\n",
    "    ae_net.save_everything(\n",
    "        save_path+dir_sep+'final_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZWXz2WjRzbq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-TW6oTlSUbt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAFlvxJBUom3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NVzLHfwU2SW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXJhKlboU9gp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy8GNcgMVD4T"
   },
   "outputs": [],
   "source": [
    "lr_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Upzed-grUiCb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ewTz1COFSocM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting losses\n",
    "\n",
    "# Visualize loss history\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_loss_hist,\n",
    "    val_loss=val_loss_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list\n",
    ")\n",
    "\n",
    "plt.savefig(dir_name_ae+'{ds}plots{ds}loss_history.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wwt4brHcOaXi"
   },
   "outputs": [],
   "source": [
    "reconstructed_data = ae_net.predict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-ALLN0mFaeSo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_reconstructed_data(\n",
    "    boundary_idx_arr=boundary_idx_arr,\n",
    "    dir_name_ae=dir_name_ae,\n",
    "    all_data=all_data,\n",
    "    reconstructed_data=reconstructed_data,\n",
    "    save_figs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl6ZvgtNtA_u",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPMTMcqk0Amv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GXs1pAq80Amv"
   },
   "outputs": [],
   "source": [
    "plot_reconstructed_data(\n",
    "    boundary_idx_arr=boundary_idx_arr,\n",
    "    dir_name_ae=dir_name_ae,\n",
    "    all_data=all_data,\n",
    "    reconstructed_data=reconstructed_data,\n",
    "    save_figs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jVqsAwsY0Amw"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "latent_states_all = ae_net.encoder_net.predict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjgPNitSrt5p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Jv8PgBgzV1_s"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_latent_states(\n",
    "    boundary_idx_arr=boundary_idx_arr,\n",
    "    latent_states_all=latent_states_all,\n",
    "    all_data=all_data,\n",
    "    xlim=[-1,1],\n",
    "    ylim=[-1,1],\n",
    "    cmap_name='gist_rainbow',\n",
    "    legend_markerscale=10\n",
    "    )\n",
    "\n",
    "plt.savefig(dir_name_ae + '{ds}plots{ds}latent_space.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnLnqg0Jrt5t"
   },
   "outputs": [],
   "source": [
    "# ae_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOJE8vREtque"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vEm2A0sB0Amx",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 750x2250 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(boundary_idx_arr)\n",
    "num_cols = 1\n",
    "num_rows = 3*n\n",
    "\n",
    "# plt.ion()\n",
    "\n",
    "fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n",
    "\n",
    "Tt = N * delta_t\n",
    "time_arr = np.arange(0, N+1) * Tt / N\n",
    "\n",
    "y_labels = [r'$x_1$', r'$x_2$', r'$x_3$']\n",
    "\n",
    "prev_idx = 0\n",
    "for i in range(n):\n",
    "    # ax = plt.axes(projection ='3d')\n",
    "    next_idx = boundary_idx_arr[i]\n",
    "\n",
    "    for j in range(3):\n",
    "        ax = fig.add_subplot(num_rows, num_cols, 3*i+j+1)\n",
    "        ax.plot(time_arr, all_data[prev_idx:next_idx, j], label='original')\n",
    "        ax.plot(time_arr, reconstructed_data[prev_idx:next_idx, j], label='reconstructed')\n",
    "        ax.set_ylabel(y_labels[j])\n",
    "        ax.set_xlabel('time')\n",
    "        ax.grid(True)\n",
    "\n",
    "\n",
    "    prev_idx = next_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvwVNuUl0Amy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IAcFjRRn_IQ"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPVqWNwjoAGP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S21-VEUYrkk-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGnj8uQQ83-y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t2_8mzI1fhX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIsWCXkbr7ws"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hx9ZaSpEMmv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EENXaWqcKW7j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8isZN1tYBifp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixetsZHjCMKO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hh1pbKjCcO4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbLa0AwlDBWh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGQN5p7rNVV3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "trainingAE-loadFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
