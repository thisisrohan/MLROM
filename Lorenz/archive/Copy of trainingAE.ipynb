{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4xhxMpe_r-Y5","executionInfo":{"status":"ok","timestamp":1656245663212,"user_tz":-120,"elapsed":3,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["# enabling 3rd party widgets\n","# from google.colab import output\n","# output.enable_custom_widget_manager()\n","# output.disable_custom_widget_manager()\n","\n","# interactive 3D plot\n","# !pip install ipympl\n","# %matplotlib widget"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"a5qPupCDsjSz","executionInfo":{"status":"ok","timestamp":1656245668098,"user_tz":-120,"elapsed":4889,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["import os\n","import math\n","from collections import OrderedDict\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import linalg\n","\n","import time as time\n","import platform as platform\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.regularizers import L2"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SxAd7iDL0Ami","executionInfo":{"status":"ok","timestamp":1656245668099,"user_tz":-120,"elapsed":35,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["current_sys = platform.system()\n","\n","if current_sys == 'Windows':\n","    dir_sep = '\\\\'\n","else:\n","    dir_sep = '/'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1656245670414,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"},"user_tz":-120},"id":"JjNnPRuk0IIX","outputId":"e9f6c2cd-c677-42a1-f67d-981087e7837b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1656245670417,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"},"user_tz":-120},"id":"9REiGIIy0IzV","outputId":"ca659f6c-7c03-423c-bde1-78b58b15fcc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz\n"]}],"source":["# import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/')\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8S1AHEkl48bn","executionInfo":{"status":"ok","timestamp":1656245670419,"user_tz":-120,"elapsed":25,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["# setting seed for PRNGs\n","prng_seed = 42\n","np.random.seed(prng_seed)\n","tf.random.set_seed(prng_seed)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1656245670421,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"},"user_tz":-120},"id":"tc3zO9xL_tNl","outputId":"e23cf09c-9e8c-434a-ef9f-e1a4f533b571"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["tf.test.gpu_device_name()"]},{"cell_type":"markdown","metadata":{"id":"7UbdnOtc4_z9"},"source":["# Lorenz System"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"O7sl7i5H5Dqz","executionInfo":{"status":"ok","timestamp":1656245672461,"user_tz":-120,"elapsed":2062,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["from tools.misc_tools import create_Lorenz_data"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ySVDz_2U5FH5","executionInfo":{"status":"ok","timestamp":1656245672464,"user_tz":-120,"elapsed":15,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bkQx9q_p5Gro","executionInfo":{"status":"ok","timestamp":1656245672465,"user_tz":-120,"elapsed":15,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["# setting up params\n","sigma_arr = np.array([10, 15, 20])\n","rho_arr = np.array([20, 25, 30])\n","beta_arr = np.array([4/3, 6/3, 8/3])\n","\n","x0 = 1\n","y0 = 1\n","z0 = 1\n","\n","t0 = 0.0\n","T = 100.0\n","delta_t = 0.01\n","\n","return_params_arr = False\n","normalize_flag = True"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"uDhfYHU45IS8","executionInfo":{"status":"ok","timestamp":1656245697037,"user_tz":-120,"elapsed":24586,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["res_dict = create_Lorenz_data(\n","    T, t0, delta_t,\n","    rho_arr, sigma_arr, beta_arr,\n","    x0, y0, z0, return_params_arr=return_params_arr,\n","    normalize=normalize_flag\n",")\n","\n","all_data = res_dict['all_data']\n","N = res_dict['N']\n","boundary_idx_arr = res_dict['boundary_idx_arr']\n","\n","if return_params_arr == True:\n","    params_arr = res_dict['params_arr']\n","\n","if normalize_flag == True:\n","    normalization_constant_arr = res_dict['normalization_constant_arr']"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-MJa7P5t5KiC","scrolled":true,"executionInfo":{"status":"ok","timestamp":1656245697038,"user_tz":-120,"elapsed":14,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["n = len(boundary_idx_arr)\n","# # '''\n","# num_cols = 1\n","# num_rows = n\n","\n","# fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n","\n","# prev_idx = 0\n","# for i in range(n):\n","#     # ax = plt.axes(projection ='3d')\n","#     next_idx = boundary_idx_arr[i]\n","    \n","#     ax_orig = fig.add_subplot(num_rows, num_cols, i+1, projection ='3d')\n","#     ax_orig.plot(all_data[prev_idx:next_idx, 0], all_data[prev_idx:next_idx, 1], all_data[prev_idx:next_idx, 2])\n","#     ax_orig.title.set_text(r'Actual Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:]))\n","#     ax_orig.set_xlabel('x')\n","#     ax_orig.set_ylabel('y')\n","#     ax_orig.set_zlabel('z')\n","    \n","#     # ax_predict = fig.add_subplot(num_rows, num_cols, 2*i+2, projection ='3d')\n","#     # ax_predict.plot(reconstructed_data[prev_idx:next_idx, 0], reconstructed_data[prev_idx:next_idx, 1], reconstructed_data[prev_idx:next_idx, 2])\n","#     # ax_predict.title.set_text(r'NN Reconstructed Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:])\n","#     # )\n","#     # ax_predict.set_xlabel('x')\n","#     # ax_predict.set_ylabel('y')\n","#     # ax_predict.set_zlabel('z')\n","\n","#     prev_idx = next_idx\n","# # '''"]},{"cell_type":"markdown","metadata":{"id":"1v6KQEjR5LkK"},"source":["# Autoencoder"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IjsRi02g5ORG","executionInfo":{"status":"ok","timestamp":1656245697039,"user_tz":-120,"elapsed":11,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["# setting up data\n","train_split = 0.8\n","val_split = 0.1  # to be used later on;\n","                 # `val_split` of total data will\n","                 # be taken out of `training_data`\n","                 # to use as validation data.\n","test_split = 1 - train_split - val_split\n","\n","\n","idx = np.arange(all_data.shape[0])\n","np.random.shuffle(idx)\n","boundary = int(np.round((1-test_split)*all_data.shape[0]))\n","training_data = all_data[idx[0:boundary], :]\n","testing_data = all_data[idx[boundary:], :]\n","\n","# train_dataset = tf.data.Dataset.from_tensor_slices((training_data, training_data))\n","# test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_data))\n","\n","batch_size = 64\n","# SHUFFLE_BUFFER_SIZE = 100\n","\n","# # train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","# train_dataset = train_dataset.batch(BATCH_SIZE)\n","# test_dataset = test_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Qwietg7eTG-s","executionInfo":{"status":"ok","timestamp":1656245697039,"user_tz":-120,"elapsed":10,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gJ-28EnzJ4Ur","executionInfo":{"status":"ok","timestamp":1656245697497,"user_tz":-120,"elapsed":467,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["from tools.ae_v4 import Autoencoder"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"7xTsmS7lgpps","executionInfo":{"status":"ok","timestamp":1656245697498,"user_tz":-120,"elapsed":9,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":14,"metadata":{"id":"7l5kI1tfMszJ","executionInfo":{"status":"ok","timestamp":1656245699682,"user_tz":-120,"elapsed":2191,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"outputs":[],"source":["# Training parameters\n","learning_rate_list = [0.001, 0.0001, 0.00001]\n","epochs = 2000\n","patience = 200  # parameter for early stopping\n","min_delta = 1e-6  # parameter for early stopping\n","lambda_reg = 1e-5  # weight for regularizer\n","\n","# Initialize network\n","ae_net = Autoencoder(\n","    data_dim=6,\n","    enc_layers=[16,12,8,8,4,4,2],\n","    dec_layers=[2,4,4,8,8,12,16],\n","    latent_space_dim=2,\n","    lambda_reg=lambda_reg,\n","    reg_name='L2',\n","    enc_layer_act_func='elu',\n","    enc_final_layer_act_func='tanh',\n","    dec_layer_act_func='elu',\n","    dec_final_layer_act_func='linear',\n","    load_file=None,\n","    batch_norm=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1656245699683,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"},"user_tz":-120},"id":"48tkgZxT0Amt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f772fdb-576b-42fa-ccf7-6e39287d6c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["AE save dir : /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004\n"]}],"source":["# saving the autoencoder\n","dir_name_ae = os.getcwd() + '/saved_ae'\n","if not os.path.isdir(dir_name_ae):\n","    os.makedirs(dir_name_ae)\n","\n","counter = 0\n","while True:\n","    dir_check = 'ae_' + str(counter).zfill(3)\n","    if os.path.isdir(dir_name_ae + '/' + dir_check):\n","        counter += 1\n","    else:\n","        break\n","\n","dir_name_ae = dir_name_ae + '/' + dir_check\n","print('AE save dir : '+dir_name_ae)\n","os.makedirs(dir_name_ae)\n","os.makedirs(dir_name_ae+'/plots')\n","\n","sim_data = {\n","    'rho_arr':rho_arr,\n","    'sigma_arr':sigma_arr,\n","    'beta_arr':beta_arr,\n","    'x0':x0,\n","    'y0':y0,\n","    'z0':z0,\n","    't0':t0,\n","    'T':T,\n","    'delta_t':delta_t,\n","    'return_params_arr':return_params_arr,\n","    'normalize_flag':normalize_flag\n","}\n","\n","# import pandas as pd\n","\n","# data_df = pd.DataFrame(data, columns=[key for key in sim_data.keys()])\n","# data_df.to_csv(dir_name_ae + '/sim_data_params.csv')\n","\n","with open(dir_name_ae+'/sim_data_params.txt', 'w') as f:\n","    f.write(str(sim_data))\n","\n","\n","training_specific_params = {\n","    'learning_rate_list':learning_rate_list,\n","    'epochs':epochs,\n","    'patience':patience,\n","    'min_delta':min_delta,\n","    'prng_seed':prng_seed,\n","    'train_split':train_split,\n","    'val_split':val_split,\n","    'batch_size':batch_size\n","}\n","\n","with open(dir_name_ae+'/training_specific_params.txt', 'w') as f:\n","    f.write(str(training_specific_params))"]},{"cell_type":"code","source":["from tools.misc_tools import mytimecallback, SaveLosses"],"metadata":{"id":"UhA5EfWY7i4e","executionInfo":{"status":"ok","timestamp":1656245699684,"user_tz":-120,"elapsed":18,"user":{"displayName":"Rohan Kaushik","userId":"13918477614376051685"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gELga1WnQeMK","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8f28f41-4038-40f2-8030-89f238405a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","\n","\n","--------------------------------------------------------------------------------\n","\n","---------------------------- LEARNING RATE : 0.001 -----------------------------\n","\n","--------------------------------------------------------------------------------\n","\n","\n","Epoch 1/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 18.2044 - tot_time: 0h 0m 26.9s\n","3323/3323 [==============================] - 27s 7ms/step - loss: 18.1850 - val_loss: 0.2024\n","Epoch 2/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1906 - tot_time: 0h 0m 49.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1906 - val_loss: 0.1937\n","Epoch 3/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1787 - tot_time: 0h 1m 10.9s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1787 - val_loss: 0.1765\n","Epoch 4/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1657 - tot_time: 0h 1m 32.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1656 - val_loss: 0.1651\n","Epoch 5/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1464 - tot_time: 0h 1m 52.8s\n","\n","Epoch 5: val_loss improved from inf to 0.14450, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1464 - val_loss: 0.1445\n","Epoch 6/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1393 - tot_time: 0h 2m 13.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1395 - val_loss: 0.1447\n","Epoch 7/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1337 - tot_time: 0h 2m 34.5s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1337 - val_loss: 0.1431\n","Epoch 8/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1295 - tot_time: 0h 2m 55.3s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1294 - val_loss: 0.1307\n","Epoch 9/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1249 - tot_time: 0h 3m 16.1s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1249 - val_loss: 0.1336\n","Epoch 10/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1273 - tot_time: 0h 3m 36.7s\n","\n","Epoch 10: val_loss improved from 0.14450 to 0.13194, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1273 - val_loss: 0.1319\n","Epoch 11/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1245 - tot_time: 0h 3m 58.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1245 - val_loss: 0.1277\n","Epoch 12/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1235 - tot_time: 0h 4m 19.1s\n","3323/3323 [==============================] - 20s 6ms/step - loss: 0.1234 - val_loss: 0.1287\n","Epoch 13/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1247 - tot_time: 0h 4m 38.9s\n","3323/3323 [==============================] - 20s 6ms/step - loss: 0.1247 - val_loss: 0.1253\n","Epoch 14/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1214 - tot_time: 0h 4m 59.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1213 - val_loss: 0.1290\n","Epoch 15/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1205 - tot_time: 0h 5m 20.3s\n","\n","Epoch 15: val_loss improved from 0.13194 to 0.12472, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1205 - val_loss: 0.1247\n","Epoch 16/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1183 - tot_time: 0h 5m 41.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1183 - val_loss: 0.1242\n","Epoch 17/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1175 - tot_time: 0h 6m 1.9s\n","3323/3323 [==============================] - 20s 6ms/step - loss: 0.1175 - val_loss: 0.1311\n","Epoch 18/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1181 - tot_time: 0h 6m 22.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1181 - val_loss: 0.1282\n","Epoch 19/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1212 - tot_time: 0h 6m 43.5s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1212 - val_loss: 0.1223\n","Epoch 20/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1179 - tot_time: 0h 7m 6.1s\n","\n","Epoch 20: val_loss did not improve from 0.12472\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1179 - val_loss: 0.1320\n","Epoch 21/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1195 - tot_time: 0h 7m 27.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1195 - val_loss: 0.1206\n","Epoch 22/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1164 - tot_time: 0h 7m 48.1s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1164 - val_loss: 0.1208\n","Epoch 23/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1159 - tot_time: 0h 8m 8.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1159 - val_loss: 0.1195\n","Epoch 24/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1162 - tot_time: 0h 8m 29.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1162 - val_loss: 0.1192\n","Epoch 25/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1148 - tot_time: 0h 8m 50.0s\n","\n","Epoch 25: val_loss improved from 0.12472 to 0.12450, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1148 - val_loss: 0.1245\n","Epoch 26/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1143 - tot_time: 0h 9m 11.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1144 - val_loss: 0.1162\n","Epoch 27/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1121 - tot_time: 0h 9m 32.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1122 - val_loss: 0.1166\n","Epoch 28/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1114 - tot_time: 0h 9m 53.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1115 - val_loss: 0.1201\n","Epoch 29/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1114 - tot_time: 0h 10m 16.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1114 - val_loss: 0.1171\n","Epoch 30/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1071 - tot_time: 0h 10m 37.4s\n","\n","Epoch 30: val_loss improved from 0.12450 to 0.11537, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1071 - val_loss: 0.1154\n","Epoch 31/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1045 - tot_time: 0h 10m 59.3s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1046 - val_loss: 0.1138\n","Epoch 32/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1084 - tot_time: 0h 11m 20.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1084 - val_loss: 0.1116\n","Epoch 33/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1098 - tot_time: 0h 11m 40.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1098 - val_loss: 0.1117\n","Epoch 34/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1098 - tot_time: 0h 12m 1.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1099 - val_loss: 0.1112\n","Epoch 35/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1075 - tot_time: 0h 12m 23.1s\n","\n","Epoch 35: val_loss improved from 0.11537 to 0.11146, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1076 - val_loss: 0.1115\n","Epoch 36/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1064 - tot_time: 0h 12m 44.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1064 - val_loss: 0.1121\n","Epoch 37/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1065 - tot_time: 0h 13m 5.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1065 - val_loss: 0.1100\n","Epoch 38/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1051 - tot_time: 0h 13m 28.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1051 - val_loss: 0.1100\n","Epoch 39/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1091 - tot_time: 0h 13m 49.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1091 - val_loss: 0.1103\n","Epoch 40/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1084 - tot_time: 0h 14m 11.1s\n","\n","Epoch 40: val_loss improved from 0.11146 to 0.11137, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1084 - val_loss: 0.1114\n","Epoch 41/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1079 - tot_time: 0h 14m 32.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1079 - val_loss: 0.1191\n","Epoch 42/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1101 - tot_time: 0h 14m 53.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1101 - val_loss: 0.1103\n","Epoch 43/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1107 - tot_time: 0h 15m 14.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1106 - val_loss: 0.1165\n","Epoch 44/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1062 - tot_time: 0h 15m 35.3s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1063 - val_loss: 0.1112\n","Epoch 45/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1056 - tot_time: 0h 15m 56.5s\n","\n","Epoch 45: val_loss did not improve from 0.11137\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1058 - val_loss: 0.1155\n","Epoch 46/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1084 - tot_time: 0h 16m 17.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1084 - val_loss: 0.1104\n","Epoch 47/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1065 - tot_time: 0h 16m 38.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1065 - val_loss: 0.1140\n","Epoch 48/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1089 - tot_time: 0h 17m 1.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1090 - val_loss: 0.1091\n","Epoch 49/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1049 - tot_time: 0h 17m 22.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1048 - val_loss: 0.1087\n","Epoch 50/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1031 - tot_time: 0h 17m 44.3s\n","\n","Epoch 50: val_loss did not improve from 0.11137\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1031 - val_loss: 0.1134\n","Epoch 51/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1050 - tot_time: 0h 18m 5.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1051 - val_loss: 0.1098\n","Epoch 52/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1063 - tot_time: 0h 18m 26.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1062 - val_loss: 0.1144\n","Epoch 53/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 0h 18m 47.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1036 - val_loss: 0.1087\n","Epoch 54/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1029 - tot_time: 0h 19m 8.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1029 - val_loss: 0.1096\n","Epoch 55/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1071 - tot_time: 0h 19m 29.0s\n","\n","Epoch 55: val_loss did not improve from 0.11137\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1071 - val_loss: 0.1133\n","Epoch 56/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1018 - tot_time: 0h 19m 49.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1018 - val_loss: 0.1089\n","Epoch 57/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 0h 20m 12.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1037 - val_loss: 0.1082\n","Epoch 58/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1028 - tot_time: 0h 20m 32.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1028 - val_loss: 0.1083\n","Epoch 59/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1045 - tot_time: 0h 20m 53.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1044 - val_loss: 0.1090\n","Epoch 60/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 0h 21m 14.8s\n","\n","Epoch 60: val_loss improved from 0.11137 to 0.10980, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1024 - val_loss: 0.1098\n","Epoch 61/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1050 - tot_time: 0h 21m 36.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1050 - val_loss: 0.1127\n","Epoch 62/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1047 - tot_time: 0h 21m 57.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1047 - val_loss: 0.1096\n","Epoch 63/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1029 - tot_time: 0h 22m 17.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1029 - val_loss: 0.1103\n","Epoch 64/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 0h 22m 38.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1023 - val_loss: 0.1079\n","Epoch 65/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1019 - tot_time: 0h 22m 59.4s\n","\n","Epoch 65: val_loss improved from 0.10980 to 0.10746, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1019 - val_loss: 0.1075\n","Epoch 66/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1031 - tot_time: 0h 23m 22.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1032 - val_loss: 0.1089\n","Epoch 67/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1030 - tot_time: 0h 23m 43.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1030 - val_loss: 0.1138\n","Epoch 68/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1050 - tot_time: 0h 24m 4.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1050 - val_loss: 0.1092\n","Epoch 69/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1031 - tot_time: 0h 24m 24.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1031 - val_loss: 0.1153\n","Epoch 70/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 0h 24m 45.8s\n","\n","Epoch 70: val_loss did not improve from 0.10746\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1003 - val_loss: 0.1081\n","Epoch 71/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1051 - tot_time: 0h 25m 7.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1051 - val_loss: 0.1156\n","Epoch 72/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1039 - tot_time: 0h 25m 27.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1039 - val_loss: 0.1085\n","Epoch 73/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 0h 25m 49.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1023 - val_loss: 0.1109\n","Epoch 74/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1064 - tot_time: 0h 26m 9.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1064 - val_loss: 0.1091\n","Epoch 75/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1025 - tot_time: 0h 26m 32.6s\n","\n","Epoch 75: val_loss did not improve from 0.10746\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1025 - val_loss: 0.1081\n","Epoch 76/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1008 - tot_time: 0h 26m 53.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1008 - val_loss: 0.1073\n","Epoch 77/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 27m 15.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1090\n","Epoch 78/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1020 - tot_time: 0h 27m 36.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1019 - val_loss: 0.1122\n","Epoch 79/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 0h 27m 58.2s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1013 - val_loss: 0.1075\n","Epoch 80/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1028 - tot_time: 0h 28m 19.2s\n","\n","Epoch 80: val_loss did not improve from 0.10746\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1028 - val_loss: 0.1080\n","Epoch 81/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 0h 28m 40.5s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1037 - val_loss: 0.1094\n","Epoch 82/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1005 - tot_time: 0h 29m 1.3s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1004 - val_loss: 0.1095\n","Epoch 83/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1028 - tot_time: 0h 29m 22.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1028 - val_loss: 0.1206\n","Epoch 84/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 0h 29m 45.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1037 - val_loss: 0.1070\n","Epoch 85/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1039 - tot_time: 0h 30m 6.7s\n","\n","Epoch 85: val_loss did not improve from 0.10746\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1039 - val_loss: 0.1079\n","Epoch 86/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1047 - tot_time: 0h 30m 28.4s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1047 - val_loss: 0.1078\n","Epoch 87/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1038 - tot_time: 0h 30m 50.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1038 - val_loss: 0.1075\n","Epoch 88/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1038 - tot_time: 0h 31m 11.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1038 - val_loss: 0.1106\n","Epoch 89/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1026 - tot_time: 0h 31m 33.2s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1027 - val_loss: 0.1082\n","Epoch 90/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1034 - tot_time: 0h 31m 54.2s\n","\n","Epoch 90: val_loss did not improve from 0.10746\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1033 - val_loss: 0.1082\n","Epoch 91/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1057 - tot_time: 0h 32m 15.5s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1057 - val_loss: 0.1084\n","Epoch 92/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 0h 32m 36.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1018 - val_loss: 0.1099\n","Epoch 93/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1052 - tot_time: 0h 32m 57.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1052 - val_loss: 0.1081\n","Epoch 94/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1008 - tot_time: 0h 33m 20.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1009 - val_loss: 0.1100\n","Epoch 95/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1021 - tot_time: 0h 33m 41.6s\n","\n","Epoch 95: val_loss did not improve from 0.10746\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1022 - val_loss: 0.1115\n","Epoch 96/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 0h 34m 2.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1036 - val_loss: 0.1097\n","Epoch 97/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 0h 34m 23.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1036 - val_loss: 0.1066\n","Epoch 98/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 0h 34m 45.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.0985 - val_loss: 0.1066\n","Epoch 99/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 35m 6.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1091\n","Epoch 100/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1045 - tot_time: 0h 35m 26.9s\n","\n","Epoch 100: val_loss did not improve from 0.10746\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1044 - val_loss: 0.1100\n","Epoch 101/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1050 - tot_time: 0h 35m 48.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1050 - val_loss: 0.1071\n","Epoch 102/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1019 - tot_time: 0h 36m 9.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1018 - val_loss: 0.1058\n","Epoch 103/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1029 - tot_time: 0h 36m 32.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1029 - val_loss: 0.1072\n","Epoch 104/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1011 - tot_time: 0h 36m 53.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1011 - val_loss: 0.1059\n","Epoch 105/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1056 - tot_time: 0h 37m 14.6s\n","\n","Epoch 105: val_loss did not improve from 0.10746\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1056 - val_loss: 0.1158\n","Epoch 106/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1009 - tot_time: 0h 37m 35.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1011 - val_loss: 0.1121\n","Epoch 107/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 37m 56.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1130\n","Epoch 108/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1073 - tot_time: 0h 38m 18.3s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1073 - val_loss: 0.1066\n","Epoch 109/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 0h 38m 39.1s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.0998 - val_loss: 0.1064\n","Epoch 110/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 0h 39m 0.3s\n","\n","Epoch 110: val_loss improved from 0.10746 to 0.10607, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0994 - val_loss: 0.1061\n","Epoch 111/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 0h 39m 21.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1016 - val_loss: 0.1075\n","Epoch 112/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0996 - tot_time: 0h 39m 44.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0996 - val_loss: 0.1073\n","Epoch 113/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1033 - tot_time: 0h 40m 5.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1033 - val_loss: 0.1083\n","Epoch 114/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 40m 27.1s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1010 - val_loss: 0.1060\n","Epoch 115/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1011 - tot_time: 0h 40m 48.3s\n","\n","Epoch 115: val_loss did not improve from 0.10607\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1080\n","Epoch 116/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 0h 41m 9.5s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.0999 - val_loss: 0.1061\n","Epoch 117/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1014 - tot_time: 0h 41m 31.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1015 - val_loss: 0.1079\n","Epoch 118/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 0h 41m 52.8s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1006 - val_loss: 0.1053\n","Epoch 119/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 0h 42m 14.0s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1007 - val_loss: 0.1075\n","Epoch 120/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 42m 35.3s\n","\n","Epoch 120: val_loss improved from 0.10607 to 0.10553, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1010 - val_loss: 0.1055\n","Epoch 121/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1022 - tot_time: 0h 42m 57.2s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1024 - val_loss: 0.1212\n","Epoch 122/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1026 - tot_time: 0h 43m 18.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1026 - val_loss: 0.1073\n","Epoch 123/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 0h 43m 40.4s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1007 - val_loss: 0.1049\n","Epoch 124/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 0h 44m 1.9s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.0984 - val_loss: 0.1065\n","Epoch 125/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 44m 23.4s\n","\n","Epoch 125: val_loss did not improve from 0.10553\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1010 - val_loss: 0.1071\n","Epoch 126/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1027 - tot_time: 0h 44m 44.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1027 - val_loss: 0.1071\n","Epoch 127/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 0h 45m 6.1s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1036 - val_loss: 0.1066\n","Epoch 128/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 0h 45m 28.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1003 - val_loss: 0.1066\n","Epoch 129/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 0h 45m 49.7s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.0994 - val_loss: 0.1058\n","Epoch 130/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 0h 46m 12.8s\n","\n","Epoch 130: val_loss did not improve from 0.10553\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0993 - val_loss: 0.1057\n","Epoch 131/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1020 - tot_time: 0h 46m 34.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1020 - val_loss: 0.1059\n","Epoch 132/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1035 - tot_time: 0h 46m 56.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1035 - val_loss: 0.1070\n","Epoch 133/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 0h 47m 18.7s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0999 - val_loss: 0.1079\n","Epoch 134/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 0h 47m 42.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0999 - val_loss: 0.1077\n","Epoch 135/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 48m 3.5s\n","\n","Epoch 135: val_loss did not improve from 0.10553\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1066\n","Epoch 136/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 0h 48m 25.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1018 - val_loss: 0.1050\n","Epoch 137/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 0h 48m 47.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1018 - val_loss: 0.1057\n","Epoch 138/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 0h 49m 8.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0984 - val_loss: 0.1125\n","Epoch 139/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1029 - tot_time: 0h 49m 30.5s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1029 - val_loss: 0.1049\n","Epoch 140/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 0h 49m 52.0s\n","\n","Epoch 140: val_loss improved from 0.10553 to 0.10513, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1018 - val_loss: 0.1051\n","Epoch 141/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0995 - tot_time: 0h 50m 14.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0995 - val_loss: 0.1051\n","Epoch 142/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1009 - tot_time: 0h 50m 36.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1009 - val_loss: 0.1065\n","Epoch 143/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1040 - tot_time: 0h 50m 59.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1040 - val_loss: 0.1054\n","Epoch 144/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1042 - tot_time: 0h 51m 20.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1043 - val_loss: 0.1080\n","Epoch 145/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 51m 42.1s\n","\n","Epoch 145: val_loss did not improve from 0.10513\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1012 - val_loss: 0.1104\n","Epoch 146/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 0h 52m 3.7s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1014 - val_loss: 0.1062\n","Epoch 147/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1026 - tot_time: 0h 52m 25.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1026 - val_loss: 0.1110\n","Epoch 148/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1000 - tot_time: 0h 52m 47.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1000 - val_loss: 0.1064\n","Epoch 149/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1034 - tot_time: 0h 53m 8.8s\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1033 - val_loss: 0.1070\n","Epoch 150/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0998 - tot_time: 0h 53m 30.4s\n","\n","Epoch 150: val_loss did not improve from 0.10513\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0998 - val_loss: 0.1147\n","Epoch 151/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1014 - tot_time: 0h 53m 54.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1014 - val_loss: 0.1065\n","Epoch 152/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1036 - tot_time: 0h 54m 16.8s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1036 - val_loss: 0.1067\n","Epoch 153/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1026 - tot_time: 0h 54m 38.4s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1026 - val_loss: 0.1084\n","Epoch 154/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1030 - tot_time: 0h 54m 59.8s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1030 - val_loss: 0.1063\n","Epoch 155/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 55m 21.4s\n","\n","Epoch 155: val_loss did not improve from 0.10513\n","3323/3323 [==============================] - 22s 6ms/step - loss: 0.1010 - val_loss: 0.1060\n","Epoch 156/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 0h 55m 43.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1012 - val_loss: 0.1175\n","Epoch 157/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 0h 56m 4.6s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1004 - val_loss: 0.1069\n","Epoch 158/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1025 - tot_time: 0h 56m 26.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1025 - val_loss: 0.1049\n","Epoch 159/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 0h 56m 47.9s\n","3323/3323 [==============================] - 21s 6ms/step - loss: 0.1003 - val_loss: 0.1081\n","Epoch 160/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1036 - tot_time: 0h 57m 9.9s\n","\n","Epoch 160: val_loss did not improve from 0.10513\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1036 - val_loss: 0.1067\n","Epoch 161/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1029 - tot_time: 0h 57m 32.8s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1029 - val_loss: 0.1099\n","Epoch 162/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1016 - tot_time: 0h 57m 56.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1016 - val_loss: 0.1093\n","Epoch 163/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0990 - tot_time: 0h 58m 18.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0990 - val_loss: 0.1094\n","Epoch 164/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 0h 58m 41.1s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1007 - val_loss: 0.1067\n","Epoch 165/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 59m 3.2s\n","\n","Epoch 165: val_loss did not improve from 0.10513\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1009 - val_loss: 0.1056\n","Epoch 166/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 0h 59m 25.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1049\n","Epoch 167/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 0h 59m 48.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1003 - val_loss: 0.1091\n","Epoch 168/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 1h 0m 9.7s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1012 - val_loss: 0.1068\n","Epoch 169/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 1h 0m 32.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1081\n","Epoch 170/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1029 - tot_time: 1h 0m 56.8s\n","\n","Epoch 170: val_loss did not improve from 0.10513\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.1029 - val_loss: 0.1077\n","Epoch 171/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1011 - tot_time: 1h 1m 19.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1011 - val_loss: 0.1210\n","Epoch 172/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1022 - tot_time: 1h 1m 41.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1022 - val_loss: 0.1059\n","Epoch 173/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1050 - tot_time: 1h 2m 3.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1050 - val_loss: 0.1079\n","Epoch 174/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1022 - tot_time: 1h 2m 25.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1022 - val_loss: 0.1058\n","Epoch 175/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 1h 2m 47.8s\n","\n","Epoch 175: val_loss did not improve from 0.10513\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0990 - val_loss: 0.1070\n","Epoch 176/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1045 - tot_time: 1h 3m 9.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1046 - val_loss: 0.1062\n","Epoch 177/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 1h 3m 32.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1004 - val_loss: 0.1149\n","Epoch 178/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1024 - tot_time: 1h 3m 54.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1024 - val_loss: 0.1046\n","Epoch 179/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0990 - tot_time: 1h 4m 17.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0990 - val_loss: 0.1113\n","Epoch 180/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 1h 4m 42.3s\n","\n","Epoch 180: val_loss did not improve from 0.10513\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0996 - val_loss: 0.1088\n","Epoch 181/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 1h 5m 6.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1071\n","Epoch 182/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1019 - tot_time: 1h 5m 28.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1020 - val_loss: 0.1123\n","Epoch 183/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1030 - tot_time: 1h 5m 51.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1030 - val_loss: 0.1117\n","Epoch 184/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 6m 14.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1014 - val_loss: 0.1070\n","Epoch 185/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 1h 6m 36.6s\n","\n","Epoch 185: val_loss improved from 0.10513 to 0.10502, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1036 - val_loss: 0.1050\n","Epoch 186/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1025 - tot_time: 1h 6m 59.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1026 - val_loss: 0.1067\n","Epoch 187/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1027 - tot_time: 1h 7m 21.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1027 - val_loss: 0.1094\n","Epoch 188/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 1h 7m 44.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0994 - val_loss: 0.1064\n","Epoch 189/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1024 - tot_time: 1h 8m 8.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1025 - val_loss: 0.1090\n","Epoch 190/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1005 - tot_time: 1h 8m 31.8s\n","\n","Epoch 190: val_loss did not improve from 0.10502\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1006 - val_loss: 0.1081\n","Epoch 191/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1004 - tot_time: 1h 8m 54.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1004 - val_loss: 0.1124\n","Epoch 192/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 1h 9m 17.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1023 - val_loss: 0.1149\n","Epoch 193/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 1h 9m 39.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1077\n","Epoch 194/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 1h 10m 2.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1023 - val_loss: 0.1049\n","Epoch 195/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1020 - tot_time: 1h 10m 24.0s\n","\n","Epoch 195: val_loss did not improve from 0.10502\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1020 - val_loss: 0.1057\n","Epoch 196/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1025 - tot_time: 1h 10m 46.2s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1024 - val_loss: 0.1116\n","Epoch 197/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 11m 8.6s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1015 - val_loss: 0.1046\n","Epoch 198/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1014 - tot_time: 1h 11m 30.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1014 - val_loss: 0.1047\n","Epoch 199/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1024 - tot_time: 1h 11m 55.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1024 - val_loss: 0.1054\n","Epoch 200/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 1h 12m 17.3s\n","\n","Epoch 200: val_loss improved from 0.10502 to 0.10461, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1014 - val_loss: 0.1046\n","Epoch 201/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 1h 12m 40.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1103\n","Epoch 202/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1024 - tot_time: 1h 13m 3.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1023 - val_loss: 0.1207\n","Epoch 203/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1007 - tot_time: 1h 13m 25.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1007 - val_loss: 0.1060\n","Epoch 204/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1027 - tot_time: 1h 13m 48.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1027 - val_loss: 0.1110\n","Epoch 205/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 14m 10.7s\n","\n","Epoch 205: val_loss did not improve from 0.10461\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0999 - val_loss: 0.1086\n","Epoch 206/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0995 - tot_time: 1h 14m 32.7s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0995 - val_loss: 0.1046\n","Epoch 207/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 1h 14m 54.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0989 - val_loss: 0.1080\n","Epoch 208/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 1h 15m 19.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1083\n","Epoch 209/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1036 - tot_time: 1h 15m 42.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1036 - val_loss: 0.1102\n","Epoch 210/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 1h 16m 4.6s\n","\n","Epoch 210: val_loss did not improve from 0.10461\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0990 - val_loss: 0.1096\n","Epoch 211/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 16m 27.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1000 - val_loss: 0.1075\n","Epoch 212/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 16m 49.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1095\n","Epoch 213/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 1h 17m 11.9s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0986 - val_loss: 0.1092\n","Epoch 214/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 1h 17m 34.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1065\n","Epoch 215/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 1h 17m 57.1s\n","\n","Epoch 215: val_loss did not improve from 0.10461\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1012 - val_loss: 0.1054\n","Epoch 216/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 1h 18m 20.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1005 - val_loss: 0.1071\n","Epoch 217/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 18m 43.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1015 - val_loss: 0.1048\n","Epoch 218/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 1h 19m 8.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.1036 - val_loss: 0.1059\n","Epoch 219/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 1h 19m 30.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1093\n","Epoch 220/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1023 - tot_time: 1h 19m 53.2s\n","\n","Epoch 220: val_loss did not improve from 0.10461\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1023 - val_loss: 0.1052\n","Epoch 221/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1011 - tot_time: 1h 20m 16.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1011 - val_loss: 0.1056\n","Epoch 222/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 1h 20m 39.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1012 - val_loss: 0.1086\n","Epoch 223/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 21m 2.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1016 - val_loss: 0.1081\n","Epoch 224/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 21m 25.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1006 - val_loss: 0.1111\n","Epoch 225/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1009 - tot_time: 1h 21m 47.8s\n","\n","Epoch 225: val_loss improved from 0.10461 to 0.10458, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1009 - val_loss: 0.1046\n","Epoch 226/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1011 - tot_time: 1h 22m 10.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1120\n","Epoch 227/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 1h 22m 35.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1004 - val_loss: 0.1102\n","Epoch 228/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0981 - tot_time: 1h 22m 58.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0981 - val_loss: 0.1048\n","Epoch 229/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1025 - tot_time: 1h 23m 20.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1026 - val_loss: 0.1042\n","Epoch 230/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0998 - tot_time: 1h 23m 43.6s\n","\n","Epoch 230: val_loss did not improve from 0.10458\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0998 - val_loss: 0.1096\n","Epoch 231/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 24m 6.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1077\n","Epoch 232/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 1h 24m 29.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1013 - val_loss: 0.1140\n","Epoch 233/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1021 - tot_time: 1h 24m 52.0s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1021 - val_loss: 0.1046\n","Epoch 234/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1022 - tot_time: 1h 25m 14.4s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1022 - val_loss: 0.1072\n","Epoch 235/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1025 - tot_time: 1h 25m 37.6s\n","\n","Epoch 235: val_loss did not improve from 0.10458\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1026 - val_loss: 0.1065\n","Epoch 236/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 26m 1.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1015 - val_loss: 0.1186\n","Epoch 237/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 26m 24.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1082\n","Epoch 238/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 1h 26m 47.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1018 - val_loss: 0.1066\n","Epoch 239/2000\n","3315/3323 [============================>.] - ETA: 0s - loss: 0.1009 - tot_time: 1h 27m 10.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1009 - val_loss: 0.1044\n","Epoch 240/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 1h 27m 33.3s\n","\n","Epoch 240: val_loss did not improve from 0.10458\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0971 - val_loss: 0.1091\n","Epoch 241/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 1h 27m 57.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0991 - val_loss: 0.1077\n","Epoch 242/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 1h 28m 19.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0988 - val_loss: 0.1101\n","Epoch 243/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 28m 42.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1007 - val_loss: 0.1124\n","Epoch 244/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 29m 5.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1007 - val_loss: 0.1069\n","Epoch 245/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 1h 29m 28.7s\n","\n","Epoch 245: val_loss did not improve from 0.10458\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0990 - val_loss: 0.1067\n","Epoch 246/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 1h 29m 51.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1080\n","Epoch 247/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 1h 30m 14.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0974 - val_loss: 0.1046\n","Epoch 248/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 30m 37.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1133\n","Epoch 249/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1021 - tot_time: 1h 30m 59.8s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1021 - val_loss: 0.1048\n","Epoch 250/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 1h 31m 22.9s\n","\n","Epoch 250: val_loss did not improve from 0.10458\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0985 - val_loss: 0.1091\n","Epoch 251/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 1h 31m 46.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1059\n","Epoch 252/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1036 - tot_time: 1h 32m 9.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1036 - val_loss: 0.1081\n","Epoch 253/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1023 - tot_time: 1h 32m 32.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1023 - val_loss: 0.1060\n","Epoch 254/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1034 - tot_time: 1h 32m 57.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1034 - val_loss: 0.1055\n","Epoch 255/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 1h 33m 20.4s\n","\n","Epoch 255: val_loss did not improve from 0.10458\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1047\n","Epoch 256/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 1h 33m 43.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1055\n","Epoch 257/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0994 - tot_time: 1h 34m 6.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0994 - val_loss: 0.1061\n","Epoch 258/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 34m 29.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1008 - val_loss: 0.1088\n","Epoch 259/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 1h 34m 52.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1055\n","Epoch 260/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 35m 15.0s\n","\n","Epoch 260: val_loss did not improve from 0.10458\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1016 - val_loss: 0.1136\n","Epoch 261/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1009 - tot_time: 1h 35m 38.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1008 - val_loss: 0.1065\n","Epoch 262/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 1h 36m 1.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1011 - val_loss: 0.1090\n","Epoch 263/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0987 - tot_time: 1h 36m 24.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0987 - val_loss: 0.1081\n","Epoch 264/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 36m 47.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1057\n","Epoch 265/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 1h 37m 10.0s\n","\n","Epoch 265: val_loss did not improve from 0.10458\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0989 - val_loss: 0.1055\n","Epoch 266/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1009 - tot_time: 1h 37m 33.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1048\n","Epoch 267/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 1h 37m 56.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0994 - val_loss: 0.1056\n","Epoch 268/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 1h 38m 20.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.1003 - val_loss: 0.1039\n","Epoch 269/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 1h 38m 43.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0983 - val_loss: 0.1047\n","Epoch 270/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 1h 39m 6.9s\n","\n","Epoch 270: val_loss did not improve from 0.10458\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1014 - val_loss: 0.1050\n","Epoch 271/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1018 - tot_time: 1h 39m 30.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1018 - val_loss: 0.1068\n","Epoch 272/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0991 - tot_time: 1h 39m 54.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0991 - val_loss: 0.1066\n","Epoch 273/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 1h 40m 17.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1005 - val_loss: 0.1065\n","Epoch 274/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 1h 40m 40.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1013 - val_loss: 0.1127\n","Epoch 275/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 1h 41m 4.0s\n","\n","Epoch 275: val_loss did not improve from 0.10458\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0983 - val_loss: 0.1101\n","Epoch 276/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 1h 41m 27.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1016 - val_loss: 0.1078\n","Epoch 277/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 41m 51.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1000 - val_loss: 0.1042\n","Epoch 278/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1017 - tot_time: 1h 42m 16.4s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1017 - val_loss: 0.1042\n","Epoch 279/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 42m 39.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1007 - val_loss: 0.1052\n","Epoch 280/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1022 - tot_time: 1h 43m 2.6s\n","\n","Epoch 280: val_loss improved from 0.10458 to 0.10420, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1022 - val_loss: 0.1042\n","Epoch 281/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1009 - tot_time: 1h 43m 26.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1042\n","Epoch 282/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 43m 49.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1046\n","Epoch 283/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1013 - tot_time: 1h 44m 13.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1013 - val_loss: 0.1100\n","Epoch 284/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1016 - tot_time: 1h 44m 37.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1016 - val_loss: 0.1062\n","Epoch 285/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 45m 0.2s\n","\n","Epoch 285: val_loss improved from 0.10420 to 0.10407, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1041\n","Epoch 286/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1020 - tot_time: 1h 45m 23.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1021 - val_loss: 0.1084\n","Epoch 287/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 1h 45m 48.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1008 - val_loss: 0.1056\n","Epoch 288/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 1h 46m 12.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0975 - val_loss: 0.1068\n","Epoch 289/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 1h 46m 35.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1004 - val_loss: 0.1053\n","Epoch 290/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 1h 46m 59.2s\n","\n","Epoch 290: val_loss did not improve from 0.10407\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1007 - val_loss: 0.1097\n","Epoch 291/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0995 - tot_time: 1h 47m 22.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0995 - val_loss: 0.1040\n","Epoch 292/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 1h 47m 46.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1014 - val_loss: 0.1086\n","Epoch 293/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0980 - tot_time: 1h 48m 9.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0981 - val_loss: 0.1053\n","Epoch 294/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 1h 48m 33.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0984 - val_loss: 0.1043\n","Epoch 295/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 48m 57.0s\n","\n","Epoch 295: val_loss did not improve from 0.10407\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1183\n","Epoch 296/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 1h 49m 20.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1088\n","Epoch 297/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 1h 49m 45.1s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0991 - val_loss: 0.1053\n","Epoch 298/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 1h 50m 8.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0979 - val_loss: 0.1085\n","Epoch 299/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 1h 50m 32.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1000 - val_loss: 0.1053\n","Epoch 300/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1016 - tot_time: 1h 50m 56.3s\n","\n","Epoch 300: val_loss did not improve from 0.10407\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1016 - val_loss: 0.1057\n","Epoch 301/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1036 - tot_time: 1h 51m 19.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1036 - val_loss: 0.1041\n","Epoch 302/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 1h 51m 42.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0984 - val_loss: 0.1121\n","Epoch 303/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1001 - tot_time: 1h 52m 6.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1001 - val_loss: 0.1091\n","Epoch 304/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1012 - tot_time: 1h 52m 30.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1012 - val_loss: 0.1079\n","Epoch 305/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 1h 52m 53.1s\n","\n","Epoch 305: val_loss did not improve from 0.10407\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1038 - val_loss: 0.1051\n","Epoch 306/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0990 - tot_time: 1h 53m 16.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0990 - val_loss: 0.1051\n","Epoch 307/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1004 - tot_time: 1h 53m 41.5s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1004 - val_loss: 0.1079\n","Epoch 308/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1037 - tot_time: 1h 54m 5.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1037 - val_loss: 0.1062\n","Epoch 309/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 1h 54m 28.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1050\n","Epoch 310/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1026 - tot_time: 1h 54m 52.0s\n","\n","Epoch 310: val_loss did not improve from 0.10407\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1026 - val_loss: 0.1061\n","Epoch 311/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 1h 55m 15.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0991 - val_loss: 0.1034\n","Epoch 312/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 1h 55m 39.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0963 - val_loss: 0.1038\n","Epoch 313/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 1h 56m 2.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1045\n","Epoch 314/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0987 - tot_time: 1h 56m 26.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0988 - val_loss: 0.1044\n","Epoch 315/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1028 - tot_time: 1h 56m 49.1s\n","\n","Epoch 315: val_loss did not improve from 0.10407\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1027 - val_loss: 0.1069\n","Epoch 316/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 1h 57m 12.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1055\n","Epoch 317/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1033 - tot_time: 1h 57m 37.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1033 - val_loss: 0.1179\n","Epoch 318/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 1h 58m 0.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0999 - val_loss: 0.1110\n","Epoch 319/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 1h 58m 23.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1047\n","Epoch 320/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 1h 58m 46.9s\n","\n","Epoch 320: val_loss did not improve from 0.10407\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1134\n","Epoch 321/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 1h 59m 10.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0987 - val_loss: 0.1062\n","Epoch 322/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1011 - tot_time: 1h 59m 34.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1011 - val_loss: 0.1040\n","Epoch 323/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 1h 59m 57.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0989 - val_loss: 0.1058\n","Epoch 324/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0998 - tot_time: 2h 0m 20.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0998 - val_loss: 0.1050\n","Epoch 325/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 2h 0m 44.5s\n","\n","Epoch 325: val_loss improved from 0.10407 to 0.10387, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1003 - val_loss: 0.1039\n","Epoch 326/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1034 - tot_time: 2h 1m 10.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1035 - val_loss: 0.1063\n","Epoch 327/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 2h 1m 33.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1011 - val_loss: 0.1045\n","Epoch 328/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0995 - tot_time: 2h 1m 56.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1047\n","Epoch 329/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 2h 2m 20.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0992 - val_loss: 0.1047\n","Epoch 330/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 2h 2m 44.4s\n","\n","Epoch 330: val_loss did not improve from 0.10387\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0972 - val_loss: 0.1050\n","Epoch 331/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 2h 3m 8.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1001 - val_loss: 0.1065\n","Epoch 332/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0996 - tot_time: 2h 3m 32.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0996 - val_loss: 0.1058\n","Epoch 333/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0996 - tot_time: 2h 3m 56.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0996 - val_loss: 0.1096\n","Epoch 334/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1021 - tot_time: 2h 4m 19.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1022 - val_loss: 0.1043\n","Epoch 335/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1005 - tot_time: 2h 4m 45.9s\n","\n","Epoch 335: val_loss did not improve from 0.10387\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1008 - val_loss: 0.1083\n","Epoch 336/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0993 - tot_time: 2h 5m 9.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1055\n","Epoch 337/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 2h 5m 33.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1005 - val_loss: 0.1046\n","Epoch 338/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 2h 5m 56.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1007 - val_loss: 0.1038\n","Epoch 339/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 2h 6m 20.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0973 - val_loss: 0.1045\n","Epoch 340/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 2h 6m 44.1s\n","\n","Epoch 340: val_loss did not improve from 0.10387\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1065\n","Epoch 341/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0999 - tot_time: 2h 7m 8.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0999 - val_loss: 0.1040\n","Epoch 342/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0987 - tot_time: 2h 7m 31.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1043\n","Epoch 343/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0987 - tot_time: 2h 7m 56.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1061\n","Epoch 344/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 2h 8m 21.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0966 - val_loss: 0.1057\n","Epoch 345/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 2h 8m 46.7s\n","\n","Epoch 345: val_loss did not improve from 0.10387\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0962 - val_loss: 0.1061\n","Epoch 346/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 2h 9m 10.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0970 - val_loss: 0.1101\n","Epoch 347/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0974 - tot_time: 2h 9m 34.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0974 - val_loss: 0.1058\n","Epoch 348/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 2h 9m 59.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1006 - val_loss: 0.1074\n","Epoch 349/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 2h 10m 23.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0999 - val_loss: 0.1045\n","Epoch 350/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0987 - tot_time: 2h 10m 47.7s\n","\n","Epoch 350: val_loss did not improve from 0.10387\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0987 - val_loss: 0.1067\n","Epoch 351/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 2h 11m 12.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0980 - val_loss: 0.1045\n","Epoch 352/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0998 - tot_time: 2h 11m 36.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0998 - val_loss: 0.1037\n","Epoch 353/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 2h 11m 59.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1013 - val_loss: 0.1045\n","Epoch 354/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1002 - tot_time: 2h 12m 25.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1002 - val_loss: 0.1070\n","Epoch 355/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 2h 12m 49.4s\n","\n","Epoch 355: val_loss did not improve from 0.10387\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0989 - val_loss: 0.1040\n","Epoch 356/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 2h 13m 13.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0967 - val_loss: 0.1129\n","Epoch 357/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1002 - tot_time: 2h 13m 37.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1002 - val_loss: 0.1049\n","Epoch 358/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 2h 14m 0.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1072\n","Epoch 359/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 14m 25.4s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0986 - val_loss: 0.1045\n","Epoch 360/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 2h 14m 49.7s\n","\n","Epoch 360: val_loss improved from 0.10387 to 0.10359, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0974 - val_loss: 0.1036\n","Epoch 361/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 2h 15m 14.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0985 - val_loss: 0.1039\n","Epoch 362/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1017 - tot_time: 2h 15m 38.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1017 - val_loss: 0.1029\n","Epoch 363/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 2h 16m 4.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0990 - val_loss: 0.1034\n","Epoch 364/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1005 - tot_time: 2h 16m 28.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1005 - val_loss: 0.1070\n","Epoch 365/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 2h 16m 52.4s\n","\n","Epoch 365: val_loss did not improve from 0.10359\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0997 - val_loss: 0.1049\n","Epoch 366/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 2h 17m 15.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0991 - val_loss: 0.1080\n","Epoch 367/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 2h 17m 39.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1029\n","Epoch 368/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0996 - tot_time: 2h 18m 3.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0997 - val_loss: 0.1034\n","Epoch 369/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 2h 18m 27.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0982 - val_loss: 0.1031\n","Epoch 370/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 18m 51.0s\n","\n","Epoch 370: val_loss did not improve from 0.10359\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1043\n","Epoch 371/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 2h 19m 15.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0993 - val_loss: 0.1060\n","Epoch 372/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1002 - tot_time: 2h 19m 41.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1002 - val_loss: 0.1039\n","Epoch 373/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 2h 20m 6.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.1001 - val_loss: 0.1029\n","Epoch 374/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 20m 31.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1045\n","Epoch 375/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1002 - tot_time: 2h 20m 55.0s\n","\n","Epoch 375: val_loss did not improve from 0.10359\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1002 - val_loss: 0.1065\n","Epoch 376/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 2h 21m 19.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1081\n","Epoch 377/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 2h 21m 43.9s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0982 - val_loss: 0.1045\n","Epoch 378/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 2h 22m 7.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1007 - val_loss: 0.1034\n","Epoch 379/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0985 - tot_time: 2h 22m 31.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0985 - val_loss: 0.1080\n","Epoch 380/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 2h 22m 55.2s\n","\n","Epoch 380: val_loss did not improve from 0.10359\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0975 - val_loss: 0.1051\n","Epoch 381/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 2h 23m 19.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1034\n","Epoch 382/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 2h 23m 45.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0966 - val_loss: 0.1032\n","Epoch 383/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 2h 24m 9.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0983 - val_loss: 0.1037\n","Epoch 384/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 24m 32.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0986 - val_loss: 0.1074\n","Epoch 385/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 24m 56.4s\n","\n","Epoch 385: val_loss did not improve from 0.10359\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1037\n","Epoch 386/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1021 - tot_time: 2h 25m 20.9s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.1021 - val_loss: 0.1034\n","Epoch 387/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 2h 25m 45.7s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0983 - val_loss: 0.1050\n","Epoch 388/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 26m 10.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0985 - val_loss: 0.1046\n","Epoch 389/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 26m 34.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0986 - val_loss: 0.1128\n","Epoch 390/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 2h 26m 59.1s\n","\n","Epoch 390: val_loss improved from 0.10359 to 0.10344, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1001 - val_loss: 0.1034\n","Epoch 391/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1013 - tot_time: 2h 27m 23.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1013 - val_loss: 0.1043\n","Epoch 392/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0996 - tot_time: 2h 27m 49.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0996 - val_loss: 0.1034\n","Epoch 393/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0981 - tot_time: 2h 28m 13.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0981 - val_loss: 0.1065\n","Epoch 394/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 2h 28m 38.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0983 - val_loss: 0.1072\n","Epoch 395/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1015 - tot_time: 2h 29m 2.4s\n","\n","Epoch 395: val_loss did not improve from 0.10344\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1015 - val_loss: 0.1038\n","Epoch 396/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 2h 29m 26.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0989 - val_loss: 0.1051\n","Epoch 397/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 2h 29m 50.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0975 - val_loss: 0.1027\n","Epoch 398/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 2h 30m 15.2s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0991 - val_loss: 0.1089\n","Epoch 399/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0980 - tot_time: 2h 30m 39.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0980 - val_loss: 0.1042\n","Epoch 400/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0991 - tot_time: 2h 31m 4.2s\n","\n","Epoch 400: val_loss did not improve from 0.10344\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0991 - val_loss: 0.1122\n","Epoch 401/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 2h 31m 28.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0996 - val_loss: 0.1050\n","Epoch 402/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 2h 31m 55.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0982 - val_loss: 0.1066\n","Epoch 403/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 2h 32m 19.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0979 - val_loss: 0.1117\n","Epoch 404/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 2h 32m 43.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0974 - val_loss: 0.1050\n","Epoch 405/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1000 - tot_time: 2h 33m 8.0s\n","\n","Epoch 405: val_loss improved from 0.10344 to 0.10327, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1000 - val_loss: 0.1033\n","Epoch 406/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 2h 33m 32.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0983 - val_loss: 0.1029\n","Epoch 407/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1003 - tot_time: 2h 33m 56.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1003 - val_loss: 0.1093\n","Epoch 408/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1028 - tot_time: 2h 34m 20.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1028 - val_loss: 0.1105\n","Epoch 409/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 2h 34m 44.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0984 - val_loss: 0.1053\n","Epoch 410/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0997 - tot_time: 2h 35m 8.9s\n","\n","Epoch 410: val_loss did not improve from 0.10327\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0997 - val_loss: 0.1074\n","Epoch 411/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 2h 35m 33.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0988 - val_loss: 0.1040\n","Epoch 412/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0993 - tot_time: 2h 35m 59.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0993 - val_loss: 0.1065\n","Epoch 413/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1011 - tot_time: 2h 36m 23.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1012 - val_loss: 0.1033\n","Epoch 414/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0977 - tot_time: 2h 36m 45.3s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0977 - val_loss: 0.1050\n","Epoch 415/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 2h 37m 8.4s\n","\n","Epoch 415: val_loss did not improve from 0.10327\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1007 - val_loss: 0.1059\n","Epoch 416/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 2h 37m 32.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0962 - val_loss: 0.1121\n","Epoch 417/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1008 - tot_time: 2h 37m 55.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1008 - val_loss: 0.1042\n","Epoch 418/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 2h 38m 18.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0979 - val_loss: 0.1043\n","Epoch 419/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 2h 38m 41.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1004 - val_loss: 0.1064\n","Epoch 420/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1007 - tot_time: 2h 39m 3.9s\n","\n","Epoch 420: val_loss did not improve from 0.10327\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1007 - val_loss: 0.1046\n","Epoch 421/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 2h 39m 27.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0994 - val_loss: 0.1037\n","Epoch 422/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 39m 52.4s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0985 - val_loss: 0.1085\n","Epoch 423/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 2h 40m 15.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0961 - val_loss: 0.1028\n","Epoch 424/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 2h 40m 38.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0969 - val_loss: 0.1069\n","Epoch 425/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 2h 41m 1.8s\n","\n","Epoch 425: val_loss did not improve from 0.10327\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0984 - val_loss: 0.1114\n","Epoch 426/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 2h 41m 25.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0984 - val_loss: 0.1044\n","Epoch 427/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 2h 41m 48.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1006 - val_loss: 0.1024\n","Epoch 428/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0998 - tot_time: 2h 42m 11.5s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0998 - val_loss: 0.1062\n","Epoch 429/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 2h 42m 34.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0963 - val_loss: 0.1030\n","Epoch 430/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 2h 42m 57.4s\n","\n","Epoch 430: val_loss did not improve from 0.10327\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0992 - val_loss: 0.1036\n","Epoch 431/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 2h 43m 21.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0978 - val_loss: 0.1032\n","Epoch 432/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 2h 43m 44.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0933 - val_loss: 0.1057\n","Epoch 433/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 2h 44m 9.5s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0961 - val_loss: 0.1085\n","Epoch 434/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0987 - tot_time: 2h 44m 32.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0987 - val_loss: 0.1063\n","Epoch 435/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 2h 44m 55.0s\n","\n","Epoch 435: val_loss did not improve from 0.10327\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0968 - val_loss: 0.1036\n","Epoch 436/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 45m 18.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0984 - val_loss: 0.1051\n","Epoch 437/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0979 - tot_time: 2h 45m 41.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0979 - val_loss: 0.1095\n","Epoch 438/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 2h 46m 5.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1004 - val_loss: 0.1077\n","Epoch 439/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 2h 46m 27.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0952 - val_loss: 0.1041\n","Epoch 440/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 2h 46m 50.4s\n","\n","Epoch 440: val_loss improved from 0.10327 to 0.10265, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0965 - val_loss: 0.1026\n","Epoch 441/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 47m 14.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0986 - val_loss: 0.1066\n","Epoch 442/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0996 - tot_time: 2h 47m 37.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0996 - val_loss: 0.1078\n","Epoch 443/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 2h 48m 2.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0976 - val_loss: 0.1027\n","Epoch 444/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 48m 24.8s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0985 - val_loss: 0.1053\n","Epoch 445/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 2h 48m 47.7s\n","\n","Epoch 445: val_loss did not improve from 0.10265\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1039\n","Epoch 446/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 2h 49m 10.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0963 - val_loss: 0.1034\n","Epoch 447/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1012 - tot_time: 2h 49m 33.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1011 - val_loss: 0.1025\n","Epoch 448/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 2h 49m 56.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1035\n","Epoch 449/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 2h 50m 19.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0996 - val_loss: 0.1025\n","Epoch 450/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 2h 50m 42.2s\n","\n","Epoch 450: val_loss did not improve from 0.10265\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0960 - val_loss: 0.1080\n","Epoch 451/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 2h 51m 6.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0942 - val_loss: 0.1035\n","Epoch 452/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 2h 51m 29.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1003 - val_loss: 0.1103\n","Epoch 453/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 2h 51m 52.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1035\n","Epoch 454/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 2h 52m 17.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0985 - val_loss: 0.1042\n","Epoch 455/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 2h 52m 40.0s\n","\n","Epoch 455: val_loss did not improve from 0.10265\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1038\n","Epoch 456/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 2h 53m 2.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0985 - val_loss: 0.1043\n","Epoch 457/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 2h 53m 25.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0978 - val_loss: 0.1026\n","Epoch 458/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 2h 53m 48.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0978 - val_loss: 0.1045\n","Epoch 459/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1012 - tot_time: 2h 54m 10.5s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.1012 - val_loss: 0.1036\n","Epoch 460/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 2h 54m 33.3s\n","\n","Epoch 460: val_loss did not improve from 0.10265\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0988 - val_loss: 0.1047\n","Epoch 461/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 2h 54m 56.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0978 - val_loss: 0.1030\n","Epoch 462/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 2h 55m 19.7s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0988 - val_loss: 0.1033\n","Epoch 463/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 2h 55m 42.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0989 - val_loss: 0.1026\n","Epoch 464/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 2h 56m 8.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0976 - val_loss: 0.1055\n","Epoch 465/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0993 - tot_time: 2h 56m 31.0s\n","\n","Epoch 465: val_loss did not improve from 0.10265\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0993 - val_loss: 0.1027\n","Epoch 466/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 2h 56m 54.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0997 - val_loss: 0.1063\n","Epoch 467/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0973 - tot_time: 2h 57m 17.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0973 - val_loss: 0.1074\n","Epoch 468/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 2h 57m 40.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0978 - val_loss: 0.1045\n","Epoch 469/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 2h 58m 3.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0990 - val_loss: 0.1052\n","Epoch 470/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0977 - tot_time: 2h 58m 26.1s\n","\n","Epoch 470: val_loss improved from 0.10265 to 0.10242, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0977 - val_loss: 0.1024\n","Epoch 471/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0980 - tot_time: 2h 58m 49.1s\n","3323/3323 [==============================] - 22s 7ms/step - loss: 0.0981 - val_loss: 0.1021\n","Epoch 472/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 2h 59m 12.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0988 - val_loss: 0.1038\n","Epoch 473/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 2h 59m 35.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0982 - val_loss: 0.1040\n","Epoch 474/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 3h 0m 0.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0968 - val_loss: 0.1022\n","Epoch 475/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1003 - tot_time: 3h 0m 23.9s\n","\n","Epoch 475: val_loss did not improve from 0.10242\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1003 - val_loss: 0.1028\n","Epoch 476/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 3h 0m 47.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1038\n","Epoch 477/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 3h 1m 11.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0981 - val_loss: 0.1025\n","Epoch 478/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0991 - tot_time: 3h 1m 35.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1021\n","Epoch 479/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 3h 1m 58.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0976 - val_loss: 0.1024\n","Epoch 480/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 3h 2m 21.1s\n","\n","Epoch 480: val_loss improved from 0.10242 to 0.10232, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0972 - val_loss: 0.1023\n","Epoch 481/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 3h 2m 45.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0963 - val_loss: 0.1048\n","Epoch 482/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0977 - tot_time: 3h 3m 8.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0977 - val_loss: 0.1043\n","Epoch 483/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1010 - tot_time: 3h 3m 31.0s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1010 - val_loss: 0.1029\n","Epoch 484/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 3h 3m 54.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0975 - val_loss: 0.1023\n","Epoch 485/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 3h 4m 18.7s\n","\n","Epoch 485: val_loss did not improve from 0.10232\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0982 - val_loss: 0.1031\n","Epoch 486/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 3h 4m 41.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0972 - val_loss: 0.1055\n","Epoch 487/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 3h 5m 5.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0986 - val_loss: 0.1060\n","Epoch 488/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1006 - tot_time: 3h 5m 28.2s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1006 - val_loss: 0.1058\n","Epoch 489/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 3h 5m 51.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0985 - val_loss: 0.1077\n","Epoch 490/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 3h 6m 15.2s\n","\n","Epoch 490: val_loss did not improve from 0.10232\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0983 - val_loss: 0.1077\n","Epoch 491/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 3h 6m 39.1s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0992 - val_loss: 0.1039\n","Epoch 492/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 3h 7m 2.4s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1002 - val_loss: 0.1031\n","Epoch 493/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0966 - tot_time: 3h 7m 25.6s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0966 - val_loss: 0.1045\n","Epoch 494/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0994 - tot_time: 3h 7m 52.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0994 - val_loss: 0.1125\n","Epoch 495/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 3h 8m 15.3s\n","\n","Epoch 495: val_loss did not improve from 0.10232\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.0981 - val_loss: 0.1066\n","Epoch 496/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1001 - tot_time: 3h 8m 38.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1001 - val_loss: 0.1114\n","Epoch 497/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 9m 2.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1025\n","Epoch 498/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 3h 9m 26.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0949 - val_loss: 0.1046\n","Epoch 499/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 9m 50.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0959 - val_loss: 0.1046\n","Epoch 500/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0996 - tot_time: 3h 10m 14.2s\n","\n","Epoch 500: val_loss did not improve from 0.10232\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0996 - val_loss: 0.1031\n","Epoch 501/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 3h 10m 38.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0993 - val_loss: 0.1065\n","Epoch 502/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1005 - tot_time: 3h 11m 1.9s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1005 - val_loss: 0.1041\n","Epoch 503/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0954 - tot_time: 3h 11m 25.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0954 - val_loss: 0.1016\n","Epoch 504/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0973 - tot_time: 3h 11m 49.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0973 - val_loss: 0.1031\n","Epoch 505/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 3h 12m 14.4s\n","\n","Epoch 505: val_loss did not improve from 0.10232\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0976 - val_loss: 0.1046\n","Epoch 506/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0995 - tot_time: 3h 12m 38.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0995 - val_loss: 0.1015\n","Epoch 507/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0997 - tot_time: 3h 13m 1.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0998 - val_loss: 0.1016\n","Epoch 508/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1001 - tot_time: 3h 13m 25.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1001 - val_loss: 0.1055\n","Epoch 509/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0979 - tot_time: 3h 13m 49.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0979 - val_loss: 0.1038\n","Epoch 510/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 14m 13.6s\n","\n","Epoch 510: val_loss did not improve from 0.10232\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0966 - val_loss: 0.1038\n","Epoch 511/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0997 - tot_time: 3h 14m 37.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0997 - val_loss: 0.1090\n","Epoch 512/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0972 - tot_time: 3h 15m 2.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0972 - val_loss: 0.1092\n","Epoch 513/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 3h 15m 25.3s\n","3323/3323 [==============================] - 23s 7ms/step - loss: 0.1004 - val_loss: 0.1020\n","Epoch 514/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.1006 - tot_time: 3h 15m 51.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1006 - val_loss: 0.1042\n","Epoch 515/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 3h 16m 15.6s\n","\n","Epoch 515: val_loss did not improve from 0.10232\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0989 - val_loss: 0.1048\n","Epoch 516/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0973 - tot_time: 3h 16m 39.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0973 - val_loss: 0.1015\n","Epoch 517/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0995 - tot_time: 3h 17m 3.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0994 - val_loss: 0.1035\n","Epoch 518/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0975 - tot_time: 3h 17m 28.5s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0975 - val_loss: 0.1018\n","Epoch 519/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 3h 17m 52.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1043\n","Epoch 520/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 3h 18m 17.1s\n","\n","Epoch 520: val_loss did not improve from 0.10232\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0951 - val_loss: 0.1027\n","Epoch 521/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0992 - tot_time: 3h 18m 41.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0992 - val_loss: 0.1029\n","Epoch 522/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 3h 19m 5.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0987 - val_loss: 0.1017\n","Epoch 523/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 3h 19m 31.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0968 - val_loss: 0.1035\n","Epoch 524/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0980 - tot_time: 3h 19m 55.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0980 - val_loss: 0.1028\n","Epoch 525/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 3h 20m 19.7s\n","\n","Epoch 525: val_loss did not improve from 0.10232\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0954 - val_loss: 0.1055\n","Epoch 526/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 3h 20m 43.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0974 - val_loss: 0.1012\n","Epoch 527/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 3h 21m 7.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0943 - val_loss: 0.1031\n","Epoch 528/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0983 - tot_time: 3h 21m 31.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0983 - val_loss: 0.1022\n","Epoch 529/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 3h 21m 55.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0978 - val_loss: 0.1015\n","Epoch 530/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 22m 19.6s\n","\n","Epoch 530: val_loss improved from 0.10232 to 0.10068, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0966 - val_loss: 0.1007\n","Epoch 531/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0975 - tot_time: 3h 22m 44.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0975 - val_loss: 0.1010\n","Epoch 532/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 23m 8.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1016\n","Epoch 533/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 3h 23m 34.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0963 - val_loss: 0.1026\n","Epoch 534/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 3h 23m 58.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0964 - val_loss: 0.1018\n","Epoch 535/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 3h 24m 22.2s\n","\n","Epoch 535: val_loss did not improve from 0.10068\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0961 - val_loss: 0.1025\n","Epoch 536/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0991 - tot_time: 3h 24m 45.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1008\n","Epoch 537/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0976 - tot_time: 3h 25m 9.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0976 - val_loss: 0.1024\n","Epoch 538/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.1008 - tot_time: 3h 25m 33.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.1007 - val_loss: 0.1006\n","Epoch 539/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0940 - tot_time: 3h 25m 57.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0940 - val_loss: 0.1089\n","Epoch 540/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0963 - tot_time: 3h 26m 21.6s\n","\n","Epoch 540: val_loss did not improve from 0.10068\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0963 - val_loss: 0.1027\n","Epoch 541/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 3h 26m 46.5s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0949 - val_loss: 0.1043\n","Epoch 542/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 3h 27m 11.4s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0975 - val_loss: 0.1062\n","Epoch 543/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 3h 27m 37.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.1012\n","Epoch 544/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0991 - tot_time: 3h 28m 1.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0991 - val_loss: 0.1017\n","Epoch 545/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 3h 28m 25.7s\n","\n","Epoch 545: val_loss did not improve from 0.10068\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0962 - val_loss: 0.1015\n","Epoch 546/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 28m 49.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0966 - val_loss: 0.1052\n","Epoch 547/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 29m 14.3s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0966 - val_loss: 0.1012\n","Epoch 548/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 3h 29m 38.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0964 - val_loss: 0.1029\n","Epoch 549/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 30m 3.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0966 - val_loss: 0.1012\n","Epoch 550/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 3h 30m 27.0s\n","\n","Epoch 550: val_loss did not improve from 0.10068\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0962 - val_loss: 0.1032\n","Epoch 551/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 3h 30m 51.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0980 - val_loss: 0.1062\n","Epoch 552/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 3h 31m 18.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0952 - val_loss: 0.1052\n","Epoch 553/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 3h 31m 42.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0956 - val_loss: 0.1009\n","Epoch 554/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 3h 32m 6.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0981 - val_loss: 0.1068\n","Epoch 555/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 3h 32m 30.2s\n","\n","Epoch 555: val_loss did not improve from 0.10068\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0946 - val_loss: 0.1033\n","Epoch 556/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 3h 32m 54.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0966 - val_loss: 0.1020\n","Epoch 557/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0950 - tot_time: 3h 33m 18.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0950 - val_loss: 0.1009\n","Epoch 558/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 3h 33m 43.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0989 - val_loss: 0.1010\n","Epoch 559/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 3h 34m 7.3s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0945 - val_loss: 0.1037\n","Epoch 560/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0983 - tot_time: 3h 34m 31.5s\n","\n","Epoch 560: val_loss did not improve from 0.10068\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0983 - val_loss: 0.1044\n","Epoch 561/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 3h 34m 56.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0965 - val_loss: 0.1002\n","Epoch 562/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0971 - tot_time: 3h 35m 21.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0971 - val_loss: 0.1003\n","Epoch 563/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 35m 46.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1035\n","Epoch 564/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 3h 36m 10.4s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0964 - val_loss: 0.1004\n","Epoch 565/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0956 - tot_time: 3h 36m 34.6s\n","\n","Epoch 565: val_loss did not improve from 0.10068\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0956 - val_loss: 0.1066\n","Epoch 566/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0962 - tot_time: 3h 36m 59.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0962 - val_loss: 0.0999\n","Epoch 567/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0967 - tot_time: 3h 37m 23.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0967 - val_loss: 0.1071\n","Epoch 568/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0950 - tot_time: 3h 37m 47.9s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0950 - val_loss: 0.1022\n","Epoch 569/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 3h 38m 12.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0942 - val_loss: 0.1018\n","Epoch 570/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 3h 38m 37.8s\n","\n","Epoch 570: val_loss did not improve from 0.10068\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0943 - val_loss: 0.1011\n","Epoch 571/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0924 - tot_time: 3h 39m 5.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0925 - val_loss: 0.1097\n","Epoch 572/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 3h 39m 30.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0972 - val_loss: 0.1052\n","Epoch 573/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 3h 39m 55.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0966 - val_loss: 0.1061\n","Epoch 574/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 3h 40m 21.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0955 - val_loss: 0.1010\n","Epoch 575/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 3h 40m 46.2s\n","\n","Epoch 575: val_loss did not improve from 0.10068\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0952 - val_loss: 0.1008\n","Epoch 576/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0953 - tot_time: 3h 41m 10.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0953 - val_loss: 0.1016\n","Epoch 577/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 3h 41m 35.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0978 - val_loss: 0.1001\n","Epoch 578/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 3h 42m 0.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0960 - val_loss: 0.1008\n","Epoch 579/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 3h 42m 25.3s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0943 - val_loss: 0.1011\n","Epoch 580/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0970 - tot_time: 3h 42m 50.6s\n","\n","Epoch 580: val_loss improved from 0.10068 to 0.10033, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0970 - val_loss: 0.1003\n","Epoch 581/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0946 - tot_time: 3h 43m 16.2s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0946 - val_loss: 0.1002\n","Epoch 582/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 3h 43m 40.9s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0961 - val_loss: 0.0999\n","Epoch 583/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 3h 44m 5.5s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0933 - val_loss: 0.1055\n","Epoch 584/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0941 - tot_time: 3h 44m 29.9s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0941 - val_loss: 0.1007\n","Epoch 585/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 3h 44m 54.7s\n","\n","Epoch 585: val_loss improved from 0.10033 to 0.09951, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0950 - val_loss: 0.0995\n","Epoch 586/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 3h 45m 20.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0958 - val_loss: 0.1043\n","Epoch 587/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 45m 45.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0957 - val_loss: 0.1007\n","Epoch 588/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 3h 46m 10.1s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0970 - val_loss: 0.1008\n","Epoch 589/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 3h 46m 35.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0981 - val_loss: 0.1045\n","Epoch 590/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 3h 47m 1.8s\n","\n","Epoch 590: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0942 - val_loss: 0.1011\n","Epoch 591/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 3h 47m 27.1s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0952 - val_loss: 0.1031\n","Epoch 592/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 3h 47m 51.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0976 - val_loss: 0.1009\n","Epoch 593/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 3h 48m 17.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0988 - val_loss: 0.1031\n","Epoch 594/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 48m 42.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0958 - val_loss: 0.1033\n","Epoch 595/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 3h 49m 6.4s\n","\n","Epoch 595: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0962 - val_loss: 0.1004\n","Epoch 596/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0964 - tot_time: 3h 49m 31.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0964 - val_loss: 0.1025\n","Epoch 597/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 3h 49m 55.6s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0959 - val_loss: 0.1003\n","Epoch 598/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 3h 50m 20.4s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0945 - val_loss: 0.1025\n","Epoch 599/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 3h 50m 47.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0944 - val_loss: 0.1006\n","Epoch 600/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 3h 51m 12.2s\n","\n","Epoch 600: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0946 - val_loss: 0.0996\n","Epoch 601/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.1005 - tot_time: 3h 51m 37.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.1005 - val_loss: 0.1039\n","Epoch 602/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0984 - tot_time: 3h 52m 2.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0984 - val_loss: 0.1020\n","Epoch 603/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0987 - tot_time: 3h 52m 27.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0987 - val_loss: 0.1002\n","Epoch 604/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 3h 52m 52.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0975 - val_loss: 0.1020\n","Epoch 605/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0941 - tot_time: 3h 53m 17.2s\n","\n","Epoch 605: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0942 - val_loss: 0.1001\n","Epoch 606/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 3h 53m 41.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0970 - val_loss: 0.1029\n","Epoch 607/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0950 - tot_time: 3h 54m 6.1s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0950 - val_loss: 0.1015\n","Epoch 608/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0953 - tot_time: 3h 54m 32.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0953 - val_loss: 0.1000\n","Epoch 609/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0958 - tot_time: 3h 54m 56.8s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1020\n","Epoch 610/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 3h 55m 21.3s\n","\n","Epoch 610: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0969 - val_loss: 0.1000\n","Epoch 611/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 3h 55m 46.2s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0958 - val_loss: 0.1135\n","Epoch 612/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0988 - tot_time: 3h 56m 10.7s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0988 - val_loss: 0.1009\n","Epoch 613/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0951 - tot_time: 3h 56m 35.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0951 - val_loss: 0.0999\n","Epoch 614/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 3h 57m 0.5s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0952 - val_loss: 0.1009\n","Epoch 615/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 3h 57m 25.2s\n","\n","Epoch 615: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0968 - val_loss: 0.1018\n","Epoch 616/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0970 - tot_time: 3h 57m 50.2s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0970 - val_loss: 0.1020\n","Epoch 617/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 3h 58m 15.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0990 - val_loss: 0.1029\n","Epoch 618/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 3h 58m 42.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0953 - val_loss: 0.1013\n","Epoch 619/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 3h 59m 7.0s\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0955 - val_loss: 0.1019\n","Epoch 620/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 3h 59m 31.7s\n","\n","Epoch 620: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0976 - val_loss: 0.1029\n","Epoch 621/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0977 - tot_time: 3h 59m 57.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0977 - val_loss: 0.1008\n","Epoch 622/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0989 - tot_time: 4h 0m 22.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0989 - val_loss: 0.1018\n","Epoch 623/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 4h 0m 47.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0950 - val_loss: 0.1011\n","Epoch 624/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 4h 1m 12.8s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0951 - val_loss: 0.1011\n","Epoch 625/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 4h 1m 37.7s\n","\n","Epoch 625: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0944 - val_loss: 0.1004\n","Epoch 626/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0938 - tot_time: 4h 2m 2.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0938 - val_loss: 0.1017\n","Epoch 627/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0941 - tot_time: 4h 2m 29.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0941 - val_loss: 0.1023\n","Epoch 628/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 4h 2m 55.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0968 - val_loss: 0.1036\n","Epoch 629/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 4h 3m 20.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0982 - val_loss: 0.1012\n","Epoch 630/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.1002 - tot_time: 4h 3m 46.4s\n","\n","Epoch 630: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1003 - val_loss: 0.1000\n","Epoch 631/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 4h 4m 11.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0946 - val_loss: 0.1063\n","Epoch 632/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 4h 4m 37.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0951 - val_loss: 0.0995\n","Epoch 633/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0980 - tot_time: 4h 5m 2.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0979 - val_loss: 0.1006\n","Epoch 634/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 4h 5m 28.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0971 - val_loss: 0.1026\n","Epoch 635/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 4h 5m 53.5s\n","\n","Epoch 635: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0966 - val_loss: 0.1015\n","Epoch 636/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 6m 20.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0962 - val_loss: 0.1005\n","Epoch 637/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 4h 6m 45.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0954 - val_loss: 0.1007\n","Epoch 638/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 7m 10.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0964 - val_loss: 0.1054\n","Epoch 639/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0971 - tot_time: 4h 7m 36.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0971 - val_loss: 0.1003\n","Epoch 640/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0943 - tot_time: 4h 8m 1.1s\n","\n","Epoch 640: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0943 - val_loss: 0.1008\n","Epoch 641/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 4h 8m 26.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0957 - val_loss: 0.1025\n","Epoch 642/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 4h 8m 52.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0953 - val_loss: 0.1037\n","Epoch 643/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 4h 9m 17.2s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0951 - val_loss: 0.1102\n","Epoch 644/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 4h 9m 41.8s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0953 - val_loss: 0.1042\n","Epoch 645/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 4h 10m 9.3s\n","\n","Epoch 645: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0965 - val_loss: 0.1001\n","Epoch 646/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 4h 10m 34.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0943 - val_loss: 0.1006\n","Epoch 647/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 4h 10m 60.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0961 - val_loss: 0.1065\n","Epoch 648/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 4h 11m 24.6s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0946 - val_loss: 0.1011\n","Epoch 649/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 4h 11m 50.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0965 - val_loss: 0.1005\n","Epoch 650/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0972 - tot_time: 4h 12m 15.7s\n","\n","Epoch 650: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0972 - val_loss: 0.1053\n","Epoch 651/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 4h 12m 41.5s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0952 - val_loss: 0.0999\n","Epoch 652/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 4h 13m 6.1s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0956 - val_loss: 0.1009\n","Epoch 653/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 4h 13m 31.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0961 - val_loss: 0.1031\n","Epoch 654/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.1004 - tot_time: 4h 13m 58.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.1004 - val_loss: 0.1007\n","Epoch 655/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0958 - tot_time: 4h 14m 24.0s\n","\n","Epoch 655: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0958 - val_loss: 0.1003\n","Epoch 656/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0950 - tot_time: 4h 14m 48.7s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0950 - val_loss: 0.0997\n","Epoch 657/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 4h 15m 13.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0967 - val_loss: 0.1007\n","Epoch 658/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0948 - tot_time: 4h 15m 39.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0949 - val_loss: 0.1009\n","Epoch 659/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0993 - tot_time: 4h 16m 4.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0993 - val_loss: 0.1004\n","Epoch 660/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 4h 16m 29.4s\n","\n","Epoch 660: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0961 - val_loss: 0.1003\n","Epoch 661/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 4h 16m 55.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0958 - val_loss: 0.1015\n","Epoch 662/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 4h 17m 20.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0962 - val_loss: 0.0996\n","Epoch 663/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 4h 17m 46.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0949 - val_loss: 0.1015\n","Epoch 664/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0938 - tot_time: 4h 18m 13.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0938 - val_loss: 0.1047\n","Epoch 665/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 18m 38.7s\n","\n","Epoch 665: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0963 - val_loss: 0.0997\n","Epoch 666/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 4h 19m 4.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0990 - val_loss: 0.1028\n","Epoch 667/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 4h 19m 29.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0953 - val_loss: 0.1057\n","Epoch 668/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 19m 54.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0961 - val_loss: 0.1005\n","Epoch 669/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0973 - tot_time: 4h 20m 20.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0973 - val_loss: 0.1002\n","Epoch 670/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0975 - tot_time: 4h 20m 45.5s\n","\n","Epoch 670: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0975 - val_loss: 0.1012\n","Epoch 671/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0945 - tot_time: 4h 21m 11.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0945 - val_loss: 0.1003\n","Epoch 672/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 4h 21m 36.6s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0952 - val_loss: 0.1094\n","Epoch 673/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 4h 22m 4.5s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0977 - val_loss: 0.1054\n","Epoch 674/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 4h 22m 29.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0969 - val_loss: 0.1013\n","Epoch 675/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 4h 22m 55.1s\n","\n","Epoch 675: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0981 - val_loss: 0.1037\n","Epoch 676/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0940 - tot_time: 4h 23m 20.0s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0940 - val_loss: 0.1109\n","Epoch 677/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 23m 45.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0962 - val_loss: 0.1007\n","Epoch 678/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 4h 24m 10.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0952 - val_loss: 0.1009\n","Epoch 679/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 24m 36.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0964 - val_loss: 0.1007\n","Epoch 680/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 4h 25m 1.6s\n","\n","Epoch 680: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0981 - val_loss: 0.1032\n","Epoch 681/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0941 - tot_time: 4h 25m 27.5s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0941 - val_loss: 0.1002\n","Epoch 682/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0947 - tot_time: 4h 25m 55.4s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0947 - val_loss: 0.1060\n","Epoch 683/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 26m 20.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0964 - val_loss: 0.1035\n","Epoch 684/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0952 - tot_time: 4h 26m 46.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0952 - val_loss: 0.1004\n","Epoch 685/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 4h 27m 11.9s\n","\n","Epoch 685: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0976 - val_loss: 0.1024\n","Epoch 686/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0939 - tot_time: 4h 27m 38.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0939 - val_loss: 0.1013\n","Epoch 687/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 4h 28m 4.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0965 - val_loss: 0.0992\n","Epoch 688/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0953 - tot_time: 4h 28m 30.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0953 - val_loss: 0.1128\n","Epoch 689/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0977 - tot_time: 4h 28m 55.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0977 - val_loss: 0.1009\n","Epoch 690/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 4h 29m 21.6s\n","\n","Epoch 690: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.1000 - val_loss: 0.1007\n","Epoch 691/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 4h 29m 47.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0966 - val_loss: 0.1017\n","Epoch 692/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 4h 30m 14.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0961 - val_loss: 0.1032\n","Epoch 693/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 30m 39.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0964 - val_loss: 0.1006\n","Epoch 694/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 4h 31m 5.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0952 - val_loss: 0.0995\n","Epoch 695/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 4h 31m 30.4s\n","\n","Epoch 695: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0972 - val_loss: 0.1050\n","Epoch 696/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 4h 31m 56.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0959 - val_loss: 0.0996\n","Epoch 697/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 4h 32m 21.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0956 - val_loss: 0.1039\n","Epoch 698/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 4h 32m 47.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0930 - val_loss: 0.0997\n","Epoch 699/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 4h 33m 12.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0956 - val_loss: 0.1019\n","Epoch 700/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 4h 33m 38.7s\n","\n","Epoch 700: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0972 - val_loss: 0.1059\n","Epoch 701/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0939 - tot_time: 4h 34m 6.8s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0939 - val_loss: 0.1011\n","Epoch 702/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0981 - tot_time: 4h 34m 32.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0981 - val_loss: 0.1007\n","Epoch 703/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 4h 34m 58.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0954 - val_loss: 0.1003\n","Epoch 704/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0933 - tot_time: 4h 35m 23.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0933 - val_loss: 0.1060\n","Epoch 705/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 4h 35m 49.6s\n","\n","Epoch 705: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0956 - val_loss: 0.1008\n","Epoch 706/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 4h 36m 15.0s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0944 - val_loss: 0.1007\n","Epoch 707/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 4h 36m 40.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0955 - val_loss: 0.0991\n","Epoch 708/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0951 - tot_time: 4h 37m 6.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.1023\n","Epoch 709/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 4h 37m 34.2s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0929 - val_loss: 0.1046\n","Epoch 710/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 4h 38m 0.1s\n","\n","Epoch 710: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0972 - val_loss: 0.1007\n","Epoch 711/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0961 - tot_time: 4h 38m 26.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0961 - val_loss: 0.0993\n","Epoch 712/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 4h 38m 52.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0953 - val_loss: 0.1009\n","Epoch 713/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 4h 39m 17.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0953 - val_loss: 0.0994\n","Epoch 714/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0946 - tot_time: 4h 39m 42.1s\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0946 - val_loss: 0.0995\n","Epoch 715/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 4h 40m 6.4s\n","\n","Epoch 715: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 24s 7ms/step - loss: 0.0973 - val_loss: 0.1026\n","Epoch 716/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 4h 40m 32.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.1034\n","Epoch 717/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 4h 40m 57.4s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0966 - val_loss: 0.1027\n","Epoch 718/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 4h 41m 24.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0981 - val_loss: 0.1028\n","Epoch 719/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 41m 50.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0962 - val_loss: 0.1002\n","Epoch 720/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 4h 42m 16.4s\n","\n","Epoch 720: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.1002\n","Epoch 721/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0972 - tot_time: 4h 42m 42.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0972 - val_loss: 0.1017\n","Epoch 722/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 4h 43m 8.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0943 - val_loss: 0.0998\n","Epoch 723/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 4h 43m 33.6s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0955 - val_loss: 0.1028\n","Epoch 724/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0937 - tot_time: 4h 43m 59.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0937 - val_loss: 0.1079\n","Epoch 725/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 4h 44m 25.6s\n","\n","Epoch 725: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.1038\n","Epoch 726/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 4h 44m 51.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0957 - val_loss: 0.1005\n","Epoch 727/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0970 - tot_time: 4h 45m 17.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0970 - val_loss: 0.0992\n","Epoch 728/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0970 - tot_time: 4h 45m 45.4s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0970 - val_loss: 0.0993\n","Epoch 729/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0976 - tot_time: 4h 46m 11.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0976 - val_loss: 0.1108\n","Epoch 730/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 4h 46m 37.3s\n","\n","Epoch 730: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.0997\n","Epoch 731/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 47m 3.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0964 - val_loss: 0.1006\n","Epoch 732/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 4h 47m 28.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0958 - val_loss: 0.1000\n","Epoch 733/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 4h 47m 54.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0956 - val_loss: 0.1110\n","Epoch 734/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 4h 48m 19.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0965 - val_loss: 0.1047\n","Epoch 735/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 4h 48m 45.7s\n","\n","Epoch 735: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0944 - val_loss: 0.1038\n","Epoch 736/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0979 - tot_time: 4h 49m 11.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0978 - val_loss: 0.1004\n","Epoch 737/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 4h 49m 38.8s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0965 - val_loss: 0.1003\n","Epoch 738/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0921 - tot_time: 4h 50m 4.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0921 - val_loss: 0.1016\n","Epoch 739/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 50m 29.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0962 - val_loss: 0.1000\n","Epoch 740/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0960 - tot_time: 4h 50m 55.5s\n","\n","Epoch 740: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0960 - val_loss: 0.1009\n","Epoch 741/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 4h 51m 21.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0965 - val_loss: 0.1031\n","Epoch 742/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 51m 46.8s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0963 - val_loss: 0.1057\n","Epoch 743/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 4h 52m 12.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.0995\n","Epoch 744/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0939 - tot_time: 4h 52m 38.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0940 - val_loss: 0.0999\n","Epoch 745/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 4h 53m 3.4s\n","\n","Epoch 745: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0943 - val_loss: 0.1022\n","Epoch 746/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0961 - tot_time: 4h 53m 30.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0962 - val_loss: 0.0997\n","Epoch 747/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 4h 53m 57.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0942 - val_loss: 0.1062\n","Epoch 748/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0980 - tot_time: 4h 54m 22.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0980 - val_loss: 0.0998\n","Epoch 749/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 4h 54m 48.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0969 - val_loss: 0.1054\n","Epoch 750/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 4h 55m 14.1s\n","\n","Epoch 750: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0970 - val_loss: 0.1002\n","Epoch 751/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 4h 55m 40.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0962 - val_loss: 0.1006\n","Epoch 752/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 4h 56m 6.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0954 - val_loss: 0.0999\n","Epoch 753/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 4h 56m 31.3s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0956 - val_loss: 0.1004\n","Epoch 754/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0973 - tot_time: 4h 56m 57.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0973 - val_loss: 0.0999\n","Epoch 755/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 4h 57m 25.7s\n","\n","Epoch 755: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0943 - val_loss: 0.1010\n","Epoch 756/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0940 - tot_time: 4h 57m 52.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0940 - val_loss: 0.1026\n","Epoch 757/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 4h 58m 17.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0964 - val_loss: 0.1014\n","Epoch 758/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0919 - tot_time: 4h 58m 44.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0919 - val_loss: 0.1011\n","Epoch 759/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 4h 59m 10.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0975 - val_loss: 0.1028\n","Epoch 760/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 4h 59m 36.9s\n","\n","Epoch 760: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0973 - val_loss: 0.1040\n","Epoch 761/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0974 - tot_time: 5h 0m 3.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0974 - val_loss: 0.0993\n","Epoch 762/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 5h 0m 30.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0943 - val_loss: 0.0996\n","Epoch 763/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0915 - tot_time: 5h 0m 57.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0915 - val_loss: 0.1033\n","Epoch 764/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.1000 - tot_time: 5h 1m 25.4s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.1000 - val_loss: 0.1017\n","Epoch 765/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 5h 1m 51.9s\n","\n","Epoch 765: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0963 - val_loss: 0.1044\n","Epoch 766/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 5h 2m 18.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0964 - val_loss: 0.0996\n","Epoch 767/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0931 - tot_time: 5h 2m 45.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0931 - val_loss: 0.1014\n","Epoch 768/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 3m 12.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0958 - val_loss: 0.1025\n","Epoch 769/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 5h 3m 38.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0933 - val_loss: 0.1001\n","Epoch 770/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0939 - tot_time: 5h 4m 5.6s\n","\n","Epoch 770: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0939 - val_loss: 0.1034\n","Epoch 771/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 5h 4m 32.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0971 - val_loss: 0.0998\n","Epoch 772/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 5h 4m 59.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0958 - val_loss: 0.1019\n","Epoch 773/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0951 - tot_time: 5h 5m 27.3s\n","3323/3323 [==============================] - 28s 9ms/step - loss: 0.0951 - val_loss: 0.0993\n","Epoch 774/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0965 - tot_time: 5h 5m 53.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0965 - val_loss: 0.1005\n","Epoch 775/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0913 - tot_time: 5h 6m 19.6s\n","\n","Epoch 775: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0913 - val_loss: 0.1002\n","Epoch 776/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 5h 6m 45.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0950 - val_loss: 0.0995\n","Epoch 777/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 5h 7m 12.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0957 - val_loss: 0.1004\n","Epoch 778/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 5h 7m 39.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0944 - val_loss: 0.1011\n","Epoch 779/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 5h 8m 4.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0951 - val_loss: 0.1002\n","Epoch 780/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0941 - tot_time: 5h 8m 30.8s\n","\n","Epoch 780: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0941 - val_loss: 0.1034\n","Epoch 781/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0939 - tot_time: 5h 8m 57.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0939 - val_loss: 0.1033\n","Epoch 782/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0948 - tot_time: 5h 9m 25.5s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0948 - val_loss: 0.1072\n","Epoch 783/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0946 - tot_time: 5h 9m 51.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0946 - val_loss: 0.1103\n","Epoch 784/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0926 - tot_time: 5h 10m 18.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0926 - val_loss: 0.0996\n","Epoch 785/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0959 - tot_time: 5h 10m 44.4s\n","\n","Epoch 785: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0959 - val_loss: 0.1072\n","Epoch 786/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 5h 11m 10.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0959 - val_loss: 0.1064\n","Epoch 787/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 5h 11m 36.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0982 - val_loss: 0.1161\n","Epoch 788/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0940 - tot_time: 5h 12m 3.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0942 - val_loss: 0.1002\n","Epoch 789/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0973 - tot_time: 5h 12m 30.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0973 - val_loss: 0.1014\n","Epoch 790/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 5h 12m 58.0s\n","\n","Epoch 790: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 28s 9ms/step - loss: 0.0949 - val_loss: 0.0996\n","Epoch 791/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0947 - tot_time: 5h 13m 24.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0947 - val_loss: 0.1053\n","Epoch 792/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 5h 13m 50.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0967 - val_loss: 0.1009\n","Epoch 793/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0960 - tot_time: 5h 14m 16.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0960 - val_loss: 0.1076\n","Epoch 794/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 14m 43.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0958 - val_loss: 0.0992\n","Epoch 795/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 5h 15m 9.2s\n","\n","Epoch 795: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0933 - val_loss: 0.1009\n","Epoch 796/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 5h 15m 35.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0956 - val_loss: 0.1029\n","Epoch 797/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0955 - tot_time: 5h 16m 1.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0955 - val_loss: 0.1021\n","Epoch 798/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0951 - tot_time: 5h 16m 28.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0952 - val_loss: 0.1030\n","Epoch 799/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 5h 16m 57.0s\n","3323/3323 [==============================] - 28s 9ms/step - loss: 0.0952 - val_loss: 0.0991\n","Epoch 800/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 5h 17m 23.3s\n","\n","Epoch 800: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0962 - val_loss: 0.1005\n","Epoch 801/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 5h 17m 51.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0950 - val_loss: 0.1041\n","Epoch 802/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0936 - tot_time: 5h 18m 18.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0936 - val_loss: 0.1013\n","Epoch 803/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 5h 18m 44.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0954 - val_loss: 0.0992\n","Epoch 804/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 5h 19m 11.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0963 - val_loss: 0.1003\n","Epoch 805/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0985 - tot_time: 5h 19m 38.1s\n","\n","Epoch 805: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0985 - val_loss: 0.1039\n","Epoch 806/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 5h 20m 4.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0952 - val_loss: 0.1093\n","Epoch 807/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0945 - tot_time: 5h 20m 30.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0946 - val_loss: 0.1003\n","Epoch 808/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 5h 20m 59.2s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0966 - val_loss: 0.0994\n","Epoch 809/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0947 - tot_time: 5h 21m 26.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0947 - val_loss: 0.1002\n","Epoch 810/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 5h 21m 52.3s\n","\n","Epoch 810: val_loss did not improve from 0.09951\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0961 - val_loss: 0.1007\n","Epoch 811/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0962 - tot_time: 5h 22m 19.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0962 - val_loss: 0.1015\n","Epoch 812/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0923 - tot_time: 5h 22m 46.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0923 - val_loss: 0.1002\n","Epoch 813/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 5h 23m 12.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0969 - val_loss: 0.1008\n","Epoch 814/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 5h 23m 38.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0969 - val_loss: 0.1002\n","Epoch 815/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0970 - tot_time: 5h 24m 5.5s\n","\n","Epoch 815: val_loss did not improve from 0.09951\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0970 - val_loss: 0.1007\n","Epoch 816/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0954 - tot_time: 5h 24m 34.7s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0954 - val_loss: 0.1063\n","Epoch 817/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0948 - tot_time: 5h 25m 1.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0949 - val_loss: 0.1005\n","Epoch 818/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0972 - tot_time: 5h 25m 27.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0972 - val_loss: 0.1026\n","Epoch 819/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 5h 25m 54.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0929 - val_loss: 0.1006\n","Epoch 820/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 5h 26m 21.8s\n","\n","Epoch 820: val_loss improved from 0.09951 to 0.09926, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0942 - val_loss: 0.0993\n","Epoch 821/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 5h 26m 48.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0943 - val_loss: 0.1044\n","Epoch 822/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 27m 15.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0958 - val_loss: 0.0995\n","Epoch 823/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0947 - tot_time: 5h 27m 42.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0947 - val_loss: 0.1018\n","Epoch 824/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0934 - tot_time: 5h 28m 9.7s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0934 - val_loss: 0.1017\n","Epoch 825/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 5h 28m 36.7s\n","\n","Epoch 825: val_loss did not improve from 0.09926\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0956 - val_loss: 0.1058\n","Epoch 826/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0941 - tot_time: 5h 29m 3.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0941 - val_loss: 0.1052\n","Epoch 827/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0952 - tot_time: 5h 29m 29.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0952 - val_loss: 0.1032\n","Epoch 828/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 5h 29m 56.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0955 - val_loss: 0.1017\n","Epoch 829/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 5h 30m 22.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0958 - val_loss: 0.1012\n","Epoch 830/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 5h 30m 48.9s\n","\n","Epoch 830: val_loss did not improve from 0.09926\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0927 - val_loss: 0.1043\n","Epoch 831/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0986 - tot_time: 5h 31m 15.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0986 - val_loss: 0.1005\n","Epoch 832/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 5h 31m 42.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0968 - val_loss: 0.1057\n","Epoch 833/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 5h 32m 10.8s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0964 - val_loss: 0.1004\n","Epoch 834/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0959 - tot_time: 5h 32m 37.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0959 - val_loss: 0.1017\n","Epoch 835/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 5h 33m 3.7s\n","\n","Epoch 835: val_loss did not improve from 0.09926\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0926 - val_loss: 0.0999\n","Epoch 836/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0968 - tot_time: 5h 33m 30.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0968 - val_loss: 0.1009\n","Epoch 837/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0940 - tot_time: 5h 33m 57.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0940 - val_loss: 0.1044\n","Epoch 838/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0953 - tot_time: 5h 34m 24.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0953 - val_loss: 0.1021\n","Epoch 839/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0966 - tot_time: 5h 34m 50.8s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0966 - val_loss: 0.0997\n","Epoch 840/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0926 - tot_time: 5h 35m 17.9s\n","\n","Epoch 840: val_loss did not improve from 0.09926\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0926 - val_loss: 0.0995\n","Epoch 841/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 5h 35m 47.4s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0956 - val_loss: 0.1081\n","Epoch 842/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 5h 36m 14.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0957 - val_loss: 0.1003\n","Epoch 843/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 5h 36m 40.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0954 - val_loss: 0.1051\n","Epoch 844/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 5h 37m 7.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0955 - val_loss: 0.0996\n","Epoch 845/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0943 - tot_time: 5h 37m 34.8s\n","\n","Epoch 845: val_loss did not improve from 0.09926\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0943 - val_loss: 0.0996\n","Epoch 846/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 5h 38m 1.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0932 - val_loss: 0.1006\n","Epoch 847/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0990 - tot_time: 5h 38m 28.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0990 - val_loss: 0.1027\n","Epoch 848/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 5h 38m 54.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0941 - val_loss: 0.0996\n","Epoch 849/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0955 - tot_time: 5h 39m 25.0s\n","3323/3323 [==============================] - 30s 9ms/step - loss: 0.0955 - val_loss: 0.1031\n","Epoch 850/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0954 - tot_time: 5h 39m 51.7s\n","\n","Epoch 850: val_loss did not improve from 0.09926\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0954 - val_loss: 0.1024\n","Epoch 851/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0914 - tot_time: 5h 40m 18.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0914 - val_loss: 0.1078\n","Epoch 852/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 5h 40m 45.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0960 - val_loss: 0.1003\n","Epoch 853/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 5h 41m 12.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0950 - val_loss: 0.1003\n","Epoch 854/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 5h 41m 39.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0942 - val_loss: 0.1009\n","Epoch 855/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 5h 42m 6.2s\n","\n","Epoch 855: val_loss did not improve from 0.09926\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0963 - val_loss: 0.1012\n","Epoch 856/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 5h 42m 33.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0934 - val_loss: 0.1034\n","Epoch 857/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0978 - tot_time: 5h 43m 1.8s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0978 - val_loss: 0.1007\n","Epoch 858/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 43m 28.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0959 - val_loss: 0.1017\n","Epoch 859/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0931 - tot_time: 5h 43m 55.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0931 - val_loss: 0.0997\n","Epoch 860/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 5h 44m 22.2s\n","\n","Epoch 860: val_loss did not improve from 0.09926\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0977 - val_loss: 0.1010\n","Epoch 861/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0982 - tot_time: 5h 44m 49.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0982 - val_loss: 0.1011\n","Epoch 862/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 5h 45m 15.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0956 - val_loss: 0.0997\n","Epoch 863/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0923 - tot_time: 5h 45m 42.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0923 - val_loss: 0.1005\n","Epoch 864/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 5h 46m 8.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.0993\n","Epoch 865/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 5h 46m 36.7s\n","\n","Epoch 865: val_loss did not improve from 0.09926\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0945 - val_loss: 0.0997\n","Epoch 866/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0947 - tot_time: 5h 47m 1.9s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0947 - val_loss: 0.0991\n","Epoch 867/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0928 - tot_time: 5h 47m 28.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0928 - val_loss: 0.0994\n","Epoch 868/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 5h 47m 54.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0967 - val_loss: 0.1032\n","Epoch 869/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 48m 21.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0958 - val_loss: 0.1004\n","Epoch 870/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 5h 48m 47.8s\n","\n","Epoch 870: val_loss did not improve from 0.09926\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0964 - val_loss: 0.1002\n","Epoch 871/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0945 - tot_time: 5h 49m 15.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0945 - val_loss: 0.1003\n","Epoch 872/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0919 - tot_time: 5h 49m 41.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0919 - val_loss: 0.1030\n","Epoch 873/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0956 - tot_time: 5h 50m 10.5s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0956 - val_loss: 0.1012\n","Epoch 874/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0937 - tot_time: 5h 50m 36.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0936 - val_loss: 0.1041\n","Epoch 875/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0919 - tot_time: 5h 51m 3.0s\n","\n","Epoch 875: val_loss improved from 0.09926 to 0.09918, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0919 - val_loss: 0.0992\n","Epoch 876/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 5h 51m 30.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0966 - val_loss: 0.0995\n","Epoch 877/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0958 - tot_time: 5h 51m 55.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0959 - val_loss: 0.1071\n","Epoch 878/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0918 - tot_time: 5h 52m 22.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0918 - val_loss: 0.0999\n","Epoch 879/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 5h 52m 49.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0962 - val_loss: 0.1012\n","Epoch 880/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0970 - tot_time: 5h 53m 16.1s\n","\n","Epoch 880: val_loss did not improve from 0.09918\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0970 - val_loss: 0.1010\n","Epoch 881/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 5h 53m 44.6s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0953 - val_loss: 0.1113\n","Epoch 882/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0953 - tot_time: 5h 54m 11.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0952 - val_loss: 0.1006\n","Epoch 883/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0967 - tot_time: 5h 54m 38.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0967 - val_loss: 0.1036\n","Epoch 884/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 5h 55m 4.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0945 - val_loss: 0.1039\n","Epoch 885/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0969 - tot_time: 5h 55m 31.1s\n","\n","Epoch 885: val_loss did not improve from 0.09918\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0969 - val_loss: 0.1002\n","Epoch 886/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0957 - tot_time: 5h 55m 57.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0956 - val_loss: 0.1000\n","Epoch 887/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0971 - tot_time: 5h 56m 24.7s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0971 - val_loss: 0.1010\n","Epoch 888/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 5h 56m 50.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0931 - val_loss: 0.0999\n","Epoch 889/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 5h 57m 19.2s\n","3323/3323 [==============================] - 28s 9ms/step - loss: 0.0963 - val_loss: 0.1000\n","Epoch 890/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0945 - tot_time: 5h 57m 46.2s\n","\n","Epoch 890: val_loss did not improve from 0.09918\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0945 - val_loss: 0.1007\n","Epoch 891/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 5h 58m 13.3s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0923 - val_loss: 0.1027\n","Epoch 892/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0966 - tot_time: 5h 58m 39.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0967 - val_loss: 0.1007\n","Epoch 893/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 5h 59m 5.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0930 - val_loss: 0.1015\n","Epoch 894/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0940 - tot_time: 5h 59m 32.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0940 - val_loss: 0.1005\n","Epoch 895/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0963 - tot_time: 5h 59m 59.0s\n","\n","Epoch 895: val_loss did not improve from 0.09918\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0963 - val_loss: 0.1048\n","Epoch 896/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0930 - tot_time: 6h 0m 27.1s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0930 - val_loss: 0.1027\n","Epoch 897/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0956 - tot_time: 6h 0m 54.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0956 - val_loss: 0.1008\n","Epoch 898/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0976 - tot_time: 6h 1m 20.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0976 - val_loss: 0.0999\n","Epoch 899/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0974 - tot_time: 6h 1m 47.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0974 - val_loss: 0.1007\n","Epoch 900/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0986 - tot_time: 6h 2m 14.3s\n","\n","Epoch 900: val_loss did not improve from 0.09918\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0987 - val_loss: 0.0994\n","Epoch 901/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 6h 2m 42.0s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0959 - val_loss: 0.1028\n","Epoch 902/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 6h 3m 8.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0932 - val_loss: 0.0998\n","Epoch 903/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0964 - tot_time: 6h 3m 34.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0964 - val_loss: 0.1097\n","Epoch 904/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0955 - tot_time: 6h 4m 3.4s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0955 - val_loss: 0.0993\n","Epoch 905/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 6h 4m 30.3s\n","\n","Epoch 905: val_loss did not improve from 0.09918\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0934 - val_loss: 0.0999\n","Epoch 906/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0975 - tot_time: 6h 4m 56.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0975 - val_loss: 0.1051\n","Epoch 907/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0958Restoring model weights from the end of the best epoch: 707.\n"," - tot_time: 6h 5m 23.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0958 - val_loss: 0.0991\n","Epoch 907: early stopping\n","\n","\n","--------------------------------------------------------------------------------\n","\n","---------------------------- LEARNING RATE : 0.0001 ----------------------------\n","\n","--------------------------------------------------------------------------------\n","\n","\n","Epoch 1/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0916 - tot_time: 6h 5m 54.2s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0916 - val_loss: 0.0990\n","Epoch 2/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0949 - tot_time: 6h 6m 21.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0950 - val_loss: 0.0989\n","Epoch 3/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0944 - tot_time: 6h 6m 47.7s\n","\n","Epoch 3: val_loss improved from 0.09918 to 0.09875, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0944 - val_loss: 0.0988\n","Epoch 4/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0917 - tot_time: 6h 7m 16.7s\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0917 - val_loss: 0.0984\n","Epoch 5/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0929 - tot_time: 6h 7m 43.9s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0928 - val_loss: 0.0984\n","Epoch 6/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 6h 8m 9.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0923 - val_loss: 0.0985\n","Epoch 7/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0920 - tot_time: 6h 8m 34.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0921 - val_loss: 0.0984\n","Epoch 8/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0923 - tot_time: 6h 9m 0.8s\n","\n","Epoch 8: val_loss improved from 0.09875 to 0.09836, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0923 - val_loss: 0.0984\n","Epoch 9/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0903 - tot_time: 6h 9m 27.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0903 - val_loss: 0.0984\n","Epoch 10/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0938 - tot_time: 6h 9m 52.4s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0938 - val_loss: 0.0990\n","Epoch 11/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 6h 10m 19.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0930 - val_loss: 0.0984\n","Epoch 12/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0928 - tot_time: 6h 10m 47.0s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0928 - val_loss: 0.0987\n","Epoch 13/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0948 - tot_time: 6h 11m 13.0s\n","\n","Epoch 13: val_loss improved from 0.09836 to 0.09836, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0947 - val_loss: 0.0984\n","Epoch 14/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0921 - tot_time: 6h 11m 38.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0921 - val_loss: 0.0984\n","Epoch 15/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0921 - tot_time: 6h 12m 4.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0921 - val_loss: 0.0985\n","Epoch 16/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0908 - tot_time: 6h 12m 30.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0908 - val_loss: 0.0986\n","Epoch 17/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0910 - tot_time: 6h 12m 56.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0910 - val_loss: 0.0985\n","Epoch 18/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0923 - tot_time: 6h 13m 21.9s\n","\n","Epoch 18: val_loss did not improve from 0.09836\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0923 - val_loss: 0.0985\n","Epoch 19/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 6h 13m 47.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0960 - val_loss: 0.0983\n","Epoch 20/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 6h 14m 16.3s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 29s 9ms/step - loss: 0.0934 - val_loss: 0.0992\n","Epoch 21/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0953 - tot_time: 6h 14m 42.2s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0953 - val_loss: 0.0990\n","Epoch 22/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0932 - tot_time: 6h 15m 8.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0932 - val_loss: 0.0984\n","Epoch 23/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0930 - tot_time: 6h 15m 33.8s\n","\n","Epoch 23: val_loss did not improve from 0.09836\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0930 - val_loss: 0.0988\n","Epoch 24/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 6h 15m 59.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.0985\n","Epoch 25/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0926 - tot_time: 6h 16m 25.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0926 - val_loss: 0.0984\n","Epoch 26/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 6h 16m 51.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0928 - val_loss: 0.0987\n","Epoch 27/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0912 - tot_time: 6h 17m 18.4s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0912 - val_loss: 0.0987\n","Epoch 28/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0911 - tot_time: 6h 17m 44.1s\n","\n","Epoch 28: val_loss did not improve from 0.09836\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0912 - val_loss: 0.0988\n","Epoch 29/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0925 - tot_time: 6h 18m 9.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0925 - val_loss: 0.0983\n","Epoch 30/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0895 - tot_time: 6h 18m 35.7s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0895 - val_loss: 0.0983\n","Epoch 31/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0879 - tot_time: 6h 19m 1.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0879 - val_loss: 0.0996\n","Epoch 32/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0925 - tot_time: 6h 19m 27.1s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0925 - val_loss: 0.0985\n","Epoch 33/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0924 - tot_time: 6h 19m 51.9s\n","\n","Epoch 33: val_loss did not improve from 0.09836\n","3323/3323 [==============================] - 25s 7ms/step - loss: 0.0924 - val_loss: 0.0984\n","Epoch 34/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0945 - tot_time: 6h 20m 18.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0945 - val_loss: 0.0984\n","Epoch 35/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0924 - tot_time: 6h 20m 45.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0924 - val_loss: 0.0982\n","Epoch 36/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0914 - tot_time: 6h 21m 11.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0914 - val_loss: 0.0983\n","Epoch 37/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0917 - tot_time: 6h 21m 37.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0919 - val_loss: 0.0983\n","Epoch 38/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0908 - tot_time: 6h 22m 3.1s\n","\n","Epoch 38: val_loss improved from 0.09836 to 0.09835, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0907 - val_loss: 0.0983\n","Epoch 39/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0946 - tot_time: 6h 22m 29.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0947 - val_loss: 0.0983\n","Epoch 40/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0942 - tot_time: 6h 22m 54.7s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0942 - val_loss: 0.0983\n","Epoch 41/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0938 - tot_time: 6h 23m 21.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0938 - val_loss: 0.0984\n","Epoch 42/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0952 - tot_time: 6h 23m 47.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0952 - val_loss: 0.0984\n","Epoch 43/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0968 - tot_time: 6h 24m 15.2s\n","\n","Epoch 43: val_loss did not improve from 0.09835\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0968 - val_loss: 0.0988\n","Epoch 44/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 6h 24m 42.5s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0927 - val_loss: 0.0983\n","Epoch 45/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0918 - tot_time: 6h 25m 8.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0921 - val_loss: 0.0984\n","Epoch 46/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 6h 25m 34.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0950 - val_loss: 0.0983\n","Epoch 47/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0931 - tot_time: 6h 25m 59.8s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0931 - val_loss: 0.0983\n","Epoch 48/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0960 - tot_time: 6h 26m 25.6s\n","\n","Epoch 48: val_loss did not improve from 0.09835\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0960 - val_loss: 0.0984\n","Epoch 49/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0920 - tot_time: 6h 26m 51.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0920 - val_loss: 0.0982\n","Epoch 50/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0903 - tot_time: 6h 27m 18.3s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0903 - val_loss: 0.0984\n","Epoch 51/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 6h 27m 45.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0923 - val_loss: 0.0983\n","Epoch 52/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0935 - tot_time: 6h 28m 11.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.0983\n","Epoch 53/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0910 - tot_time: 6h 28m 37.4s\n","\n","Epoch 53: val_loss did not improve from 0.09835\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0910 - val_loss: 0.0986\n","Epoch 54/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0904 - tot_time: 6h 29m 2.7s\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0903 - val_loss: 0.0983\n","Epoch 55/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0934 - tot_time: 6h 29m 28.7s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0934 - val_loss: 0.0984\n","Epoch 56/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0893 - tot_time: 6h 29m 54.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0893 - val_loss: 0.0984\n","Epoch 57/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0908 - tot_time: 6h 30m 20.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0909 - val_loss: 0.0983\n","Epoch 58/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0903 - tot_time: 6h 30m 48.0s\n","\n","Epoch 58: val_loss did not improve from 0.09835\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0902 - val_loss: 0.0987\n","Epoch 59/2000\n","3316/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 6h 31m 15.8s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0922 - val_loss: 0.0985\n","Epoch 60/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0902 - tot_time: 6h 31m 42.4s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0903 - val_loss: 0.0984\n","Epoch 61/2000\n","3317/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 6h 32m 8.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0927 - val_loss: 0.0990\n","Epoch 62/2000\n","3321/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 6h 32m 34.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0922 - val_loss: 0.0982\n","Epoch 63/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0913 - tot_time: 6h 33m 0.8s\n","\n","Epoch 63: val_loss improved from 0.09835 to 0.09819, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0913 - val_loss: 0.0982\n","Epoch 64/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0901 - tot_time: 6h 33m 27.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0901 - val_loss: 0.0986\n","Epoch 65/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0905 - tot_time: 6h 33m 52.8s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0905 - val_loss: 0.0997\n","Epoch 66/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0912 - tot_time: 6h 34m 20.5s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0912 - val_loss: 0.0983\n","Epoch 67/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0910 - tot_time: 6h 34m 48.2s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0910 - val_loss: 0.0983\n","Epoch 68/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0933 - tot_time: 6h 35m 14.2s\n","\n","Epoch 68: val_loss did not improve from 0.09819\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0932 - val_loss: 0.0982\n","Epoch 69/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0919 - tot_time: 6h 35m 40.0s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0919 - val_loss: 0.0984\n","Epoch 70/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0889 - tot_time: 6h 36m 5.9s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0890 - val_loss: 0.0982\n","Epoch 71/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0936 - tot_time: 6h 36m 32.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0936 - val_loss: 0.0984\n","Epoch 72/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0922 - tot_time: 6h 36m 58.2s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0922 - val_loss: 0.0983\n","Epoch 73/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0912 - tot_time: 6h 37m 25.8s\n","\n","Epoch 73: val_loss did not improve from 0.09819\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0912 - val_loss: 0.0983\n","Epoch 74/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0950 - tot_time: 6h 37m 52.6s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0950 - val_loss: 0.0984\n","Epoch 75/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0908 - tot_time: 6h 38m 18.5s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0908 - val_loss: 0.0987\n","Epoch 76/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0890 - tot_time: 6h 38m 44.6s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0891 - val_loss: 0.0983\n","Epoch 77/2000\n","3319/3323 [============================>.] - ETA: 0s - loss: 0.0899 - tot_time: 6h 39m 10.9s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0900 - val_loss: 0.0985\n","Epoch 78/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0906 - tot_time: 6h 39m 37.1s\n","\n","Epoch 78: val_loss improved from 0.09819 to 0.09818, saving model to /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/checkpoint\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0906 - val_loss: 0.0982\n","Epoch 79/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0899 - tot_time: 6h 40m 3.1s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0899 - val_loss: 0.0982\n","Epoch 80/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0913 - tot_time: 6h 40m 29.5s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0913 - val_loss: 0.0990\n","Epoch 81/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0924 - tot_time: 6h 40m 57.8s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0924 - val_loss: 0.0982\n","Epoch 82/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0892 - tot_time: 6h 41m 25.3s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0892 - val_loss: 0.0986\n","Epoch 83/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0913 - tot_time: 6h 41m 50.5s\n","\n","Epoch 83: val_loss did not improve from 0.09818\n","3323/3323 [==============================] - 25s 8ms/step - loss: 0.0913 - val_loss: 0.0990\n","Epoch 84/2000\n","3322/3323 [============================>.] - ETA: 0s - loss: 0.0927 - tot_time: 6h 42m 17.1s\n","3323/3323 [==============================] - 27s 8ms/step - loss: 0.0926 - val_loss: 0.0984\n","Epoch 85/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0928 - tot_time: 6h 42m 43.4s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0927 - val_loss: 0.0983\n","Epoch 86/2000\n","3320/3323 [============================>.] - ETA: 0s - loss: 0.0938 - tot_time: 6h 43m 9.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0937 - val_loss: 0.0984\n","Epoch 87/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0925 - tot_time: 6h 43m 35.3s\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0925 - val_loss: 0.0983\n","Epoch 88/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0926 - tot_time: 6h 44m 1.7s\n","\n","Epoch 88: val_loss did not improve from 0.09818\n","3323/3323 [==============================] - 26s 8ms/step - loss: 0.0926 - val_loss: 0.0983\n","Epoch 89/2000\n","3323/3323 [==============================] - ETA: 0s - loss: 0.0916 - tot_time: 6h 44m 29.4s\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0916 - val_loss: 0.0982\n","Epoch 90/2000\n","3318/3323 [============================>.] - ETA: 0s - loss: 0.0921 - tot_time: 6h 44m 56.6s\n"," - saving loss histories at /content/drive/MyDrive/Colab Notebooks/Thesis/Lorenz/saved_ae/ae_004/checkpoints/LossHistoriesCheckpoint\n","3323/3323 [==============================] - 28s 8ms/step - loss: 0.0921 - val_loss: 0.0982\n","Epoch 91/2000\n"," 931/3323 [=======>......................] - ETA: 18s - loss: 0.0925"]}],"source":["# compiling the network\n","ae_net.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_list[0]),\n","    loss=losses.MeanSquaredError()\n",")\n","\n","# implementing early stopping\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=patience,\n","    restore_best_weights=True,\n","    verbose=True,\n","    min_delta=min_delta\n",")\n","\n","# model checkpoint callback\n","dir_name_ckpt = dir_name_ae+'/checkpoints'\n","os.makedirs(dir_name_ckpt)\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=dir_name_ckpt+dir_sep+'checkpoint',#+'/checkpoint--loss={loss:.4f}--vall_loss={val_loss:.4f}',\n","    monitor='val_loss',\n","    save_best_only=True,\n","    verbose=2,\n","    save_weights_only=True,\n","    period=5\n",")\n","\n","timekeeper_cb = mytimecallback()\n","\n","savelosses_cb_vallossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n","savelosses_cb_trainlossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n","savelosses_cb = SaveLosses(\n","    filepath=dir_name_ckpt+dir_sep+'LossHistoriesCheckpoint',\n","    val_loss_arr=savelosses_cb_vallossarr,\n","    train_loss_arr=savelosses_cb_trainlossarr,\n","    total_epochs=epochs,\n","    period=10)\n","\n","\n","# training the network\n","val_loss_hist = []\n","train_loss_hist = []\n","lr_change=[0]\n","for i in range(len(learning_rate_list)):\n","    learning_rate = learning_rate_list[i]\n","    K.set_value(ae_net.optimizer.lr, learning_rate)\n","\n","    savelosses_cb.update_lr_idx(i)\n","\n","    total_s_len = 80\n","    sep_lr_s = ' LEARNING RATE : {} '.format(learning_rate)\n","    sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'-' + sep_lr_s\n","    sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'-'\n","    print('\\n\\n' + '-'*len(sep_lr_s))\n","    print('\\n' + sep_lr_s+'\\n')\n","    print('-'*len(sep_lr_s) + '\\n\\n')\n","    \n","    history = ae_net.fit(training_data, training_data,\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        validation_split=val_split/train_split,\n","        callbacks=[early_stopping_cb, timekeeper_cb, checkpoint_cb, savelosses_cb],\n","        verbose=1\n","    )\n","\n","    val_loss_hist.extend(history.history['val_loss'])\n","    train_loss_hist.extend(history.history['loss'])\n","    \n","    lr_change.append(lr_change[i]+len(history.history['val_loss']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewTz1COFSocM"},"outputs":[],"source":["# plotting losses\n","from tools.misc_tools import plot_losses\n","\n","\n","test_loss = ae_net.evaluate(\n","    testing_data, testing_data,\n",")\n","# lr_change = [0, 987, 987+334]\n","# for i in range(1,len(lr_change)):\n","#     lr_change[i] += lr_change[i-1]\n","\n","# Visualize loss history\n","fig, ax = plot_losses(\n","    training_loss=train_loss_hist,\n","    val_loss=val_loss_hist,\n","    lr_change=lr_change,\n","    learning_rate_list=learning_rate_list\n",")\n","\n","plt.savefig(dir_name_ae+'/plots/loss_history.png', dpi=300, bbox_inches='tight')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwt4brHcOaXi"},"outputs":[],"source":["reconstructed_data = ae_net.predict(all_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zl6ZvgtNtA_u","scrolled":false},"outputs":[],"source":["n = len(boundary_idx_arr)\n","num_cols = 2\n","num_rows = n\n","\n","# plt.ion()\n","\n","fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n","\n","prev_idx = 0\n","for i in range(n):\n","    # ax = plt.axes(projection ='3d')\n","    next_idx = boundary_idx_arr[i]\n","    \n","    ax_orig = fig.add_subplot(num_rows, num_cols, 2*i+1, projection ='3d')\n","    ax_orig.plot(all_data[prev_idx:next_idx, 0], all_data[prev_idx:next_idx, 1], all_data[prev_idx:next_idx, 2])\n","    ax_orig.title.set_text(r'Actual Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:]))\n","    ax_orig.set_xlabel('x')\n","    ax_orig.set_ylabel('y')\n","    ax_orig.set_zlabel('z')\n","    \n","    ax_predict = fig.add_subplot(num_rows, num_cols, 2*i+2, projection ='3d')\n","    ax_predict.plot(reconstructed_data[prev_idx:next_idx, 0], reconstructed_data[prev_idx:next_idx, 1], reconstructed_data[prev_idx:next_idx, 2])\n","    ax_predict.title.set_text(r'NN Reconstructed Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:])\n","    )\n","    ax_predict.set_xlabel('x')\n","    ax_predict.set_ylabel('y')\n","    ax_predict.set_zlabel('z')\n","\n","    prev_idx = next_idx\n","\n","# fig.savefig(dir_name+'/reconstructed_data.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPMTMcqk0Amv"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXs1pAq80Amv"},"outputs":[],"source":["# saving reconstructed data\n","n = len(boundary_idx_arr)\n","num_cols = 2\n","num_rows = 1\n","\n","# plt.ion()\n","\n","# fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n","\n","recon_data_dir = dir_name_ae+'/plots/reconstructed_data'\n","if not os.path.isdir(recon_data_dir):\n","    os.makedirs(recon_data_dir)\n","\n","num_digits_n = int(np.log10(n)+1)\n","\n","prev_idx = 0\n","for i in range(n):\n","    fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n","    # ax = plt.axes(projection ='3d')\n","    next_idx = boundary_idx_arr[i]\n","    \n","    ax_orig = fig.add_subplot(num_rows, num_cols, 1, projection ='3d')\n","    ax_orig.plot(all_data[prev_idx:next_idx, 0], all_data[prev_idx:next_idx, 1], all_data[prev_idx:next_idx, 2])\n","    ax_orig.title.set_text(r'Actual Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:]))\n","    ax_orig.set_xlabel('x')\n","    ax_orig.set_ylabel('y')\n","    ax_orig.set_zlabel('z')\n","    \n","    ax_predict = fig.add_subplot(num_rows, num_cols, 2, projection ='3d')\n","    ax_predict.plot(reconstructed_data[prev_idx:next_idx, 0], reconstructed_data[prev_idx:next_idx, 1], reconstructed_data[prev_idx:next_idx, 2])\n","    ax_predict.title.set_text(r'NN Reconstructed Data - [$\\sigma$, $\\rho$, $\\beta$] = ' + str(all_data[next_idx-1, 3:])\n","    )\n","    ax_predict.set_xlabel('x')\n","    ax_predict.set_ylabel('y')\n","    ax_predict.set_zlabel('z')\n","\n","    prev_idx = next_idx\n","    \n","    fig.savefig(recon_data_dir+'/reconstructed_'+str(i+1).zfill(num_digits_n)+'.png', dpi=300, bbox_inches='tight')\n","    fig.clear()\n","#     fig.close()\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVqsAwsY0Amw"},"outputs":[],"source":["# create data\n","latent_states_all = ae_net.encoder_net.predict(all_data)"]},{"cell_type":"code","source":["from tools.misc_tools import plot_latent_states"],"metadata":{"id":"3Toyb7mJHRO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjgPNitSrt5p"},"outputs":[],"source":["fig, ax = plot_latent_states(\n","    boundary_idx_arr=boundary_idx_arr,\n","    latent_states_all=latent_states_all,\n","    all_data=all_data,\n","    xlim=[-1,1],\n","    ylim=[-1,1],)\n","\n","plt.savefig(dir_name_ae + '{ds}plots{ds}latent_space.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnLnqg0Jrt5t"},"outputs":[],"source":["# ae_net.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOJE8vREtque"},"outputs":[],"source":["save_path = dir_name_ae+dir_sep+'final_net'\n","\n","if not os.path.isdir(save_path):\n","    os.makedirs(save_path)\n","\n","with open(save_path+dir_sep+'losses.txt', 'w') as f:\n","    f.write(str({\n","        'val_loss_hist':val_loss_hist,\n","        'train_loss_hist':train_loss_hist,\n","        'lr_change':lr_change,\n","        'test_loss':test_loss\n","    }))\n","\n","ae_net.save_everything(file_name=save_path+dir_sep+'final_net')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEm2A0sB0Amx","scrolled":false},"outputs":[],"source":["n = len(boundary_idx_arr)\n","num_cols = 1\n","num_rows = 3*n\n","\n","# plt.ion()\n","\n","fig = plt.figure(figsize=(7.5*num_cols, 7.5*num_rows))\n","\n","Tt = N * delta_t\n","time_arr = np.arange(0, N+1) * Tt / N\n","\n","y_labels = [r'$x_1$', r'$x_2$', r'$x_3$']\n","\n","prev_idx = 0\n","for i in range(n):\n","    # ax = plt.axes(projection ='3d')\n","    next_idx = boundary_idx_arr[i]\n","\n","    for j in range(3):\n","        ax = fig.add_subplot(num_rows, num_cols, 3*i+j+1)\n","        ax.plot(time_arr, all_data[prev_idx:next_idx, j], label='original')\n","        ax.plot(time_arr, reconstructed_data[prev_idx:next_idx, j], label='reconstructed')\n","        ax.set_ylabel(y_labels[j])\n","        ax.set_xlabel('time')\n","        ax.grid(True)\n","\n","\n","    prev_idx = next_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvwVNuUl0Amy"},"outputs":[],"source":["ae_net.encoder_layers_list[1].moving_variance"]},{"cell_type":"markdown","metadata":{"id":"8IAcFjRRn_IQ"},"source":["# LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPVqWNwjoAGP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S21-VEUYrkk-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGnj8uQQ83-y"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0t2_8mzI1fhX"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIsWCXkbr7ws"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4hx9ZaSpEMmv"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EENXaWqcKW7j"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8isZN1tYBifp"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixetsZHjCMKO"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hh1pbKjCcO4"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbLa0AwlDBWh"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGQN5p7rNVV3"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of Lorenz_AE_v2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}