{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788634667,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3089,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "3AVrZNGlZu4Z"
   },
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788637753,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "SxAd7iDL0Ami"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27766,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "JjNnPRuk0IIX",
    "outputId": "f93a8628-71fe-4d6d-b3b6-245dfcb8eb60"
   },
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "9REiGIIy0IzV",
    "outputId": "2b5b0b02-2f67-4635-a00c-82084a8d2ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/Kolmogorov\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1666788666890,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import mytimecallback, SaveLosses, plot_losses, readAndReturnLossHistories\n",
    "from tools.ae_v1 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666891,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-mIQj_v4gzMh"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "QL5n-abCg0nI"
   },
   "outputs": [],
   "source": [
    "# setting seed for PRNGs\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    prng_seed = 42\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "f77bf689-c865-4a8d-8d40-37ec9c75f1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 04:43:48.511847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.512546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.573117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.573566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.573964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.574327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.575614: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 04:43:48.576118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.576435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:48.576748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:49.177738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:49.177976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:49.178177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 04:43:49.178347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3359 MB memory:  -> device: 0, name: Quadro K2200, pci bus id: 0000:02:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 0\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "xcNgt4hqg6Xv",
    "outputId": "7735ac54-495c-493f-869b-7d15538ee30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000\n",
      "24 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "from numpy import *\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # loading data directory\n",
    "    data_dir_idx = '000'\n",
    "\n",
    "    # making ae save directory\n",
    "    dir_name_ae = os.getcwd() + dir_sep + 'saved_ae'\n",
    "    if not os.path.isdir(dir_name_ae):\n",
    "        os.makedirs(dir_name_ae)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        dir_check = 'ae_' + str(counter).zfill(3)\n",
    "        if os.path.isdir(dir_name_ae + dir_sep + dir_check):\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dir_name_ae = dir_name_ae + dir_sep + dir_check\n",
    "    os.makedirs(dir_name_ae)\n",
    "    os.makedirs(dir_name_ae+dir_sep+'plots')\n",
    "else:\n",
    "    # some paramaters\n",
    "    dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_015'.format(ds=dir_sep)\n",
    "\n",
    "    with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    params_dict = eval(''.join(lines))\n",
    "    data_dir_idx = params_dict['data_dir_idx']\n",
    "    normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "    normalization_constant_arr_aedata = params_dict['normalization_constant_arr_aedata']\n",
    "    if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "        with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "            normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "\n",
    "print('dir_name_ae:', dir_name_ae)\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "    \n",
    "with h5py.File(dir_name_data + '/data.h5', 'r') as f:\n",
    "    t_recorded_samples = np.array(f['t'])\n",
    "    \n",
    "    N = int(0.5*(np.array(f['num_wavenumbers'])-1))\n",
    "    print(N, type(N))\n",
    "    \n",
    "    u_ref = np.array(f['u_reference'], dtype=FTYPE)\n",
    "    v_ref = np.array(f['v_reference'], dtype=FTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.empty(shape=(u_ref.shape[0], 2, u_ref.shape[1], u_ref.shape[2]), dtype=FTYPE)\n",
    "all_data[:, 0, :, :] = u_ref\n",
    "del(u_ref)\n",
    "all_data[:, 1, :, :] = v_ref\n",
    "del(v_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "O7sl7i5H5Dqz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2415,
     "status": "ok",
     "timestamp": 1666788671329,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ySVDz_2U5FH5",
    "outputId": "53f23b1d-fa61-4f27-bbc4-2e624421a866"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788671330,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [],
   "source": [
    "# dealing with normalizing the data before feeding into autoencoder\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # normalize data before feeding into autoencoder?\n",
    "    normalizeforae_flag = True\n",
    "    normalization_type = 'stddev' # could be 'stddev' or 'minmax'\n",
    "    stddev_multiplier = 3\n",
    "    \n",
    "    normalization_constant_arr_aedata = None\n",
    "    if normalizeforae_flag == True:\n",
    "        normalization_constant_arr_aedata = np.empty(shape=(2,) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "        if normalization_type == 'stddev':\n",
    "            normalization_constant_arr_aedata[0] = np.mean(all_data, axis=0)\n",
    "            normalization_constant_arr_aedata[1] = stddev_multiplier * np.std(all_data, axis=0)\n",
    "        elif normalization_type == 'minmax':\n",
    "            sample_min = all_data.min(axis=0)\n",
    "            sample_max = all_data.max(axis=0)\n",
    "            idx = np.where(sample_min == sample_max)\n",
    "            if len(idx) > 0:\n",
    "                num_elems = len(idx[0])\n",
    "                for i in range(num_elems):\n",
    "                    i0 = idx[0][i]\n",
    "                    i1 = idx[1][i]\n",
    "                    i2 = idx[2][i]\n",
    "                    sample_min[i0, i1, i2] -= 0.5\n",
    "                    sample_max[i0, i1, i2] = sample_min[i0, i1, i2] + 1.\n",
    "            normalization_constant_arr_aedata[0] = sample_min\n",
    "            normalization_constant_arr_aedata[1] = sample_max - sample_min\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "    # saving sim data\n",
    "    ae_data = {\n",
    "        'data_dir_idx':data_dir_idx,\n",
    "        'normalizeforae_flag':normalizeforae_flag,\n",
    "        # 'normalization_constant_arr_aedata':normalization_constant_arr_aedata,\n",
    "        'normalization_type':normalization_type,\n",
    "        'stddev_multiplier':stddev_multiplier,\n",
    "        'ae_data_with_params':False,\n",
    "        'module':Autoencoder.__module__,\n",
    "    }\n",
    "    with open(dir_name_ae+dir_sep+'ae_data.txt', 'w') as f:\n",
    "        f.write(str(ae_data))\n",
    "    np.savez(\n",
    "        dir_name_ae+dir_sep+'normalization_data',\n",
    "        normalization_constant_arr_aedata=[normalization_constant_arr_aedata],\n",
    "    )\n",
    "else:\n",
    "    if normalizeforae_flag == True:\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "time_stddev = np.std(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1666788672340,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "uDhfYHU45IS8",
    "outputId": "982f534f-255c-41b9-f40a-327730ac89ae"
   },
   "outputs": [],
   "source": [
    "all_data = all_data[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1666788672341,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "59kkrSP1GvzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788672342,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-MJa7P5t5KiC",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1666788672765,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "c5cjQ1lnjcwt"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    learning_rate_list = [1e-3, 1e-4, 1e-5]\n",
    "    epochs = 200\n",
    "    patience = 10  # parameter for early stopping\n",
    "    min_delta = 1e-6  # parameter for early stopping\n",
    "    lambda_reg = 5e-7 # weight for regularizer\n",
    "    train_split = 0.8\n",
    "    val_split = 0.1\n",
    "    test_split = 1 - train_split - val_split\n",
    "    batch_size = 64\n",
    "    fRMS = 2/100\n",
    "    timeMeanofSpaceRMS = np.mean(np.mean(all_data**2, axis=1)**0.5)\n",
    "    \n",
    "    # stddev = fRMS*timeMeanofSpaceRMS\n",
    "    stddev = fRMS * np.mean(time_stddev)\n",
    "    use_weights_post_dense = False\n",
    "    use_batch_norm = True\n",
    "\n",
    "    # saving training params\n",
    "    training_specific_params = {\n",
    "        'learning_rate_list':learning_rate_list,\n",
    "        'epochs':epochs,\n",
    "        'patience':patience,\n",
    "        'min_delta':min_delta,\n",
    "        'prng_seed':prng_seed,\n",
    "        'train_split':train_split,\n",
    "        'val_split':val_split,\n",
    "        'batch_size':batch_size,\n",
    "        'fRMS':fRMS,\n",
    "        'timeMeanofSpaceRMS':timeMeanofSpaceRMS,\n",
    "        'stddev':stddev,\n",
    "        'use_batch_norm':use_batch_norm,\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ae+dir_sep+'training_specific_params.txt', 'w') as f:\n",
    "        f.write(str(training_specific_params))\n",
    "else:\n",
    "    with open(dir_name_ae + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    learning_rate_list = tparams_dict['learning_rate_list']\n",
    "    epochs = tparams_dict['epochs']\n",
    "    patience = tparams_dict['patience']\n",
    "    min_delta = tparams_dict['min_delta']\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "    try:\n",
    "        stddev = tparams_dict['stddev']\n",
    "    except:\n",
    "        print(\"'stddev' not in tparams_dict, set to 0\")\n",
    "        stddev = 0.0\n",
    "\n",
    "    test_split = 1 - train_split - val_split\n",
    "\n",
    "    # setting seed for PRNGs\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672769,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "lovTI3zuhlX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672770,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "IjsRi02g5ORG"
   },
   "outputs": [],
   "source": [
    "# # setting up data\n",
    "# idx = np.arange(all_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# boundary = int(np.round((1-test_split)*all_data.shape[0]))\n",
    "# training_data = all_data[idx[0:boundary], :]\n",
    "# testing_data = all_data[idx[boundary:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672771,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Qwietg7eTG-s"
   },
   "outputs": [],
   "source": [
    "num_train = int(all_data.shape[0]*train_split)\n",
    "num_val = int(all_data.shape[0]*val_split)\n",
    "num_test = all_data.shape[0] - num_train - num_val\n",
    "\n",
    "idx = np.arange(all_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "training_data = np.empty(shape=(num_train, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "val_data = np.empty(shape=(num_val, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "testing_data = np.empty(shape=(num_test, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "\n",
    "training_data[:] = all_data[idx[0:num_train]]\n",
    "val_data[:] = all_data[idx[num_train:num_train+num_val]]\n",
    "testing_data[:] = all_data[idx[num_train+num_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672772,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gJ-28EnzJ4Ur"
   },
   "outputs": [],
   "source": [
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1666788672773,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7xTsmS7lgpps"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1626,
     "status": "ok",
     "timestamp": 1666788674381,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7l5kI1tfMszJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 04:43:57.137205: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n"
     ]
    }
   ],
   "source": [
    "# Initialize network\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    enc_filters = [8, 16, 32, 2]\n",
    "    dec_filters = [32, 16, 8, 2]\n",
    "    kernel_size = 3\n",
    "    \n",
    "    enc_layer_act_func = 'elu'\n",
    "    enc_final_layer_act_func = 'tanh'\n",
    "    dec_layer_act_func = 'elu'\n",
    "    dec_final_layer_act_func = 'tanh'\n",
    "    reg_name = 'L2'\n",
    "    \n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(\n",
    "                data_dim=training_data.shape[1:],\n",
    "                kernel_size=kernel_size,\n",
    "                enc_filters=enc_filters, # number of filters\n",
    "                dec_filters=dec_filters, # number of filters\n",
    "                lambda_reg=lambda_reg,\n",
    "                reg_name=reg_name,\n",
    "                enc_layer_act_func=enc_layer_act_func,\n",
    "                enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "                dec_layer_act_func=dec_layer_act_func,\n",
    "                dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "                load_file=None,\n",
    "                stddev=stddev,\n",
    "                use_weights_post_dense=use_weights_post_dense,\n",
    "                use_batch_norm=use_batch_norm,)\n",
    "    else:\n",
    "        ae_net = Autoencoder(\n",
    "            data_dim=training_data.shape[1:],\n",
    "            kernel_size=kernel_size,\n",
    "            enc_filters=enc_filters, # number of filters\n",
    "            dec_filters=dec_filters, # number of filters\n",
    "            lambda_reg=lambda_reg,\n",
    "            reg_name=reg_name,\n",
    "            enc_layer_act_func=enc_layer_act_func,\n",
    "            enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "            dec_layer_act_func=dec_layer_act_func,\n",
    "            dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "            load_file=None,\n",
    "            stddev=stddev,\n",
    "            use_weights_post_dense=use_weights_post_dense,\n",
    "            use_batch_norm=use_batch_norm,)\n",
    "    # saving the AE configuration\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    ae_net.save_class_dict(save_path+dir_sep+'final_net_class_dict.txt')\n",
    "else:\n",
    "    load_file = dir_name_ae + dir_sep + 'final_net' + dir_sep + 'final_net_class_dict.txt'\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    else:\n",
    "        ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    \n",
    "    if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "        wt_file = tf.train.latest_checkpoint(dir_name_ae+dir_sep+'checkpoints')\n",
    "        # ae_net.load_weights(wt_file)\n",
    "    elif behaviour == 'loadFinalNetAndPlot':\n",
    "        wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "        ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1666788674637,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "48tkgZxT0Amt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1666788674956,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "yUChBAKqIFtX"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    val_loss_hist = []\n",
    "    train_loss_hist = []\n",
    "    lr_change=[0, 0]\n",
    "    savelosses_cb_vallossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    savelosses_cb_trainlossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    starting_lr_idx = 0\n",
    "    num_epochs_left = epochs\n",
    "elif behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    val_loss_hist, train_loss_hist, lr_change, starting_lr_idx, num_epochs_left, val_loss_arr_fromckpt, train_loss_arr_fromckpt = readAndReturnLossHistories(\n",
    "        dir_name_ae=dir_name_ae,\n",
    "        dir_sep=dir_sep,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list)\n",
    "    savelosses_cb_vallossarr = val_loss_arr_fromckpt\n",
    "    savelosses_cb_trainlossarr = train_loss_arr_fromckpt\n",
    "elif behaviour == 'loadFinalNetAndPlot':\n",
    "    with open(dir_name_ae+'{ds}final_net{ds}losses.txt'.format(ds=dir_sep), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    losses_dict = eval(''.join(lines))\n",
    "\n",
    "    val_loss_hist = losses_dict['val_loss_hist']\n",
    "    train_loss_hist = losses_dict['train_loss_hist']\n",
    "    lr_change = losses_dict['lr_change']\n",
    "    test_loss = losses_dict['test_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_hist = []\n",
    "val_MSE_hist = []\n",
    "\n",
    "train_NMSE_hist = []\n",
    "val_NMSE_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788674957,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Z0oEGp6WKGu2"
   },
   "outputs": [],
   "source": [
    "class NMSE(tf.keras.metrics.MeanSquaredError):\n",
    "    def __init__(self, divisor_arr, name='NMSE', **kwargs):\n",
    "        super(NMSE, self).__init__(name, **kwargs)\n",
    "        self.divisor_arr = divisor_arr\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = y_true / self.divisor_arr\n",
    "        y_pred = y_pred / self.divisor_arr\n",
    "        return super(NMSE, self).update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if strategy is not None:\n",
    "    with strategy.scope():\n",
    "        NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))\n",
    "else:\n",
    "    NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191278,
     "status": "ok",
     "timestamp": 1666788866231,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gELga1WnQeMK",
    "outputId": "e923a97a-2d9d-4c74-c328-4793de05b919",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0914 - mse: 0.0914 - NMSE: 0.8224 - tot_time: 0h 0m 9.2s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.23202, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 8s 21ms/step - loss: 0.0914 - mse: 0.0914 - NMSE: 0.8224 - val_loss: 0.0259 - val_mse: 0.0258 - val_NMSE: 0.2320\n",
      "Epoch 2/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0210 - mse: 0.0210 - NMSE: 0.1887 - tot_time: 0h 0m 14.4s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.23202 to 0.15503, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0211 - mse: 0.0210 - NMSE: 0.1888 - val_loss: 0.0173 - val_mse: 0.0172 - val_NMSE: 0.1550\n",
      "Epoch 3/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0155 - NMSE: 0.1393 - tot_time: 0h 0m 19.7s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.15503 to 0.12649, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0156 - mse: 0.0155 - NMSE: 0.1393 - val_loss: 0.0141 - val_mse: 0.0141 - val_NMSE: 0.1265\n",
      "Epoch 4/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0132 - mse: 0.0131 - NMSE: 0.1179 - tot_time: 0h 0m 25.0s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.12649 to 0.10931, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0132 - mse: 0.0131 - NMSE: 0.1179 - val_loss: 0.0122 - val_mse: 0.0121 - val_NMSE: 0.1093\n",
      "Epoch 5/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0117 - mse: 0.0116 - NMSE: 0.1043 - tot_time: 0h 0m 30.1s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.10931 to 0.09716, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0117 - mse: 0.0116 - NMSE: 0.1043 - val_loss: 0.0109 - val_mse: 0.0108 - val_NMSE: 0.0972\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0954 - tot_time: 0h 0m 35.3s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.09716 to 0.08936, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0954 - val_loss: 0.0100 - val_mse: 0.0099 - val_NMSE: 0.0894\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0100 - mse: 0.0099 - NMSE: 0.0889 - tot_time: 0h 0m 40.6s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.08936 to 0.08455, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0100 - mse: 0.0099 - NMSE: 0.0889 - val_loss: 0.0095 - val_mse: 0.0094 - val_NMSE: 0.0845\n",
      "Epoch 8/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0095 - mse: 0.0094 - NMSE: 0.0844 - tot_time: 0h 0m 45.8s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.08455 to 0.08320, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0095 - mse: 0.0094 - NMSE: 0.0844 - val_loss: 0.0093 - val_mse: 0.0092 - val_NMSE: 0.0832\n",
      "Epoch 9/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0090 - mse: 0.0089 - NMSE: 0.0803 - tot_time: 0h 0m 51.0s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.08320 to 0.07760, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0090 - mse: 0.0089 - NMSE: 0.0802 - val_loss: 0.0087 - val_mse: 0.0086 - val_NMSE: 0.0776\n",
      "Epoch 10/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0086 - mse: 0.0085 - NMSE: 0.0767 - tot_time: 0h 0m 56.2s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.07760 to 0.07493, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0086 - mse: 0.0085 - NMSE: 0.0767 - val_loss: 0.0084 - val_mse: 0.0083 - val_NMSE: 0.0749\n",
      "Epoch 11/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0083 - NMSE: 0.0748 - tot_time: 0h 1m 1.4s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.07493\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0084 - mse: 0.0083 - NMSE: 0.0748 - val_loss: 0.0087 - val_mse: 0.0086 - val_NMSE: 0.0776\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0082 - mse: 0.0081 - NMSE: 0.0730 - tot_time: 0h 1m 6.6s\n",
      "\n",
      "Epoch 12: val_NMSE improved from 0.07493 to 0.07221, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0082 - mse: 0.0081 - NMSE: 0.0730 - val_loss: 0.0081 - val_mse: 0.0080 - val_NMSE: 0.0722\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0078 - mse: 0.0077 - NMSE: 0.0696 - tot_time: 0h 1m 11.8s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.07221 to 0.06900, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0078 - mse: 0.0077 - NMSE: 0.0696 - val_loss: 0.0078 - val_mse: 0.0077 - val_NMSE: 0.0690\n",
      "Epoch 14/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0077 - mse: 0.0076 - NMSE: 0.0683 - tot_time: 0h 1m 17.0s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.06900 to 0.06847, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0077 - mse: 0.0076 - NMSE: 0.0683 - val_loss: 0.0077 - val_mse: 0.0076 - val_NMSE: 0.0685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0075 - mse: 0.0075 - NMSE: 0.0671 - tot_time: 0h 1m 22.1s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.06847\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0075 - mse: 0.0075 - NMSE: 0.0671 - val_loss: 0.0078 - val_mse: 0.0077 - val_NMSE: 0.0696\n",
      "Epoch 16/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0075 - mse: 0.0074 - NMSE: 0.0663 - tot_time: 0h 1m 27.3s\n",
      "\n",
      "Epoch 16: val_NMSE improved from 0.06847 to 0.06598, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0075 - mse: 0.0074 - NMSE: 0.0663 - val_loss: 0.0074 - val_mse: 0.0073 - val_NMSE: 0.0660\n",
      "Epoch 17/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0072 - mse: 0.0071 - NMSE: 0.0643 - tot_time: 0h 1m 32.5s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.06598 to 0.06438, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0072 - mse: 0.0071 - NMSE: 0.0643 - val_loss: 0.0072 - val_mse: 0.0072 - val_NMSE: 0.0644\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0070 - mse: 0.0069 - NMSE: 0.0623 - tot_time: 0h 1m 37.8s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.06438 to 0.06248, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0070 - mse: 0.0069 - NMSE: 0.0623 - val_loss: 0.0070 - val_mse: 0.0069 - val_NMSE: 0.0625\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0069 - mse: 0.0068 - NMSE: 0.0616 - tot_time: 0h 1m 42.9s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.06248\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0069 - mse: 0.0068 - NMSE: 0.0616 - val_loss: 0.0073 - val_mse: 0.0072 - val_NMSE: 0.0650\n",
      "Epoch 20/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0069 - mse: 0.0068 - NMSE: 0.0609 - tot_time: 0h 1m 48.0s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.06248\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0069 - mse: 0.0068 - NMSE: 0.0609 - val_loss: 0.0072 - val_mse: 0.0071 - val_NMSE: 0.0635\n",
      "Epoch 21/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0068 - mse: 0.0067 - NMSE: 0.0600 - tot_time: 0h 1m 53.1s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.06248\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0068 - mse: 0.0067 - NMSE: 0.0600 - val_loss: 0.0075 - val_mse: 0.0074 - val_NMSE: 0.0666\n",
      "Epoch 22/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0067 - mse: 0.0066 - NMSE: 0.0595 - tot_time: 0h 1m 58.2s\n",
      "\n",
      "Epoch 22: val_NMSE improved from 0.06248 to 0.05850, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0067 - mse: 0.0066 - NMSE: 0.0595 - val_loss: 0.0066 - val_mse: 0.0065 - val_NMSE: 0.0585\n",
      "Epoch 23/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0066 - mse: 0.0065 - NMSE: 0.0581 - tot_time: 0h 2m 3.4s\n",
      "\n",
      "Epoch 23: val_NMSE did not improve from 0.05850\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0065 - mse: 0.0064 - NMSE: 0.0580 - val_loss: 0.0066 - val_mse: 0.0065 - val_NMSE: 0.0588\n",
      "Epoch 24/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0068 - mse: 0.0067 - NMSE: 0.0606 - tot_time: 0h 2m 8.5s\n",
      "\n",
      "Epoch 24: val_NMSE did not improve from 0.05850\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0069 - mse: 0.0068 - NMSE: 0.0608 - val_loss: 0.0081 - val_mse: 0.0080 - val_NMSE: 0.0723\n",
      "Epoch 25/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0067 - mse: 0.0066 - NMSE: 0.0597 - tot_time: 0h 2m 13.6s\n",
      "\n",
      "Epoch 25: val_NMSE improved from 0.05850 to 0.05819, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0067 - mse: 0.0066 - NMSE: 0.0597 - val_loss: 0.0066 - val_mse: 0.0065 - val_NMSE: 0.0582\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0064 - mse: 0.0063 - NMSE: 0.0569 - tot_time: 0h 2m 18.7s\n",
      "\n",
      "Epoch 26: val_NMSE improved from 0.05819 to 0.05710, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0064 - mse: 0.0063 - NMSE: 0.0569 - val_loss: 0.0065 - val_mse: 0.0063 - val_NMSE: 0.0571\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0073 - mse: 0.0072 - NMSE: 0.0651 - tot_time: 0h 2m 23.9s\n",
      "\n",
      "Epoch 27: val_NMSE did not improve from 0.05710\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0073 - mse: 0.0072 - NMSE: 0.0651 - val_loss: 0.0065 - val_mse: 0.0064 - val_NMSE: 0.0573\n",
      "Epoch 28/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0064 - mse: 0.0063 - NMSE: 0.0565 - tot_time: 0h 2m 29.1s\n",
      "\n",
      "Epoch 28: val_NMSE improved from 0.05710 to 0.05535, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0064 - mse: 0.0063 - NMSE: 0.0565 - val_loss: 0.0063 - val_mse: 0.0062 - val_NMSE: 0.0554\n",
      "Epoch 29/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0063 - mse: 0.0062 - NMSE: 0.0554 - tot_time: 0h 2m 34.3s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.05535\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0063 - mse: 0.0062 - NMSE: 0.0555 - val_loss: 0.0063 - val_mse: 0.0062 - val_NMSE: 0.0556\n",
      "Epoch 30/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0062 - mse: 0.0061 - NMSE: 0.0547 - tot_time: 0h 2m 39.5s\n",
      "\n",
      "Epoch 30: val_NMSE improved from 0.05535 to 0.05475, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0062 - mse: 0.0061 - NMSE: 0.0546 - val_loss: 0.0062 - val_mse: 0.0061 - val_NMSE: 0.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0063 - mse: 0.0062 - NMSE: 0.0554 - tot_time: 0h 2m 44.6s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.05475\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0063 - mse: 0.0062 - NMSE: 0.0554 - val_loss: 0.0064 - val_mse: 0.0063 - val_NMSE: 0.0565\n",
      "Epoch 32/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0537 - tot_time: 0h 2m 49.5s\n",
      "\n",
      "Epoch 32: val_NMSE improved from 0.05475 to 0.05302, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0537 - val_loss: 0.0060 - val_mse: 0.0059 - val_NMSE: 0.0530\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0060 - mse: 0.0059 - NMSE: 0.0532 - tot_time: 0h 2m 54.6s\n",
      "\n",
      "Epoch 33: val_NMSE did not improve from 0.05302\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0060 - mse: 0.0059 - NMSE: 0.0532 - val_loss: 0.0066 - val_mse: 0.0065 - val_NMSE: 0.0586\n",
      "Epoch 34/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0541 - tot_time: 0h 2m 59.6s\n",
      "\n",
      "Epoch 34: val_NMSE improved from 0.05302 to 0.05228, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0541 - val_loss: 0.0059 - val_mse: 0.0058 - val_NMSE: 0.0523\n",
      "Epoch 35/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0059 - mse: 0.0058 - NMSE: 0.0520 - tot_time: 0h 3m 4.7s\n",
      "\n",
      "Epoch 35: val_NMSE improved from 0.05228 to 0.05122, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0059 - mse: 0.0058 - NMSE: 0.0520 - val_loss: 0.0058 - val_mse: 0.0057 - val_NMSE: 0.0512\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0059 - mse: 0.0057 - NMSE: 0.0516 - tot_time: 0h 3m 9.6s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.05122\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0059 - mse: 0.0057 - NMSE: 0.0516 - val_loss: 0.0066 - val_mse: 0.0064 - val_NMSE: 0.0580\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0060 - mse: 0.0059 - NMSE: 0.0527 - tot_time: 0h 3m 14.5s\n",
      "\n",
      "Epoch 37: val_NMSE improved from 0.05122 to 0.05027, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0060 - mse: 0.0059 - NMSE: 0.0527 - val_loss: 0.0057 - val_mse: 0.0056 - val_NMSE: 0.0503\n",
      "Epoch 38/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0058 - mse: 0.0057 - NMSE: 0.0513 - tot_time: 0h 3m 19.3s\n",
      "\n",
      "Epoch 38: val_NMSE improved from 0.05027 to 0.04970, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0058 - mse: 0.0057 - NMSE: 0.0513 - val_loss: 0.0056 - val_mse: 0.0055 - val_NMSE: 0.0497\n",
      "Epoch 39/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0505 - tot_time: 0h 3m 24.1s\n",
      "\n",
      "Epoch 39: val_NMSE improved from 0.04970 to 0.04952, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0504 - val_loss: 0.0056 - val_mse: 0.0055 - val_NMSE: 0.0495\n",
      "Epoch 40/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0505 - tot_time: 0h 3m 29.2s\n",
      "\n",
      "Epoch 40: val_NMSE improved from 0.04952 to 0.04922, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0505 - val_loss: 0.0056 - val_mse: 0.0055 - val_NMSE: 0.0492\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0500 - tot_time: 0h 3m 34.1s\n",
      "\n",
      "Epoch 41: val_NMSE improved from 0.04922 to 0.04876, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0500 - val_loss: 0.0055 - val_mse: 0.0054 - val_NMSE: 0.0488\n",
      "Epoch 42/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0500 - tot_time: 0h 3m 39.1s\n",
      "\n",
      "Epoch 42: val_NMSE improved from 0.04876 to 0.04868, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0057 - mse: 0.0056 - NMSE: 0.0500 - val_loss: 0.0055 - val_mse: 0.0054 - val_NMSE: 0.0487\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0056 - mse: 0.0054 - NMSE: 0.0489 - tot_time: 0h 3m 43.8s\n",
      "\n",
      "Epoch 43: val_NMSE did not improve from 0.04868\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0056 - mse: 0.0054 - NMSE: 0.0489 - val_loss: 0.0056 - val_mse: 0.0055 - val_NMSE: 0.0492\n",
      "Epoch 44/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0486 - tot_time: 0h 3m 48.4s\n",
      "\n",
      "Epoch 44: val_NMSE improved from 0.04868 to 0.04820, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0486 - val_loss: 0.0055 - val_mse: 0.0054 - val_NMSE: 0.0482\n",
      "Epoch 45/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0056 - mse: 0.0054 - NMSE: 0.0489 - tot_time: 0h 3m 53.2s\n",
      "\n",
      "Epoch 45: val_NMSE improved from 0.04820 to 0.04743, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0056 - mse: 0.0054 - NMSE: 0.0489 - val_loss: 0.0054 - val_mse: 0.0053 - val_NMSE: 0.0474\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/313 [============================>.] - ETA: 0s - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0482 - tot_time: 0h 3m 58.2s\n",
      "\n",
      "Epoch 46: val_NMSE improved from 0.04743 to 0.04704, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0482 - val_loss: 0.0054 - val_mse: 0.0052 - val_NMSE: 0.0470\n",
      "Epoch 47/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0055 - mse: 0.0053 - NMSE: 0.0479 - tot_time: 0h 4m 3.1s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.04704\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0055 - mse: 0.0053 - NMSE: 0.0479 - val_loss: 0.0054 - val_mse: 0.0053 - val_NMSE: 0.0474\n",
      "Epoch 48/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0488 - tot_time: 0h 4m 8.0s\n",
      "\n",
      "Epoch 48: val_NMSE improved from 0.04704 to 0.04622, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0487 - val_loss: 0.0053 - val_mse: 0.0051 - val_NMSE: 0.0462\n",
      "Epoch 49/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0054 - mse: 0.0053 - NMSE: 0.0476 - tot_time: 0h 4m 12.9s\n",
      "\n",
      "Epoch 49: val_NMSE improved from 0.04622 to 0.04604, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0054 - mse: 0.0053 - NMSE: 0.0477 - val_loss: 0.0052 - val_mse: 0.0051 - val_NMSE: 0.0460\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0054 - mse: 0.0052 - NMSE: 0.0472 - tot_time: 0h 4m 17.9s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.04604\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0054 - mse: 0.0052 - NMSE: 0.0472 - val_loss: 0.0053 - val_mse: 0.0052 - val_NMSE: 0.0466\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0054 - mse: 0.0052 - NMSE: 0.0470 - tot_time: 0h 4m 22.8s\n",
      "\n",
      "Epoch 51: val_NMSE improved from 0.04604 to 0.04602, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0054 - mse: 0.0052 - NMSE: 0.0470 - val_loss: 0.0052 - val_mse: 0.0051 - val_NMSE: 0.0460\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0467 - tot_time: 0h 4m 27.8s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.04602\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0467 - val_loss: 0.0053 - val_mse: 0.0052 - val_NMSE: 0.0466\n",
      "Epoch 53/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0465 - tot_time: 0h 4m 32.6s\n",
      "\n",
      "Epoch 53: val_NMSE improved from 0.04602 to 0.04600, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0465 - val_loss: 0.0052 - val_mse: 0.0051 - val_NMSE: 0.0460\n",
      "Epoch 54/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0540 - tot_time: 0h 4m 37.6s\n",
      "\n",
      "Epoch 54: val_NMSE did not improve from 0.04600\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0061 - mse: 0.0060 - NMSE: 0.0540 - val_loss: 0.0057 - val_mse: 0.0056 - val_NMSE: 0.0503\n",
      "Epoch 55/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0486 - tot_time: 0h 4m 42.4s\n",
      "\n",
      "Epoch 55: val_NMSE improved from 0.04600 to 0.04558, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0055 - mse: 0.0054 - NMSE: 0.0486 - val_loss: 0.0052 - val_mse: 0.0051 - val_NMSE: 0.0456\n",
      "Epoch 56/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0464 - tot_time: 0h 4m 47.4s\n",
      "\n",
      "Epoch 56: val_NMSE improved from 0.04558 to 0.04543, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0052 - NMSE: 0.0465 - val_loss: 0.0052 - val_mse: 0.0050 - val_NMSE: 0.0454\n",
      "Epoch 57/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0053 - mse: 0.0051 - NMSE: 0.0462 - tot_time: 0h 4m 52.4s\n",
      "\n",
      "Epoch 57: val_NMSE improved from 0.04543 to 0.04487, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0051 - NMSE: 0.0462 - val_loss: 0.0051 - val_mse: 0.0050 - val_NMSE: 0.0449\n",
      "Epoch 58/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0052 - mse: 0.0051 - NMSE: 0.0455 - tot_time: 0h 4m 57.4s\n",
      "\n",
      "Epoch 58: val_NMSE improved from 0.04487 to 0.04469, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0052 - mse: 0.0051 - NMSE: 0.0456 - val_loss: 0.0051 - val_mse: 0.0050 - val_NMSE: 0.0447\n",
      "Epoch 59/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0052 - mse: 0.0051 - NMSE: 0.0460 - tot_time: 0h 5m 2.4s\n",
      "\n",
      "Epoch 59: val_NMSE improved from 0.04469 to 0.04386, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0051 - NMSE: 0.0460 - val_loss: 0.0050 - val_mse: 0.0049 - val_NMSE: 0.0439\n",
      "Epoch 60/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0053 - mse: 0.0051 - NMSE: 0.0460 - tot_time: 0h 5m 7.4s\n",
      "\n",
      "Epoch 60: val_NMSE did not improve from 0.04386\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - mse: 0.0051 - NMSE: 0.0461 - val_loss: 0.0051 - val_mse: 0.0049 - val_NMSE: 0.0443\n",
      "Epoch 61/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0051 - mse: 0.0050 - NMSE: 0.0448 - tot_time: 0h 5m 12.3s\n",
      "\n",
      "Epoch 61: val_NMSE improved from 0.04386 to 0.04377, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0051 - mse: 0.0050 - NMSE: 0.0448 - val_loss: 0.0050 - val_mse: 0.0049 - val_NMSE: 0.0438\n",
      "Epoch 62/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0051 - mse: 0.0050 - NMSE: 0.0446 - tot_time: 0h 5m 17.4s\n",
      "\n",
      "Epoch 62: val_NMSE improved from 0.04377 to 0.04331, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0051 - mse: 0.0050 - NMSE: 0.0446 - val_loss: 0.0050 - val_mse: 0.0048 - val_NMSE: 0.0433\n",
      "Epoch 63/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0051 - mse: 0.0049 - NMSE: 0.0444 - tot_time: 0h 5m 22.2s\n",
      "\n",
      "Epoch 63: val_NMSE did not improve from 0.04331\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0051 - mse: 0.0049 - NMSE: 0.0443 - val_loss: 0.0050 - val_mse: 0.0048 - val_NMSE: 0.0434\n",
      "Epoch 64/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0051 - mse: 0.0049 - NMSE: 0.0442 - tot_time: 0h 5m 27.2s\n",
      "\n",
      "Epoch 64: val_NMSE did not improve from 0.04331\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0051 - mse: 0.0049 - NMSE: 0.0442 - val_loss: 0.0050 - val_mse: 0.0048 - val_NMSE: 0.0436\n",
      "Epoch 65/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0050 - mse: 0.0049 - NMSE: 0.0439 - tot_time: 0h 5m 32.1s\n",
      "\n",
      "Epoch 65: val_NMSE improved from 0.04331 to 0.04291, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0050 - mse: 0.0049 - NMSE: 0.0439 - val_loss: 0.0049 - val_mse: 0.0048 - val_NMSE: 0.0429\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0050 - mse: 0.0049 - NMSE: 0.0437 - tot_time: 0h 5m 37.1s\n",
      "\n",
      "Epoch 66: val_NMSE improved from 0.04291 to 0.04247, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0050 - mse: 0.0049 - NMSE: 0.0437 - val_loss: 0.0049 - val_mse: 0.0047 - val_NMSE: 0.0425\n",
      "Epoch 67/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0050 - mse: 0.0048 - NMSE: 0.0436 - tot_time: 0h 5m 42.0s\n",
      "\n",
      "Epoch 67: val_NMSE improved from 0.04247 to 0.04213, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0050 - mse: 0.0048 - NMSE: 0.0436 - val_loss: 0.0048 - val_mse: 0.0047 - val_NMSE: 0.0421\n",
      "Epoch 68/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0050 - mse: 0.0048 - NMSE: 0.0434 - tot_time: 0h 5m 46.9s\n",
      "\n",
      "Epoch 68: val_NMSE did not improve from 0.04213\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0050 - mse: 0.0048 - NMSE: 0.0434 - val_loss: 0.0048 - val_mse: 0.0047 - val_NMSE: 0.0423\n",
      "Epoch 69/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0432 - tot_time: 0h 5m 51.8s\n",
      "\n",
      "Epoch 69: val_NMSE did not improve from 0.04213\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0432 - val_loss: 0.0048 - val_mse: 0.0047 - val_NMSE: 0.0423\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0430 - tot_time: 0h 5m 56.5s\n",
      "\n",
      "Epoch 70: val_NMSE improved from 0.04213 to 0.04140, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0430 - val_loss: 0.0047 - val_mse: 0.0046 - val_NMSE: 0.0414\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0429 - tot_time: 0h 6m 1.3s\n",
      "\n",
      "Epoch 71: val_NMSE did not improve from 0.04140\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0049 - mse: 0.0048 - NMSE: 0.0429 - val_loss: 0.0048 - val_mse: 0.0047 - val_NMSE: 0.0420\n",
      "Epoch 72/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0049 - mse: 0.0047 - NMSE: 0.0425 - tot_time: 0h 6m 6.1s\n",
      "\n",
      "Epoch 72: val_NMSE did not improve from 0.04140\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0049 - mse: 0.0047 - NMSE: 0.0426 - val_loss: 0.0048 - val_mse: 0.0047 - val_NMSE: 0.0420\n",
      "Epoch 73/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0049 - mse: 0.0047 - NMSE: 0.0424 - tot_time: 0h 6m 11.0s\n",
      "\n",
      "Epoch 73: val_NMSE improved from 0.04140 to 0.04137, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0049 - mse: 0.0047 - NMSE: 0.0424 - val_loss: 0.0047 - val_mse: 0.0046 - val_NMSE: 0.0414\n",
      "Epoch 74/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0048 - mse: 0.0047 - NMSE: 0.0421 - tot_time: 0h 6m 15.8s\n",
      "\n",
      "Epoch 74: val_NMSE did not improve from 0.04137\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0048 - mse: 0.0047 - NMSE: 0.0421 - val_loss: 0.0047 - val_mse: 0.0046 - val_NMSE: 0.0414\n",
      "Epoch 75/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0418 - tot_time: 0h 6m 20.7s\n",
      "\n",
      "Epoch 75: val_NMSE improved from 0.04137 to 0.04101, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0418 - val_loss: 0.0047 - val_mse: 0.0046 - val_NMSE: 0.0410\n",
      "Epoch 76/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0417 - tot_time: 0h 6m 25.6s\n",
      "\n",
      "Epoch 76: val_NMSE improved from 0.04101 to 0.04061, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0417 - val_loss: 0.0047 - val_mse: 0.0045 - val_NMSE: 0.0406\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/313 [============================>.] - ETA: 0s - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0416 - tot_time: 0h 6m 30.4s\n",
      "\n",
      "Epoch 77: val_NMSE improved from 0.04061 to 0.04039, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0048 - mse: 0.0046 - NMSE: 0.0416 - val_loss: 0.0046 - val_mse: 0.0045 - val_NMSE: 0.0404\n",
      "Epoch 78/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0047 - mse: 0.0046 - NMSE: 0.0413 - tot_time: 0h 6m 35.3s\n",
      "\n",
      "Epoch 78: val_NMSE did not improve from 0.04039\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0047 - mse: 0.0046 - NMSE: 0.0413 - val_loss: 0.0046 - val_mse: 0.0045 - val_NMSE: 0.0404\n",
      "Epoch 79/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0047 - mse: 0.0046 - NMSE: 0.0410 - tot_time: 0h 6m 40.1s\n",
      "\n",
      "Epoch 79: val_NMSE improved from 0.04039 to 0.03992, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0047 - mse: 0.0046 - NMSE: 0.0410 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0399\n",
      "Epoch 80/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0047 - mse: 0.0045 - NMSE: 0.0408 - tot_time: 0h 6m 45.1s\n",
      "\n",
      "Epoch 80: val_NMSE did not improve from 0.03992\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0047 - mse: 0.0045 - NMSE: 0.0408 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0400\n",
      "Epoch 81/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0047 - mse: 0.0045 - NMSE: 0.0405 - tot_time: 0h 6m 49.9s\n",
      "\n",
      "Epoch 81: val_NMSE improved from 0.03992 to 0.03952, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0047 - mse: 0.0045 - NMSE: 0.0406 - val_loss: 0.0045 - val_mse: 0.0044 - val_NMSE: 0.0395\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0405 - tot_time: 0h 6m 54.9s\n",
      "\n",
      "Epoch 82: val_NMSE did not improve from 0.03952\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0405 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0398\n",
      "Epoch 83/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0405 - tot_time: 0h 6m 59.8s\n",
      "\n",
      "Epoch 83: val_NMSE did not improve from 0.03952\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0404 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0397\n",
      "Epoch 84/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0401 - tot_time: 0h 7m 4.6s\n",
      "\n",
      "Epoch 84: val_NMSE improved from 0.03952 to 0.03920, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0401 - val_loss: 0.0045 - val_mse: 0.0044 - val_NMSE: 0.0392\n",
      "Epoch 85/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0402 - tot_time: 0h 7m 9.6s\n",
      "\n",
      "Epoch 85: val_NMSE improved from 0.03920 to 0.03904, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0402 - val_loss: 0.0045 - val_mse: 0.0043 - val_NMSE: 0.0390\n",
      "Epoch 86/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0045 - NMSE: 0.0401 - tot_time: 0h 7m 14.5s\n",
      "\n",
      "Epoch 86: val_NMSE did not improve from 0.03904\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0046 - mse: 0.0044 - NMSE: 0.0400 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0397\n",
      "Epoch 87/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0044 - NMSE: 0.0399 - tot_time: 0h 7m 19.5s\n",
      "\n",
      "Epoch 87: val_NMSE did not improve from 0.03904\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0046 - mse: 0.0044 - NMSE: 0.0398 - val_loss: 0.0045 - val_mse: 0.0043 - val_NMSE: 0.0391\n",
      "Epoch 88/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0396 - tot_time: 0h 7m 24.3s\n",
      "\n",
      "Epoch 88: val_NMSE improved from 0.03904 to 0.03882, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0395 - val_loss: 0.0045 - val_mse: 0.0043 - val_NMSE: 0.0388\n",
      "Epoch 89/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0396 - tot_time: 0h 7m 29.2s\n",
      "\n",
      "Epoch 89: val_NMSE did not improve from 0.03882\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0396 - val_loss: 0.0045 - val_mse: 0.0043 - val_NMSE: 0.0389\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0393 - tot_time: 0h 7m 34.1s\n",
      "\n",
      "Epoch 90: val_NMSE improved from 0.03882 to 0.03845, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0393 - val_loss: 0.0044 - val_mse: 0.0043 - val_NMSE: 0.0385\n",
      "Epoch 91/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0393 - tot_time: 0h 7m 39.0s\n",
      "\n",
      "Epoch 91: val_NMSE improved from 0.03845 to 0.03821, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0393 - val_loss: 0.0044 - val_mse: 0.0042 - val_NMSE: 0.0382\n",
      "Epoch 92/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0393 - tot_time: 0h 7m 43.9s\n",
      "\n",
      "Epoch 92: val_NMSE did not improve from 0.03821\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0045 - mse: 0.0044 - NMSE: 0.0392 - val_loss: 0.0044 - val_mse: 0.0043 - val_NMSE: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0391 - tot_time: 0h 7m 48.8s\n",
      "\n",
      "Epoch 93: val_NMSE did not improve from 0.03821\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0391 - val_loss: 0.0044 - val_mse: 0.0043 - val_NMSE: 0.0383\n",
      "Epoch 94/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0389 - tot_time: 0h 7m 53.6s\n",
      "\n",
      "Epoch 94: val_NMSE improved from 0.03821 to 0.03816, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0389 - val_loss: 0.0044 - val_mse: 0.0042 - val_NMSE: 0.0382\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0389 - tot_time: 0h 7m 58.5s\n",
      "\n",
      "Epoch 95: val_NMSE did not improve from 0.03816\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0389 - val_loss: 0.0044 - val_mse: 0.0043 - val_NMSE: 0.0383\n",
      "Epoch 96/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0388 - tot_time: 0h 8m 3.4s\n",
      "\n",
      "Epoch 96: val_NMSE improved from 0.03816 to 0.03773, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0388 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0377\n",
      "Epoch 97/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0043 - NMSE: 0.0387 - tot_time: 0h 8m 8.3s\n",
      "\n",
      "Epoch 97: val_NMSE did not improve from 0.03773\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0387 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0377\n",
      "Epoch 98/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0386 - tot_time: 0h 8m 13.3s\n",
      "\n",
      "Epoch 98: val_NMSE improved from 0.03773 to 0.03763, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0386 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0376\n",
      "Epoch 99/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0384 - tot_time: 0h 8m 18.3s\n",
      "\n",
      "Epoch 99: val_NMSE did not improve from 0.03763\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0384 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0378\n",
      "Epoch 100/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0386 - tot_time: 0h 8m 23.1s\n",
      "\n",
      "Epoch 100: val_NMSE did not improve from 0.03763\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0386 - val_loss: 0.0044 - val_mse: 0.0042 - val_NMSE: 0.0378\n",
      "Epoch 101/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0384 - tot_time: 0h 8m 28.0s\n",
      "\n",
      "Epoch 101: val_NMSE improved from 0.03763 to 0.03755, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0043 - NMSE: 0.0383 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0375\n",
      "Epoch 102/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - tot_time: 0h 8m 33.0s\n",
      "\n",
      "Epoch 102: val_NMSE improved from 0.03755 to 0.03734, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0373\n",
      "Epoch 103/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - tot_time: 0h 8m 38.0s\n",
      "\n",
      "Epoch 103: val_NMSE did not improve from 0.03734\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - val_loss: 0.0043 - val_mse: 0.0042 - val_NMSE: 0.0374\n",
      "Epoch 104/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - tot_time: 0h 8m 42.9s\n",
      "\n",
      "Epoch 104: val_NMSE improved from 0.03734 to 0.03694, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0381 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0369\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0380 - tot_time: 0h 8m 47.9s\n",
      "\n",
      "Epoch 105: val_NMSE improved from 0.03694 to 0.03687, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0380 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0369\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0379 - tot_time: 0h 8m 52.8s\n",
      "\n",
      "Epoch 106: val_NMSE did not improve from 0.03687\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0379 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0372\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0378 - tot_time: 0h 8m 57.7s\n",
      "\n",
      "Epoch 107: val_NMSE did not improve from 0.03687\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0378 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0372\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0379 - tot_time: 0h 9m 2.5s\n",
      "\n",
      "Epoch 108: val_NMSE improved from 0.03687 to 0.03681, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0044 - mse: 0.0042 - NMSE: 0.0379 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0375 - tot_time: 0h 9m 7.5s\n",
      "\n",
      "Epoch 109: val_NMSE did not improve from 0.03681\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0375 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0371\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - tot_time: 0h 9m 12.4s\n",
      "\n",
      "Epoch 110: val_NMSE improved from 0.03681 to 0.03669, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0367\n",
      "Epoch 111/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - tot_time: 0h 9m 17.2s\n",
      "\n",
      "Epoch 111: val_NMSE did not improve from 0.03669\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0369\n",
      "Epoch 112/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - tot_time: 0h 9m 22.1s\n",
      "\n",
      "Epoch 112: val_NMSE did not improve from 0.03669\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0376 - val_loss: 0.0043 - val_mse: 0.0041 - val_NMSE: 0.0371\n",
      "Epoch 113/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0375 - tot_time: 0h 9m 27.0s\n",
      "\n",
      "Epoch 113: val_NMSE improved from 0.03669 to 0.03628, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0042 - NMSE: 0.0374 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0363\n",
      "Epoch 114/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0373 - tot_time: 0h 9m 31.9s\n",
      "\n",
      "Epoch 114: val_NMSE did not improve from 0.03628\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0373 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0367\n",
      "Epoch 115/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0373 - tot_time: 0h 9m 36.8s\n",
      "\n",
      "Epoch 115: val_NMSE did not improve from 0.03628\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0373 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0365\n",
      "Epoch 116/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - tot_time: 0h 9m 41.7s\n",
      "\n",
      "Epoch 116: val_NMSE improved from 0.03628 to 0.03609, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0361\n",
      "Epoch 117/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - tot_time: 0h 9m 46.6s\n",
      "\n",
      "Epoch 117: val_NMSE did not improve from 0.03609\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0361\n",
      "Epoch 118/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0372 - tot_time: 0h 9m 51.4s\n",
      "\n",
      "Epoch 118: val_NMSE improved from 0.03609 to 0.03585, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0372 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0359\n",
      "Epoch 119/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - tot_time: 0h 9m 56.2s\n",
      "\n",
      "Epoch 119: val_NMSE did not improve from 0.03585\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0371 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0365\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0370 - tot_time: 0h 10m 0.9s\n",
      "\n",
      "Epoch 120: val_NMSE did not improve from 0.03585\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0370 - val_loss: 0.0042 - val_mse: 0.0041 - val_NMSE: 0.0365\n",
      "Epoch 121/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0369 - tot_time: 0h 10m 5.7s\n",
      "\n",
      "Epoch 121: val_NMSE did not improve from 0.03585\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0369 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0364\n",
      "Epoch 122/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - tot_time: 0h 10m 10.4s\n",
      "\n",
      "Epoch 122: val_NMSE did not improve from 0.03585\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0369 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0360\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - tot_time: 0h 10m 15.2s\n",
      "\n",
      "Epoch 123: val_NMSE did not improve from 0.03585\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0362\n",
      "Epoch 124/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - tot_time: 0h 10m 20.0s\n",
      "\n",
      "Epoch 124: val_NMSE improved from 0.03585 to 0.03565, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0357\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - tot_time: 0h 10m 24.8s\n",
      "\n",
      "Epoch 125: val_NMSE did not improve from 0.03565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0360\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - tot_time: 0h 10m 29.7s\n",
      "\n",
      "Epoch 126: val_NMSE did not improve from 0.03565\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0361\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - tot_time: 0h 10m 34.6s\n",
      "\n",
      "Epoch 127: val_NMSE did not improve from 0.03565\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0368 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0361\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - tot_time: 0h 10m 39.5s\n",
      "\n",
      "Epoch 128: val_NMSE did not improve from 0.03565\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0361\n",
      "Epoch 129/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - tot_time: 0h 10m 44.4s\n",
      "\n",
      "Epoch 129: val_NMSE did not improve from 0.03565\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0358\n",
      "Epoch 130/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - tot_time: 0h 10m 49.4s\n",
      "\n",
      "Epoch 130: val_NMSE improved from 0.03565 to 0.03542, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 131/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - tot_time: 0h 10m 54.3s\n",
      "\n",
      "Epoch 131: val_NMSE did not improve from 0.03542\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0365 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0362\n",
      "Epoch 132/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - tot_time: 0h 10m 59.1s\n",
      "\n",
      "Epoch 132: val_NMSE did not improve from 0.03542\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0041 - NMSE: 0.0366 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0355\n",
      "Epoch 133/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0363 - tot_time: 0h 11m 4.0s\n",
      "\n",
      "Epoch 133: val_NMSE did not improve from 0.03542\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0364 - val_loss: 0.0042 - val_mse: 0.0040 - val_NMSE: 0.0362\n",
      "Epoch 134/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0364 - tot_time: 0h 11m 8.9s\n",
      "\n",
      "Epoch 134: val_NMSE did not improve from 0.03542\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0364 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0357\n",
      "Epoch 135/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0362 - tot_time: 0h 11m 13.7s\n",
      "\n",
      "Epoch 135: val_NMSE did not improve from 0.03542\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0362 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0358\n",
      "Epoch 136/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0362 - tot_time: 0h 11m 18.6s\n",
      "\n",
      "Epoch 136: val_NMSE improved from 0.03542 to 0.03530, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0361 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0353\n",
      "Epoch 137/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0363 - tot_time: 0h 11m 23.5s\n",
      "\n",
      "Epoch 137: val_NMSE did not improve from 0.03530\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0363 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 138/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0363 - tot_time: 0h 11m 28.3s\n",
      "\n",
      "Epoch 138: val_NMSE did not improve from 0.03530\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0363 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0359\n",
      "Epoch 139/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0362 - tot_time: 0h 11m 33.3s\n",
      "\n",
      "Epoch 139: val_NMSE improved from 0.03530 to 0.03524, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0362 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0352\n",
      "Epoch 140/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0361 - tot_time: 0h 11m 38.2s\n",
      "\n",
      "Epoch 140: val_NMSE did not improve from 0.03524\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 141/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - tot_time: 0h 11m 43.1s\n",
      "\n",
      "Epoch 141: val_NMSE improved from 0.03524 to 0.03514, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - tot_time: 0h 11m 48.1s\n",
      "\n",
      "Epoch 142: val_NMSE did not improve from 0.03514\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0361 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0357\n",
      "Epoch 143/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0361 - tot_time: 0h 11m 53.0s\n",
      "\n",
      "Epoch 143: val_NMSE improved from 0.03514 to 0.03514, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0351\n",
      "Epoch 144/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0359 - tot_time: 0h 11m 58.0s\n",
      "\n",
      "Epoch 144: val_NMSE improved from 0.03514 to 0.03511, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0359 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0351\n",
      "Epoch 145/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - tot_time: 0h 12m 2.9s\n",
      "\n",
      "Epoch 145: val_NMSE improved from 0.03511 to 0.03500, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0360 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0350\n",
      "Epoch 146/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - tot_time: 0h 12m 7.9s\n",
      "\n",
      "Epoch 146: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 147/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0040 - NMSE: 0.0359 - tot_time: 0h 12m 12.8s\n",
      "\n",
      "Epoch 147: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0359 - val_loss: 0.0041 - val_mse: 0.0040 - val_NMSE: 0.0357\n",
      "Epoch 148/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0359 - tot_time: 0h 12m 17.6s\n",
      "\n",
      "Epoch 148: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0359 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0353\n",
      "Epoch 149/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - tot_time: 0h 12m 22.5s\n",
      "\n",
      "Epoch 149: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - tot_time: 0h 12m 27.4s\n",
      "\n",
      "Epoch 150: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 151/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0357 - tot_time: 0h 12m 32.3s\n",
      "\n",
      "Epoch 151: val_NMSE did not improve from 0.03500\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0357 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - tot_time: 0h 12m 37.2s\n",
      "\n",
      "Epoch 152: val_NMSE improved from 0.03500 to 0.03485, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0358 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0349\n",
      "Epoch 153/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - tot_time: 0h 12m 42.1s\n",
      "\n",
      "Epoch 153: val_NMSE did not improve from 0.03485\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 154/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - tot_time: 0h 12m 47.0s\n",
      "\n",
      "Epoch 154: val_NMSE did not improve from 0.03485\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0352\n",
      "Epoch 155/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0357 - tot_time: 0h 12m 51.8s\n",
      "\n",
      "Epoch 155: val_NMSE did not improve from 0.03485\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0357 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0349\n",
      "Epoch 156/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 12m 56.7s\n",
      "\n",
      "Epoch 156: val_NMSE did not improve from 0.03485\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0353\n",
      "Epoch 157/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 13m 1.6s\n",
      "\n",
      "Epoch 157: val_NMSE improved from 0.03485 to 0.03477, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n",
      "Epoch 158/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 13m 6.4s\n",
      "\n",
      "Epoch 158: val_NMSE did not improve from 0.03477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 13m 11.4s\n",
      "\n",
      "Epoch 159: val_NMSE did not improve from 0.03477\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0350\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - tot_time: 0h 13m 16.3s\n",
      "\n",
      "Epoch 160: val_NMSE did not improve from 0.03477\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0040 - NMSE: 0.0356 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0351\n",
      "Epoch 161/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - tot_time: 0h 13m 21.2s\n",
      "\n",
      "Epoch 161: val_NMSE did not improve from 0.03477\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0349\n",
      "Epoch 162/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 13m 26.1s\n",
      "\n",
      "Epoch 162: val_NMSE improved from 0.03477 to 0.03467, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0347\n",
      "Epoch 163/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - tot_time: 0h 13m 31.0s\n",
      "\n",
      "Epoch 163: val_NMSE did not improve from 0.03467\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n",
      "Epoch 164/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - tot_time: 0h 13m 35.9s\n",
      "\n",
      "Epoch 164: val_NMSE did not improve from 0.03467\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0352\n",
      "Epoch 165/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - tot_time: 0h 13m 40.7s\n",
      "\n",
      "Epoch 165: val_NMSE improved from 0.03467 to 0.03462, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0355 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0346\n",
      "Epoch 166/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - tot_time: 0h 13m 45.6s\n",
      "\n",
      "Epoch 166: val_NMSE did not improve from 0.03462\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n",
      "Epoch 167/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - tot_time: 0h 13m 50.4s\n",
      "\n",
      "Epoch 167: val_NMSE improved from 0.03462 to 0.03461, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0354 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0346\n",
      "Epoch 168/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - tot_time: 0h 13m 55.4s\n",
      "\n",
      "Epoch 168: val_NMSE improved from 0.03461 to 0.03443, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0344\n",
      "Epoch 169/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - tot_time: 0h 14m 0.3s\n",
      "\n",
      "Epoch 169: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0344\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - tot_time: 0h 14m 5.2s\n",
      "\n",
      "Epoch 170: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n",
      "Epoch 171/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - tot_time: 0h 14m 10.0s\n",
      "\n",
      "Epoch 171: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0346\n",
      "Epoch 172/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - tot_time: 0h 14m 14.8s\n",
      "\n",
      "Epoch 172: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0353 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0349\n",
      "Epoch 173/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - tot_time: 0h 14m 19.7s\n",
      "\n",
      "Epoch 173: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0345\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - tot_time: 0h 14m 24.5s\n",
      "\n",
      "Epoch 174: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 14m 29.5s\n",
      "\n",
      "Epoch 175: val_NMSE did not improve from 0.03443\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0345\n",
      "Epoch 176/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 14m 34.4s\n",
      "\n",
      "Epoch 176: val_NMSE improved from 0.03443 to 0.03433, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0343\n",
      "Epoch 177/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 14m 39.4s\n",
      "\n",
      "Epoch 177: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0344\n",
      "Epoch 178/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 14m 44.3s\n",
      "\n",
      "Epoch 178: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0352 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0343\n",
      "Epoch 179/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 14m 49.2s\n",
      "\n",
      "Epoch 179: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0352\n",
      "Epoch 180/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0350 - tot_time: 0h 14m 54.0s\n",
      "\n",
      "Epoch 180: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0350 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0345\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0350 - tot_time: 0h 14m 58.9s\n",
      "\n",
      "Epoch 181: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0350 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0350\n",
      "Epoch 182/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - tot_time: 0h 15m 3.8s\n",
      "\n",
      "Epoch 182: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0351 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0348\n",
      "Epoch 183/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0350 - tot_time: 0h 15m 8.7s\n",
      "\n",
      "Epoch 183: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0350 - val_loss: 0.0041 - val_mse: 0.0039 - val_NMSE: 0.0354\n",
      "Epoch 184/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - tot_time: 0h 15m 13.6s\n",
      "\n",
      "Epoch 184: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - val_loss: 0.0040 - val_mse: 0.0039 - val_NMSE: 0.0347\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - tot_time: 0h 15m 18.5s\n",
      "\n",
      "Epoch 185: val_NMSE did not improve from 0.03433\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0346\n",
      "Epoch 186/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - tot_time: 0h 15m 23.4s\n",
      "\n",
      "Epoch 186: val_NMSE improved from 0.03433 to 0.03408, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0341\n",
      "Epoch 187/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 15m 28.5s\n",
      "\n",
      "Epoch 187: val_NMSE did not improve from 0.03408\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0345\n",
      "Epoch 188/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - tot_time: 0h 15m 33.3s\n",
      "\n",
      "Epoch 188: val_NMSE did not improve from 0.03408\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0342\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 15m 38.1s\n",
      "\n",
      "Epoch 189: val_NMSE did not improve from 0.03408\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0343\n",
      "Epoch 190/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0349 - tot_time: 0h 15m 43.0s\n",
      "\n",
      "Epoch 190: val_NMSE did not improve from 0.03408\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0041 - mse: 0.0039 - NMSE: 0.0350 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0343\n",
      "Epoch 191/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 15m 47.8s\n",
      "\n",
      "Epoch 191: val_NMSE did not improve from 0.03408\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0342\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 15m 52.6s\n",
      "\n",
      "Epoch 192: val_NMSE improved from 0.03408 to 0.03401, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0039 - val_mse: 0.0038 - val_NMSE: 0.0340\n",
      "Epoch 193/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0347 - tot_time: 0h 15m 57.6s\n",
      "\n",
      "Epoch 193: val_NMSE did not improve from 0.03401\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0347 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0344\n",
      "Epoch 194/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0347 - tot_time: 0h 16m 2.4s\n",
      "\n",
      "Epoch 194: val_NMSE did not improve from 0.03401\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0343\n",
      "Epoch 195/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 16m 7.4s\n",
      "\n",
      "Epoch 195: val_NMSE did not improve from 0.03401\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0344\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 16m 12.3s\n",
      "\n",
      "Epoch 196: val_NMSE improved from 0.03401 to 0.03398, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0039 - val_mse: 0.0038 - val_NMSE: 0.0340\n",
      "Epoch 197/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 16m 17.3s\n",
      "\n",
      "Epoch 197: val_NMSE did not improve from 0.03398\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0346\n",
      "Epoch 198/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0348 - tot_time: 0h 16m 22.2s\n",
      "\n",
      "Epoch 198: val_NMSE did not improve from 0.03398\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0039 - NMSE: 0.0347 - val_loss: 0.0040 - val_mse: 0.0038 - val_NMSE: 0.0342\n",
      "Epoch 199/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0038 - NMSE: 0.0346 - tot_time: 0h 16m 27.2s\n",
      "\n",
      "Epoch 199: val_NMSE improved from 0.03398 to 0.03388, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0038 - NMSE: 0.0346 - val_loss: 0.0039 - val_mse: 0.0038 - val_NMSE: 0.0339\n",
      "Epoch 200/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0040 - mse: 0.0038 - NMSE: 0.0346 - tot_time: 0h 16m 32.1s\n",
      "\n",
      "Epoch 200: val_NMSE improved from 0.03388 to 0.03387, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - mse: 0.0038 - NMSE: 0.0346 - val_loss: 0.0039 - val_mse: 0.0038 - val_NMSE: 0.0339\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0331 - tot_time: 0h 17m 30.0s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.03387 to 0.03252, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0331 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 2/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 17m 34.9s\n",
      "\n",
      "Epoch 2: val_NMSE did not improve from 0.03252\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0326\n",
      "Epoch 3/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0330 - tot_time: 0h 17m 39.8s\n",
      "\n",
      "Epoch 3: val_NMSE did not improve from 0.03252\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0330 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 4/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0331 - tot_time: 0h 17m 44.7s\n",
      "\n",
      "Epoch 4: val_NMSE did not improve from 0.03252\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0331 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 5/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 17m 49.5s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.03252 to 0.03251, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 6/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0330 - tot_time: 0h 17m 54.3s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.03251\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 7/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0330 - tot_time: 0h 17m 59.2s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.03251 to 0.03247, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 4.0s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.03247\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 9/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 8.9s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.03247 to 0.03246, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 10/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 13.9s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.03246\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 11/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 18.8s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.03246\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 23.7s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.03246\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 18m 28.6s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.03246 to 0.03246, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 33.5s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.03246 to 0.03241, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 15/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0330 - tot_time: 0h 18m 38.6s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.03241\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 16/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 18m 43.5s\n",
      "\n",
      "Epoch 16: val_NMSE improved from 0.03241 to 0.03238, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 17/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 48.7s\n",
      "\n",
      "Epoch 17: val_NMSE did not improve from 0.03238\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 18/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 18m 53.6s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.03238 to 0.03238, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 19/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 18m 58.6s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.03238\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 3.5s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.03238\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 21/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 8.4s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.03238\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 22/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - tot_time: 0h 19m 13.3s\n",
      "\n",
      "Epoch 22: val_NMSE did not improve from 0.03238\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 18.3s\n",
      "\n",
      "Epoch 23: val_NMSE improved from 0.03238 to 0.03235, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 23.3s\n",
      "\n",
      "Epoch 24: val_NMSE did not improve from 0.03235\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0037 - NMSE: 0.0329 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 28.3s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.03235\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 26/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 19m 33.2s\n",
      "\n",
      "Epoch 26: val_NMSE did not improve from 0.03235\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 27/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 19m 38.1s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.03235 to 0.03232, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 28/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 43.1s\n",
      "\n",
      "Epoch 28: val_NMSE did not improve from 0.03232\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 29/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 48.1s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.03232\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 30/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 19m 53.0s\n",
      "\n",
      "Epoch 30: val_NMSE did not improve from 0.03232\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 31/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 19m 57.9s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.03232\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0325\n",
      "Epoch 32/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 20m 2.8s\n",
      "\n",
      "Epoch 32: val_NMSE improved from 0.03232 to 0.03231, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 33/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 7.8s\n",
      "\n",
      "Epoch 33: val_NMSE improved from 0.03231 to 0.03226, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 34/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 20m 12.7s\n",
      "\n",
      "Epoch 34: val_NMSE did not improve from 0.03226\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 35/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 20m 17.7s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.03226\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 36/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 20m 22.6s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.03226\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 37/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 27.5s\n",
      "\n",
      "Epoch 37: val_NMSE improved from 0.03226 to 0.03226, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 38/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 32.5s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.03226\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 39/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 37.3s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.03226\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 40/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 42.2s\n",
      "\n",
      "Epoch 40: val_NMSE improved from 0.03226 to 0.03224, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 47.3s\n",
      "\n",
      "Epoch 41: val_NMSE improved from 0.03224 to 0.03224, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 42/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 52.2s\n",
      "\n",
      "Epoch 42: val_NMSE did not improve from 0.03224\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 43/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 20m 57.1s\n",
      "\n",
      "Epoch 43: val_NMSE did not improve from 0.03224\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 44/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - tot_time: 0h 21m 2.0s\n",
      "\n",
      "Epoch 44: val_NMSE improved from 0.03224 to 0.03222, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 45/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 21m 7.0s\n",
      "\n",
      "Epoch 45: val_NMSE improved from 0.03222 to 0.03219, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 46/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 21m 12.1s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 21m 17.0s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 48/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - tot_time: 0h 21m 21.8s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 49/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - tot_time: 0h 21m 26.8s\n",
      "\n",
      "Epoch 49: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 21m 31.8s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0038 - val_mse: 0.0036 - val_NMSE: 0.0324\n",
      "Epoch 51/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - tot_time: 0h 21m 36.6s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0323\n",
      "Epoch 52/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - tot_time: 0h 21m 41.4s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 53/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - tot_time: 0h 21m 46.1s\n",
      "\n",
      "Epoch 53: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 54/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328 - tot_time: 0h 21m 50.9s\n",
      "\n",
      "Epoch 54: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0327 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 55/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326Restoring model weights from the end of the best epoch: 45.\n",
      " - tot_time: 0h 21m 55.7s\n",
      "\n",
      "Epoch 55: val_NMSE did not improve from 0.03219\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0326 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0322\n",
      "Epoch 55: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 1.7s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.03219 to 0.03206, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0037 - mse: 0.0036 - NMSE: 0.0323 - tot_time: 0h 22m 6.7s\n",
      "\n",
      "Epoch 2: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 3/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 11.5s\n",
      "\n",
      "Epoch 3: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 4/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0325 - tot_time: 0h 22m 16.5s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.03206 to 0.03206, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0325 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 21.4s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 6/200\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 26.1s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 30.9s\n",
      "\n",
      "Epoch 7: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 35.6s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 9/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 40.3s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 10/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 45.0s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0325 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 11/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 49.8s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 12/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 54.6s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 13/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - tot_time: 0h 22m 59.6s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 14/200\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0325Restoring model weights from the end of the best epoch: 4.\n",
      " - tot_time: 0h 23m 4.6s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.03206\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_000/checkpoints/LossHistoriesCheckpoint\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0324 - val_loss: 0.0037 - val_mse: 0.0036 - val_NMSE: 0.0321\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compiling the network\n",
    "ae_net.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_list[0]),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "#     loss=losses.BinaryCrossentropy(from_logits=False),\n",
    "    run_eagerly=False,\n",
    "    metrics=['mse', NMSE_metric]\n",
    ")\n",
    "\n",
    "if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # this loads the weights/attributes of the optimizer as well\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net.load_weights(wt_file)\n",
    "    else:\n",
    "        ae_net.load_weights(wt_file)\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # implementing early stopping\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_NMSE',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=True,\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "\n",
    "    # time callback for each epoch\n",
    "    timekeeper_cb = mytimecallback()\n",
    "\n",
    "    # model checkpoint callback\n",
    "    dir_name_ckpt = dir_name_ae+dir_sep+'checkpoints'\n",
    "    if not os.path.isdir(dir_name_ckpt):\n",
    "        os.makedirs(dir_name_ckpt)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=dir_name_ckpt+dir_sep+'checkpoint',#+'/checkpoint--loss={loss:.4f}--vall_loss={val_loss:.4f}',\n",
    "        monitor='val_NMSE',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=2,\n",
    "        period=1  # saves every 5 epochs\n",
    "    )\n",
    "\n",
    "    # save losses callback\n",
    "    savelosses_cb = SaveLosses(\n",
    "        filepath=dir_name_ckpt+dir_sep+'LossHistoriesCheckpoint',\n",
    "        val_loss_arr=savelosses_cb_vallossarr,\n",
    "        train_loss_arr=savelosses_cb_trainlossarr,\n",
    "        total_epochs=epochs,\n",
    "        period=1)\n",
    "\n",
    "    # training the network\n",
    "    for i in range(starting_lr_idx, len(learning_rate_list)):\n",
    "        learning_rate = learning_rate_list[i]\n",
    "        K.set_value(ae_net.optimizer.lr, learning_rate)\n",
    "\n",
    "        savelosses_cb.update_lr_idx(i)\n",
    "\n",
    "        if i == starting_lr_idx:\n",
    "            EPOCHS = num_epochs_left\n",
    "            savelosses_cb.update_offset(epochs-num_epochs_left)\n",
    "        else:\n",
    "            EPOCHS = epochs\n",
    "            savelosses_cb.update_offset(0)\n",
    "\n",
    "        total_s_len = 80\n",
    "        sep_lr_s = ' LEARNING RATE : {} '.format(learning_rate)\n",
    "        sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'-' + sep_lr_s\n",
    "        sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'-'\n",
    "        print('\\n\\n' + '-'*len(sep_lr_s))\n",
    "        print('\\n' + sep_lr_s+'\\n')\n",
    "        print('-'*len(sep_lr_s) + '\\n\\n')\n",
    "        \n",
    "        history = ae_net.fit(training_data, training_data,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=batch_size,\n",
    "#             validation_split=val_split/train_split,\n",
    "            validation_data=(val_data, val_data),\n",
    "            callbacks=[early_stopping_cb, timekeeper_cb, checkpoint_cb, savelosses_cb],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss_hist.extend(history.history['val_loss'])\n",
    "        train_loss_hist.extend(history.history['loss'])\n",
    "        \n",
    "        val_MSE_hist.extend(history.history['val_mse'])\n",
    "        train_MSE_hist.extend(history.history['mse'])\n",
    "        \n",
    "        val_NMSE_hist.extend(history.history['val_NMSE'])\n",
    "        train_NMSE_hist.extend(history.history['NMSE'])\n",
    "        \n",
    "        if i == starting_lr_idx:\n",
    "            lr_change[i+1] += len(history.history['val_loss'])\n",
    "        else:\n",
    "            lr_change.append(lr_change[i]+len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2, 50, 50)]       0         \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 2, 50, 50)        0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 25, 25)         144       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 25, 25)        32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 8, 25, 25)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 13, 13)        1152      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 13, 13)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 13, 13)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 7, 7)          4608      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 7, 7)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 7, 7)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 4, 4)          9216      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 4, 4)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 4, 4)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 4, 4)           576       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 4, 4)          8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2, 4, 4)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,056\n",
      "Trainable params: 15,876\n",
      "Non-trainable params: 180\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_net.encoder_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2, 4, 4)]         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 6, 6)         576       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " cropping2d (Cropping2D)     (None, 32, 4, 4)          0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 4, 4)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32, 4, 4)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 9, 9)         9216      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_1 (Cropping2D)   (None, 32, 7, 7)          0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 7, 7)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 7, 7)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 15, 15)       4608      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_2 (Cropping2D)   (None, 16, 13, 13)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 13, 13)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 13, 13)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 8, 27, 27)        1152      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_3 (Cropping2D)   (None, 8, 25, 25)         0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 25, 25)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 8, 25, 25)         0         \n",
      "                                                                 \n",
      " periodic_padding (periodic_  (None, 8, 27, 27)        1350      \n",
      " padding)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 2, 55, 55)        144       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_4 (Cropping2D)   (None, 2, 50, 50)         0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 2, 50, 50)        8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 2, 50, 50)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,406\n",
      "Trainable params: 15,876\n",
      "Non-trainable params: 1,530\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_net.decoder_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 2, 50, 50)]       0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 2, 4, 4)           16056     \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 2, 50, 50)         17406     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,462\n",
      "Trainable params: 31,752\n",
      "Non-trainable params: 1,710\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_net.ae_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9705,
     "status": "ok",
     "timestamp": 1666788875924,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "d_Od0ul4P9bK",
    "outputId": "860e9f94-e593-4a74-fcff-6a6657d925de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0038 - NMSE: 0.0344\n",
      "625/625 [==============================] - 4s 5ms/step - loss: 0.0039 - mse: 0.0037 - NMSE: 0.0333\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0036 - NMSE: 0.0328\n"
     ]
    }
   ],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    test_metrics = ae_net.evaluate(\n",
    "        testing_data, testing_data,\n",
    "    )\n",
    "    train_metrics = ae_net.evaluate(training_data, training_data)\n",
    "    val_metrics = ae_net.evaluate(val_data, val_data)\n",
    "\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "\n",
    "    with open(save_path+dir_sep+'losses.txt', 'w') as f:\n",
    "        f.write(str({\n",
    "            'val_loss_hist':val_loss_hist,\n",
    "            'train_loss_hist':train_loss_hist,\n",
    "            'val_MSE_hist':val_MSE_hist,\n",
    "            'train_MSE_hist':train_MSE_hist,\n",
    "            'val_NMSE_hist':val_NMSE_hist,\n",
    "            'train_NMSE_hist':train_NMSE_hist,\n",
    "            'lr_change':lr_change,\n",
    "            'test_loss':test_metrics[0],\n",
    "            'test_mse':test_metrics[1],\n",
    "            'train_loss':train_metrics[0],\n",
    "            'train_mse':train_metrics[1],\n",
    "            'val_loss':val_metrics[0],\n",
    "            'val_mse':val_metrics[1],\n",
    "        }))\n",
    "\n",
    "    ae_net.save_everything(\n",
    "        file_name=save_path+dir_sep+'final_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788875925,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Dy8GNcgMVD4T",
    "outputId": "e50e8738-9da1-43de-e551-43f47b64135e"
   },
   "outputs": [],
   "source": [
    "print('lr_change : ', lr_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1666788876686,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ewTz1COFSocM",
    "outputId": "15bc2be5-d571-433e-b5cd-9c722f38b48b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGxCAYAAACOSdkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0OElEQVR4nO3dd3wUdf7H8ddsyaYHQoAQepEmvR4cKBaqYj0LNhDUQxAP4c7ys2H3zhM8EbuAFRHb2U5ABQERRZogiCAICAQIYHrZMr8/hiSEhJDAZnezeT8fj32QnZmd/cyXzXc/+c63GKZpmoiIiIjUQLZgByAiIiISLEqEREREpMZSIiQiIiI1lhIhERERqbGUCImIiEiNpURIREREaiwlQiIiIlJjKRESERGRGssR7ABCmc/nY8+ePcTFxWEYRrDDERERkQowTZPMzExSUlKw2cpv81EiVI49e/bQuHHjYIchIiIiJ2HXrl00atSo3GOUCJUjLi4OsAoyPj7eL+fMPZTLD81/oMf2HkQlRvnlnDWZ2+1mwYIFDBo0CKfTGexwwoLK1L9Unv6lOtS/TvT59GR4+Lbxt/TZ1QdHfPVJGTIyMmjcuHHR93h5qs9VnYKLL76YxYsXc8455/Duu+9W+HWFt8Pi4+P9lgg53U5iiCE+Lp6oeP0Snyq32010dDTx8fH6kvETlal/qTz9S3Wof53o8+nBY5V3fHy1SoQKVaRbS43oLH3rrbfy2muvBTsMERERCTE1IhE666yzKtQ8JiIiIjVL0BOhJUuWMHz4cFJSUjAMgw8//LDUMc8++yzNmzcnMjKS7t27s3Tp0sAH6ie2SBs543OwRQa96EVEqh3VoYFli7TR+qXWYV3eQb/hl52dTefOnbn++uu59NJLS+2fO3cuEydO5Nlnn+XPf/4zL7zwAkOHDmXjxo00adIEgO7du5Ofn1/qtQsWLCAlJaXKr6EybBE23APd2CLC90Mlwef1enG73Sf1WrfbjcPhIC8vD6/X6+fIap5wKU+n04ndbg92GKpDA8wWYSPlhtD6HvW3oCdCQ4cOZejQocfdP3XqVMaMGcMNN9wAwFNPPcX8+fN57rnneOyxxwBYtWqVX2LJz88vkVBlZGQAVkV2sl8qx8o7nEfshFjy+uRBbb+cskYr/H/x1/9PdWeaJvv37y/67J7sOZKTk9m5c6fmz/KDcCrP+Ph46tWrF9TrUB3qXyeqQ71ZXtb9eR2dv+mMPTb4iXBFVeY7IeiJUHkKCgpYtWoVd955Z4ntgwYNYvny5X5/v8cee4wHHnig1PYFCxYQHR3tnzfxgmO0g6+WfQXV5zMV8hYuXBjsEEJCXFwctWvXJikpiYiIiGr/xSuhwTRNCgoKOHDgAL/88guZmZnBC0Z1aJU4bh3qBcflDuYvml+tyjsnJ6fCx4Z0IpSWlobX66V+/folttevX5/U1NQKn2fw4MGsXr2a7OxsGjVqxAcffEDPnj1LHXfXXXcxadKkoueF8xAMGjTIb8Pn3W43C+0LGThwoIbS+oHb7WbhQpUnWLfDtm3bRt26dalTp85Jn6dwRlbNqO4f4VSekZGRuFwu+vbtG7TbZKpD/atCdejwwMbkD5VpFQ/pRKjQsZWHaZqVqlDmz59foeNcLhcul6vUdqfT6bdfOE+Gh/gR8Ri7DJzR+iX2F3/+H1VXXq8XwzCIjY094ZTy5fH5fID1e3cq5xFLOJVnbGwsaWlpAEH7fVMdWjWOV4d6Mjx82+hb+vxevSZUrMznM6R/K5OSkrDb7aVaf/bv31+qlag6MXKr91+FEtqqe6uDhK5Q+WypDg0sb2b17eRfESGdCEVERNC9e/dS9y4XLlxI3759gxSViIiIhIugJ0JZWVmsXbuWtWvXArB9+3bWrl3Lzp07AZg0aRIvv/wyM2fOZNOmTdx2223s3LmTsWPHBjFqEQl1AwYMYOLEiRU+/rfffsMwjKK6SERqhqAnQj/88ANdu3ala9eugJX4dO3alfvuuw+AK664gqeeeooHH3yQLl26sGTJEj777DOaNm0azLBFxE8Mwyj3MWrUqJM67/vvv89DDz1U4eMbN27M3r176dChw0m9X0UVJlwOh4Pdu3eX2Ld3714cDgeGYfDbb78VbX/vvffo3bs3CQkJxMXFcfrppzN58uSi/bNnzy6z7CIjI6v0WkTCQdB7Pg0YMADTNMs9Zty4cYwbNy5AEYlIIO3du7fo57lz53LfffexefPmom1RUSUX1nS73RXqCJmYmFipOOx2O8nJyZV6zalISUnhtdde46677ira9uqrr9KwYcOiFnGAL774giuvvJJHH32UCy64AMMw2LhxI19++WWJ88XHx5coNwidPj0ioSzoLUI11qFDsH8/HBlRIlJTJScnFz0SEhIwDKPoeV5eHrVq1eKdd95hwIABREZG8sYbb3Dw4EFGjBhBo0aNiI6OpmPHjsyZM6fEeY+9NdasWTMeffRRRo8eTVxcHE2aNOHFF18s2n/srbHFixdjGAZffvklPXr0IDo6mr59+5ZKNh5++GHq1atHXFwcN9xwA3feeSddunQ54XWPHDmSWbNmldg2e/ZsRo4cWWLbJ598Qr9+/fjHP/5BmzZtaN26NRdddBHTp08vcdzR5Vb4qM6DSkQCRYlQgNlj7GRN+4PI1k2gfn1ITw92SFITZGcf/5GXV/Fjc3NPfGwVuOOOO7j11lvZtGkTgwcPJi8vj+7du/PJJ5+wYcMGbrrpJq699lq+++67cs/z5JNP0qNHD9asWcO4ceO4+eab+fnnn8t9zd13382TTz7JDz/8gMPhYPTo0UX73nzzTR555BH++c9/smrVKpo0acJzzz1XoWu64IILOHz4MMuWLQNg2bJlHDp0iOHDS07akpyczE8//cSGDRsqdN5wZ4+xk/l0JvaYajS7XzVmj7HTc0PPsC5vJUJlmDFjBu3bty9z0sVTZgNvkg840hKkFiEJhNjY4z+OWePPSE6mVqNG2OLjSx977HI4zZqVPqYKTJw4kUsuuYTmzZuTkpJCw4YN+fvf/06XLl1o0aIFEyZMYPDgwcybN6/c8wwbNoxx48bRqlUr7rjjDpKSkli8eHG5r3nkkUc488wzad++PXfeeSfLly8n70jyOH36dMaMGcP1119P69atue++++jYsWOFrsnpdHLNNdcwc+ZMAGbOnMk111xT6rbfhAkT6NmzJx07dqRZs2ZceeWVzJw5s9T6iunp6cTGxpZ4DBo0qEKxVCs28CX59O0VKDZwNXaFdXmH8aWdvPHjx7Nx40ZWrlzp93N7M70kXJuIlyNLdlTjRRhFAqVHjx4lnnu9Xh555BE6depEnTp1iI2NZcGCBSX61pSlU6dORT8X3krav39/hV/ToEEDgKLXbN68mV69epU4/tjn5RkzZgzz5s0jNTWVefPmlWhtKhQTE8Onn37K1q1bueeee4iNjWXy5Mn06tWrxDICcXFxRSNwCx/H3noLB95MLwlXJYT93DahwpvpZVnCsrAu76B3lq5p7HF20t9Kx3Z1HpgoEZLAyMo6/r5jlkowU1NJz8ggPj6+9EzIxz4/amRTVYqJiSnx/Mknn2TatGk89dRTdOzYkZiYGCZOnEhBQUG55zm2tcUwjKKZnyvymsLOx0e/pqyZ7yuqQ4cOtG3blhEjRtCuXTs6dOhw3OH7LVu2pGXLltxwww3cfffdtG7dmrlz53L99dcDYLPZaNWqVYXfu7oqrEPtceF7qyaU2OPs9EvvF9blrRahQPOBLc0G9iOVqxIhCYSYmOM/jh1iXd6xx4zgKvOYAFi6dCkXXngh11xzDZ07d6ZFixZs2bIlIO99tDZt2vD999+X2PbDDz9U6hyjR49m8eLFZbYGHU+zZs2Ijo4mu4r6ZIW0wjpUvQoCwwf5u/LDurzVIhRg3mwvcbfG4Y2Ixka+EiGRk9CqVSvee+89li9fTu3atZk6dSqpqam0a9cuoHFMmDCBG2+8kR49etC3b1/mzp3Ljz/+SIsWLSp8jhtvvJHLLruMWrVqlbl/ypQp5OTkMGzYMJo2bcoff/zB008/jdvtZuDAgUXHmaZZ5mLU9erVq/ZrnB2tqA69yguaJqnKebO9rOywkn7p/arVWmOVEZ5XVR3Yj1RMSoREKu3ee+9l+/btDB48mOjoaG666SYuuugi0gM8CvPqq69m27Zt/P3vfycvL4/LL7+cUaNGlWolKo/D4SApKem4+88880xmzJjBddddx759+6hduzZdu3ZlwYIFtGnTpui4jIyMoj5MR9u7d29A50cSqW4MszI3tGuYjIwMEhISSE9PJz4+3i/nzD2Yy3dJ39H32rlE2HLhn/+0htHLSXG73Xz22WcMGzasxq8+n5eXx/bt22nevPkpzSjs8/nIOF4fITmhgQMHkpyczOuvvw6EV3n66zN2Kgrr0N5pvYmqE3XiF0i5TlSHejI8LEtYVu1ahCrz/V19rirMeKdNBf0Si1RrOTk5PP/88wwePBi73c6cOXP44osvSi0ULSKhS4mQiMhJMgyDzz77jIcffpj8/HzatGnDe++9x7nnnhvs0ESkgpQIBUt+AWT7rBE79vAdligSzqKiovjiiy+CHYaInILqfcO6mjKjTBzdulmz8GrafBGRSjGj1LU1kMJ5DiFQIhRwjngHGXMycDiOTI+vUWMiIhVWVIdWo4671Zkj3kH/jP5hXd5KhALM9Jg41jgwbZpQUUSksorqUI9ahQLB5/FxaP4hfJ7wnVFRiVAZqnLRVV+ej8iZkfhsR4aeKhESEamwojo0L3y/mEOJL8/H1klbw7q8lQiVoSoXXbXH2smanoXd6bE2KBESEamwojo0Nrz7rYQKR6yDXj/1whGrW2PiJ74CH86FTnyGbo2JiFRWUR1aEL4tFKHEV+Bjz8t7wrq8lQgFmC/PR/SMaHyGbo2J+NOAAQOYOHFi0fNmzZrx1FNPlfsawzD48MMPT/m9/XUeObGiOjSMb9WEEl+ej19u/CWsy1uJUJD4zjoL/vIXKGeNIZGaYPjw4cedgPDbb7/FMAxWr15d6fOuXLmSm2666VTDK2HKlCl06dKl1Pa9e/cydOhQv77XsWbPno1hGGUuLPvOO+9gGAbNmjUr2ub1ennsscdo27YtUVFRJCYm8qc//YlZs2YVHTNq1CgMwyj1GDJkSJVei0goCd+bfiHO98jDWmJDBBgzZgyXXHIJO3bsoGnTpiX2zZw5ky5dutCtW7dKn7du3br+CvGEArWoaUxMDPv37+fbb7+lT58+RdtnzpxJkyZNShw7ZcoUXnzxRZ555hl69OhBRkYGP/zwA4cPHy5x3JAhQ0okRwAul6vqLkIkxKhFSESC6vzzz6devXrMnj27xPacnBzmzp3LmDFjOHjwICNGjKBRo0ZER0fTsWNH5syZU+55j701tmXLFs444wwiIyNp3759meuB3XHHHbRu3Zro6GhatGjBvffei9vtBqwWmQceeIB169YVtZwUxnzsrbH169dz9tlnExUVRd26dZk4cSJZWVlF+0eNGsVFF13Ev//9bxo0aECdOnUYP3580Xsdj8Ph4KqrrmLmzJlF237//XcWL17MVVddVeLYjz/+mHHjxnHZZZfRvHlzOnfuzJgxY5g0aVKJ41wuF8nJySUetWvXLjcOkXCiRCiYTNN6iNRgDoeD6667jtmzZ2Me9fswb948CgoKuPrqq8nLy6N79+588sknbNiwgZtuuolrr72W7777rkLv4fP5uOSSS7Db7axYsYLnn3+eO+64o9RxcXFxzJ49m40bN/Kf//yHl156iWnTpgFwxRVXMHnyZE4//XT27t3L3r17ueKKK0qdIycnhyFDhlC7dm1WrlzJ3LlzWbx4MRMmTChx3KJFi/j1119ZtGgRr776KrNnzy6VDJZlzJgxzJ07l5ycHMBK0IYMGUL9+vVLHJecnMxXX33FgQMHKlRGIjWVEqEgsQ8ZCjYbfPxxsEORMGeakJER2Edl8/vRo0fz22+/sXjx4qJtM2fO5JJLLqF27do0bNiQv//973Tp0oUWLVowYcIEBg8ezLx58yp0/i+++IJNmzbx+uuv06VLF8444wweffTRUsfdc8899O3bl2bNmjF8+HAmT57MO++8A1jrisXGxuJwOIpaTqKiSt/efvPNN8nNzeW1116jQ4cOnH322fzrX//ijTfeYN++fUXH1a5dm2eeeYa2bdty/vnnc9555/Hll1+e8Fq6dOlCy5YteffddzFNk9mzZzN69OhSx02dOpUDBw6QnJxMp06dGDt2LP/73/9KHffJJ58QGxtb4vHQQw+dMA6RcKE+QgFm2A3cXdwYtiPfFBo1JlUsMxMSEirzChtQ65TeMz0d4uMrfnzbtm3p27cvM2fO5KyzzuLXX39l6dKlLFiwALA6/j7++OPMnTuX3bt3k5+fT35+PjExMRU6/6ZNm2jSpAmNGjUq2nZ0H5tC7777Lk899RRbt24lKysLj8dDfGUu5Mh7de7cuURsvXv3xufzsXnz5qKWm9NPPx37UQsuN2jQgPXr11foPUaPHs2sWbNo0qQJWVlZDBs2jGeeeabEMe3bt2fDhg2sWrWKZcuWsWTJEoYPH86oUaN4+eWXi44766yzeO6550q8NjExsVLXHEhFdajdCHYoNYJhN6g9qHZYl7cSoQCzx9jJmZKD/d9HhiIqEZIqFhdnJSYV5fP5yMjIID4+Hpvt5BqN4+Iq/5oxY8Zwyy23MGPGDGbNmkXTpk0555xzAHjyySeZNm0aTz31FB07diQmJoaJEydSUFBQoXObZTRRGUbJin3FihVceeWVPPDAAwwePJiEhATefvttnnzyyUpdh2mapc5d1ns6nc5S+3y+ig1Rvvrqq7n99tuZMmUK1113HQ5H2VW5zWajZ8+e9OzZk9tuu4033niDa6+9lrvvvpvmzZsDVgfsVq1aVeh9Q0FRHRqjCRUDwR5jp/P8zsEOo0opEQowX74P1xwXPiPCui+pREiqmGFUrnWm8Ls4Pt66exsol19+OX/729946623ePXVV7nxxhuLEoelS5dy4YUXcs011xyJ0ceWLVvKHEpelvbt27Nz50727NlDSkoKYA3NP9o333xD06ZNufvuu4u27dixo8QxEREReE/wO9u+fXteffVVsrOzi1qFvvvuO2w2G61bt65QvCeSmJjIBRdcwDvvvMPzzz9f4de1b98egOzsbL/EEQxFdeg5PnCe+Hg5Nb58Hzse20HTu5pic4Vnb5rwvKoQZvpMbAdtmLYjOagSIREAYmNjueKKK/i///s/9uzZw6hRo4r2tWrVioULF7J8+XI2bdrEX//6V1JTUyt87nPPPZc2bdpw3XXXsW7dOpYuXVoi4Sl8j507d/L222/z66+/8vTTT/PBBx+UOKZZs2Zs376dtWvXkpaWRn5+fqn3uvrqq4mMjGTkyJFs2LCBRYsWcccdd3DNNdeU6tB8KmbPnk1aWhpt27Ytc/9f/vIXpk2bxnfffceOHTtYvHgx48ePp3Xr1iVek5+fT2pqaolHWlqa3+L0t6I61KeBJoFg+kzyf88P6/JWIhRg9ig7ubfkYo9QHyGRY40ZM4bDhw9z7rnnlpgX595776Vbt24MHjyYAQMGkJyczEUXXVTh89psNj744APy8/Pp1asXN9xwA4888kiJYy688EJuu+02brnlFrp06cLy5cu59957Sxxz6aWXMmTIEM466yzq1q1b5hD+6Oho5s+fz6FDh+jZsyeXX345Z555JtOnT69cYZxAVFQUderUOe7+wYMH8/HHHzN8+HBat27NyJEjadu2LQsWLChxK+3zzz+nQYMGJR79+vXza6z+VFSHRunWWCDYo+y0fbltWJe3YZZ187yGmzFjBjNmzMDr9fLLL7+Qnp5e6Q6Tx5OXkceSS5dwljEd58JPYNYsOOovX6kct9vNZ599xrBhw0r1uahp8vLy2L59O82bNycyMvKkz+OPPkJSLJzK01+fsVOK4UgdesZ7ZxAZH5wYwsmJ6lBvrpctE7Zw2vTTqlUylJGRQUJCQoW+v6v3b2UVqcrV5023ScQXEfg6d4Nhw6BhQ7+/h4hIuCqsQ023/oYPBNNtkvpKaliXtzpLB4nvzju1xIaIiEiQqUVIREREaiwlQiIiIlJjKREKEvstEyAmBo6Z0VXkVGn8g1QVfbYkHCkRCpaCfMjJgTLmIRE5GYUjPgoX4xTxt8LPVk0foSnhRZ2lA8zmspF3RV5xBqp5hMRP7HY7tWrVYv/+/YA1n83xlnooj8/no6CggLy8vGo/3DsUhEN5mqZJTk4O+/fvp1atWiXWSAu0ojo0TGc5DjU2l42m94fvrNKgRCjgbC4b+SPysb135AtKiZD4UXJyMkBRMnQyTNMkNzeXqKiok0qkpKRwKs9atWoVfcaCpagODeMv5lBic9loPqV5sMOoUkqEAsyb7SV6SjTe011aa0z8zjAMGjRoQL169XC73Sd1DrfbzZIlSzjjjDN0C8QPwqU8nU5nUFuCChXVoWd6cdaqvuVZXXizvWy4ZAMd3u8QtgvdKhEKMMNp4P6zGyNbLUJSdex2+0l/adntdjweD5GRkdX6iztUqDz9q6gOdVbv1rXqwnAa1L2sbliXt9oWA8wWYcM90I1RWB8WLvUtIiInVFiH2iL09RUItggbKTekhHV5h++VhShvlpfYCbF4m7SBM86AoxaWFBGR8hXVoVlqTQ8ET5aH70//Hk+WJ9ihVBndGgsw02di32XHe/M4uGdysMMREalWCutQ06c5jQLCBzkbcyCMb16oRUhERERqLCVCZZgxYwbt27enZ8+ewQ5FREREqpASoTKMHz+ejRs3snLlyip7D9u//w1168K991bZe4iIiEj5lAgFS04upKVBZmawIxEREamxlAgFi/1I0Wv4vIiISNBo1FiA2aPtZN+fjb1AEyqKiFRWUR0aHZ6zHIcaW7SNTp93whYdvu0m4XtlIcpwGHi6ejCcR4peiZCISIUV1aGO8J3pOJTYHDYSBydic4RvuhC+VxaiPBke4kfE4yk4MrW0EiERkQorqkMzwneCv1DiyfCwNH5pWJe3EqEAs8fYyfpnFvaoIxvUR0hEpMKK6tAwXQA01Nhj7HT7tltYl7f6CAWaDXxJPsyoBtCjBzRrFuyIRESqjyN1qP6MDxAbuBq7wrq8lQgFmDfTS8JVCXjSBuG8YUywwxERqVYK61BvmhfqBDua8OfN9LIsYRn90vvhiA/PlCGMczwRERGR8ikREhERkRpLiVCQGPPmWf2Dxo4NdigiIiI1lhKhIDGyc2DHDti3L9ihiIiI1FhKhILEtB8Ziqh5hERERIJGiVCw2DSztIiISLApEQowe5yd9LfSsUcf2aAJFUVEKqyoDo0L3wn+Qok9zk6/9H5hXd5KhALNB7Y0G9h0a0xEpNIK61D9DRkYPsjflR/W5a1EKMC82V5i74jF61YiJCJSWUV1aLbqzkDwZntZ3Wd1WJd3eE4TeYpmzJjBjBkz8FZBkuKId5AxJwOHkQBt20KTJn5/DxGRcFVUh4bpLMehxhHvoH9G/2CHUaXUIlSG8ePHs3HjRlauXOn3c5seE8caB76BQ2DTJpg1y+/vISISrgrrUNNjBjuUGsHn8XFo/iF8nvC9N6ZEKMC8OV5iHojBmxO+zYwiIlVFdWhg+XJ8/DjkR3w5SoREREREwo4SoSAxvl0Bp58Ol10W7FBERERqLPU2C5acbNi4EVyuYEciIiJSY6lFKFi0xIaIiEjQKREKlsIJFTWztIiISNAoEQoww2bgbezFcGitMRGRyiqqQ21GsEOpGWwQ3T46rLMF9REKMHusnazpWdhj460NSoRERCqsuA4N37WvQokj1kGvn3oFO4wqFcY5XmjyFfhwLnTi86lFSESksorq0AJ1KwgEX4GPPS/vCevyViIUYKbbxPmNE58j0lpeo2HDYIckIlJtFNahplszSweC6TY5MO9AWJe3bo0FmD3GTs6UHOx9B8COHcEOR0SkWimqQ2N0aywQ7DF2Os/vHOwwqpRahALMl+/DNceFLz98mxlFRKqK6tDA8uX72D5le1iXtxKhAPPl+4icGxnWHyoRkaqiOjSwfPk+djywI6zLW4lQsPz2G/TqBQMHBjsSERGRGkt9hIIlvwBWroTExGBHIiIiUmOpRShY7EeKXjNLi4iIBI0SoWCxaR4hERGRYFMiFCxadFVERCTolAgFmOE0KDi3AMOlREhEpLKK6lCn1hoLBMNpkDwmOazLW52lA8weZSf3llzsMU5rgxIhEZEKK6pDozShYiDYo+y0fbltsMOoUmoRCjBvrpeoZ6LweuxQpw4kJQU7JBGRaqOoDs3VH5GB4M318vMNP4d1eatFqAwzZsxgxowZeKugtcawGfjq+DCS60Famt/PLyISzorqUFv43qoJJYbNwNXIFdblrRahMowfP56NGzeycuVKv5/b5rKRPyIfm0tFLyJSWapDA8vmstF8SvOwLu/wvbIQ5c32Ej0lGm92+DYziohUFdWhgeXN9rJu8LqwLm8lQgFmek2ca52YWbkwYACccQbk5QU7LBGRaqGoDvWawQ6lRjC9JocXHA7r8lYfoWAxTfj6a+tnjye4sYiIiNRQahEKFttRRa8h9CIiIkGhRChY7EfNgaFESEREJCiUCAWL/aii18KrIiIiQaFEKFh0a0xERCTolAgFmC3SRs74HGyRNi28KiJSSSXqUKlytkgbrV9qHdblrVFjAWaLsOEe6MYWYYPYWGvEmBm+wxJFRPypRB0qVc4WYSPlhpRgh1Gl9EkKMG+Wl9gJsXizvPDHH5CVBQ0bBjssEZFqoUQdKlXOk+Xh+9O/x5MVvtO8KBEKMFukjbzReWHdzCgiUlVUhwaWLdJGq6mtwrq8dWsswAyHgaerB8MRvgvYiYhUFdWhgWVz2EgcnBjsMKpU+KZ4IcqT4SF+RDyeDA9ceSUMHQo7dwY7LBGRaqFEHSpVzpPhYWn80rAub7UIBYGRe+QvmS++gIMHITMzuAGJiFQjRXWoBIQ3M7z7Y6lFKJg0fF5ERCSolAgFkxIhERGRoFIiFEyFiZCW2BAREQkKJULBpBYhERGRoFIiFExKhERERIJKiVCA2WPsZD6diT3GrltjIiKVVKIOlSpnj7HTc0PPsC5vDZ8PNBv4knxWCvrzzyVXoRcRkfIdXYdK1bOBq7ErrMs7jC8tNHkzvSRclWDNy6AkSESkUkrUoVLlvJleliUsC+vy1jdxgNnj7KS/lY49LnybGUVEqorq0MCyx9npl94vrMtbiVCg+cCWZgMfcMcdcOmlsGZNsKMSEakejq5Dper5IH9XfliXtxKhAPNme4m7NQ5vthe+/BLefx/27g12WCIi1UKJOlSqnDfby8oOK8O6vJUIBZOGz4uIiASVEqFgUiIkIiISVEqEgqlw1JgSIRERkaBQIlSGGTNm0L59e3r27Fm1b6QWIRERkaBSIlSG8ePHs3HjRlauXFm1b6RESEREJKiUCAWBGWVaP2iJDRGRSiuqQyUgwnkOIdASGwHniHeQMScDR7wDPvrI2hgREdygRESqiRJ1qFQ5R7yD/hn9gx1GlVKLUICZHhPHGgemx4SoKOthD+9sW0TEX0rUoVLlfB4fh+YfwucJ3zsXSoQCzJfnI3JmJL688P1QiYhUFdWhgeXL87F10tawLm8lQgFmj7WTNT0Le6wdpk+H666Dr74KdlgiItVCiTpUqpwj1kGvn3rhiA3fW5FKhALMV+DDudCJr8AHixfD66/D5s3BDktEpFooUYdKlfMV+Njz8p6wLm8lQgHmy/MRPSPaambU8HkRkUopUYdKlfPl+fjlxl/CuryVCAWTEiEREZGgUiIUTEqEREREgkqJUDApERIREQkqJULBpJmlRUREgkqJUDBp9XkREZGgCt+JAUKUYTdwd3Fj2A2YOhUeewxiY4MdlohItVCiDj1GXl4ebrfbb+/ldDqJjIz02/mqI8NuUHtQ7TLLO1woEQowe4ydnCk5/He+A9OM5Morgx2RiEj1UViH2mNKTqiYl5fHypVf4fVm+O+97PH07Hl2jU6G7DF2Os/vHOwwqpQSoQDz5ftwzXGxoqHJ4WyUCImIVEJhHeo7xwfO4u1utxuvN4N27SKIjj71xCUnJ49NmzJwu901OhHy5fvY8dgOmt7VFJsrPHvTKBEKMNNnYjtoI+Y0k90/7ICbH4fBg+Gii4IdmohIyCusQ01f2YuuRkdHEhcX7ad3K/DTeaov02eS/3v+ccs7HCgRCjB7lJ3cW3KJ3GIne086LHkeEhKUCImIVEBhHWqP0lpjgWCPstP25bZl7guXPllKhALMm+sl6pkoYs7zkuOJOLLRGjUWLh8qEZGqUliHes/y4nQ6T/wCOSXeXC9bJmzhtOmnlUg+w6lPlhKhADPdJhFfRBB9iY8cb3EiFE4fKhGRqlJYh5ru8L1VE0pMt0nqK6m0mtoKooq3h1OfLCVCQRIdBdlul/XE6w2rD5WIiNQM4dAnS4lQkERFQ47nSLPuUTNLh8OHSkSkOti0aQfnnXcX27a9FexQJIjCcyxcNRATDTnukn2EREQkcAoK3OzYsS/YYUiQqUUoSKKiTbLdR1qElAiJiPjdpEkzyt1/4EB6gCKRUKZEKEiiIiGHaPjtN4iLC3Y4IiJh5z//eZ8uXVoSHx9T5v6srNwARyShSIlQgNlcNvKuyCOmlo2cHAOzSVMMA8jMDHZoIiIhr7AOrcgsx6ed1pDbbruMa64ZWOb+tWu30r37X/0dYlixuWw0vf/UZ5U+cOAPatWKxekMvbRDfYQCzOaykT8in5jaVtHnnsIfJOvWbcVuP8dPkYmIhL7COrQiX8zdu7dm1apfjrvfMMA0NQy/PDaXjeZTmlc4EXrxxY/Jz7cG6pimyaOPvkHt2sNJTr6UWrWGM2nSDHxHDRAKBUqEAsyb7SV6SjQu0+oXlPP3++CNN076fPolFpGapLAO9WafuG/lk0+OY+LES4+7v3PnVvh8X/kzvLDjzfaybvC6CpU3wM03P0V6ejZgJUWPPvom9957LUuX/od//vMmZs78H88++9+qDLnSQq+NKswZTgP3n91ExxsA5Dw3Gw71hQsvLHXsJZfcV+650tOzMAyjKsIUEQlJhXWo4Txx3ZecnBiAiMKb4TSoe1ndCpU3lPzj/JVX/sdDD43mttsuA6Bv3w5ERkYwffr73HLLxVUS78lQi1CA2SJsuAe6sbtsREe4rQ7Tx2km/Pjj5eTlFZCQEFPmIzY2qszXiYiEq8I61BZRua+vHTtS+e67jXz//SZ27EitoujCjy3CRsoNKZUq78I/0Ldv38s553Qrse/ss7uybdtev8Z4qtQiFGDeLC+xE2LxnuElOsIkuyDmuMPn27VryqWX9mfMmPPK3L927VY++WRFVYYrIhJSjq5DnbVPvNbYtGnzmDp1Hnv2HCxqrTAMg5SUOkyefDkTJ/6lqkOu1jxZHlb3Xk2377rhiK1YyvD559+TkBBDVJSL3Nz8Evtyc/Ox2UKrDUaJUICZPhP7LjumzyTG5SEnK/q4iVD37q1ZvXoLY8aUfS6Xy0mTJvWqMFoRkdBydB16Ig899Br//vc7/N//Xc3gwT2pX782pmmyf/8fzJ+/kilTZpOVlcs991wbgMirKR/kbMyBSvRvHjny8aKfv/xyNb17ty96/u23G2nZMsWfEZ4yJUJBFB3hsW6NHScRev752/B6j//pa9euKdu3z6mq8EREqrUXX/yEV1+9k4su6ldie0pKEl26tKJ160bccsvTSoT86ESdz5OTE3nssRsCFE3FKBEKougIL9nEgC+/zP0uV0SAIxIRCR8HD2bQpk3j4+5v3boRhw9rDrdAOv/8PsEOoRQlQkEUE1nYIpRT7nFZWbmsWrWZ1NRDGIZB/fq16d69jTpLi4iUo1evtjzyyBvMnn0nDoe9xD6Px8ujj75Jr15tgxRdeNuy5XeWL99AauphDAPq169N374dOO20RsEOrRQlQkEU3agOOVf+C8aUfWvM4/EyefKzvPTSp+TlFRAR4cA0we32EBkZwU03nc8TT4wNyZk6RUSCbfr0Wxk06B/Uq3cxZ57Zmfr1a2MYBqmph1iy5EdcLicLFz4R7DDDSnp6Ftdd9xgff/wtCQkx1Ktn9cs6cOAPMjJyGD68D6+9dtdxlz0JBn2DBlF0gpPshBRoTJlLbEye/CzvvbeEWbNuZ/DgXtSqFQvAH39kMX/+9/zjHy8A8NRTtwQybBGRaqFjxxb88svrvPHGQlas2Mj27daw7eTkRB55ZAxXXXVOSH0hh4MJE55m+/ZUvv32mRKdpAG++24jN930JBMmPM2rr94VpAhLUyIUYPZoO9n3Z2OPthMTAznl3BV7660vmTv3Ps4+u+Q8DLVqxXLFFWeTlJTAlVc+pERIRGqMo+vQioiLi+bmmy/k5ptLT1orJ2aLttHp807Yois25P2jj5Yzf/6/SiVBAL17t+eFFyYzZMjt/g7zlCgRCjDDYeDp6sFwGESb2eTMXw22ZXBL6WQmNzefpKSE456rTp2EUnM0iIiEs6Pr0Io6tp9lcnIi3bq1Vj/LCrA5bCQOrtwM3eWteBCKiyGE1qxGNYAnw0P8iHg8GR6ijVyyl66Cp54q89izzurKpEnPsm/foVL79u07xO23v1CqtUhEJJwdXYee8FiPl7/9bTr16l3MWWdNYuTIx7n22scYMOA26tW7mIkTn8HtPvF5ajJPhoel8UsrVN4Aw4f35cYb/80PP2wute+HHzYzduw0Lrigr7/DPCVqEQowe4ydrH9mYY+xE5PgYB/RkJFR5rHPPjuRYcPupFGjy+nQoXmJjn4bNmynffumfPrp42W+VkQkHB1dh56I+lmeOnuMnW7fdqtQeYPVQX3EiIfo1etmatWKpV69WhiGwb59h0lPz2bw4J48/fStVRx15VQqEfrXv/7FhAkTiIqymhOXLFlC7969cblcAGRmZnLHHXfw7LPP+j/SAJoxYwYzZszAe5yJDk+JDXxJPrBBdK0Ia/h8Xh643aUObdy4HuvWvcz8+StZsWIjqalWy1CvXm157LEbGTSoR8hNVS4iUqWOqkNPRP0s/cAGrsauCt8/qlUrlv/975/8/PNOvv32p6LvreTkRPr0OZ22bZtUYbAnp1KJ0F133cWoUaOKEqHzzz+ftWvX0qJFCwBycnJ44YUXqn0iNH78eMaPH09GRgYJCcfvo3MyvJleEq5KwJvmJbq2y5pQEcocNQZgs9kYOrQ3Q4f29mscIiLV0dF1KHXKP1b9LE+dN9PLsoRl9EvvhyO+4ilD27ZNQjLpKUulEqHCBeuO91wqJybeTo4t1lrD5TiJEFSvialEREJFYT/LN9+8m/r1S3b4VT/LwImPP4+1a1+iRYvQWmOskPoIBVF0NOTY46xEKCur1P7qODGViEioUD/L0BDqjSZKhIIoOhqrRQisFiFnyf3VcWIqEZFQoX6WUhGVToRefvllYmOtL2+Px8Ps2bNJSkoCrM7SUnExMZDdoBV89CPUqwebFpXYXx0nphIRCSXqZxl811wzMKTvXFQqEWrSpAkvvfRS0fPk5GRef/31UsdIxURHQ443Ejp2PG4foeo2MZWISKhRP8vgmjZtPJGREcEO47gqlQj99ttvVRRGzRQdXf4SG4UTU73yyu306NGmxL5QnZhKRCRUqJ9l8Ph8Ph555A2ef/5j9u07xC+/vE6LFince+9MmjWrz5gx5wU7xCK6ORpg9jg76W+lY4+z1hrLzvTCQw/BN9+UOnb69FtJSUmiV6+bSUy8gLZtr6Ndu5EkJl5A797jaNCgTshNTCUiUpWOrkNP5Oh+locPf8zmza/xyy+vc/jwxyxfPp3t2/cyYcLTAYi6+rLH2emX3q9C5X20hx9+ndmz5/Ovf91ERERxB9iOHZvz8suf+TvMU1KpFqHvvvuOQ4cOMXTo0KJtr732Gvfffz/Z2dlcdNFFTJ8+vWiCRSmDD2xpNvBZLUJ5BXZ8990Pd94BgzuXOLQ6TkwlIlKljqpDT0T9LP3AB/m78oluGw2VyIVee20BL744iXPO6c7YsdOKtnfq1JKff95ZBYGevEolQlOmTGHAgAFFidD69esZM2YMo0aNol27djzxxBOkpKQwZcqUqog1LHizvcTeEYv3Ki/R0da2XKLKHD5fqDpNTCUiUpWOrkOJPPHx6md5arzZXlb3WU2f3/tUakLF3bvTaNWqYantPp8v5NZ3q9StsbVr13LOOecUPX/77bfp3bs3L730EpMmTeLpp5/mnXfe8XuQ4cQR7yBjTgaOeAcxR25LZxNz3PXGyrN370F27tzn5whFRELX0XXoiVTHBUBDjSPeQf+M/pVKggBOP70ZS5euL7V93ryv6dr1NH+F5xeVurLDhw9Tv379oudff/01Q4YMKXres2dPdu3a5b/owpDpMXGscWAOMomIBJvhI8eMJuokph44++xJ/PLL73i9X1ZBpCIioefoOvTYudeOVR0XAA01Po+PP778g1rn1MLmqHjbyf33j+Taax9l9+40fD6T999fyubNu3jttQV88smjVRhx5VUqEapfvz7bt2+ncePGFBQUsHr1ah544IGi/ZmZmTidJ/hk1nDeHC8xD8TgneAlIgqiXV5y8qKpU86tseN57bW7yMnJq4IoRURC09F1KFHlH6t+lqfOl+PjxyE/0i+9H7b4iidCw4f3Ze7c+3j00TcxDLjvvll063YaH3/8CAMH9qjCiCuvUonQkCFDuPPOO/nnP//Jhx9+SHR0NP379y/a/+OPP9KyZUu/BxnOYiK9ZOed3K2xnj3bVkFEIiLhRf0sg2Pw4F4MHtwr2GGcUKUSoYcffphLLrmEM888k9jYWGbPnk1ERPEkSTNnzmTQoEF+DzKcRUf6rD5CmQfKPW7HjlRSUw9hGAb169emadPkAEUoIhKe9u49iNvtoUmT+ic+WMJWpRKhunXrsnTpUtLT04mNjcVuLzmWbt68ecTFxfk1wHCXmBzBoQnPweAcyNxSav+0afOYOnUee/YcLFq4zjAMUlLqMHny5Uyc+JdAhywiEhbUzzLw1q3bSrdufw2pMq9UIjR69OgKHTdz5syTCqYmSqrvIC2pHbTOhFUlE6GHHnqNf//7Hf7v/65m8OCe1K9vzYq6f/8fzJ+/kilTZpOVlcs991wbpOhFRKov9bMMjlBbjb5SidDs2bNp2rQpXbt2DbkLqa7q1oW0tLL3vfjiJ7z66p1cdFG/EttTUpLo0qUVrVs34pZbnlYiJCJyEtTP0v8uueS+cvenp2eVO7dTMFQqERo7dixvv/0227ZtY/To0VxzzTUkJiZWVWxhybAZeBt7MWzWByEp0ceBBesg933oX3JuhYMHM2jTpvFxz9W6dSMOH678sHsRkerq2Dq0otTP8iTZILp9dIVnHfz44+UMHNiD+vVrl7nf6/X6MTj/qFQi9OyzzzJt2jTef/99Zs6cyV133cV5553HmDFjGDRoUMhleaHIHmsna3oW9lirf1XderDp6w3w9cPwwXMlju3Vqy2PPPIGs2fficNRsj+Wx+Pl0UffpFcv/UUjIjXHsXXoiaif5alxxDro9VPFR361a9eUSy/tf9xFVdeu3conn6zwV3h+UbmpIgGXy8WIESMYMWIEO3bsYPbs2YwbNw63283GjRuJjY2tijjDhq/Ah3OhE9+5PnBCUl0bB+wNwAvklbxXPX36rQwa9A/q1buYM8/sTP36tTEMg9TUQyxZ8iMul5OFC58IzoWIiATBsXVoedTP8tT5CnykvpZK8nXJ2CJO3CzUvXtrVq/ewpgxZe93uZw0aVLPz1GemkonQkczDAPDMDBNE5+vAivgCabbxPmNE9Nt/WWSlARptrpWIpSbW+LYjh1b8Msvr/PGGwtZsWIj27fvBazJwB55ZAxXXXUO8fExgb4EEZGgObYOLY/6WZ46021yYN4B6o+oDxEnPv7552/D6z1+PtCuXVO2b5/jxwhPXaUTofz8/KJbY8uWLeP888/nmWeeYciQIdhslVq6rEayx9jJmZKDPebIrbG6cMCsa+08JhECiIuL5uabL+Tmmy8MZJgiIiHp2Dq0POpneersMXY6z+9c4eNdrgpkSyGmUpnLuHHjaNCgAf/85z85//zz+f3335k3bx7Dhg1TElRBvnwfrjkufPlWxpyUBGm+I53KykiERESk2LF1aHkK+1l6PKU76KqfZcX48n1sn7K9QuVdXVWqRej555+nSZMmNG/enK+//pqvv/66zOPef/99vwQXjnz5PiLnRuKb4YNYq0UoxxdFDpHlJkIdO47ms88ep3HjeiV+FhGpSY6tQ8ujfpanzpfvY8cDO2g8qTE2V+UaPKrL91alEqHrrrtOI8P8rHZtMPBxkDqQk3Pc4377LRW321PqZxERKZv6WQZXdfneqvSEiuJfdjvUqeXl4MNvQ+ONwQ5HRCSsqJ+lnIg69oSApGQnaSmdIT4+2KGIiIjUKEqEQkBSEhw8GOwoRETCV8eOo9m1a3+pn0WUCIWAunF5pH20HBYsCHYoIiJhqbr0V5HAUyIUYIbToODcAgxncafzJFcGBz9eBh9+GLzARESqgbLqUKk6htMgeUxyWJf3Kc0sLZVnj7KTe0su9qjiycDqNopkL3UgPR00Q7eIyHGVVYdK1bFH2Wn7cnjPtaQWoQDz5nqJeiYKb27xBF9JTWNIIwm8Psgoe5bTpk3r43Q6Sv0sIlKTlFWHStXx5nr5+YafT6q8q8v3VmhGFcYMm4Gvjg/DVtzMWDfZzkFHfevJoUPQuEGp123YMKvMn0VEapKy6lCpOobNwNXIdVLlXV2+t9QiFGA2l438EfklZui0Fl49MtvmoUMljne7PVx//T/Ztm1PIMMUEQlJZdWhUnVsLhvNpzSvVHlXt+8tfZICzJvtJXpKNN7so26NJUGaL9F6crhkIuR0Ovjgg6WBDFFEJGSVVYdK1fFme1k3eF2lyru6fW8pEQow02viXOvE9JpF21JS4JCnFgXYS7UIAVx8cX8+/HBZIMMUEQlJZdWhFVFd+quEGtNrcnjB4UqXd3X63tInIQTUrw92u8kff3sABrcotb9Vq4Y89NDrLF/+E927tyYmJrLE/ltvvTRQoYqIVEvVpb9KuKhO31tKhEKA3Q4NGhikJbSEWqWX2Xj55U+pVSuWVat+YdWqX0rsMwwjpD5QIiKhxO32cNNNT3LvvdfSokVKsMOpMarT95YSoRDRsGGZd8UA2L59TmCDEREJE4X9Ve6999pgh1KjVKfvLSVCIaJhUj4Hv90MDXfA9dcxadKMCr3OMAyefHJcFUcnIlJ9FfZXmTTp8mCHEtaq6/eWEqEQ0Sgxh0MLtkP+HBh1LWvWbK3Q6wxDc2mIiJSnOvVXqc6q6/eWEqEAs0XayBmfgy2y5IC9lNOi+XVBHXJyCmBfGh999EiFz5mZmVNqW05O3inHKiISao5Xh5anOvVXCTW2SButX2p93PI++rvmVL63gvmdpUQowGwRNtwD3dgiSn6omp4Wy5yc5mzaBizYDk2anPJ72e3xOJ3OUz6PiEioOF4dWp7q1F8l1NgibKTcULqTudPpxG6PZ9OmDKDAL+8VrO8sJUIB5s3yEjshFu8ZXpy1i//DW7SIZE/OxXTPnAARTaD7eaf8Xk6nk8jIyBMfKCJSTRyvDj1Wde2vEmo8WR5W915Nt++64YgtThkiIyPp2fNs3G63394rWN9ZSoQCzBZpI290XqlmxsaN4YC3IRFE4EpNhbi4IEUoIhK6jleHHqu69lcJNbZIG62mtiqzvCMjI8Pij20lQgFmOAw8XT0YjpK/fPXqgcPmZbevIS22bw9SdCIioe14deixFi2aFqCIwpvNYSNxcGKww6hSSoQCzJPhIX5EPJ5dHpx1ipt17XZIqZXDrkONabFtWxAjFBEJXcerQwv5q9OtBpxYPBkevm30LX1+74MjPjxThvC8qhBn5Jb9l0zjlhH8fstLMC4hwBGJiFQfZdWh4dR5N9R4M8N7gVslQiGkUQsXu6JaQ/1gRyIiUr2EU+ddCSwlQiGkcWPYtSvYUYiIVE/h0nlXAqviEzFIlWvWDH5bvhtuvx02bQp2OCIiImFPiVAIadkStm72wRNPwKpVwQ5HREQk7CkRCiGtWsH2/AZ4sYFGjomIiFQ5JUIBZo+xk/l0JvYYe6l9TZuCDxu/00iJkIhIGcqrQ8X/7DF2em7oGdblrUQo0GzgS/KVWfJOJzRJyuFXWsKvvwY+NhGRUFdOHSpVwAauxq6wLu8wvrTQ5M30knBVwnHnZWjVwsdWWsGGDWCaAY5ORCS0nagOFf/yZnpZlrAsrMtbiVCA2ePspL+Vjj2u7GbGlh1j+NU4Df74A37/PbDBiYiEuBPVoeJf9jg7/dL7hXV5KxEKNB/Y0mzgK3t3y9Z2fo3rYj3ZsCFgYYmIVAsnqEPFz3yQvys/rMtbiVCAebO9xN0ahzf7OLfGWsGvKf1g714YOjTA0YmIhLYT1aHiX95sLys7rAzr8tbM0iGmZUvY+nsUZv0oyl9bWURERE6VWoRCTIsWkJUFBw4EOxIREZHwp0QoxMTEQIMGJr/+43kYPhxycoIdkoiISNhSIhSC2raFn97fDJ98Aj/9FOxwREREwpYSoRDUtavBmlpnWU/WrQtuMCIiImEs7BOhXbt2MWDAANq3b0+nTp2YN29esEPCjCp/osRu3WC1r7P15PvvAxCRiEj1caI6VPwrnOcQghowaszhcPDUU0/RpUsX9u/fT7du3Rg2bBgxMTHBiSfeQcacDBzxxy/6bt1gXVpDvNiwL1sWwOhEREJbRepQ8R9HvIP+Gf2DHUaVCvsWoQYNGtClSxcA6tWrR2JiIocOHQpaPKbHxLHGgek5/l80rVuD4bCzmTawaRMEMV4RkVBSkTpU/Mfn8XFo/iF8nvCdUTHoidCSJUsYPnw4KSkpGIbBhx9+WOqYZ599lubNmxMZGUn37t1ZunTpSb3XDz/8gM/no3HjxqcY9cnz5fmInBmJL+/4Hyq7HTp3NlidfJ61YfnyAEUnIhLaKlKHiv/48nxsnbQ1rMs76IlQdnY2nTt35plnnilz/9y5c5k4cSJ33303a9asoX///gwdOpSdO3cWHdO9e3c6dOhQ6rFnz56iYw4ePMh1113Hiy++WOXXVB57rJ2s6VnYY8u/59q1K6ypcy7Ex8O+fQGKTkQktFW0DhX/cMQ66PVTLxyx4XsrMuhXNnToUIaWs5TE1KlTGTNmDDfccAMATz31FPPnz+e5557jscceA2DVqlXlvkd+fj4XX3wxd911F3379i33uPz8/KLnGRkZALjdbtxud4WvqdxYsvNxLnSSf2Y+lNNNqXNng7fWnYX7h31WE5Gf3j/cFP6/+Ov/R1Sm/qby9K+K1qFSMSf6fPoKfOx/Yz/1rqmHLSLobScVVpnft6AnQuUpKChg1apV3HnnnSW2Dxo0iOUVvF1kmiajRo3i7LPP5tprry332Mcee4wHHnig1PYFCxYQHR1d8cDLkwMJMxL48s9fQjmnzM5OYOWaP/PxZ/Ox6w+fE1q4cGGwQwg7KlP/Unn6SQXrUKmc434+cyBhbAKr41dXq/LOqcRkxCGdCKWlpeH1eqlfv36J7fXr1yc1NbVC5/jmm2+YO3cunTp1Kup/9Prrr9OxY8dSx951111MmjSp6HlGRgaNGzdm0KBBxMfHn/yFHCXvYB6rWMXZZ51NZJ3I4x7n8cBDDzmoW/c8/tTbB7m54K9kLIy43W4WLlzIwIEDcTqdwQ4nLKhM/Uvl6V8VrUOlYk70+fRkePiO7xg0aFC1GqlXeEenIqrFVRlGyeVHTdMste14+vXrh89XsU5eLpcLl8tVarvT6fRbBeZxegBwOB3lntPphCFDYP60X+i/ehicdx7MmOGXGMKRP/+PxKIy9S+Vp39UtA6Vyjne59NwGkX7Hc5qkTIAVOqzEdI3/JKSkrDb7aVaf/bv31+qlSgcnX8+fLquIezYAR9+CBVM6ERERKRiQjoRioiIoHv37qXuXS5cuLDcTs/hYsgQWL8jnt3Rp8GePbByZbBDEhERCStBT4SysrJYu3Yta9euBWD79u2sXbu2aHj8pEmTePnll5k5cyabNm3itttuY+fOnYwdOzaIUQdGYiL86U8Gn7b7u7Xhgw+CG5CIiEiYCXoi9MMPP9C1a1e6du0KWIlP165due+++wC44ooreOqpp3jwwQfp0qULS5Ys4bPPPqNp06bBDPukGXYDdxc3hr1ifZwuvhieSr2CAyRZiZCp2VRFpOaqbB0qp8awG9QeVDusyzvoPZ8GDBiAeYIv93HjxjFu3LgARVS17DF2cqbkYI+p2Jj4v/0NVi6P5uwPFrH4lzOps2kTtG9fxVGKiISmytahcmrsMXY6z+8c7DCqVNBbhGoaX74P1xwXvvyKdXx2OOCNuU4Sahm8ykjdHhORGq2ydaicGl++j+1Ttod1eSsRCjDTZ2I7aMP0VfwWl8MB5w/18k2La+Hcc6swOhGR0HYydaicPNNnkv97fliXd9BvjdU09ig7ubfkYo+qXLNuv5s78dSXYPaC8L1TKyJSvpOtQ+Xk2KPstH25bbDDqFJqESrDjBkzaN++PT179vT7ub25XqKeicKb663U63r0gMOH4ddf/R6SiEi1cbJ1qJwcb66Xn2/4OazLW4lQGcaPH8/GjRtZWQXz9phuk4gvIjDdlWtmjIyEHj1Mls38BR591O9xiYhUBydbh8rJMd0mqa+khnV5KxGqRvp1y+Wbx5fA3XfD5s3BDkdERKTaUyJUjfx5YDTLogdbT958k8xMa3FWEREROTlKhKqRfv1gW34KP9MG84036d/f5IUXgh2ViIhI9aVEqBpJTISrR5j823EXn21vy7p1BkuWBDsqERGR6kvD56uZf9zloOtbV/EDnRnoXMy33/QHNIxURETkZKhFKMBsLht5V+Rhc51c0bdrB4OH2thma8VM9zXs3mOwa5efgxQRCVGnWodK5dhcNpre3zSsyzt8ryxE2Vw28kfkn9KHatp/7Lz17700amKnc/NMvv3WjwGKiIQwf9ShUnE2l43mU5qHdXmH75WFKG+2l+gp0XizT35yqhYt4PzbToOtW+k7NIHly/0YoIhICPNHHSoV5832sm7wurAubyVCAWY4Ddx/dmM4/bBQhtNJ374oERKRGsOvdaickOE0qHtZ3bAubyVCAWaLsOEe6MYW4Z+i79sxkzWrvGSdcyH4/LM68N/+Blu3+uVUIiJ+5e86VMpni7CRckNKWJd3+F7ZKajStcayvMROiMWb5Z9mxqatnLTmFz7+KhpWrPDLOefOhbVr/XIqERG/8ncdKuXzZHn4/vTv8WSF7+y9SoTKUKVrjflM7LvsmD7/rNtiREVydaf1vME18M47p3w+04S0NDh40A/BiYj4mb/rUDkBH+RszAH/3HAISUqEwsBV4xNZwCD2v/3VKd8eS08Hr9dKhkRERMKdEqEw0Oza/vSxr+SdfWfA9OmsWWPNN7RzZ+XPVZgAqUVIRERqAiVC4cDl4vpLM5jCFO6fmM6gM/PZvx/++9/Kn0qJkIiI1CRKhMLEqDmDeXXYOyzmTP4W9QL3/p+Xjz+u/HkOHLD+VSIkIiI1gRKhMGHYDM776K98ffdC7ll/JcMvsrN4MWRkVO48ahESEZGaRIlQgNmj7WTfn409ugoWSrXb4eGHoV49WraEVq1gwZPry33Jpk0l+1enpUGdOkqERCQ0VWkdKqXYom10+rwTtujwTRfC98pClOEw8HT1YDiqfpbO4S1/4uMHV8N775W5PzMTuneHJUuKt6WlQZs2GjUmIqEpkHWogM1hI3FwIjZH+KYL4XtlIcqT4SF+RDyejKqfnOqqxPm8y1/YOPkV8JR+v//+F3JzYdu24m2FidAff1jD6AGryej55+HHH6s8ZhGR8gSyDhWrvJfGLw3r8lYiFGD2GDtZ/8zCHlP1zbqdp9/A+MiZXL/jfjyvvArA6tVw/vmQlwdz5oDTCb/9VvyatDRo29aaWPHw4SMb334bbr4ZOneu8phFRMoTyDpUrPLu9m23sC5vJUKBZgNfki8wJR8fzwNTTNJJYPodv0NuLtOmwf/+B+PGwcKFcM01JROhAwegSROIjDyqn9CyZQEIVkSkAgJZhwrYwNXYFdblHcaXFpq8mV4SrkrAmxmYdXKi/nYTT9d9iIfSJ/Drg28yb57VZejtt6FbNzjrrNItQnXrHtNhevTo4gNycgISt4hIWQJdh9Z03kwvyxKWhXV5O4IdgFSxyEgGPX4O3ces4tx/DaR3Hw8XXeRgzhyIiQGXC7ZvLz48LQ2SkqxEqKjDdPfuEBsLWVmwa5fViUhERCQMqEWoDFW5+nxQXHcdjzd7nt98TRl79i8AXHghnHsuNGsGu3dDQYHVn/rw4eJEqKhFyDCs+2VgJUIiIiJhQi1CZRg/fjzjx48nIyODhISEYIdz6hwOun9wL98dSKf72e1L7EpJAYfDym/i4qxtdepYyVBRIjRnDvxiJVAntYCZiIhIiFIiVFN06UKvo5+/8ALYbNhvvJEmTax+Qg0aWHfAIr9fQp3Y3hw86LKaiq6+2hpGNnMmDB0apAsQERHxPyVCNdGWLfC3v0F+PmzbRrNmj/LbbwYOByRF58CZZ1Kn1jPsP+96+D3VSoIiI2HUKOs2mYiISJhQH6GaqGVLuOce6+fHH6fZz5/z23f7rI7SBXsAqPPHVg5+vBzWH1mio0kTJUEiIhJ21CIUYPY4O+lvpWOPC+LkVDablQg1agQ33USz3d/w80uHaOTsSN1EF0Q1ICk9l7QMJ0yebL0mIQHefNMaOfbXvwYvdhGp0UKiDq1B7HF2+qX3C+vyVotQoPnAlmYD34kPrXKjRsGmTTTvUovNtGbVrB9J6tEMdu2izk2XcpA68Ouv1rFRUdbsi5MnW7fKRESCIZTq0JrAB/m78sO6vJUIBZg320vsHbF4s0NkcqqWLTnt6Qn8QE+W5PbgmuQvwG6nznl/shKhQv36Wf9mZx+19kZpI0bA66+X3OZ2l1zhXkTkZIVcHRrmvNleVvdZHdblrUQowBzxDjLmZOCID527kj37udj58To2ffgLg/5zHgCndYujICqBl7jBOqhNG2vKaSh3LqEVK6z1zI52443wzDNVEbmI1DShWIeGM0e8g/4Z/cO6vJUIBZjpMXGscWB6Quf2kmFA4/M7Y1x4QdG2xET44PNoJkY+z23nrueiNy5lTZ1zrZ3HSYSys61h+Fu3lty+YQNs3lxFwYtIjRKKdWg483l8HJp/CJ8nfJv1lQgFmDfHS8wDMXhzQr+Z8Ywz4M05dg437IDXFcN9h2+zdhT2GzoiNdX6tzDZ2bKl5Hm2b9eE1CLiH9WpDg0HvhwfPw75EV+OEiGpoS66CGbPhpdegi8OduFHOsIDDxTNNL1kCTRsaCU6GzdakzJu22Yt1wGQng6HDikREhGR0KRESCokORlGjza4s9bzPJh/B8/PdGKacNdNBzF9Pr56eRsbN8LgwdagssLEp3BBVyVCIiISipQISYX94y4Hv9bpxU9njeeBV5sztPdBtmz2cgvP8NXTG9j4k0mnTtC8efHtse3brfXMDh6EnJzgxi8iInIsJUJSYc2aweatDuZ+EsuyZbD1UCJTOn3AhXzEV390ZeP3WbRvD61aFXeY3r4devUClwt+/z3AAft8Vg9uERGR41AiJCelZUv45ReDcSuvp+/dZ7GfemxJjaNdSjqnnVayRahlS2sS64DfHrv8cqhfH3bvDvAbi4hIdaFEqAwzZsygffv29OzZ0+/nNmwG3sZeDFv1X7fLZgMiIoi6fQJ9HSuJJZPGV/TltMa5bN1iwmefsW2Ll+bNoXHjILQIvfee1SL08ssBfmMRqSrhVIdWCzaIbh8d1tlCGF/ayRs/fjwbN25k5cqVfj+3PdZO1vQs7LFhtG5LfDznjG5Ku8jtGD9votWepWz5ahecdx7b12daiVADd2BbhHJzi3/OzAzgG4tIVQrLOjSEOWId9PqpF45YTagofuIr8OFc6MRXEF5zMox/vDEvL2sHb7zBaf2T2VbQEA92fkuNpHmDPBp9+Rq73loCeXmBCSgiAq66yvp5797AvKeIVLlwrUNDla/Ax56X94R1eSsRCjDTbeL8xonpDq9ZUWvXhk7dnXDVVTQd3omkJJhiPEiuL5Jml3an8f4f2PVrgTV8LBDsdrjsMutnTWstEjbCtQ4NVabb5MC8A2Fd3kqEAsweYydnSg72mPBt1nU4YN57dv5l3E4D9hC1fSON+Z1dKX+yZl88cCAwPafbtLH+3bzZmtxIRKq9mlCHhhJ7jJ3O8zuHdXkrEQowX74P1xwXvvzwbWYE+POf4dkXHAy+NBYee4zGU29j1+FY+OADaN0aBgyAn3+2RnRVRZKycCG88w7cfjusWuX/84tIUNSUOjRU+PJ9bJ+yPazLW4lQgPnyfUTOjQzrD1WhG26AWe/Gw5130njk2aSnQ+bpf4I6dax1ONq1s8bV9+4Nixf7d5j7xx+TN+UxdmUnWomXoREmIuGgJtWhocCX72PHAzvCuryVCElA1K4Np50GIyY1YN+cr6BjR2uHzQYrV8JZZ0G/fv57w99/ZxbXc9mnI/13ThERCTtKhCQgDANWrIDYWGjSrwl/il7HA/d52f5tKlx/PdSqBfHx/nvD339nDV3ZsCcR85FH4Y03/HduEREJG0qEJGASE+Htt61V6sePN1izzkbb/nW53pzJnp8Ow7p1fPIJdO4MH4//HF580Rr5dd11kJFRuTfbvZt1dCa7IIJd9zwPr71WNRclIiLVWvjOkCQhq2VL63HttfDbb/CPf1iDyWJjwemEqy8r4Jpn+/Atk2jPJutF69dbHa2bNTvxG7jdePfsYwMdiIzwsrGgPU3Wr7M6ZauvkIiIHEUtQhJUzZrBvHmQlgbffGMt1jr9wcPc2v0bznct5Pe/PgR168Latday9nffbb1w92648EL49dfSJ01N5Vda4MHBwHNNNkZ0hdRUWL48kJcmIiLVgBKhADOcBgXnFmA41TJxtDp1oFMn6/YZ9evzwPfDOPe6hgz44h52vfc9DBiAiUHqo6/Al1/CLbfARx/hOPdcGi5dCgUFxSfbvZsf6cTpEVvo3M3BxqZDrO3qJyRS7akODSzDaZA8Jjmsy1uJUIDZo+zk3pKLPSp8J6fyB5sNnn8eBg+G9sOaManrInp1zqexfQ/rk86Cp5+Gli0xdu+mx5NP4qhTB849Fz77DLp0Yd1Nz9Lp3Hq0bw8/OTpbJ33nnZIJk4hUO6pDA8seZafty23DuryVCAWYN9dL1DNReHO9wQ4l5NlsMGMGLFhgrVx/+dVOxt9i48a/2vCmNIb163Hfez/fxAyA/Hz48kt+Pm8S6TdM5sfUenQ+kght3J2AmdwADh2Cjz8O9mWJyClQHRpY3lwvP9/wc1iXtzpLB5hhM/DV8WHYwreZ0d/69LEeADk50KED3HYbXHxxFA8uvY/F2TYuOjedbjnf8uDyc2j8eQ5ZNrj1Vmsuxawsgz0jbqbh64/DkCHFJ05Lg1dfhR07wOWCKVMgJiYo1ygiFaM6NLAMm4GrkSusy1uJUIDZXDbyR+Rjc6kx7mRER1tD8B96CC6/HIYPhxEjFvLf/57D6zuGsPzrXBZ9HcnDT0CXLhAVBS1awMbzb6dh36bFic727daM1gcOFJ/c54MnnwzKdYlIxagODSyby0bzKc2DHUaV0icpwLzZXqKnROPNDt9mxqrWq5d1h+vAAXjhBS/16+fw4YdeNm+GnmdEcfu9Lg4ftjpgA5xxBlx0hYsBM68rXnbsk0+sE3TqBH/9q7XtP/+BDRuCck0iUjGqQwPLm+1l3eB1YV3eSoQCzPSaONc6Mb1aDd3fjp4iyH5Uv74XX4TvrYFnnHEGPPYYbDqQhDlzFqxebfXKvuQS8Hrh//4v4HGLSMWpDg0s02tyeMHhsC5vJUJlmDFjBu3bt6dnz57BDkX8wG6H00+3ugB9+il88QV0e2IEo5eMwrQdyZimTYOEBBg0qPiFGzbAxInWvTi3Oxihi4hIFVMiVIbx48ezceNGVq5cGexQxM8GDLCmIdq2zfp30iSrMahhnya888gWuOqq4oO//966XTZihDUV9r33WrM+Hj4ctPhFRMS/lAhJjdSggdU69MYbVl+iRx6BcffX5fKxiUX9p3NbdmD+Rc/xc50/w65d8PDD0K+fNetjo0bqTyQiEgY0akxqrI4dYf/+4r5FQ4fCuHHQpo2VHO3a1Yu6dXuRXvBX/nvXF5y19SVYutRaruPwYWjVqvhks2ZZ8xR16QJ/+pOG4YuIVBNKhKRGO7qDdf368O67Vq7jdkPjxnDaafDqqwbDbxnI448P5OY5YM/Lhs2bITKy+MX//jds3Gj9XKsW3HijNb6/WzdrZkgREQlJqqEDzBZpI2d8DrZIFX0oMgxrZNk551iTMRoGjBoFH31k9afu2xcWLo/hQONuvPsuvPce/LTeZx10ySXWLbM//oAnnoCePa3njz0W5KsSCR+qQwPLFmmj9Uutw7q81SIUYLYIG+6BbmwR4fuhCkdnnw3r1xf3nT50yLq15nTCTz/Z+OCDfzBoMkx90seOr3fQ5LclTPhtMpF798JvvxWfKCMDVqywbqHVqxesyxGptlSHBpYtwkbKDSnBDqNK6ZMUYN4sL7ETYvFmhe/kVOEqOhruustakWPfPli3Dn74AV5+2UqOLrkEnn/BRlT75syJGMngbvvZ+ewn/HrJP4pH369YYa0kW78+tG0LDz4Ie/cG9bpEqhPVoYHlyfLw/enf48nyBDuUKqNEKMBskTbyRueFdTNjuIuJgbp1i59ffbU1OfX+/bB8OfzrX7BsGdRJstF03HmcNrQVnTvD4sVAXl7xPbfNm+H++6FZM+sES5dakzqKyHGpDg0sW6SNVlNbhXV5h++VhSjDYeDp6sFwhO8CdjXR449bSVDh3a7oaKv/UEYG5OfDmDHWumjXvXsBqV9vtvoRvfYa/PnPUFBgTX99xhnw88/FJ920CVautI4VEUB1aKDZHDYSBydic4RvuhC+VxaiPBke4kfE48kI32ZGsRgGxMVZ/YgmT7YGlWVnQ5MmMOTyeMavuJZbuy1j5zsr4LrrrGH37dsXn2DCBGthtZQUa1z/vffCbbfBBx9AZmbwLkwkiFSHBpYnw8PS+KVhXd7qLB0ERq7+kqmJGje2Wom2bYMPP7Rupe3YAV3H9uaee3pT0M6k/7cGffseeYHTac38uHcvPPdc8YmeesrqbL1mTeAvQiQEqA4NLG9meN+yVyIkEmAtWlhLexR66y145RWoVcvgwYes7kI7dsA3a/5HkyYmlw3/lcl5j2CLcmHa7PzfnI78YXbmGe+RxWUXLbLmLEpMtO7B9egBERFWh+zGjUvOdyQiIiUoERIJsquuKl7i7Mcf4Y47oHt36y7Yrl0G99zTii9Pm8Xf/w7ffguzI01q5cHIkTBzJkRER0NamvW4446SJ3e5rP5H111nPT90CDweDd0XETlCiZBICOnUCf73v5Lbhg2zhu1ff73Vx2jRIoPkZGtJkObN4doru+EduZ/2tp8Z+et92A4esEanpaZaLzi639HMmfCPf1gv7NLFGrGWmGj1QzrvPKsVSUSkBlEiJBLiEhLg2WdhxgxrdL3jyG/tDz/AJ5/A++87iYmpywOf1uX1Fot49GXo3Rs2bTTZuWwnzWOb0OrIbTTTBDAwtm+H7dtLvlGdOlbydITx+edWj+++fSE+vnhov8sVkOsWEQkEJUIi1YRhFCdBYC1hdsEF1gOsIfxTpljzNTockJNj0LRpU377G0RFQdeu8NNPfyex9W18dvdymmesszojpafD2rXWUP1Vq6BbNwyPB/ukSbBzZ8kgbDZr/bQLL4R77rG2FRTAnDnQsKG1NomhjqwiUn0oEQowe4ydzKczscfYgx2KhJm4OHjySXjoIau1qHt3a/JHj8caYLZmDZx+OsybZ6fvHf0ZObI/2KFNH6g1FL77KptfHongYLqd05s14qwhlxD36TzYvbv4TXw+6+S1axdvs9utTtpeL/TvbzVH7d9vPQoKYPRoa9ZJET9QHRpY9hg7PTf0DOvyViIUaDbwJfk0g5NUmehoa27GQg6Htf5rz57W8759rW5D69ZZec2sWXD4MPTuHUP/s8Dp9DJ1ahvmHJ7KxRdPo20rD/mZBYy+zkPDmD+sabOjoorOb9rsGMOHW52bli61HkcbPLj45x9/tNYiMQyrZWn0aGuagNRUa92SoUOtpUdEjkd1aGDZwNXYFdblrUQowLyZXhKuSsCb5oU6wY5GaiLDgJtuOv5+t9tHo0ZfU6fOebz/voO1Gxykpzt4qh888UQ83bpdxTffwDPtrPVko6Ph8cc/oNlf9jPtvsNc0Hw9fz33V3bYW/Du2pZ8M78Vt/3pSHL244/w66/WG23dCu+8U/LNO3UqToRefdXqJd6sWfGjYUOrmSsqyloJt3Ctk40brdt2SqLCnurQwPJmelmWsIx+6f1wxIdnyhCeVxXC7HF20t9Kxx4Xvs2MUv0ZBvzpTyb9+xdve/ttqx/Sjh3WoLN777UadTZvhltvhYyMeowdW4+HXmvDM6mwZYvVZahRS7jySqsF6nvjfFaM3MmFvVPpvuZljP99Zt3TS04uWoj20CFr4uy4n/aSuHevNaHkt9+WDnLp0uJE6MUX4T//sZYsSUmBrCzr38REa/+//lX8uh9+sDK49u1LjqiTakF1aGDZ4+z0S+8X1uWtRCjQfGBLs4Ev2IGIVM6VV1qPY7VtC0OGWF2EoqOtySLffddaW61RI2uk2l/+Yt2a++OPWgwcWIv/3NGYfv168sr31uTZhRYutEbxezxgmnfSrvnfGN1vC3/r8CX2HdvI351GVEE65ORAUlLxC3v3BpsN85tvOLar9mZa0/T2+4hMiiU/H3JuvZ/a335m7ezRw2qFcrth9Wor4M8/L37xkiXWKLmYGDhwwOpY7nJBq1bWQx3DA091aGD5IH9XPtFtoyFMcyElQgHmzfYSd2sc3qu8oAl/JUwcPaK+bl24+ebi54YBL71kjWibNMm6w/XHH3DLLdYs2xER1muuu87q7P3KK3DttXDwICxaFMWUKZ2YsbQT6elWn6b337daol54Ab681VqbNiZmBLkNLmPfPrimx2Yev2INSRnb2Lgtkh5vTuS8MfD6XGtOpo3r5vBZ+/F0++Vtq3Xohx+KYi0wnbz/tpW4OQwvjBgBe/aUfdF33w0PP2z97PNZM1x+/701k3fdutaklXXrYktMJMlut9680IEDVkvYvn1W/yiv1yqY5GTrFp8cl+rQwPJme1nZYaVujdU0M2bMYMaMGXi94b2+ikigJCbC008XP69VC954A/7v/6wc4qefrP333mslQWBNa/SXv1gj9T/80MoT1q+3WpoiIqBzZ2tlkXvvteaPjIhwEBsLDz10Om0eOp1HH4Xn3oeRN8D8+dCxozUn04T/i2fAP1+nZduZZOzLY/qQTxl22hYOt+7FpdP68fXV8M03MP3/9lutPg4HZGezIuYcPvMO5t46z+Lc9KOV9BTaupXlb/zKK9zO5bzDYBYU7bID9YZfgNdr9Qvn99+tpU/KEhEBjz4KkydjmmB8sdCaSfPwYejXz7roH36w+kj16WNNSd6ihfXanTut+5RZWdYM4q1bw2mnWUmZ221lq2rBEilFiVAZxo8fz/jx48nIyCAhISHY4YiErcIuOh06wBVXlH2M0wmXXWb93LOnldBkZ8OZZ5b9vf7hh/Dxx1a/paQkq+vQli1w553w8stWV6R+/eDQIScHDji5fNKVdOsGa5+As86y+jKdfTakpTVgp+drmvWzRtrdcYeVU6xuPJpn52RRK/Vn4rEadW76azKLIhfzlwFpXL7kOro3PciuAy72ZUThwEPGp1HEp9iYPx8afL+KC1hFMqnc6XiS/g224jUcvLBrGP0LvqZTQgL33mst0PvOnXU4ffduDlCXugsWYCwoTrD47DPyu/Rmj9GC5s2BN9+0MstjGYZ1f3LvXqvFCaxk64UXrNar9HQrAevSxcoUPR6YPr3o1qM5fwGr391Gtz4ujObNoGlTazLOtWuZsa4fH+7qzsf/c2hJO6m2lAiJSLVSOA1AeYYPh0GDrDtOERHW/Ekff1y8/8wzi3/u29fqCvT001aDi2FYM3a/+qo18n/tWpg6FWbPhnPPhUsvhaanxwI9aNAA8vNh4MB4ftsNiYkpPLAL3n03mXbtrC5HeXlufvjhKzIyzmbwYDuJiRdy5tX5NEhuz4WvDKVtQwOvF/b6TO5ONxm9uoDZb1stY33GdyWhbj67D0TQOXkfN7RcxKgr84j1ZfDzwl2MuOMMNv1q3S4cZhh4mp+Go06CNc/T5s1W65PPhwc7W1dl02aY1QK38LvadNuZSz2OmjBz167inx99tCgRmvufVEb8byz/eflWxvJXbudfZBNDA7L5D21p2s7k1lut/upMnWolWAUFVjNgQYF1669+fSvReuON4vcYN85Kwlq3tt4rM9N6np1tNf8dvTLxG29Y2XLnztYFiPiTKceVnp5uAmZ6errfzpmTlmMuYpGZk5bjt3PWZAUFBeaHH35oFhQUBDuUsKEyPTGPxzQPHjTNJUtM84svTNPnO/6xR5fn1Kmmedttpun1WvvS003z3/82zQcfNM3cXNOcOdM0Y2JM86uvrP3ffGOaX35pmgcOmOasWabZvbtp1q5tmq1amabdbpq3326ab7xhmtHRptm7t7WtUyfTvOce01y50jRzM93mryv2m/36uE3D8JmdOplm+/ammVjLa9aOd5u3j9hptm+Ra6Yk5Zl3DvzB/OWOl03zP/8xzcOHTdM0zf37TTMpPs+8s8v/zGhbrvmnyNVmV2O1OSHmFbNbra3mN71vM3f85jPr1DHNc881zVFNvjR30dA0wdxJI3MHjU3Tao+yHlu3FhdMw4Yl9x396NXL9PlM8+GHTXPhQtM0Gx85j8NhuolWHepHJ/p9d6e7zUUsMt3p7gBHdmoq8/2tFiERkUqy260Gj6OnF6iI224r+Tw+HiZPLn5+/fVWS1DhUip9+xbvGzXK6o/9zTfWoLnOnYvXyG3YELZts1qxVq+G//7Xur2XmekA6nLDDfD+f63tpgkjR9qYP9/GrFmNueN+q0Fm1qzudJjWnbZtIfMpyM21+m2fOdDFY+8Oof3r8P77XXl1tkl8QtcjUU0FrJkMvv4avnq3MwO8W7jz2j1M+k8T3F4b1194mAauQ+w/YHDg9iZExlmNOxfePJXEglRufaMn36S2pEFMBvvya5HlieSVbkv4+d/Wbc2cHHi4zSPcmnYzttxsIMJ6612/Q53TKvcfIFIGJUJBYEaZwQ5BREKUo5xa2TCs/k3HGjDAegC0aWMNdisosEbnuVxW1x+AG24ofs3w4daj0LBh1mC2RYusvlDR0dYqKYXnvfbawo7spTtmtWtnPW66qQ5jx8LE6S159XUrliefTGKrL4l6HaFbXevO19dfw90LLsflss7/youwf3896tWzBuldNW4Ypmkd53bD5Zdfy+ttr2bciD+Ie+lpkrfkYHv/fehyR0WLVU5BOM8hBEqEAs4R7yBjTkbYDkMUkdAQEWGN4K+MunWtkXgny2azugg98URx8jVrVtnHHjhgTX3Qv3/pTu/du1sD37p3t55v3gxPP23j9U8T+TXt74zgWfp/8AY8qESoqjniHfTPqGTTZzWjCSsCzPSYONY4MD1qFRKR8GMYxUlQeerWtZZdKWvkX/v2JVu+oqKsUXuLF8PLz7tZw2Xk9jzD6qkO1v2zTZus5qx9+/xyHWLxeXwcmn8Inyd8O6mrWSLAfHk+ImdG4vubD6JOfLyIiBTrf04UBxyb+aj/VK50ueD1163ZOI/WsKE1DYBhWMPZCu8BLl1qddTat88aUmi3W486daw5ox55xPoXYM0aeOwx6+e0NKsjVXS0NU9TQgKMH2/N7AnW2jP//a812s1ms5rjmja1pitISLA6bBV26Fq71orD4bCOa9XKOiYz04qlQwer8xjA7t3W/cGDB63Z0xs1suaC8Hqte57du1M0b8HmzVZHsY4drevPyLCu89AhK5Ns04Yy5zjweLDn51vl5XBYncgMoyhD9aXnsXXSVrp91w1bbHi2nSgRCjB7rJ2s6VnYY8P7nquISFVwxttZeFUc22c5SWoMh3/pTEP6UDu6gKg60UTu+gVjt5vD1CaaHFLcJhmHrL5JDbbtxLtqPb/RjLocoDaHySIWY0casatXw8UXFydCixbBvHkA5BOBi4KSgRw98VX9+rBihfUoy1dfFSdCCxfC7bcX7cokFgOTWLKtDcuWWWvmgfX+x/awP9rmzdb0AwBvvQUPPnikkJxW56qjrV9vJVkAr70G06ZBdjaO7ds53+OxthcmQLt2WWv1AY5XnqHX/ifgweutCTyTk63E8NdfrekOjk5C16+3Xh8RYfW2dzqtx9at1qSgV11VfOyePVbyl5ZWfL1BokQowHwFPpwLnfjO9YEz2NGIiFQvvgIfF9j3cPP6towdC4m1O7A7eRnpmQa5u42iJciiIn3kFxj4LrVaNgwD7Par8NmuwmE3KXDbiHD6KHBbrRxxrnxS7jRJfNpq9LEV3Exy64v4Ja0O2w8l0KFBGskxWfycVod4Zx6tnowlf6rVkBIfeTVxZ55FZH4GOw7HcyDTRZyZgSffR3aBgzZP1KfZfKvz+S/fXs8vrps4PW4XyY40/ruvN3a8XBv3X3q41pO0qiG2w0caZH5tg3H6PzCiozB+2sDvuXVYEXsudSPS6eb4kfjFLiL3Wg09ZkE3PM2vxb1jDza3m3gySIjxElk7ii3ZKexbkkztvdZox5j5O9iwtiU/0ok9pBBFLm35mXbmJhqZv5O5KB2jXQq1a4Nj8W/kpZ1FyyemYXviiZL/GXFxVg/6wvubN910/GSwdu2SidCNN8Jnn1kJ1+7d/vuAnAQlQgHmy/MRPSMa3wM+iAl2NCIi1Ysvz0edWU5+O1BAdFIUR3d1NU2rIcQ0weWy4XZbE2rXrm3dHdq1y8DhgEaNjCN3jmwkJRVOvO1izx7rTlJcHHg8Uezd24IWLayFhVeuTOLgwSTatYP09Di2bbPO6XBAZmYEGRnNyMmBbk2t/k+ZmQ1wOq1jNm60GlkaN4YBA5I47TRYty6BnTthxZVWV6dXXrmat7ZC2sziOSNNcygmQzGzgWYmdZNM/tTHxoE0eOJHyP6PtbxMbi4YxoU4HBfibObDW+AjI8dOerqB93frjlrKq9YowkOHICP9btq1yKLradmktI5k47b9bM27iX//Ymd3qp2Eidb7HzoEkb6n+ZRlXB3zKKe512IWFOBzRuKLjcOMicN3sQ+fceQOx+7pGBGp4DMx7AaGzwc+L0ZMNEZcAsYVxY1Oxne3YtiuxciN57J38rnw8qMWLAwwJUIiIlLtlNXJuvCuTCGnE5o0KX7evHnxzwkJJTt116lTfOeoLEefp7Iuvrj0tj59Sj4/8YzpBmVNXVCajcLksDAxPLpMio+JB+Jxu9189tkShg1rgdNZMiUwTfBkwDe14O/Tm7FtXyts+LA5bNhsVnkX/msYYJ7Vo2hWzMLXH/fReXDRz0kNK3BZVUiJkIiISBg6NjE8mdcXJpyXXAqOeAjHwebhd0UiIiIiFaRESERERGosJUIiIiJSYykRCjDDbuDu4sawV6TTm4iIHE11aGAZdoPag2qHdXmrs3SA2WPs5EzJwR6jCRVFRCpLdWhg2WPsdJ7fOdhhVCm1CAWYL9+Ha44LX374rtsiIlJVVIcGli/fx/Yp28O6vJUIBZjpM7EdtGH6tOiqiEhlqQ4NLNNnkv97fliXt26NBZg9yk7uLbnYo9SsKyJSWapDA8seZafty22DHUaVUotQgHlzvUQ9E4U31xvsUEREqh3VoYHlzfXy8w0/h3V5KxEKMNNtEvFFBKY7fJsZRUSqiurQwDLdJqmvpIZ1eSsREhERkRpLiZCIiIjUWEqEREREpMZSIiQiIiI1lobPl8M0rc5hGRkZfjtnbmYu2WSTkZmB2+n223lrKrfbTU5ODhkZGTidzmCHExZUpv6l8vQv1aH+daLPpyfDY5V3RgaOapQyFH5vF36Pl6f6XFUQZGZmAtC4cWP/n7y5/08pIlJjqA4NrCr4GgyEzMxMEhISyj3GMCuSLtVQPp+PPXv2EBcXh2H4Z8G5jIwMGjduzK5du4iPj/fLOWsylaf/qUz9S+XpXypP/wrX8jRNk8zMTFJSUrDZyu8FpBahcthsNho1alQl546Pjw+rD12wqTz9T2XqXypP/1J5+lc4lueJWoIKqbO0iIiI1FhKhERERKTGUiIUYC6Xi/vvvx+XyxXsUMKCytP/VKb+pfL0L5Wnf6k81VlaREREajC1CImIiEiNpURIREREaiwlQiIiIlJjKRESERGRGkuJUIA9++yzNG/enMjISLp3787SpUuDHVK1MGXKFAzDKPFITk4u2m+aJlOmTCElJYWoqCgGDBjATz/9FMSIQ8uSJUsYPnw4KSkpGIbBhx9+WGJ/RcovPz+fCRMmkJSURExMDBdccAG///57AK8idJyoPEeNGlXq8/qnP/2pxDEqz2KPPfYYPXv2JC4ujnr16nHRRRexefPmEsfoM1pxFSlPfUaLKREKoLlz5zJx4kTuvvtu1qxZQ//+/Rk6dCg7d+4MdmjVwumnn87evXuLHuvXry/a969//YupU6fyzDPPsHLlSpKTkxk4cGDRenE1XXZ2Np07d+aZZ54pc39Fym/ixIl88MEHvP322yxbtoysrCzOP/98vF5voC4jZJyoPAGGDBlS4vP62Wefldiv8iz29ddfM378eFasWMHChQvxeDwMGjSI7OzsomP0Ga24ipQn6DNaxJSA6dWrlzl27NgS29q2bWveeeedQYqo+rj//vvNzp07l7nP5/OZycnJ5uOPP160LS8vz0xISDCff/75AEVYfQDmBx98UPS8IuX3xx9/mE6n03z77beLjtm9e7dps9nMzz//PGCxh6Jjy9M0TXPkyJHmhRdeeNzXqDzLt3//fhMwv/76a9M09Rk9VceWp2nqM3o0tQgFSEFBAatWrWLQoEEltg8aNIjly5cHKarqZcuWLaSkpNC8eXOuvPJKtm3bBsD27dtJTU0tUbYul4szzzxTZVsBFSm/VatW4Xa7SxyTkpJChw4dVMbHsXjxYurVq0fr1q258cYb2b9/f9E+lWf50tPTAUhMTAT0GT1Vx5ZnIX1GLUqEAiQtLQ2v10v9+vVLbK9fvz6pqalBiqr66N27N6+99hrz58/npZdeIjU1lb59+3Lw4MGi8lPZnpyKlF9qaioRERHUrl37uMdIsaFDh/Lmm2/y1Vdf8eSTT7Jy5UrOPvts8vPzAZVneUzTZNKkSfTr148OHToA+oyeirLKE/QZPZpWnw8wwzBKPDdNs9Q2KW3o0KFFP3fs2JE+ffrQsmVLXn311aIOfirbU3My5acyLtsVV1xR9HOHDh3o0aMHTZs25dNPP+WSSy457utUnnDLLbfw448/smzZslL79BmtvOOVpz6jxdQiFCBJSUnY7fZSmfT+/ftL/ZUjJxYTE0PHjh3ZsmVL0egxle3JqUj5JScnU1BQwOHDh497jBxfgwYNaNq0KVu2bAFUnsczYcIEPvroIxYtWkSjRo2KtuszenKOV55lqcmfUSVCARIREUH37t1ZuHBhie0LFy6kb9++QYqq+srPz2fTpk00aNCA5s2bk5ycXKJsCwoK+Prrr1W2FVCR8uvevTtOp7PEMXv37mXDhg0q4wo4ePAgu3btokGDBoDK81imaXLLLbfw/vvv89VXX9G8efMS+/UZrZwTlWdZavRnNDh9tGumt99+23Q6neYrr7xibty40Zw4caIZExNj/vbbb8EOLeRNnjzZXLx4sblt2zZzxYoV5vnnn2/GxcUVld3jjz9uJiQkmO+//765fv16c8SIEWaDBg3MjIyMIEceGjIzM801a9aYa9asMQFz6tSp5po1a8wdO3aYplmx8hs7dqzZqFEj84svvjBXr15tnn322Wbnzp1Nj8cTrMsKmvLKMzMz05w8ebK5fPlyc/v27eaiRYvMPn36mA0bNlR5HsfNN99sJiQkmIsXLzb37t1b9MjJySk6Rp/RijtReeozWpISoQCbMWOG2bRpUzMiIsLs1q1bieGMcnxXXHGF2aBBA9PpdJopKSnmJZdcYv70009F+30+n3n//febycnJpsvlMs844wxz/fr1QYw4tCxatMgESj1GjhxpmmbFyi83N9e85ZZbzMTERDMqKso8//zzzZ07dwbhaoKvvPLMyckxBw0aZNatW9d0Op1mkyZNzJEjR5YqK5VnsbLKEjBnzZpVdIw+oxV3ovLUZ7QkwzRNM3DtTyIiIiKhQ32EREREpMZSIiQiIiI1lhIhERERqbGUCImIiEiNpURIREREaiwlQiIiIlJjKRESERGRGkuJkIhIJRmGwYcffhjsMETED5QIiUi1MmrUKAzDKPUYMmRIsEMTkWrIEewAREQqa8iQIcyaNavENpfLFaRoRKQ6U4uQiFQ7LpeL5OTkEo/atWsD1m2r5557jqFDhxIVFUXz5s2ZN29eidevX7+es88+m6ioKOrUqcNNN91EVlZWiWNmzpzJ6aefjsvlokGDBtxyyy0l9qelpXHxxRcTHR3NaaedxkcffVS1Fy0iVUKJkIiEnXvvvZdLL72UdevWcc011zBixAg2bdoEQE5ODkOGDKF27dqsXLmSefPm8cUXX5RIdJ577jnGjx/PTTfdxPr16/noo49o1apVifd44IEHuPzyy/nxxx8ZNmwYV199NYcOHQrodYqIHwR71VcRkcoYOXKkabfbzZiYmBKPBx980DRNa+XtsWPHlnhN7969zZtvvtk0TdN88cUXzdq1a5tZWVlF+z/99FPTZrOZqamppmmaZkpKinn33XcfNwbAvOeee4qeZ2VlmYZhmP/73//8dp0iEhjqIyQi1c5ZZ53Fc889V2JbYmJi0c99+vQpsa9Pnz6sXbsWgE2bNtG5c2diYmKK9v/5z3/G5/OxefNmDMNgz549nHPOOeXG0KlTp6KfY2JiiIuLY//+/Sd7SSISJEqERKTaiYmJKXWr6kQMwwDANM2in8s6JioqqkLnczqdpV7r8/kqFZOIBJ/6CIlI2FmxYkWp523btgWgffv2rF27luzs7KL933zzDTabjdatWxMXF0ezZs348ssvAxqziASHWoREpNrJz88nNTW1xDaHw0FSUhIA8+bNo0ePHvTr148333yT77//nldeeQWAq6++mvvvv5+RI0cyZcoUDhw4wIQJE7j22mupX78+AFOmTGHs2LHUq1ePoUOHkpmZyTfffMOECRMCe6EiUuWUCIlItfP555/ToEGDEtvatGnDzz//DFgjut5++23GjRtHcnIyb775Ju3btwcgOjqa+fPn87e//Y2ePXsSHR3NpZdeytSpU4vONXLkSPLy8pg2bRp///vfSUpK4i9/+UvgLlBEAsYwTdMMdhAiIv5iGAYffPABF110UbBDEZFqQH2EREREpMZSIiQiIiI1lvoIiUhY0d1+EakMtQiJiIhIjaVESERERGosJUIiIiJSYykREhERkRpLiZCIiIjUWEqEREREpMZSIiQiIiI1lhIhERERqbGUCImIiEiN9f9uDHlJSCUOHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting losses\n",
    "dir_name_plot = dir_name_ae + '/plots'\n",
    "if not os.path.isdir(dir_name_plot):\n",
    "    os.makedirs(dir_name_plot)\n",
    "\n",
    "# Visualize loss history\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_loss_hist,\n",
    "    val_loss=val_loss_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list\n",
    ")\n",
    "\n",
    "plt.savefig(dir_name_plot + '{ds}loss_history.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_MSE_hist,\n",
    "    val_loss=val_MSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training MSE', 'Validation MSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='MSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/MSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_NMSE_hist,\n",
    "    val_loss=val_NMSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training NMSE', 'Validation NMSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='NMSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/NMSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1666788877562,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wwt4brHcOaXi",
    "outputId": "7ba39105-aa8e-49e8-dbfd-619069123fdd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1kzRwBdNfA2o28NxHkc2fku7QnFPAI8Bo"
    },
    "executionInfo": {
     "elapsed": 4835,
     "status": "ok",
     "timestamp": 1666788882395,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "_6rNhThyQrKc",
    "outputId": "fdeeb3f5-009a-404e-8856-b7655d596a88"
   },
   "source": [
    "# POD Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 17515,
     "status": "ok",
     "timestamp": 1666788899903,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "cAiMV0iU0EpK"
   },
   "outputs": [],
   "source": [
    "pod_training_data = np.empty(shape=(training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "pod_training_data[:, :] = np.reshape(training_data, (training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "\n",
    "pod_centering_means = np.mean(pod_training_data, axis=0)\n",
    "pod_mean_centered_data = pod_training_data - pod_centering_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = np.transpose(pod_mean_centered_data) @ pod_mean_centered_data\n",
    "C /= pod_mean_centered_data.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1666788900494,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "jVqsAwsY0Amw",
    "outputId": "95dd7bc9-f2b0-421e-a1b4-3e7e594cd44a"
   },
   "outputs": [],
   "source": [
    "eigenvals, eigenvecs = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2127,
     "status": "ok",
     "timestamp": 1666788902619,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wjgPNitSrt5p",
    "outputId": "d60c9340-28f4-479b-8b66-5ee2a5fc5cee"
   },
   "outputs": [],
   "source": [
    "abs_eigenvals = np.abs(eigenvals)\n",
    "idx = np.argsort(abs_eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 5242,
     "status": "ok",
     "timestamp": 1666788907858,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Jv8PgBgzV1_s"
   },
   "outputs": [],
   "source": [
    "idx = idx[::-1]\n",
    "W = eigenvecs[:, idx[0:4*4*enc_filters[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666788907859,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wnLnqg0Jrt5t"
   },
   "outputs": [],
   "source": [
    "reconstructed_val_data = val_data.reshape(val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]) @ W @ W.transpose()\n",
    "reconstructed_val_data = np.reshape(reconstructed_val_data, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_recon_MSE = np.reshape((reconstructed_val_data - val_data)**2, (val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "val_recon_MSE = np.mean(np.sum(val_recon_MSE, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33.50498242976434+0j) (0.060308983097448636+0j) 555.5554\n"
     ]
    }
   ],
   "source": [
    "print(val_recon_MSE, val_recon_MSE/np.sum(time_stddev**2), np.sum(time_stddev**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141.06480022, 127.16714509,  98.61910161,  91.65162949,\n",
       "         5.56133   ,   5.22346317,   4.68067162,   4.42568335,\n",
       "         4.19825384,   4.0372301 ,   2.4475167 ,   2.31831582,\n",
       "         2.13058072,   1.98340622,   1.86565824,   1.82063678,\n",
       "         1.80347498,   1.75448435,   1.72730789,   1.65783234,\n",
       "         1.62272897,   1.56117176,   1.50364009,   1.32153963,\n",
       "         1.24070886,   1.21754198,   1.19416454,   1.17101344,\n",
       "         1.15816117,   1.14939802,   1.13011238,   1.09943646])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_eigenvals[idx[0:4*4*2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KE and Dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
