{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ad0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg, fft\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "plt.rcParams.update({\"text.usetex\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c93738",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577cbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da48a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86279bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/Kolmogorov\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6626956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ae_v5 import Autoencoder as ae_org\n",
    "from tools.ae_v9 import Autoencoder as ae_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbb0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 03:38:13.349230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.349496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.383952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.384223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.384424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.384615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.385545: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 03:38:13.386175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.386391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.386592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.956126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.956358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.956552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-14 03:38:13.956730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3365 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 1\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8afec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6117a",
   "metadata": {},
   "source": [
    "# Loading and Converting AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151acdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_all_ae = os.getcwd()+'{ds}saved_ae'.format(ds=dir_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62bd729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ae_036', 'ae_038', 'ae_037', 'ae_031', 'ae_035']\n"
     ]
    }
   ],
   "source": [
    "all_ae = os.listdir(dir_name_all_ae)\n",
    "chosen_dir_list = []\n",
    "\n",
    "for dir_name in all_ae:\n",
    "    with open(dir_name_all_ae+'/'+dir_name+'/ae_data.txt', 'r') as f:\n",
    "        try:\n",
    "            ae_dict = eval(f.readline())\n",
    "            if ae_dict['module'].endswith('ae_v5'):\n",
    "                chosen_dir_list.append(dir_name)\n",
    "        except:\n",
    "            print(dir_name)\n",
    "            continue\n",
    "\n",
    "print(chosen_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b340fd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae_038\n",
      "ListWrapper([5]) <class 'tensorflow.python.training.tracking.data_structures.ListWrapper'>\n",
      "[5] <class 'numpy.ndarray'>\n",
      "[TensorShape([50, 50]), (24, 24)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6), (3, 3)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6), (3, 3), (3, 3)]\n",
      "0 -- kernelsize : 5 -- 0 / 4\n",
      "(3, 3)\n",
      "0 -- kernelsize : 5 -- 1 / 4\n",
      "(3, 3)\n",
      "0 -- kernelsize : 5 -- 2 / 4\n",
      "(6, 6)\n",
      "0 -- kernelsize : 5 -- 3 / 4\n",
      "(12, 12)\n",
      "0 -- kernelsize : 5 -- 4 / 4\n",
      "(24, 24)\n",
      "(59, 59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 03:38:15.816954: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([5]) <class 'tensorflow.python.training.tracking.data_structures.ListWrapper'>\n",
      "[5] <class 'numpy.ndarray'>\n",
      "[TensorShape([50, 50]), (24, 24)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6), (3, 3)]\n",
      "[TensorShape([50, 50]), (24, 24), (12, 12), (6, 6), (3, 3), (3, 3)]\n",
      "0 -- kernelsize : 5 -- 0 / 4\n",
      "(3, 3)\n",
      "0 -- kernelsize : 5 -- 1 / 4\n",
      "(3, 3)\n",
      "0 -- kernelsize : 5 -- 2 / 4\n",
      "(6, 6)\n",
      "0 -- kernelsize : 5 -- 3 / 4\n",
      "(12, 12)\n",
      "0 -- kernelsize : 5 -- 4 / 4\n",
      "(24, 24)\n",
      "(59, 59)\n",
      "\n",
      " encoded_vec_wts :  [1.0]\n",
      "\n",
      " decoded_vec_wts :  [1.0]\n",
      "post_setting : ae_net_new.encoded_vec_weights[0] :  [1.]\n",
      "post_setting : ae_net_new.decoded_vec_weights[0] :  [1.]\n"
     ]
    }
   ],
   "source": [
    "for dir_name in chosen_dir_list[1:2]:\n",
    "    print(dir_name)\n",
    "    dir_name_ae = dir_name_all_ae + '/' + dir_name\n",
    "    \n",
    "    load_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_class_dict.txt'\n",
    "    wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'OLD_final_net_ae_weights.h5'\n",
    "    \n",
    "    ae_net_new = ae_new(load_file=load_file)\n",
    "    ae_net_org = ae_org(load_file=load_file)\n",
    "    \n",
    "    ae_net_new.load_weights(wt_file)#, by_name=True)\n",
    "    ae_net_org.load_weights_from_file(wt_file)\n",
    "\n",
    "    num_kernels = len(ae_net_new.kernel_size)\n",
    "    \n",
    "    if num_kernels > 1:\n",
    "        encoded_vec_wts = []\n",
    "        decoded_vec_wts = []\n",
    "        trainable = True\n",
    "        with open(dir_name_ae+'/encoded_decoded_vec_weights.txt', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[2:2+num_kernels]:\n",
    "                idx = line.find('.')\n",
    "                encoded_vec_wts.append(float(line[idx-1:]))\n",
    "            for line in lines[num_kernels+3 + 2:]:\n",
    "                idx = line.find('.')\n",
    "                decoded_vec_wts.append(float(line[idx-1:]))\n",
    "    else:\n",
    "        encoded_vec_wts = [1.]\n",
    "        decoded_vec_wts = [1.]\n",
    "        trainable = False\n",
    "        \n",
    "                \n",
    "    print('\\n encoded_vec_wts : ', encoded_vec_wts)\n",
    "    print('\\n decoded_vec_wts : ', decoded_vec_wts)\n",
    "        \n",
    "    for ks_i in range(num_kernels):\n",
    "        ae_net_new.create_enc_wt(encoded_vec_wts[ks_i], trainable=trainable)\n",
    "    for ks_i in range(num_kernels):\n",
    "        ae_net_new.create_dec_wt(decoded_vec_wts[ks_i], trainable=trainable)\n",
    "\n",
    "\n",
    "    for ks_i in range(num_kernels):\n",
    "        print('post_setting : ae_net_new.encoded_vec_weights[{}] : '.format(ks_i),\n",
    "              ae_net_new.encoded_vec_layers[ks_i].scalar_multiplier.numpy())\n",
    "    for ks_i in range(num_kernels):\n",
    "        print('post_setting : ae_net_new.decoded_vec_weights[{}] : '.format(ks_i),\n",
    "              ae_net_new.decoded_vec_layers[ks_i].scalar_multiplier.numpy())\n",
    "\n",
    "    ae_net_new.update_models()\n",
    "        \n",
    "    ae_net_new.save_model_weights(dir_name_ae+'/final_net/final_net_ae_weights', H5=True)\n",
    "\n",
    "#     if dir_name != 'ae_032':\n",
    "#         del(ae_net_new)\n",
    "#         del(ae_net_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89c76bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise_1\n",
      "periodic_padding_10\n",
      "conv2d_5\n",
      "batch_normalization_10\n",
      "activation_10\n",
      "periodic_padding_11\n",
      "conv2d_6\n",
      "batch_normalization_11\n",
      "activation_11\n",
      "periodic_padding_12\n",
      "conv2d_7\n",
      "batch_normalization_12\n",
      "activation_12\n",
      "periodic_padding_13\n",
      "conv2d_8\n",
      "batch_normalization_13\n",
      "activation_13\n",
      "periodic_padding_14\n",
      "conv2d_9\n",
      "batch_normalization_14\n",
      "activation_14\n",
      "model_3\n",
      "periodic_padding_15\n",
      "conv2d_transpose_5\n",
      "cropping2d_5\n",
      "batch_normalization_15\n",
      "activation_15\n",
      "periodic_padding_16\n",
      "conv2d_transpose_6\n",
      "cropping2d_6\n",
      "batch_normalization_16\n",
      "activation_16\n",
      "periodic_padding_17\n",
      "conv2d_transpose_7\n",
      "cropping2d_7\n",
      "batch_normalization_17\n",
      "activation_17\n",
      "periodic_padding_18\n",
      "conv2d_transpose_8\n",
      "cropping2d_8\n",
      "batch_normalization_18\n",
      "activation_18\n",
      "periodic_padding_19\n",
      "conv2d_transpose_9\n",
      "cropping2d_9\n",
      "batch_normalization_19\n",
      "activation_19\n",
      "model_4\n",
      "model_5\n"
     ]
    }
   ],
   "source": [
    "for l in ae_net_org.layers:\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75204f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_3\n",
      "--------------------\n",
      "input_4\n",
      "gaussian_noise_1\n",
      "periodic_padding_10\n",
      "conv2d_5\n",
      "batch_normalization_10\n",
      "activation_10\n",
      "periodic_padding_11\n",
      "conv2d_6\n",
      "batch_normalization_11\n",
      "activation_11\n",
      "periodic_padding_12\n",
      "conv2d_7\n",
      "batch_normalization_12\n",
      "activation_12\n",
      "periodic_padding_13\n",
      "conv2d_8\n",
      "batch_normalization_13\n",
      "activation_13\n",
      "periodic_padding_14\n",
      "conv2d_9\n",
      "batch_normalization_14\n",
      "activation_14\n",
      "tf.math.multiply_2\n",
      "\n",
      "\n",
      "\n",
      "model_4\n",
      "--------------------\n",
      "input_5\n",
      "periodic_padding_15\n",
      "conv2d_transpose_5\n",
      "cropping2d_5\n",
      "batch_normalization_15\n",
      "activation_15\n",
      "periodic_padding_16\n",
      "conv2d_transpose_6\n",
      "cropping2d_6\n",
      "batch_normalization_16\n",
      "activation_16\n",
      "periodic_padding_17\n",
      "conv2d_transpose_7\n",
      "cropping2d_7\n",
      "batch_normalization_17\n",
      "activation_17\n",
      "periodic_padding_18\n",
      "conv2d_transpose_8\n",
      "cropping2d_8\n",
      "batch_normalization_18\n",
      "activation_18\n",
      "periodic_padding_19\n",
      "conv2d_transpose_9\n",
      "cropping2d_9\n",
      "batch_normalization_19\n",
      "activation_19\n",
      "tf.math.multiply_3\n",
      "\n",
      "\n",
      "\n",
      "model_5\n",
      "--------------------\n",
      "input_6\n",
      "model_3\n",
      "model_4\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in ae_net_org.layers:\n",
    "    if l.name.startswith('model'):\n",
    "        print(l.name)\n",
    "        print('-'*20)\n",
    "        for l2 in l.layers:\n",
    "            print(l2.name)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f53529a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "--------------------\n",
      "input_7\n",
      "gaussian_noise\n",
      "periodic_padding\n",
      "conv2d\n",
      "batch_normalization\n",
      "activation\n",
      "periodic_padding_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "activation_1\n",
      "periodic_padding_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "activation_2\n",
      "periodic_padding_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "activation_3\n",
      "periodic_padding_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "activation_4\n",
      "scalar_multiplication\n",
      "\n",
      "\n",
      "\n",
      "model_1\n",
      "--------------------\n",
      "input_8\n",
      "periodic_padding_5\n",
      "conv2d_transpose\n",
      "cropping2d\n",
      "batch_normalization_5\n",
      "activation_5\n",
      "periodic_padding_6\n",
      "conv2d_transpose_1\n",
      "cropping2d_1\n",
      "batch_normalization_6\n",
      "activation_6\n",
      "periodic_padding_7\n",
      "conv2d_transpose_2\n",
      "cropping2d_2\n",
      "batch_normalization_7\n",
      "activation_7\n",
      "periodic_padding_8\n",
      "conv2d_transpose_3\n",
      "cropping2d_3\n",
      "batch_normalization_8\n",
      "activation_8\n",
      "periodic_padding_9\n",
      "conv2d_transpose_4\n",
      "cropping2d_4\n",
      "batch_normalization_9\n",
      "activation_9\n",
      "scalar_multiplication_1\n",
      "\n",
      "\n",
      "\n",
      "model_2\n",
      "--------------------\n",
      "input_9\n",
      "model\n",
      "model_1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in ae_net_new.layers:\n",
    "    if l.name.startswith('model'):\n",
    "        print(l.name)\n",
    "        print('-'*20)\n",
    "        for l2 in l.layers:\n",
    "            print(l2.name)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff841a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 activation\n",
      "1 activation_1\n",
      "2 activation_2\n",
      "3 activation_3\n",
      "4 activation_4\n",
      "5 activation_5\n",
      "6 activation_6\n",
      "7 activation_7\n",
      "8 activation_8\n",
      "9 activation_9\n",
      "10 batch_normalization\n",
      "11 batch_normalization_1\n",
      "12 batch_normalization_2\n",
      "13 batch_normalization_3\n",
      "14 batch_normalization_4\n",
      "15 batch_normalization_5\n",
      "16 batch_normalization_6\n",
      "17 batch_normalization_7\n",
      "18 batch_normalization_8\n",
      "19 batch_normalization_9\n",
      "20 conv2d\n",
      "21 conv2d_1\n",
      "22 conv2d_2\n",
      "23 conv2d_3\n",
      "24 conv2d_4\n",
      "25 conv2d_transpose\n",
      "26 conv2d_transpose_1\n",
      "27 conv2d_transpose_2\n",
      "28 conv2d_transpose_3\n",
      "29 conv2d_transpose_4\n",
      "30 cropping2d\n",
      "31 cropping2d_1\n",
      "32 cropping2d_2\n",
      "33 cropping2d_3\n",
      "34 cropping2d_4\n",
      "35 gaussian_noise\n",
      "36 model\n",
      "37 model_1\n",
      "38 model_2\n",
      "39 periodic_padding\n",
      "40 periodic_padding_1\n",
      "41 periodic_padding_2\n",
      "42 periodic_padding_3\n",
      "43 periodic_padding_4\n",
      "44 periodic_padding_5\n",
      "45 periodic_padding_6\n",
      "46 periodic_padding_7\n",
      "47 periodic_padding_8\n",
      "48 periodic_padding_9\n",
      "49 top_level_model_weights\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(wt_file, 'r') as f:\n",
    "    counter = 0\n",
    "    for key in f.keys():\n",
    "        print(counter, key)\n",
    "        counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5881c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"kernel:0\": shape (5, 5, 2, 8), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(wt_file, 'r') as f:\n",
    "    print(f['conv2d/conv2d/kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bb70e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 activation\n",
      "1 activation_1\n",
      "2 activation_2\n",
      "3 activation_3\n",
      "4 activation_4\n",
      "5 activation_5\n",
      "6 activation_6\n",
      "7 activation_7\n",
      "8 activation_8\n",
      "9 activation_9\n",
      "10 batch_normalization\n",
      "11 batch_normalization_1\n",
      "12 batch_normalization_2\n",
      "13 batch_normalization_3\n",
      "14 batch_normalization_4\n",
      "15 batch_normalization_5\n",
      "16 batch_normalization_6\n",
      "17 batch_normalization_7\n",
      "18 batch_normalization_8\n",
      "19 batch_normalization_9\n",
      "20 conv2d\n",
      "21 conv2d_1\n",
      "22 conv2d_2\n",
      "23 conv2d_3\n",
      "24 conv2d_4\n",
      "25 conv2d_transpose\n",
      "26 conv2d_transpose_1\n",
      "27 conv2d_transpose_2\n",
      "28 conv2d_transpose_3\n",
      "29 conv2d_transpose_4\n",
      "30 cropping2d\n",
      "31 cropping2d_1\n",
      "32 cropping2d_2\n",
      "33 cropping2d_3\n",
      "34 cropping2d_4\n",
      "35 gaussian_noise\n",
      "36 model\n",
      "37 model_1\n",
      "38 model_2\n",
      "39 periodic_padding\n",
      "40 periodic_padding_1\n",
      "41 periodic_padding_2\n",
      "42 periodic_padding_3\n",
      "43 periodic_padding_4\n",
      "44 periodic_padding_5\n",
      "45 periodic_padding_6\n",
      "46 periodic_padding_7\n",
      "47 periodic_padding_8\n",
      "48 periodic_padding_9\n",
      "49 scalar_multiplication\n",
      "50 scalar_multiplication_1\n",
      "51 top_level_model_weights\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dir_name_ae+'/final_net/final_net_ae_weights.h5', 'r') as f:\n",
    "    counter = 0\n",
    "    for key in f.keys():\n",
    "        print(counter, key)\n",
    "        counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6271a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"N_mat:0\": shape (24, 28), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dir_name_ae+'/final_net/final_net_ae_weights.h5', 'r') as f:\n",
    "#     print(np.array(f['scalar_multiplication/scalar_multiplication/scalar_multiplier:0']))\n",
    "    print(f['periodic_padding_9/periodic_padding_9/N_mat:0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d83b1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 activation\n",
      "1 activation_1\n",
      "2 activation_2\n",
      "3 activation_3\n",
      "4 activation_4\n",
      "5 activation_5\n",
      "6 activation_6\n",
      "7 activation_7\n",
      "8 activation_8\n",
      "9 activation_9\n",
      "10 batch_normalization\n",
      "11 batch_normalization_1\n",
      "12 batch_normalization_2\n",
      "13 batch_normalization_3\n",
      "14 batch_normalization_4\n",
      "15 batch_normalization_5\n",
      "16 batch_normalization_6\n",
      "17 batch_normalization_7\n",
      "18 batch_normalization_8\n",
      "19 batch_normalization_9\n",
      "20 conv2d\n",
      "21 conv2d_1\n",
      "22 conv2d_2\n",
      "23 conv2d_3\n",
      "24 conv2d_4\n",
      "25 conv2d_transpose\n",
      "26 conv2d_transpose_1\n",
      "27 conv2d_transpose_2\n",
      "28 conv2d_transpose_3\n",
      "29 conv2d_transpose_4\n",
      "30 cropping2d\n",
      "31 cropping2d_1\n",
      "32 cropping2d_2\n",
      "33 cropping2d_3\n",
      "34 cropping2d_4\n",
      "35 gaussian_noise\n",
      "36 model\n",
      "37 model_1\n",
      "38 model_2\n",
      "39 periodic_padding\n",
      "40 periodic_padding_1\n",
      "41 periodic_padding_2\n",
      "42 periodic_padding_3\n",
      "43 periodic_padding_4\n",
      "44 periodic_padding_5\n",
      "45 periodic_padding_6\n",
      "46 periodic_padding_7\n",
      "47 periodic_padding_8\n",
      "48 periodic_padding_9\n",
      "49 scalar_multiplication\n",
      "50 scalar_multiplication_1\n",
      "51 top_level_model_weights\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dir_name_all_ae+'/ae_038/final_net/final_net_ae_weights.h5', 'r') as f:\n",
    "    counter = 0\n",
    "    for key in f.keys():\n",
    "        print(counter, key)\n",
    "        counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c46432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dir_name_all_ae+'/ae_038/final_net/final_net_ae_weights.h5', 'r') as f:\n",
    "    print(np.array(f['scalar_multiplication/scalar_multiplication/scalar_multiplier:0']).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ad866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb1c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef0a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370be652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ac8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3b91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da581d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9053e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fa653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
