{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788634667,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3089,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "3AVrZNGlZu4Z"
   },
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788637753,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "SxAd7iDL0Ami"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27766,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "JjNnPRuk0IIX",
    "outputId": "f93a8628-71fe-4d6d-b3b6-245dfcb8eb60"
   },
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "9REiGIIy0IzV",
    "outputId": "2b5b0b02-2f67-4635-a00c-82084a8d2ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/Kolmogorov\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1666788666890,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import mytimecallback, SaveLosses, plot_losses, readAndReturnLossHistories\n",
    "from tools.ae_v3 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666891,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-mIQj_v4gzMh"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "QL5n-abCg0nI"
   },
   "outputs": [],
   "source": [
    "# setting seed for PRNGs\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    prng_seed = 42\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "f77bf689-c865-4a8d-8d40-37ec9c75f1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 01:30:00.013962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.014374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.053428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.053664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.053842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.054013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.054762: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 01:30:00.055354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.055595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.055807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.617971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.618235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.618460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-08 01:30:00.618646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3365 MB memory:  -> device: 1, name: Quadro K2200, pci bus id: 0000:03:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 1\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "xcNgt4hqg6Xv",
    "outputId": "7735ac54-495c-493f-869b-7d15538ee30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030\n",
      "24 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "from numpy import *\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # loading data directory\n",
    "    data_dir_idx = '000'\n",
    "\n",
    "    # making ae save directory\n",
    "    dir_name_ae = os.getcwd() + dir_sep + 'saved_ae'\n",
    "    if not os.path.isdir(dir_name_ae):\n",
    "        os.makedirs(dir_name_ae)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        dir_check = 'ae_' + str(counter).zfill(3)\n",
    "        if os.path.isdir(dir_name_ae + dir_sep + dir_check):\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dir_name_ae = dir_name_ae + dir_sep + dir_check\n",
    "    os.makedirs(dir_name_ae)\n",
    "    os.makedirs(dir_name_ae+dir_sep+'plots')\n",
    "else:\n",
    "    # some paramaters\n",
    "    dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_015'.format(ds=dir_sep)\n",
    "\n",
    "    with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    params_dict = eval(''.join(lines))\n",
    "    data_dir_idx = params_dict['data_dir_idx']\n",
    "    normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "    normalization_constant_arr_aedata = params_dict['normalization_constant_arr_aedata']\n",
    "    if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "        with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "            normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "\n",
    "print('dir_name_ae:', dir_name_ae)\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "    \n",
    "with h5py.File(dir_name_data + '/data.h5', 'r') as f:\n",
    "    t_recorded_samples = np.array(f['t'])\n",
    "    \n",
    "    N = int(0.5*(np.array(f['num_wavenumbers'])-1))\n",
    "    print(N, type(N))\n",
    "    \n",
    "    u_ref = np.array(f['u_reference'], dtype=FTYPE)\n",
    "    v_ref = np.array(f['v_reference'], dtype=FTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.empty(shape=(u_ref.shape[0], 2, u_ref.shape[1], u_ref.shape[2]), dtype=FTYPE)\n",
    "all_data[:, 0, :, :] = u_ref\n",
    "del(u_ref)\n",
    "all_data[:, 1, :, :] = v_ref\n",
    "del(v_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "O7sl7i5H5Dqz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2415,
     "status": "ok",
     "timestamp": 1666788671329,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ySVDz_2U5FH5",
    "outputId": "53f23b1d-fa61-4f27-bbc4-2e624421a866"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788671330,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [],
   "source": [
    "# dealing with normalizing the data before feeding into autoencoder\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # normalize data before feeding into autoencoder?\n",
    "    normalizeforae_flag = True\n",
    "    normalization_type = 'stddev' # could be 'stddev' or 'minmax'\n",
    "    stddev_multiplier = 3\n",
    "    \n",
    "    normalization_constant_arr_aedata = None\n",
    "    if normalizeforae_flag == True:\n",
    "        normalization_constant_arr_aedata = np.empty(shape=(2,) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "        if normalization_type == 'stddev':\n",
    "            normalization_constant_arr_aedata[0] = np.mean(all_data, axis=0)\n",
    "            normalization_constant_arr_aedata[1] = stddev_multiplier * np.std(all_data, axis=0)\n",
    "        elif normalization_type == 'minmax':\n",
    "            sample_min = all_data.min(axis=0)\n",
    "            sample_max = all_data.max(axis=0)\n",
    "            idx = np.where(sample_min == sample_max)\n",
    "            if len(idx) > 0:\n",
    "                num_elems = len(idx[0])\n",
    "                for i in range(num_elems):\n",
    "                    i0 = idx[0][i]\n",
    "                    i1 = idx[1][i]\n",
    "                    i2 = idx[2][i]\n",
    "                    sample_min[i0, i1, i2] -= 0.5\n",
    "                    sample_max[i0, i1, i2] = sample_min[i0, i1, i2] + 1.\n",
    "            normalization_constant_arr_aedata[0] = sample_min\n",
    "            normalization_constant_arr_aedata[1] = sample_max - sample_min\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "    # saving sim data\n",
    "    ae_data = {\n",
    "        'data_dir_idx':data_dir_idx,\n",
    "        'normalizeforae_flag':normalizeforae_flag,\n",
    "        # 'normalization_constant_arr_aedata':normalization_constant_arr_aedata,\n",
    "        'normalization_type':normalization_type,\n",
    "        'stddev_multiplier':stddev_multiplier,\n",
    "        'ae_data_with_params':False,\n",
    "        'module':Autoencoder.__module__,\n",
    "    }\n",
    "    with open(dir_name_ae+dir_sep+'ae_data.txt', 'w') as f:\n",
    "        f.write(str(ae_data))\n",
    "    np.savez(\n",
    "        dir_name_ae+dir_sep+'normalization_data',\n",
    "        normalization_constant_arr_aedata=[normalization_constant_arr_aedata],\n",
    "    )\n",
    "else:\n",
    "    if normalizeforae_flag == True:\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "time_stddev = np.std(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1666788672340,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "uDhfYHU45IS8",
    "outputId": "982f534f-255c-41b9-f40a-327730ac89ae"
   },
   "outputs": [],
   "source": [
    "all_data = all_data[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1666788672341,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "59kkrSP1GvzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788672342,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-MJa7P5t5KiC",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1666788672765,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "c5cjQ1lnjcwt"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    learning_rate_list = [1e-3, 1e-4, 1e-5]\n",
    "    epochs = 200\n",
    "    patience = 10  # parameter for early stopping\n",
    "    min_delta = 1e-6  # parameter for early stopping\n",
    "    lambda_reg = 5e-7 # weight for regularizer\n",
    "    train_split = 0.8\n",
    "    val_split = 0.1\n",
    "    test_split = 1 - train_split - val_split\n",
    "    batch_size = 16\n",
    "    fRMS = 2/100\n",
    "    timeMeanofSpaceRMS = np.mean(np.mean(all_data**2, axis=1)**0.5)\n",
    "    \n",
    "    # stddev = fRMS*timeMeanofSpaceRMS\n",
    "    stddev = fRMS * np.mean(time_stddev)\n",
    "    use_weights_post_dense = False\n",
    "    use_batch_norm = True\n",
    "\n",
    "    # saving training params\n",
    "    training_specific_params = {\n",
    "        'learning_rate_list':learning_rate_list,\n",
    "        'epochs':epochs,\n",
    "        'patience':patience,\n",
    "        'min_delta':min_delta,\n",
    "        'prng_seed':prng_seed,\n",
    "        'train_split':train_split,\n",
    "        'val_split':val_split,\n",
    "        'batch_size':batch_size,\n",
    "        'fRMS':fRMS,\n",
    "        'timeMeanofSpaceRMS':timeMeanofSpaceRMS,\n",
    "        'stddev':stddev,\n",
    "        'use_batch_norm':use_batch_norm,\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ae+dir_sep+'training_specific_params.txt', 'w') as f:\n",
    "        f.write(str(training_specific_params))\n",
    "else:\n",
    "    with open(dir_name_ae + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    learning_rate_list = tparams_dict['learning_rate_list']\n",
    "    epochs = tparams_dict['epochs']\n",
    "    patience = tparams_dict['patience']\n",
    "    min_delta = tparams_dict['min_delta']\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "    try:\n",
    "        stddev = tparams_dict['stddev']\n",
    "    except:\n",
    "        print(\"'stddev' not in tparams_dict, set to 0\")\n",
    "        stddev = 0.0\n",
    "\n",
    "    test_split = 1 - train_split - val_split\n",
    "\n",
    "    # setting seed for PRNGs\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672769,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "lovTI3zuhlX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672770,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "IjsRi02g5ORG"
   },
   "outputs": [],
   "source": [
    "# # setting up data\n",
    "# idx = np.arange(all_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# boundary = int(np.round((1-test_split)*all_data.shape[0]))\n",
    "# training_data = all_data[idx[0:boundary], :]\n",
    "# testing_data = all_data[idx[boundary:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672771,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Qwietg7eTG-s"
   },
   "outputs": [],
   "source": [
    "num_train = int(all_data.shape[0]*train_split)\n",
    "num_val = int(all_data.shape[0]*val_split)\n",
    "num_test = all_data.shape[0] - num_train - num_val\n",
    "\n",
    "idx = np.arange(all_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "training_data = np.empty(shape=(num_train, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "val_data = np.empty(shape=(num_val, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "testing_data = np.empty(shape=(num_test, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "\n",
    "training_data[:] = all_data[idx[0:num_train]]\n",
    "val_data[:] = all_data[idx[num_train:num_train+num_val]]\n",
    "testing_data[:] = all_data[idx[num_train+num_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672772,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gJ-28EnzJ4Ur"
   },
   "outputs": [],
   "source": [
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1666788672773,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7xTsmS7lgpps"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1626,
     "status": "ok",
     "timestamp": 1666788674381,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7l5kI1tfMszJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4\n",
      "1 / 4\n",
      "2 / 4\n",
      "3 / 4\n",
      "(69, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 01:30:09.408314: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n"
     ]
    }
   ],
   "source": [
    "# Initialize network\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    enc_filters = [8, 16, 32, 2] # [8, 3, 1]\n",
    "    enc_strides = [2, 2, 2, 2] # [2, 1, 1]\n",
    "    enc_attn_placement = [1, 2, 3]\n",
    "    dec_filters = [32, 16, 8, 2]# [3, 8, 2]\n",
    "    dec_strides = [2, 2, 2, 2] # [1, 1, 2]\n",
    "    dec_attn_placement = [0, 1]\n",
    "    kernel_size = 3\n",
    "    \n",
    "    enc_layer_act_func = 'elu'\n",
    "    enc_final_layer_act_func = 'tanh'\n",
    "    dec_layer_act_func = 'elu'\n",
    "    dec_final_layer_act_func = 'tanh'\n",
    "    reg_name = 'L2'\n",
    "    \n",
    "    use_periodic_padding = True\n",
    "    use_attention_module = False\n",
    "    \n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(\n",
    "                data_dim=training_data.shape[1:],\n",
    "                kernel_size=kernel_size,\n",
    "                enc_filters=enc_filters, # number of filters\n",
    "                dec_filters=dec_filters, # number of filters\n",
    "                lambda_reg=lambda_reg,\n",
    "                reg_name=reg_name,\n",
    "                enc_layer_act_func=enc_layer_act_func,\n",
    "                enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "                dec_layer_act_func=dec_layer_act_func,\n",
    "                dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "                load_file=None,\n",
    "                stddev=stddev,\n",
    "                use_weights_post_dense=use_weights_post_dense,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "                use_periodic_padding=use_periodic_padding,\n",
    "                use_attention_module=use_attention_module,\n",
    "                enc_strides=enc_strides,\n",
    "                enc_attn_placement=enc_attn_placement,\n",
    "                dec_strides=dec_strides,\n",
    "                dec_attn_placement=dec_attn_placement,)\n",
    "    else:\n",
    "        ae_net = Autoencoder(\n",
    "            data_dim=training_data.shape[1:],\n",
    "            kernel_size=kernel_size,\n",
    "            enc_filters=enc_filters, # number of filters\n",
    "            dec_filters=dec_filters, # number of filters\n",
    "            lambda_reg=lambda_reg,\n",
    "            reg_name=reg_name,\n",
    "            enc_layer_act_func=enc_layer_act_func,\n",
    "            enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "            dec_layer_act_func=dec_layer_act_func,\n",
    "            dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "            load_file=None,\n",
    "            stddev=stddev,\n",
    "            use_weights_post_dense=use_weights_post_dense,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            use_periodic_padding=use_periodic_padding,\n",
    "            use_attention_module=use_attention_module,\n",
    "            enc_strides=enc_strides,\n",
    "            enc_attn_placement=enc_attn_placement,\n",
    "            dec_strides=dec_strides,\n",
    "            dec_attn_placement=dec_attn_placement,)\n",
    "    # saving the AE configuration\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    ae_net.save_class_dict(save_path+dir_sep+'final_net_class_dict.txt')\n",
    "else:\n",
    "    load_file = dir_name_ae + dir_sep + 'final_net' + dir_sep + 'final_net_class_dict.txt'\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    else:\n",
    "        ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    \n",
    "    if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "        wt_file = tf.train.latest_checkpoint(dir_name_ae+dir_sep+'checkpoints')\n",
    "        # ae_net.load_weights(wt_file)\n",
    "    elif behaviour == 'loadFinalNetAndPlot':\n",
    "        wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "        ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1666788674637,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "48tkgZxT0Amt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1666788674956,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "yUChBAKqIFtX"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    val_loss_hist = []\n",
    "    train_loss_hist = []\n",
    "    lr_change=[0, 0]\n",
    "    savelosses_cb_vallossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    savelosses_cb_trainlossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    starting_lr_idx = 0\n",
    "    num_epochs_left = epochs\n",
    "elif behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    val_loss_hist, train_loss_hist, lr_change, starting_lr_idx, num_epochs_left, val_loss_arr_fromckpt, train_loss_arr_fromckpt = readAndReturnLossHistories(\n",
    "        dir_name_ae=dir_name_ae,\n",
    "        dir_sep=dir_sep,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list)\n",
    "    savelosses_cb_vallossarr = val_loss_arr_fromckpt\n",
    "    savelosses_cb_trainlossarr = train_loss_arr_fromckpt\n",
    "elif behaviour == 'loadFinalNetAndPlot':\n",
    "    with open(dir_name_ae+'{ds}final_net{ds}losses.txt'.format(ds=dir_sep), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    losses_dict = eval(''.join(lines))\n",
    "\n",
    "    val_loss_hist = losses_dict['val_loss_hist']\n",
    "    train_loss_hist = losses_dict['train_loss_hist']\n",
    "    lr_change = losses_dict['lr_change']\n",
    "    test_loss = losses_dict['test_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_hist = []\n",
    "val_MSE_hist = []\n",
    "\n",
    "train_NMSE_hist = []\n",
    "val_NMSE_hist = []\n",
    "\n",
    "if use_attention_module == True:\n",
    "    encoder_attention_lambdas = {}\n",
    "    for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "        l = ae_net.encoder_attention_modules_list[i]\n",
    "        encoder_attention_lambdas['encoder_attention_module_{}_lambda'.format(i)] = [0]\n",
    "    decoder_attention_lambdas = {}\n",
    "    for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "        l = ae_net.decoder_attention_modules_list[i]\n",
    "        decoder_attention_lambdas['decoder_attention_module_{}_lambda'.format(i)] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788674957,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Z0oEGp6WKGu2"
   },
   "outputs": [],
   "source": [
    "class NMSE(tf.keras.metrics.MeanSquaredError):\n",
    "    def __init__(self, divisor_arr, name='NMSE', **kwargs):\n",
    "        super(NMSE, self).__init__(name, **kwargs)\n",
    "        self.divisor_arr = divisor_arr\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = y_true / self.divisor_arr\n",
    "        y_pred = y_pred / self.divisor_arr\n",
    "        return super(NMSE, self).update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if strategy is not None:\n",
    "    with strategy.scope():\n",
    "        NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))\n",
    "else:\n",
    "    NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191278,
     "status": "ok",
     "timestamp": 1666788866231,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gELga1WnQeMK",
    "outputId": "e923a97a-2d9d-4c74-c328-4793de05b919",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0456 - mse: 0.0456 - NMSE: 0.4105 - tot_time: 0h 0m 15.4s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.18934, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 14s 10ms/step - loss: 0.0456 - mse: 0.0456 - NMSE: 0.4102 - val_loss: 0.0211 - val_mse: 0.0210 - val_NMSE: 0.1893\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0196 - mse: 0.0196 - NMSE: 0.1762 - tot_time: 0h 0m 27.4s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.18934 to 0.15872, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0196 - mse: 0.0196 - NMSE: 0.1762 - val_loss: 0.0177 - val_mse: 0.0176 - val_NMSE: 0.1587\n",
      "Epoch 3/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0175 - mse: 0.0175 - NMSE: 0.1574 - tot_time: 0h 0m 39.4s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.15872 to 0.14694, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0175 - mse: 0.0175 - NMSE: 0.1574 - val_loss: 0.0164 - val_mse: 0.0163 - val_NMSE: 0.1469\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0164 - mse: 0.0163 - NMSE: 0.1470 - tot_time: 0h 0m 51.5s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.14694 to 0.13508, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0164 - mse: 0.0163 - NMSE: 0.1470 - val_loss: 0.0151 - val_mse: 0.0150 - val_NMSE: 0.1351\n",
      "Epoch 5/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0154 - mse: 0.0154 - NMSE: 0.1385 - tot_time: 0h 1m 3.7s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.13508 to 0.13008, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0154 - mse: 0.0154 - NMSE: 0.1384 - val_loss: 0.0145 - val_mse: 0.0145 - val_NMSE: 0.1301\n",
      "Epoch 6/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0147 - mse: 0.0146 - NMSE: 0.1318 - tot_time: 0h 1m 15.9s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.13008 to 0.12394, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0147 - mse: 0.0146 - NMSE: 0.1318 - val_loss: 0.0138 - val_mse: 0.0138 - val_NMSE: 0.1239\n",
      "Epoch 7/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0142 - mse: 0.0141 - NMSE: 0.1273 - tot_time: 0h 1m 28.1s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.12394 to 0.11995, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0142 - mse: 0.0141 - NMSE: 0.1272 - val_loss: 0.0134 - val_mse: 0.0133 - val_NMSE: 0.1200\n",
      "Epoch 8/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0138 - mse: 0.0137 - NMSE: 0.1233 - tot_time: 0h 1m 40.3s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.11995 to 0.11585, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0138 - mse: 0.0137 - NMSE: 0.1233 - val_loss: 0.0129 - val_mse: 0.0129 - val_NMSE: 0.1159\n",
      "Epoch 9/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0134 - mse: 0.0133 - NMSE: 0.1198 - tot_time: 0h 1m 52.6s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.11585 to 0.11328, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0134 - mse: 0.0133 - NMSE: 0.1198 - val_loss: 0.0127 - val_mse: 0.0126 - val_NMSE: 0.1133\n",
      "Epoch 10/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0131 - mse: 0.0130 - NMSE: 0.1169 - tot_time: 0h 2m 4.8s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.11328 to 0.10959, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0131 - mse: 0.0130 - NMSE: 0.1169 - val_loss: 0.0123 - val_mse: 0.0122 - val_NMSE: 0.1096\n",
      "Epoch 11/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0126 - mse: 0.0126 - NMSE: 0.1131 - tot_time: 0h 2m 16.8s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.10959 to 0.10510, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0126 - mse: 0.0126 - NMSE: 0.1131 - val_loss: 0.0118 - val_mse: 0.0117 - val_NMSE: 0.1051\n",
      "Epoch 12/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0123 - mse: 0.0123 - NMSE: 0.1103 - tot_time: 0h 2m 29.0s\n",
      "\n",
      "Epoch 12: val_NMSE improved from 0.10510 to 0.10508, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0123 - mse: 0.0123 - NMSE: 0.1104 - val_loss: 0.0118 - val_mse: 0.0117 - val_NMSE: 0.1051\n",
      "Epoch 13/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0121 - mse: 0.0121 - NMSE: 0.1085 - tot_time: 0h 2m 41.1s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.10508 to 0.10300, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0121 - mse: 0.0121 - NMSE: 0.1085 - val_loss: 0.0115 - val_mse: 0.0114 - val_NMSE: 0.1030\n",
      "Epoch 14/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0120 - mse: 0.0119 - NMSE: 0.1070 - tot_time: 0h 2m 53.3s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.10300 to 0.10036, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0120 - mse: 0.0119 - NMSE: 0.1070 - val_loss: 0.0112 - val_mse: 0.0112 - val_NMSE: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0118 - mse: 0.0118 - NMSE: 0.1058 - tot_time: 0h 3m 5.6s\n",
      "\n",
      "Epoch 15: val_NMSE improved from 0.10036 to 0.10008, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0118 - mse: 0.0118 - NMSE: 0.1058 - val_loss: 0.0112 - val_mse: 0.0111 - val_NMSE: 0.1001\n",
      "Epoch 16/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0117 - mse: 0.0116 - NMSE: 0.1047 - tot_time: 0h 3m 18.0s\n",
      "\n",
      "Epoch 16: val_NMSE improved from 0.10008 to 0.09981, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0117 - mse: 0.0116 - NMSE: 0.1047 - val_loss: 0.0112 - val_mse: 0.0111 - val_NMSE: 0.0998\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0116 - mse: 0.0115 - NMSE: 0.1036 - tot_time: 0h 3m 30.3s\n",
      "\n",
      "Epoch 17: val_NMSE improved from 0.09981 to 0.09782, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0116 - mse: 0.0115 - NMSE: 0.1036 - val_loss: 0.0110 - val_mse: 0.0109 - val_NMSE: 0.0978\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0115 - mse: 0.0114 - NMSE: 0.1030 - tot_time: 0h 3m 42.6s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.09782 to 0.09664, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0115 - mse: 0.0114 - NMSE: 0.1030 - val_loss: 0.0108 - val_mse: 0.0107 - val_NMSE: 0.0966\n",
      "Epoch 19/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0114 - mse: 0.0113 - NMSE: 0.1021 - tot_time: 0h 3m 55.1s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.09664\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0115 - mse: 0.0114 - NMSE: 0.1022 - val_loss: 0.0111 - val_mse: 0.0110 - val_NMSE: 0.0987\n",
      "Epoch 20/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0114 - mse: 0.0113 - NMSE: 0.1015 - tot_time: 0h 4m 7.5s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.09664\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0114 - mse: 0.0113 - NMSE: 0.1015 - val_loss: 0.0108 - val_mse: 0.0107 - val_NMSE: 0.0967\n",
      "Epoch 21/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0113 - mse: 0.0112 - NMSE: 0.1009 - tot_time: 0h 4m 19.7s\n",
      "\n",
      "Epoch 21: val_NMSE improved from 0.09664 to 0.09593, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0113 - mse: 0.0112 - NMSE: 0.1008 - val_loss: 0.0108 - val_mse: 0.0107 - val_NMSE: 0.0959\n",
      "Epoch 22/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0113 - mse: 0.0112 - NMSE: 0.1004 - tot_time: 0h 4m 32.0s\n",
      "\n",
      "Epoch 22: val_NMSE improved from 0.09593 to 0.09515, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0113 - mse: 0.0112 - NMSE: 0.1004 - val_loss: 0.0107 - val_mse: 0.0106 - val_NMSE: 0.0951\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0112 - mse: 0.0111 - NMSE: 0.0999 - tot_time: 0h 4m 44.2s\n",
      "\n",
      "Epoch 23: val_NMSE improved from 0.09515 to 0.09452, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0112 - mse: 0.0111 - NMSE: 0.0999 - val_loss: 0.0106 - val_mse: 0.0105 - val_NMSE: 0.0945\n",
      "Epoch 24/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0112 - mse: 0.0111 - NMSE: 0.0995 - tot_time: 0h 4m 56.5s\n",
      "\n",
      "Epoch 24: val_NMSE did not improve from 0.09452\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0112 - mse: 0.0111 - NMSE: 0.0995 - val_loss: 0.0107 - val_mse: 0.0105 - val_NMSE: 0.0948\n",
      "Epoch 25/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0111 - mse: 0.0110 - NMSE: 0.0989 - tot_time: 0h 5m 8.7s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.09452\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0111 - mse: 0.0110 - NMSE: 0.0990 - val_loss: 0.0106 - val_mse: 0.0105 - val_NMSE: 0.0946\n",
      "Epoch 26/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0111 - mse: 0.0110 - NMSE: 0.0986 - tot_time: 0h 5m 20.8s\n",
      "\n",
      "Epoch 26: val_NMSE improved from 0.09452 to 0.09404, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0111 - mse: 0.0110 - NMSE: 0.0986 - val_loss: 0.0106 - val_mse: 0.0104 - val_NMSE: 0.0940\n",
      "Epoch 27/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0982 - tot_time: 0h 5m 33.0s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.09404 to 0.09303, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0982 - val_loss: 0.0105 - val_mse: 0.0103 - val_NMSE: 0.0930\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0978 - tot_time: 0h 5m 45.3s\n",
      "\n",
      "Epoch 28: val_NMSE improved from 0.09303 to 0.09252, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0978 - val_loss: 0.0104 - val_mse: 0.0103 - val_NMSE: 0.0925\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0977 - tot_time: 0h 5m 57.5s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.09252\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0110 - mse: 0.0109 - NMSE: 0.0977 - val_loss: 0.0105 - val_mse: 0.0103 - val_NMSE: 0.0929\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0109 - mse: 0.0108 - NMSE: 0.0973 - tot_time: 0h 6m 9.8s\n",
      "\n",
      "Epoch 30: val_NMSE improved from 0.09252 to 0.09200, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0109 - mse: 0.0108 - NMSE: 0.0973 - val_loss: 0.0104 - val_mse: 0.0102 - val_NMSE: 0.0920\n",
      "Epoch 31/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0109 - mse: 0.0108 - NMSE: 0.0968 - tot_time: 0h 6m 21.9s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.09200\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0109 - mse: 0.0108 - NMSE: 0.0968 - val_loss: 0.0105 - val_mse: 0.0104 - val_NMSE: 0.0933\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0109 - mse: 0.0107 - NMSE: 0.0967 - tot_time: 0h 6m 34.2s\n",
      "\n",
      "Epoch 32: val_NMSE improved from 0.09200 to 0.09156, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0109 - mse: 0.0107 - NMSE: 0.0967 - val_loss: 0.0103 - val_mse: 0.0102 - val_NMSE: 0.0916\n",
      "Epoch 33/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0109 - mse: 0.0107 - NMSE: 0.0965 - tot_time: 0h 6m 46.5s\n",
      "\n",
      "Epoch 33: val_NMSE improved from 0.09156 to 0.09102, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0109 - mse: 0.0107 - NMSE: 0.0965 - val_loss: 0.0103 - val_mse: 0.0101 - val_NMSE: 0.0910\n",
      "Epoch 34/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0961 - tot_time: 0h 6m 58.7s\n",
      "\n",
      "Epoch 34: val_NMSE did not improve from 0.09102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0961 - val_loss: 0.0103 - val_mse: 0.0101 - val_NMSE: 0.0910\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0960 - tot_time: 0h 7m 11.0s\n",
      "\n",
      "Epoch 35: val_NMSE did not improve from 0.09102\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0960 - val_loss: 0.0105 - val_mse: 0.0103 - val_NMSE: 0.0930\n",
      "Epoch 36/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0959 - tot_time: 0h 7m 23.1s\n",
      "\n",
      "Epoch 36: val_NMSE improved from 0.09102 to 0.08950, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0108 - mse: 0.0107 - NMSE: 0.0959 - val_loss: 0.0101 - val_mse: 0.0099 - val_NMSE: 0.0895\n",
      "Epoch 37/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0954 - tot_time: 0h 7m 35.2s\n",
      "\n",
      "Epoch 37: val_NMSE did not improve from 0.08950\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0108 - mse: 0.0106 - NMSE: 0.0954 - val_loss: 0.0101 - val_mse: 0.0100 - val_NMSE: 0.0899\n",
      "Epoch 38/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0954 - tot_time: 0h 7m 47.4s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.08950\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0954 - val_loss: 0.0102 - val_mse: 0.0100 - val_NMSE: 0.0901\n",
      "Epoch 39/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0952 - tot_time: 0h 7m 59.5s\n",
      "\n",
      "Epoch 39: val_NMSE improved from 0.08950 to 0.08908, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0106 - NMSE: 0.0952 - val_loss: 0.0101 - val_mse: 0.0099 - val_NMSE: 0.0891\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0949 - tot_time: 0h 8m 11.9s\n",
      "\n",
      "Epoch 40: val_NMSE did not improve from 0.08908\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0949 - val_loss: 0.0101 - val_mse: 0.0099 - val_NMSE: 0.0895\n",
      "Epoch 41/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0947 - tot_time: 0h 8m 24.1s\n",
      "\n",
      "Epoch 41: val_NMSE improved from 0.08908 to 0.08907, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0947 - val_loss: 0.0101 - val_mse: 0.0099 - val_NMSE: 0.0891\n",
      "Epoch 42/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0947 - tot_time: 0h 8m 36.2s\n",
      "\n",
      "Epoch 42: val_NMSE improved from 0.08907 to 0.08808, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0947 - val_loss: 0.0099 - val_mse: 0.0098 - val_NMSE: 0.0881\n",
      "Epoch 43/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0944 - tot_time: 0h 8m 48.3s\n",
      "\n",
      "Epoch 43: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0107 - mse: 0.0105 - NMSE: 0.0944 - val_loss: 0.0101 - val_mse: 0.0099 - val_NMSE: 0.0894\n",
      "Epoch 44/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0105 - NMSE: 0.0942 - tot_time: 0h 9m 0.6s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0105 - NMSE: 0.0942 - val_loss: 0.0100 - val_mse: 0.0099 - val_NMSE: 0.0888\n",
      "Epoch 45/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0105 - NMSE: 0.0941 - tot_time: 0h 9m 12.8s\n",
      "\n",
      "Epoch 45: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0105 - NMSE: 0.0941 - val_loss: 0.0101 - val_mse: 0.0100 - val_NMSE: 0.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0939 - tot_time: 0h 9m 25.1s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0940 - val_loss: 0.0100 - val_mse: 0.0099 - val_NMSE: 0.0887\n",
      "Epoch 47/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0938 - tot_time: 0h 9m 37.2s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0939 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0886\n",
      "Epoch 48/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0937 - tot_time: 0h 9m 49.5s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0937 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0885\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0935 - tot_time: 0h 10m 1.8s\n",
      "\n",
      "Epoch 49: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0935 - val_loss: 0.0101 - val_mse: 0.0100 - val_NMSE: 0.0898\n",
      "Epoch 50/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0936 - tot_time: 0h 10m 13.9s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0106 - mse: 0.0104 - NMSE: 0.0936 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0882\n",
      "Epoch 51/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0104 - NMSE: 0.0932 - tot_time: 0h 10m 26.0s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.08808\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0104 - NMSE: 0.0932 - val_loss: 0.0101 - val_mse: 0.0100 - val_NMSE: 0.0896\n",
      "Epoch 52/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0931 - tot_time: 0h 10m 38.1s\n",
      "\n",
      "Epoch 52: val_NMSE improved from 0.08808 to 0.08806, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0931 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0881\n",
      "Epoch 53/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0931 - tot_time: 0h 10m 50.2s\n",
      "\n",
      "Epoch 53: val_NMSE did not improve from 0.08806\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0931 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0881\n",
      "Epoch 54/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0929 - tot_time: 0h 11m 2.7s\n",
      "\n",
      "Epoch 54: val_NMSE improved from 0.08806 to 0.08722, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0929 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0872\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0928 - tot_time: 0h 11m 15.4s\n",
      "\n",
      "Epoch 55: val_NMSE did not improve from 0.08722\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0928 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0883\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0926 - tot_time: 0h 11m 27.5s\n",
      "\n",
      "Epoch 56: val_NMSE did not improve from 0.08722\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0926 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0885\n",
      "Epoch 57/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0928 - tot_time: 0h 11m 39.6s\n",
      "\n",
      "Epoch 57: val_NMSE did not improve from 0.08722\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0928 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0882\n",
      "Epoch 58/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0926 - tot_time: 0h 11m 51.8s\n",
      "\n",
      "Epoch 58: val_NMSE improved from 0.08722 to 0.08692, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0926 - val_loss: 0.0098 - val_mse: 0.0097 - val_NMSE: 0.0869\n",
      "Epoch 59/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0103 - NMSE: 0.0923 - tot_time: 0h 12m 4.1s\n",
      "\n",
      "Epoch 59: val_NMSE improved from 0.08692 to 0.08665, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0924 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0866\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0922 - tot_time: 0h 12m 16.0s\n",
      "\n",
      "Epoch 60: val_NMSE did not improve from 0.08665\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0922 - val_loss: 0.0100 - val_mse: 0.0099 - val_NMSE: 0.0887\n",
      "Epoch 61/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0103 - NMSE: 0.0923 - tot_time: 0h 12m 28.2s\n",
      "\n",
      "Epoch 61: val_NMSE did not improve from 0.08665\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0103 - NMSE: 0.0923 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0869\n",
      "Epoch 62/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0922 - tot_time: 0h 12m 40.4s\n",
      "\n",
      "Epoch 62: val_NMSE improved from 0.08665 to 0.08659, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0922 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0866\n",
      "Epoch 63/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0921 - tot_time: 0h 12m 52.5s\n",
      "\n",
      "Epoch 63: val_NMSE did not improve from 0.08659\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0921 - val_loss: 0.0099 - val_mse: 0.0098 - val_NMSE: 0.0878\n",
      "Epoch 64/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0920 - tot_time: 0h 13m 4.8s\n",
      "\n",
      "Epoch 64: val_NMSE did not improve from 0.08659\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0920 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0873\n",
      "Epoch 65/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0919 - tot_time: 0h 13m 16.8s\n",
      "\n",
      "Epoch 65: val_NMSE did not improve from 0.08659\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0919 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0877\n",
      "Epoch 66/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0920 - tot_time: 0h 13m 28.9s\n",
      "\n",
      "Epoch 66: val_NMSE improved from 0.08659 to 0.08599, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0920 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0860\n",
      "Epoch 67/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0918 - tot_time: 0h 13m 41.1s\n",
      "\n",
      "Epoch 67: val_NMSE did not improve from 0.08599\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0918 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0876\n",
      "Epoch 68/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0919 - tot_time: 0h 13m 53.2s\n",
      "\n",
      "Epoch 68: val_NMSE did not improve from 0.08599\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0919 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0864\n",
      "Epoch 69/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0916 - tot_time: 0h 14m 5.2s\n",
      "\n",
      "Epoch 69: val_NMSE did not improve from 0.08599\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0916 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0862\n",
      "Epoch 70/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0917 - tot_time: 0h 14m 17.2s\n",
      "\n",
      "Epoch 70: val_NMSE improved from 0.08599 to 0.08564, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0917 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0856\n",
      "Epoch 71/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0917 - tot_time: 0h 14m 29.5s\n",
      "\n",
      "Epoch 71: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0917 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0865\n",
      "Epoch 72/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0914 - tot_time: 0h 14m 41.7s\n",
      "\n",
      "Epoch 72: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0915 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0866\n",
      "Epoch 73/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0914 - tot_time: 0h 14m 53.6s\n",
      "\n",
      "Epoch 73: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0914 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0857\n",
      "Epoch 74/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0912 - tot_time: 0h 15m 5.7s\n",
      "\n",
      "Epoch 74: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0912 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0868\n",
      "Epoch 75/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0911 - tot_time: 0h 15m 17.7s\n",
      "\n",
      "Epoch 75: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0911 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0869\n",
      "Epoch 76/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0912 - tot_time: 0h 15m 29.8s\n",
      "\n",
      "Epoch 76: val_NMSE did not improve from 0.08564\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0912 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0880\n",
      "Epoch 77/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0914 - tot_time: 0h 15m 41.9s\n",
      "\n",
      "Epoch 77: val_NMSE improved from 0.08564 to 0.08548, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0104 - mse: 0.0102 - NMSE: 0.0914 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0855\n",
      "Epoch 78/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - tot_time: 0h 15m 54.1s\n",
      "\n",
      "Epoch 78: val_NMSE improved from 0.08548 to 0.08538, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0909 - tot_time: 0h 16m 6.2s\n",
      "\n",
      "Epoch 79: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0909 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0865\n",
      "Epoch 80/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0911 - tot_time: 0h 16m 18.4s\n",
      "\n",
      "Epoch 80: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0911 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0863\n",
      "Epoch 81/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - tot_time: 0h 16m 30.7s\n",
      "\n",
      "Epoch 81: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0854\n",
      "Epoch 82/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - tot_time: 0h 16m 42.8s\n",
      "\n",
      "Epoch 82: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0909 - val_loss: 0.0098 - val_mse: 0.0095 - val_NMSE: 0.0859\n",
      "Epoch 83/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - tot_time: 0h 16m 54.9s\n",
      "\n",
      "Epoch 83: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0910 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0856\n",
      "Epoch 84/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - tot_time: 0h 17m 6.7s\n",
      "\n",
      "Epoch 84: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0866\n",
      "Epoch 85/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - tot_time: 0h 17m 18.9s\n",
      "\n",
      "Epoch 85: val_NMSE did not improve from 0.08538\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0855\n",
      "Epoch 86/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - tot_time: 0h 17m 31.1s\n",
      "\n",
      "Epoch 86: val_NMSE improved from 0.08538 to 0.08427, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - val_loss: 0.0096 - val_mse: 0.0094 - val_NMSE: 0.0843\n",
      "Epoch 87/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0907 - tot_time: 0h 17m 43.3s\n",
      "\n",
      "Epoch 87: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0908 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0861\n",
      "Epoch 88/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0906 - tot_time: 0h 17m 55.5s\n",
      "\n",
      "Epoch 88: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0905 - val_loss: 0.0097 - val_mse: 0.0094 - val_NMSE: 0.0850\n",
      "Epoch 89/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0905 - tot_time: 0h 18m 7.5s\n",
      "\n",
      "Epoch 89: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0101 - NMSE: 0.0905 - val_loss: 0.0097 - val_mse: 0.0094 - val_NMSE: 0.0850\n",
      "Epoch 90/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - tot_time: 0h 18m 19.7s\n",
      "\n",
      "Epoch 90: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0862\n",
      "Epoch 91/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - tot_time: 0h 18m 31.8s\n",
      "\n",
      "Epoch 91: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - val_loss: 0.0100 - val_mse: 0.0098 - val_NMSE: 0.0881\n",
      "Epoch 92/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - tot_time: 0h 18m 43.9s\n",
      "\n",
      "Epoch 92: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - val_loss: 0.0096 - val_mse: 0.0094 - val_NMSE: 0.0847\n",
      "Epoch 93/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0902 - tot_time: 0h 18m 56.0s\n",
      "\n",
      "Epoch 93: val_NMSE did not improve from 0.08427\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0903 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0873\n",
      "Epoch 94/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - tot_time: 0h 19m 8.1s\n",
      "\n",
      "Epoch 94: val_NMSE improved from 0.08427 to 0.08423, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - val_loss: 0.0096 - val_mse: 0.0094 - val_NMSE: 0.0842\n",
      "Epoch 95/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0902 - tot_time: 0h 19m 20.3s\n",
      "\n",
      "Epoch 95: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0902 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - tot_time: 0h 19m 32.4s\n",
      "\n",
      "Epoch 96: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0865\n",
      "Epoch 97/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - tot_time: 0h 19m 44.4s\n",
      "\n",
      "Epoch 97: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0903 - val_loss: 0.0096 - val_mse: 0.0094 - val_NMSE: 0.0844\n",
      "Epoch 98/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - tot_time: 0h 19m 56.6s\n",
      "\n",
      "Epoch 98: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0902 - val_loss: 0.0096 - val_mse: 0.0094 - val_NMSE: 0.0845\n",
      "Epoch 99/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0903 - tot_time: 0h 20m 8.6s\n",
      "\n",
      "Epoch 99: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0902 - val_loss: 0.0097 - val_mse: 0.0094 - val_NMSE: 0.0850\n",
      "Epoch 100/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - tot_time: 0h 20m 20.9s\n",
      "\n",
      "Epoch 100: val_NMSE did not improve from 0.08423\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0103 - mse: 0.0100 - NMSE: 0.0904 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0857\n",
      "Epoch 101/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0901 - tot_time: 0h 20m 33.1s\n",
      "\n",
      "Epoch 101: val_NMSE improved from 0.08423 to 0.08382, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0900 - val_loss: 0.0095 - val_mse: 0.0093 - val_NMSE: 0.0838\n",
      "Epoch 102/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - tot_time: 0h 20m 45.3s\n",
      "\n",
      "Epoch 102: val_NMSE improved from 0.08382 to 0.08368, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - val_loss: 0.0095 - val_mse: 0.0093 - val_NMSE: 0.0837\n",
      "Epoch 103/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0901 - tot_time: 0h 20m 57.5s\n",
      "\n",
      "Epoch 103: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0901 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0854\n",
      "Epoch 104/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0900 - tot_time: 0h 21m 9.7s\n",
      "\n",
      "Epoch 104: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0900 - val_loss: 0.0097 - val_mse: 0.0094 - val_NMSE: 0.0848\n",
      "Epoch 105/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - tot_time: 0h 21m 22.6s\n",
      "\n",
      "Epoch 105: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - val_loss: 0.0098 - val_mse: 0.0095 - val_NMSE: 0.0858\n",
      "Epoch 106/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0899 - tot_time: 0h 21m 35.6s\n",
      "\n",
      "Epoch 106: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0899 - val_loss: 0.0097 - val_mse: 0.0094 - val_NMSE: 0.0849\n",
      "Epoch 107/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - tot_time: 0h 21m 48.3s\n",
      "\n",
      "Epoch 107: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - val_loss: 0.0099 - val_mse: 0.0097 - val_NMSE: 0.0872\n",
      "Epoch 108/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - tot_time: 0h 22m 1.2s\n",
      "\n",
      "Epoch 108: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0864\n",
      "Epoch 109/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0896 - tot_time: 0h 22m 14.1s\n",
      "\n",
      "Epoch 109: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0896 - val_loss: 0.0098 - val_mse: 0.0096 - val_NMSE: 0.0865\n",
      "Epoch 110/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0896 - tot_time: 0h 22m 26.8s\n",
      "\n",
      "Epoch 110: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0852\n",
      "Epoch 111/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - tot_time: 0h 22m 39.6s\n",
      "\n",
      "Epoch 111: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0898 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0853\n",
      "Epoch 112/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897Restoring model weights from the end of the best epoch: 102.\n",
      " - tot_time: 0h 22m 52.5s\n",
      "\n",
      "Epoch 112: val_NMSE did not improve from 0.08368\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0102 - mse: 0.0100 - NMSE: 0.0897 - val_loss: 0.0097 - val_mse: 0.0095 - val_NMSE: 0.0851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.0001 ----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0100 - mse: 0.0097 - NMSE: 0.0876 - tot_time: 0h 23m 6.6s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.08368 to 0.08182, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.0100 - mse: 0.0097 - NMSE: 0.0876 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0818\n",
      "Epoch 2/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0875 - tot_time: 0h 23m 19.5s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.08182 to 0.08172, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0100 - mse: 0.0097 - NMSE: 0.0876 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 3/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 23m 32.6s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.08172 to 0.08169, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 4/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0100 - mse: 0.0097 - NMSE: 0.0876 - tot_time: 0h 23m 45.6s\n",
      "\n",
      "Epoch 4: val_NMSE did not improve from 0.08169\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0100 - mse: 0.0097 - NMSE: 0.0876 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 5/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 23m 58.4s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.08169 to 0.08166, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 6/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0875 - tot_time: 0h 24m 11.4s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.08166\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0819\n",
      "Epoch 7/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 24m 24.2s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.08166 to 0.08155, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 8/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - tot_time: 0h 24m 37.3s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.08155\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0818\n",
      "Epoch 9/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 24m 50.3s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.08155 to 0.08150, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 10/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 25m 3.2s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.08150\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 11/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 25m 16.2s\n",
      "\n",
      "Epoch 11: val_NMSE did not improve from 0.08150\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0816\n",
      "Epoch 12/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - tot_time: 0h 25m 29.1s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.08150\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0874 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0816\n",
      "Epoch 13/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - tot_time: 0h 25m 41.8s\n",
      "\n",
      "Epoch 13: val_NMSE improved from 0.08150 to 0.08143, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 14/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - tot_time: 0h 25m 54.7s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.08143\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 15/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - tot_time: 0h 26m 7.6s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.08143\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 26m 20.6s\n",
      "\n",
      "Epoch 16: val_NMSE did not improve from 0.08143\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 17/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 26m 33.7s\n",
      "\n",
      "Epoch 17: val_NMSE did not improve from 0.08143\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 18/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - tot_time: 0h 26m 46.7s\n",
      "\n",
      "Epoch 18: val_NMSE improved from 0.08143 to 0.08134, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0873 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 19/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 26m 59.9s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 20/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 27m 13.1s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 27m 26.0s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 22/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 27m 38.9s\n",
      "\n",
      "Epoch 22: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 23/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 27m 51.7s\n",
      "\n",
      "Epoch 23: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 24/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 28m 4.8s\n",
      "\n",
      "Epoch 24: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0818\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 28m 17.7s\n",
      "\n",
      "Epoch 25: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 26/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 28m 30.7s\n",
      "\n",
      "Epoch 26: val_NMSE did not improve from 0.08134\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 27/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 28m 43.7s\n",
      "\n",
      "Epoch 27: val_NMSE improved from 0.08134 to 0.08125, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 28/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 28m 56.9s\n",
      "\n",
      "Epoch 28: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 29/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 29m 9.8s\n",
      "\n",
      "Epoch 29: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0815\n",
      "Epoch 30/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 29m 22.9s\n",
      "\n",
      "Epoch 30: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0816\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 29m 35.8s\n",
      "\n",
      "Epoch 31: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 32/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 29m 48.8s\n",
      "\n",
      "Epoch 32: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 30m 2.0s\n",
      "\n",
      "Epoch 33: val_NMSE did not improve from 0.08125\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 34/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 30m 15.0s\n",
      "\n",
      "Epoch 34: val_NMSE improved from 0.08125 to 0.08123, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 35/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 30m 28.1s\n",
      "\n",
      "Epoch 35: val_NMSE improved from 0.08123 to 0.08123, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 36/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - tot_time: 0h 30m 41.1s\n",
      "\n",
      "Epoch 36: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0872 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0816\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 30m 54.0s\n",
      "\n",
      "Epoch 37: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - tot_time: 0h 31m 7.0s\n",
      "\n",
      "Epoch 38: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 39/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 31m 20.0s\n",
      "\n",
      "Epoch 39: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 40/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 31m 32.0s\n",
      "\n",
      "Epoch 40: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 41/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 31m 44.1s\n",
      "\n",
      "Epoch 41: val_NMSE did not improve from 0.08123\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 42/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 31m 56.3s\n",
      "\n",
      "Epoch 42: val_NMSE improved from 0.08123 to 0.08113, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0871 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0811\n",
      "Epoch 43/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 32m 8.6s\n",
      "\n",
      "Epoch 43: val_NMSE improved from 0.08113 to 0.08112, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0811\n",
      "Epoch 44/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 32m 20.9s\n",
      "\n",
      "Epoch 44: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 32m 33.1s\n",
      "\n",
      "Epoch 45: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0093 - val_mse: 0.0090 - val_NMSE: 0.0814\n",
      "Epoch 46/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 32m 45.3s\n",
      "\n",
      "Epoch 46: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 47/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 32m 57.6s\n",
      "\n",
      "Epoch 47: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 48/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0870 - tot_time: 0h 33m 9.8s\n",
      "\n",
      "Epoch 48: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 49/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0096 - NMSE: 0.0868 - tot_time: 0h 33m 21.8s\n",
      "\n",
      "Epoch 49: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - tot_time: 0h 33m 34.0s\n",
      "\n",
      "Epoch 50: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 51/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0096 - NMSE: 0.0868 - tot_time: 0h 33m 46.2s\n",
      "\n",
      "Epoch 51: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0096 - NMSE: 0.0868 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0812\n",
      "Epoch 52/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0868 - tot_time: 0h 33m 58.5s\n",
      "\n",
      "Epoch 52: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0868 - val_loss: 0.0093 - val_mse: 0.0091 - val_NMSE: 0.0817\n",
      "Epoch 53/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869Restoring model weights from the end of the best epoch: 43.\n",
      " - tot_time: 0h 34m 10.8s\n",
      "\n",
      "Epoch 53: val_NMSE did not improve from 0.08112\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0099 - mse: 0.0097 - NMSE: 0.0869 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0813\n",
      "Epoch 53: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 1e-05 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 34m 24.2s\n",
      "\n",
      "Epoch 1: val_NMSE improved from 0.08112 to 0.08091, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 2/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 34m 36.4s\n",
      "\n",
      "Epoch 2: val_NMSE did not improve from 0.08091\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 3/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 34m 48.7s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.08091 to 0.08091, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 4/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 35m 0.8s\n",
      "\n",
      "Epoch 4: val_NMSE did not improve from 0.08091\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 5/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 35m 13.0s\n",
      "\n",
      "Epoch 5: val_NMSE did not improve from 0.08091\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 6/200\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 35m 25.2s\n",
      "\n",
      "Epoch 6: val_NMSE did not improve from 0.08091\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 7/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 35m 37.3s\n",
      "\n",
      "Epoch 7: val_NMSE improved from 0.08091 to 0.08090, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 8/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - tot_time: 0h 35m 49.6s\n",
      "\n",
      "Epoch 8: val_NMSE did not improve from 0.08090\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 9/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - tot_time: 0h 36m 1.7s\n",
      "\n",
      "Epoch 9: val_NMSE did not improve from 0.08090\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 36m 13.9s\n",
      "\n",
      "Epoch 10: val_NMSE did not improve from 0.08090\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 11/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 36m 26.0s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.08090 to 0.08088, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 12/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 36m 38.2s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 36m 50.3s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 37m 2.5s\n",
      "\n",
      "Epoch 14: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 15/200\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 37m 14.8s\n",
      "\n",
      "Epoch 15: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 16/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 37m 27.1s\n",
      "\n",
      "Epoch 16: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 17/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 37m 39.1s\n",
      "\n",
      "Epoch 17: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 18/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - tot_time: 0h 37m 51.4s\n",
      "\n",
      "Epoch 18: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0867 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 19/200\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - tot_time: 0h 38m 3.4s\n",
      "\n",
      "Epoch 19: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 20/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - tot_time: 0h 38m 15.7s\n",
      "\n",
      "Epoch 20: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0866 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 21/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865Restoring model weights from the end of the best epoch: 11.\n",
      " - tot_time: 0h 38m 28.0s\n",
      "\n",
      "Epoch 21: val_NMSE did not improve from 0.08088\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_030/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0098 - mse: 0.0096 - NMSE: 0.0865 - val_loss: 0.0092 - val_mse: 0.0090 - val_NMSE: 0.0809\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compiling the network\n",
    "ae_net.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_list[0]),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "#     loss=losses.BinaryCrossentropy(from_logits=False),\n",
    "    run_eagerly=False,\n",
    "    metrics=['mse', NMSE_metric]\n",
    ")\n",
    "\n",
    "if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # this loads the weights/attributes of the optimizer as well\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net.load_weights(wt_file)\n",
    "    else:\n",
    "        ae_net.load_weights(wt_file)\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # implementing early stopping\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_NMSE',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=True,\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "\n",
    "    # time callback for each epoch\n",
    "    timekeeper_cb = mytimecallback()\n",
    "\n",
    "    # model checkpoint callback\n",
    "    dir_name_ckpt = dir_name_ae+dir_sep+'checkpoints'\n",
    "    if not os.path.isdir(dir_name_ckpt):\n",
    "        os.makedirs(dir_name_ckpt)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=dir_name_ckpt+dir_sep+'checkpoint',#+'/checkpoint--loss={loss:.4f}--vall_loss={val_loss:.4f}',\n",
    "        monitor='val_NMSE',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=2,\n",
    "        period=1  # saves every 5 epochs\n",
    "    )\n",
    "\n",
    "    # save losses callback\n",
    "    savelosses_cb = SaveLosses(\n",
    "        filepath=dir_name_ckpt+dir_sep+'LossHistoriesCheckpoint',\n",
    "        val_loss_arr=savelosses_cb_vallossarr,\n",
    "        train_loss_arr=savelosses_cb_trainlossarr,\n",
    "        total_epochs=epochs,\n",
    "        period=1)\n",
    "\n",
    "    # training the network\n",
    "    for i in range(starting_lr_idx, len(learning_rate_list)):\n",
    "        learning_rate = learning_rate_list[i]\n",
    "        K.set_value(ae_net.optimizer.lr, learning_rate)\n",
    "\n",
    "        savelosses_cb.update_lr_idx(i)\n",
    "\n",
    "        if i == starting_lr_idx:\n",
    "            EPOCHS = num_epochs_left\n",
    "            savelosses_cb.update_offset(epochs-num_epochs_left)\n",
    "        else:\n",
    "            EPOCHS = epochs\n",
    "            savelosses_cb.update_offset(0)\n",
    "\n",
    "        total_s_len = 80\n",
    "        sep_lr_s = ' LEARNING RATE : {} '.format(learning_rate)\n",
    "        sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'-' + sep_lr_s\n",
    "        sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'-'\n",
    "        print('\\n\\n' + '-'*len(sep_lr_s))\n",
    "        print('\\n' + sep_lr_s+'\\n')\n",
    "        print('-'*len(sep_lr_s) + '\\n\\n')\n",
    "        \n",
    "        history = ae_net.fit(training_data, training_data,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=batch_size,\n",
    "#             validation_split=val_split/train_split,\n",
    "            validation_data=(val_data, val_data),\n",
    "            callbacks=[early_stopping_cb, timekeeper_cb, checkpoint_cb, savelosses_cb],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss_hist.extend(history.history['val_loss'])\n",
    "        train_loss_hist.extend(history.history['loss'])\n",
    "        \n",
    "        val_MSE_hist.extend(history.history['val_mse'])\n",
    "        train_MSE_hist.extend(history.history['mse'])\n",
    "        \n",
    "        val_NMSE_hist.extend(history.history['val_NMSE'])\n",
    "        train_NMSE_hist.extend(history.history['NMSE'])\n",
    "        \n",
    "        if use_attention_module == True:\n",
    "            for j in range(len(ae_net.encoder_attention_modules_list)):\n",
    "                key = 'encoder_attention_module_{}_lambda'.format(j)\n",
    "                lst1 = history.history[key]\n",
    "                lst2 = encoder_attention_lambdas[key]\n",
    "                lst2.extend(lst1)\n",
    "                encoder_attention_lambdas[key] = lst2\n",
    "            for j in range(len(ae_net.decoder_attention_modules_list)):\n",
    "                key = 'decoder_attention_module_{}_lambda'.format(j)\n",
    "                lst1 = history.history[key]\n",
    "                lst2 = decoder_attention_lambdas[key]\n",
    "                lst2.extend(lst1)\n",
    "                decoder_attention_lambdas[key] = lst2\n",
    "        \n",
    "        if i == starting_lr_idx:\n",
    "            lr_change[i+1] += len(history.history['val_loss'])\n",
    "        else:\n",
    "            lr_change.append(lr_change[i]+len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Capturing() as output:\n",
    "    ae_net.encoder_net.summary()\n",
    "\n",
    "with open(dir_name_ae + '/ae_encoder_summary.txt', 'w') as f:\n",
    "    for line in output:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Capturing() as output:\n",
    "    ae_net.decoder_net.summary()\n",
    "\n",
    "with open(dir_name_ae + '/ae_decoder_summary.txt', 'w') as f:\n",
    "    for line in output:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 2, 50, 50)]       0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 2, 4, 4)           13778     \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 2, 50, 50)         9672      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,450\n",
      "Trainable params: 13,192\n",
      "Non-trainable params: 10,258\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_net.ae_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9705,
     "status": "ok",
     "timestamp": 1666788875924,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "d_Od0ul4P9bK",
    "outputId": "860e9f94-e593-4a74-fcff-6a6657d925de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 10ms/step - loss: 0.0093 - mse: 0.0091 - NMSE: 0.0821\n"
     ]
    }
   ],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    test_metrics = ae_net.evaluate(\n",
    "        testing_data, testing_data,\n",
    "    )\n",
    "#     train_metrics = ae_net.evaluate(training_data, training_data)\n",
    "#     val_metrics = ae_net.evaluate(val_data, val_data)\n",
    "\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    save_dict = {\n",
    "        'val_loss_hist':val_loss_hist,\n",
    "        'train_loss_hist':train_loss_hist,\n",
    "        'val_MSE_hist':val_MSE_hist,\n",
    "        'train_MSE_hist':train_MSE_hist,\n",
    "        'val_NMSE_hist':val_NMSE_hist,\n",
    "        'train_NMSE_hist':train_NMSE_hist,\n",
    "        'lr_change':lr_change,\n",
    "        'test_loss':test_metrics[0],\n",
    "        'test_mse':test_metrics[1],\n",
    "#         'train_loss':train_metrics[0],\n",
    "#         'train_mse':train_metrics[1],\n",
    "#         'val_loss':val_metrics[0],\n",
    "#         'val_mse':val_metrics[1],\n",
    "    }\n",
    "    if use_attention_module == True:\n",
    "        for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "            key = 'encoder_attention_module_{}_lambda'.format(i)\n",
    "            save_dict[key] = encoder_attention_lambdas[key]\n",
    "        for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "            key = 'decoder_attention_module_{}_lambda'.format(i)\n",
    "            save_dict[key] = decoder_attention_lambdas[key]\n",
    "\n",
    "    with open(save_path+dir_sep+'losses.txt', 'w') as f:\n",
    "        f.write(str(save_dict))\n",
    "\n",
    "    np.savez(\n",
    "        save_path+dir_sep+'losses',\n",
    "        **save_dict\n",
    "    )\n",
    "        \n",
    "\n",
    "    ae_net.save_everything(\n",
    "        file_name=save_path+dir_sep+'final_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788875925,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Dy8GNcgMVD4T",
    "outputId": "e50e8738-9da1-43de-e551-43f47b64135e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_change :  [0, 112, 165, 186]\n"
     ]
    }
   ],
   "source": [
    "print('lr_change : ', lr_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1666788876686,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ewTz1COFSocM",
    "outputId": "15bc2be5-d571-433e-b5cd-9c722f38b48b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting losses\n",
    "dir_name_plot = dir_name_ae + '/plots'\n",
    "if not os.path.isdir(dir_name_plot):\n",
    "    os.makedirs(dir_name_plot)\n",
    "\n",
    "# Visualize loss history\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_loss_hist,\n",
    "    val_loss=val_loss_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list\n",
    ")\n",
    "\n",
    "plt.savefig(dir_name_plot + '{ds}loss_history.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_MSE_hist,\n",
    "    val_loss=val_MSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training MSE', 'Validation MSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='MSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/MSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_NMSE_hist,\n",
    "    val_loss=val_NMSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training NMSE', 'Validation NMSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='NMSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/NMSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1666788877562,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wwt4brHcOaXi",
    "outputId": "7ba39105-aa8e-49e8-dbfd-619069123fdd"
   },
   "outputs": [],
   "source": [
    "if use_attention_module == True:\n",
    "    # plotting encoder attention lambdas\n",
    "    plot_lst = []\n",
    "    legend_lst = []\n",
    "    for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "        key = 'encoder_attention_module_{}_lambda'.format(i)\n",
    "        plot_lst.append(encoder_attention_lambdas[key])\n",
    "        legend_lst.append(\"attention module (encoder) {}\".format(i+1))\n",
    "    fig, ax = plot_losses(\n",
    "        training_loss=plot_lst[0],\n",
    "        val_loss=None,\n",
    "        more_plot_arrs_lst=plot_lst[1:] if len(plot_lst)>1 else [],\n",
    "        lr_change=lr_change,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        legend_list=legend_lst,\n",
    "        xlabel='Epoch',\n",
    "        ylabel=r\"$\\lambda_{attention}$\",\n",
    "        plot_type='plot',\n",
    "        traininglossplot_args=[],\n",
    "        traininglossplot_kwargs={},\n",
    "        epoch_count_begin=0,\n",
    "        epoch_count_end=len(plot_lst[0])-1,\n",
    "    )\n",
    "    plt.savefig(dir_name_plot+'/attention_lambdas_encoder.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plotting decoder attention lambdas\n",
    "    plot_lst = []\n",
    "    legend_lst = []\n",
    "    for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "        key = 'decoder_attention_module_{}_lambda'.format(i)\n",
    "        plot_lst.append(decoder_attention_lambdas[key])\n",
    "        legend_lst.append(\"attention module (decoder) {}\".format(i+1))\n",
    "    fig, ax = plot_losses(\n",
    "        training_loss=plot_lst[0],\n",
    "        val_loss=None,\n",
    "        more_plot_arrs_lst=plot_lst[1:] if len(plot_lst)>1 else [],\n",
    "        lr_change=lr_change,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        legend_list=legend_lst,\n",
    "        xlabel='Epoch',\n",
    "        ylabel=r\"$\\lambda_{attention}$\",\n",
    "        plot_type='plot',\n",
    "        traininglossplot_args=[],\n",
    "        traininglossplot_kwargs={},\n",
    "        epoch_count_begin=0,\n",
    "        epoch_count_end=len(plot_lst[0])-1,\n",
    "    )\n",
    "    plt.savefig(dir_name_plot+'/attention_lambdas_decoder.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1kzRwBdNfA2o28NxHkc2fku7QnFPAI8Bo"
    },
    "executionInfo": {
     "elapsed": 4835,
     "status": "ok",
     "timestamp": 1666788882395,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "_6rNhThyQrKc",
    "outputId": "fdeeb3f5-009a-404e-8856-b7655d596a88"
   },
   "source": [
    "# POD Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 17515,
     "status": "ok",
     "timestamp": 1666788899903,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "cAiMV0iU0EpK"
   },
   "outputs": [],
   "source": [
    "# pod_training_data = np.empty(shape=(training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "# pod_training_data[:, :] = np.reshape(training_data, (training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "\n",
    "# pod_centering_means = np.mean(pod_training_data, axis=0)\n",
    "# pod_mean_centered_data = pod_training_data - pod_centering_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C = np.transpose(pod_mean_centered_data) @ pod_mean_centered_data\n",
    "# C /= pod_mean_centered_data.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1666788900494,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "jVqsAwsY0Amw",
    "outputId": "95dd7bc9-f2b0-421e-a1b4-3e7e594cd44a"
   },
   "outputs": [],
   "source": [
    "# eigenvals, eigenvecs = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2127,
     "status": "ok",
     "timestamp": 1666788902619,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wjgPNitSrt5p",
    "outputId": "d60c9340-28f4-479b-8b66-5ee2a5fc5cee"
   },
   "outputs": [],
   "source": [
    "# abs_eigenvals = np.abs(eigenvals)\n",
    "# idx = np.argsort(abs_eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 5242,
     "status": "ok",
     "timestamp": 1666788907858,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Jv8PgBgzV1_s"
   },
   "outputs": [],
   "source": [
    "# idx = idx[::-1]\n",
    "# W = eigenvecs[:, idx[0:4*4*enc_filters[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666788907859,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wnLnqg0Jrt5t"
   },
   "outputs": [],
   "source": [
    "# reconstructed_val_data = val_data.reshape(val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]) @ W @ W.transpose()\n",
    "# reconstructed_val_data = np.reshape(reconstructed_val_data, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_recon_MSE = np.reshape((reconstructed_val_data - val_data)**2, (val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "# val_recon_MSE = np.mean(np.sum(val_recon_MSE, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(val_recon_MSE, val_recon_MSE/np.sum(time_stddev**2), np.sum(time_stddev**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_eigenvals[idx[0:4*4*2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = ''\n",
    "for i in range(len(ae_net.encoder_layers_list)):\n",
    "    l = ae_net.encoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('attention_module'):\n",
    "        # print(i, name, l.lambda_att.numpy())\n",
    "        s += 'i : {}, name : {}, lambda_att : {}\\n'.format(i, name, l.lambda_att.numpy())\n",
    "print(s)\n",
    "\n",
    "if s != '':\n",
    "    with open(dir_name_ae + '/attention_lambdas_encoder.txt', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = ''\n",
    "for i in range(len(ae_net.decoder_layers_list)):\n",
    "    l = ae_net.decoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('attention_module'):\n",
    "        # print(i, name, l.lambda_att.numpy())\n",
    "        s += 'i : {}, name : {}, lambda_att : {}\\n'.format(i, name, l.lambda_att.numpy())\n",
    "print(s)\n",
    "\n",
    "if s != '':\n",
    "    with open(dir_name_ae + '/attention_lambdas_decoder.txt', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 periodic_padding <tf.Variable 'periodic_padding/M_mat:0' shape=(52, 50) dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 1.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 1.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>\n",
      "4 periodic_padding_1 <tf.Variable 'periodic_padding_1/M_mat:0' shape=(27, 25) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>\n",
      "8 periodic_padding_2 <tf.Variable 'periodic_padding_2/M_mat:0' shape=(15, 13) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>\n",
      "12 periodic_padding_3 <tf.Variable 'periodic_padding_3/M_mat:0' shape=(9, 7) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ae_net.encoder_layers_list)):\n",
    "    l = ae_net.encoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('periodic_padding'):\n",
    "        print(i, name, l.M_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 periodic_padding_4 <tf.Variable 'periodic_padding_4/M_mat:0' shape=(6, 4) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.]], dtype=float32)>\n",
      "5 periodic_padding_5 <tf.Variable 'periodic_padding_5/M_mat:0' shape=(10, 8) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>\n",
      "10 periodic_padding_6 <tf.Variable 'periodic_padding_6/M_mat:0' shape=(18, 16) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>\n",
      "15 periodic_padding_7 <tf.Variable 'periodic_padding_7/M_mat:0' shape=(34, 32) dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 1.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 1.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ae_net.decoder_layers_list)):\n",
    "    l = ae_net.decoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('periodic_padding'):\n",
    "        print(i, name, l.M_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
