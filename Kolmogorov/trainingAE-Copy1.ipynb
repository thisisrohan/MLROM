{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788634667,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "4xhxMpe_r-Y5"
   },
   "outputs": [],
   "source": [
    "# enabling 3rd party widgets\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# output.disable_custom_widget_manager()\n",
    "\n",
    "# interactive 3D plot\n",
    "# !pip install ipympl\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3089,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "a5qPupCDsjSz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "import time as time\n",
    "import platform as platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import h5py\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788637752,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "3AVrZNGlZu4Z"
   },
   "outputs": [],
   "source": [
    "colab_flag = False\n",
    "\n",
    "FTYPE = np.float32\n",
    "ITYPE = np.int32\n",
    "\n",
    "strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788637753,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "SxAd7iDL0Ami"
   },
   "outputs": [],
   "source": [
    "current_sys = platform.system()\n",
    "\n",
    "if current_sys == 'Windows':\n",
    "    dir_sep = '\\\\'\n",
    "else:\n",
    "    dir_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27766,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "JjNnPRuk0IIX",
    "outputId": "f93a8628-71fe-4d6d-b3b6-245dfcb8eb60"
   },
   "outputs": [],
   "source": [
    "if colab_flag == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Github/MLROM/KS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788665512,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "9REiGIIy0IzV",
    "outputId": "2b5b0b02-2f67-4635-a00c-82084a8d2ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rkaushik/Documents/Thesis/MLROM/Kolmogorov\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1666788666890,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "8S1AHEkl48bn"
   },
   "outputs": [],
   "source": [
    "from tools.misc_tools import mytimecallback, SaveLosses, plot_losses, readAndReturnLossHistories\n",
    "from tools.ae_v2 import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666891,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-mIQj_v4gzMh"
   },
   "outputs": [],
   "source": [
    "behaviour = 'initialiseAndTrainFromScratch'\n",
    "# behaviour = 'loadCheckpointAndContinueTraining'\n",
    "# behaviour = 'loadFinalNetAndPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "QL5n-abCg0nI"
   },
   "outputs": [],
   "source": [
    "# setting seed for PRNGs\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    prng_seed = 42\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788666892,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "tc3zO9xL_tNl",
    "outputId": "f77bf689-c865-4a8d-8d40-37ec9c75f1ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 16:28:19.232013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.306082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.306310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 16:28:19.308599: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 16:28:19.309511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.309869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.310200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.920960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.921136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.921287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 16:28:19.921405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23547 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if colab_flag == False:\n",
    "    if strategy is None:\n",
    "        if gpus:\n",
    "            gpu_to_use = 0\n",
    "            tf.config.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    print(logical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "2.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 16:53:54.440185: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-29 16:53:54.440250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: TUD0035344\n",
      "2023-04-29 16:53:54.440268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: TUD0035344\n",
      "2023-04-29 16:53:54.440399: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 530.41.3\n",
      "2023-04-29 16:53:54.440450: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 530.41.3\n",
      "2023-04-29 16:53:54.440465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 530.41.3\n",
      "2023-04-29 16:53:54.442021: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.gpu_device_name())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.list_logical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UbdnOtc4_z9"
   },
   "source": [
    "# KS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "xcNgt4hqg6Xv",
    "outputId": "7735ac54-495c-493f-869b-7d15538ee30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name_ae: /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018\n",
      "24 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# setting up params (and saving, if applicable)\n",
    "from numpy import *\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # loading data directory\n",
    "    data_dir_idx = '000'\n",
    "\n",
    "    # making ae save directory\n",
    "    dir_name_ae = os.getcwd() + dir_sep + 'saved_ae'\n",
    "    if not os.path.isdir(dir_name_ae):\n",
    "        os.makedirs(dir_name_ae)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        dir_check = 'ae_' + str(counter).zfill(3)\n",
    "        if os.path.isdir(dir_name_ae + dir_sep + dir_check):\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dir_name_ae = dir_name_ae + dir_sep + dir_check\n",
    "    os.makedirs(dir_name_ae)\n",
    "    os.makedirs(dir_name_ae+dir_sep+'plots')\n",
    "else:\n",
    "    # some paramaters\n",
    "    dir_name_ae = os.getcwd()+'{ds}saved_ae{ds}ae_015'.format(ds=dir_sep)\n",
    "\n",
    "    with open(dir_name_ae + dir_sep + 'ae_data.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    params_dict = eval(''.join(lines))\n",
    "    data_dir_idx = params_dict['data_dir_idx']\n",
    "    normalizeforae_flag = params_dict['normalizeforae_flag']\n",
    "    normalization_constant_arr_aedata = params_dict['normalization_constant_arr_aedata']\n",
    "    if os.path.exists(dir_name_ae+dir_sep+'normalization_data.npz'):\n",
    "        with np.load(dir_name_ae+dir_sep+'normalization_data.npz', allow_pickle=True) as fl:\n",
    "            normalization_constant_arr_aedata = fl['normalization_constant_arr_aedata'][0]\n",
    "\n",
    "print('dir_name_ae:', dir_name_ae)\n",
    "# loading data\n",
    "dir_name_data = os.getcwd() + dir_sep + 'saved_data' + dir_sep + 'data_' + data_dir_idx\n",
    "    \n",
    "with h5py.File(dir_name_data + '/data.h5', 'r') as f:\n",
    "    t_recorded_samples = np.array(f['t'])\n",
    "    \n",
    "    N = int(0.5*(np.array(f['num_wavenumbers'])-1))\n",
    "    print(N, type(N))\n",
    "    \n",
    "    u_ref = np.array(f['u_reference'], dtype=FTYPE)\n",
    "    v_ref = np.array(f['v_reference'], dtype=FTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.empty(shape=(u_ref.shape[0], 2, u_ref.shape[1], u_ref.shape[2]), dtype=FTYPE)\n",
    "all_data[:, 0, :, :] = u_ref\n",
    "del(u_ref)\n",
    "all_data[:, 1, :, :] = v_ref\n",
    "del(v_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666788668916,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "O7sl7i5H5Dqz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2415,
     "status": "ok",
     "timestamp": 1666788671329,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ySVDz_2U5FH5",
    "outputId": "53f23b1d-fa61-4f27-bbc4-2e624421a866"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788671330,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "bkQx9q_p5Gro"
   },
   "outputs": [],
   "source": [
    "# dealing with normalizing the data before feeding into autoencoder\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    # normalize data before feeding into autoencoder?\n",
    "    normalizeforae_flag = True\n",
    "    normalization_type = 'stddev' # could be 'stddev' or 'minmax'\n",
    "    stddev_multiplier = 3\n",
    "    \n",
    "    normalization_constant_arr_aedata = None\n",
    "    if normalizeforae_flag == True:\n",
    "        normalization_constant_arr_aedata = np.empty(shape=(2,) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "        if normalization_type == 'stddev':\n",
    "            normalization_constant_arr_aedata[0] = np.mean(all_data, axis=0)\n",
    "            normalization_constant_arr_aedata[1] = stddev_multiplier * np.std(all_data, axis=0)\n",
    "        elif normalization_type == 'minmax':\n",
    "            sample_min = all_data.min(axis=0)\n",
    "            sample_max = all_data.max(axis=0)\n",
    "            idx = np.where(sample_min == sample_max)\n",
    "            if len(idx) > 0:\n",
    "                num_elems = len(idx[0])\n",
    "                for i in range(num_elems):\n",
    "                    i0 = idx[0][i]\n",
    "                    i1 = idx[1][i]\n",
    "                    i2 = idx[2][i]\n",
    "                    sample_min[i0, i1, i2] -= 0.5\n",
    "                    sample_max[i0, i1, i2] = sample_min[i0, i1, i2] + 1.\n",
    "            normalization_constant_arr_aedata[0] = sample_min\n",
    "            normalization_constant_arr_aedata[1] = sample_max - sample_min\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "    # saving sim data\n",
    "    ae_data = {\n",
    "        'data_dir_idx':data_dir_idx,\n",
    "        'normalizeforae_flag':normalizeforae_flag,\n",
    "        # 'normalization_constant_arr_aedata':normalization_constant_arr_aedata,\n",
    "        'normalization_type':normalization_type,\n",
    "        'stddev_multiplier':stddev_multiplier,\n",
    "        'ae_data_with_params':False,\n",
    "        'module':Autoencoder.__module__,\n",
    "    }\n",
    "    with open(dir_name_ae+dir_sep+'ae_data.txt', 'w') as f:\n",
    "        f.write(str(ae_data))\n",
    "    np.savez(\n",
    "        dir_name_ae+dir_sep+'normalization_data',\n",
    "        normalization_constant_arr_aedata=[normalization_constant_arr_aedata],\n",
    "    )\n",
    "else:\n",
    "    if normalizeforae_flag == True:\n",
    "        all_data -= normalization_constant_arr_aedata[0]\n",
    "        all_data /= normalization_constant_arr_aedata[1]\n",
    "            \n",
    "time_stddev = np.std(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1666788672340,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "uDhfYHU45IS8",
    "outputId": "982f534f-255c-41b9-f40a-327730ac89ae"
   },
   "outputs": [],
   "source": [
    "all_data = all_data[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1666788672341,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "59kkrSP1GvzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666788672342,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "-MJa7P5t5KiC",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6KQEjR5LkK"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1666788672765,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "c5cjQ1lnjcwt"
   },
   "outputs": [],
   "source": [
    "# setting up training params\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    learning_rate_list = [1e-3, 1e-4, 1e-5]\n",
    "    epochs = 200\n",
    "    patience = 10  # parameter for early stopping\n",
    "    min_delta = 1e-6  # parameter for early stopping\n",
    "    lambda_reg = 5e-7 # weight for regularizer\n",
    "    train_split = 0.8\n",
    "    val_split = 0.1\n",
    "    test_split = 1 - train_split - val_split\n",
    "    batch_size = 16\n",
    "    fRMS = 2/100\n",
    "    timeMeanofSpaceRMS = np.mean(np.mean(all_data**2, axis=1)**0.5)\n",
    "    \n",
    "    # stddev = fRMS*timeMeanofSpaceRMS\n",
    "    stddev = fRMS * np.mean(time_stddev)\n",
    "    use_weights_post_dense = False\n",
    "    use_batch_norm = True\n",
    "\n",
    "    # saving training params\n",
    "    training_specific_params = {\n",
    "        'learning_rate_list':learning_rate_list,\n",
    "        'epochs':epochs,\n",
    "        'patience':patience,\n",
    "        'min_delta':min_delta,\n",
    "        'prng_seed':prng_seed,\n",
    "        'train_split':train_split,\n",
    "        'val_split':val_split,\n",
    "        'batch_size':batch_size,\n",
    "        'fRMS':fRMS,\n",
    "        'timeMeanofSpaceRMS':timeMeanofSpaceRMS,\n",
    "        'stddev':stddev,\n",
    "        'use_batch_norm':use_batch_norm,\n",
    "    }\n",
    "\n",
    "    with open(dir_name_ae+dir_sep+'training_specific_params.txt', 'w') as f:\n",
    "        f.write(str(training_specific_params))\n",
    "else:\n",
    "    with open(dir_name_ae + dir_sep + 'training_specific_params.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    tparams_dict = eval(''.join(lines))\n",
    "\n",
    "    learning_rate_list = tparams_dict['learning_rate_list']\n",
    "    epochs = tparams_dict['epochs']\n",
    "    patience = tparams_dict['patience']\n",
    "    min_delta = tparams_dict['min_delta']\n",
    "    prng_seed = tparams_dict['prng_seed']\n",
    "    train_split = tparams_dict['train_split']\n",
    "    val_split = tparams_dict['val_split']\n",
    "    batch_size = tparams_dict['batch_size']\n",
    "    try:\n",
    "        stddev = tparams_dict['stddev']\n",
    "    except:\n",
    "        print(\"'stddev' not in tparams_dict, set to 0\")\n",
    "        stddev = 0.0\n",
    "\n",
    "    test_split = 1 - train_split - val_split\n",
    "\n",
    "    # setting seed for PRNGs\n",
    "    np.random.seed(prng_seed)\n",
    "    tf.random.set_seed(prng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672769,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "lovTI3zuhlX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666788672770,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "IjsRi02g5ORG"
   },
   "outputs": [],
   "source": [
    "# # setting up data\n",
    "# idx = np.arange(all_data.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# boundary = int(np.round((1-test_split)*all_data.shape[0]))\n",
    "# training_data = all_data[idx[0:boundary], :]\n",
    "# testing_data = all_data[idx[boundary:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672771,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Qwietg7eTG-s"
   },
   "outputs": [],
   "source": [
    "num_train = int(all_data.shape[0]*train_split)\n",
    "num_val = int(all_data.shape[0]*val_split)\n",
    "num_test = all_data.shape[0] - num_train - num_val\n",
    "\n",
    "idx = np.arange(all_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "training_data = np.empty(shape=(num_train, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "val_data = np.empty(shape=(num_val, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "testing_data = np.empty(shape=(num_test, ) + tuple(all_data.shape[1:]), dtype=FTYPE)\n",
    "\n",
    "training_data[:] = all_data[idx[0:num_train]]\n",
    "val_data[:] = all_data[idx[num_train:num_train+num_val]]\n",
    "testing_data[:] = all_data[idx[num_train+num_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666788672772,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gJ-28EnzJ4Ur"
   },
   "outputs": [],
   "source": [
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1666788672773,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7xTsmS7lgpps"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1626,
     "status": "ok",
     "timestamp": 1666788674381,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "7l5kI1tfMszJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 16:28:57.923677: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n"
     ]
    }
   ],
   "source": [
    "# Initialize network\n",
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    enc_filters = [8, 8, 3, 1] # [8, 16, 32, 16, 6, 2]\n",
    "    enc_strides = [2, 2, 1, 1] # [2,  2,  2,  2, 1, 1]\n",
    "    enc_attn_placement = [1, 2, 3]\n",
    "    dec_filters = [3, 8, 8, 2] # [6, 16, 32, 16, 8, 2]\n",
    "    dec_strides = [1, 1, 2, 2] # [1,  1,  2,  2, 2, 2]\n",
    "    dec_attn_placement = [1, 2, 3]\n",
    "    kernel_size = 5\n",
    "    \n",
    "    enc_layer_act_func = 'elu'\n",
    "    enc_final_layer_act_func = 'tanh'\n",
    "    dec_layer_act_func = 'elu'\n",
    "    dec_final_layer_act_func = 'tanh'\n",
    "    reg_name = 'L2'\n",
    "    \n",
    "    use_periodic_padding = True\n",
    "    use_attention_module = True\n",
    "    \n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(\n",
    "                data_dim=training_data.shape[1:],\n",
    "                kernel_size=kernel_size,\n",
    "                enc_filters=enc_filters, # number of filters\n",
    "                dec_filters=dec_filters, # number of filters\n",
    "                lambda_reg=lambda_reg,\n",
    "                reg_name=reg_name,\n",
    "                enc_layer_act_func=enc_layer_act_func,\n",
    "                enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "                dec_layer_act_func=dec_layer_act_func,\n",
    "                dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "                load_file=None,\n",
    "                stddev=stddev,\n",
    "                use_weights_post_dense=use_weights_post_dense,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "                use_periodic_padding=use_periodic_padding,\n",
    "                use_attention_module=use_attention_module,\n",
    "                enc_strides=enc_strides,\n",
    "                enc_attn_placement=enc_attn_placement,\n",
    "                dec_strides=dec_strides,\n",
    "                dec_attn_placement=dec_attn_placement,)\n",
    "    else:\n",
    "        ae_net = Autoencoder(\n",
    "            data_dim=training_data.shape[1:],\n",
    "            kernel_size=kernel_size,\n",
    "            enc_filters=enc_filters, # number of filters\n",
    "            dec_filters=dec_filters, # number of filters\n",
    "            lambda_reg=lambda_reg,\n",
    "            reg_name=reg_name,\n",
    "            enc_layer_act_func=enc_layer_act_func,\n",
    "            enc_final_layer_act_func=enc_final_layer_act_func,\n",
    "            dec_layer_act_func=dec_layer_act_func,\n",
    "            dec_final_layer_act_func=dec_final_layer_act_func,\n",
    "            load_file=None,\n",
    "            stddev=stddev,\n",
    "            use_weights_post_dense=use_weights_post_dense,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            use_periodic_padding=use_periodic_padding,\n",
    "            use_attention_module=use_attention_module,\n",
    "            enc_strides=enc_strides,\n",
    "            enc_attn_placement=enc_attn_placement,\n",
    "            dec_strides=dec_strides,\n",
    "            dec_attn_placement=dec_attn_placement,)\n",
    "    # saving the AE configuration\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    ae_net.save_class_dict(save_path+dir_sep+'final_net_class_dict.txt')\n",
    "else:\n",
    "    load_file = dir_name_ae + dir_sep + 'final_net' + dir_sep + 'final_net_class_dict.txt'\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    else:\n",
    "        ae_net = Autoencoder(data_dim=training_data.shape[1:], load_file=load_file)\n",
    "    \n",
    "    if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "        wt_file = tf.train.latest_checkpoint(dir_name_ae+dir_sep+'checkpoints')\n",
    "        # ae_net.load_weights(wt_file)\n",
    "    elif behaviour == 'loadFinalNetAndPlot':\n",
    "        wt_file = dir_name_ae+dir_sep+'final_net'+dir_sep+'final_net_ae_weights.h5'\n",
    "        ae_net.load_weights_from_file(wt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1666788674637,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "48tkgZxT0Amt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1666788674956,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "yUChBAKqIFtX"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch':\n",
    "    val_loss_hist = []\n",
    "    train_loss_hist = []\n",
    "    lr_change=[0, 0]\n",
    "    savelosses_cb_vallossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    savelosses_cb_trainlossarr = np.ones(shape=epochs*len(learning_rate_list))*np.NaN\n",
    "    starting_lr_idx = 0\n",
    "    num_epochs_left = epochs\n",
    "elif behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    val_loss_hist, train_loss_hist, lr_change, starting_lr_idx, num_epochs_left, val_loss_arr_fromckpt, train_loss_arr_fromckpt = readAndReturnLossHistories(\n",
    "        dir_name_ae=dir_name_ae,\n",
    "        dir_sep=dir_sep,\n",
    "        epochs=epochs,\n",
    "        learning_rate_list=learning_rate_list)\n",
    "    savelosses_cb_vallossarr = val_loss_arr_fromckpt\n",
    "    savelosses_cb_trainlossarr = train_loss_arr_fromckpt\n",
    "elif behaviour == 'loadFinalNetAndPlot':\n",
    "    with open(dir_name_ae+'{ds}final_net{ds}losses.txt'.format(ds=dir_sep), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    losses_dict = eval(''.join(lines))\n",
    "\n",
    "    val_loss_hist = losses_dict['val_loss_hist']\n",
    "    train_loss_hist = losses_dict['train_loss_hist']\n",
    "    lr_change = losses_dict['lr_change']\n",
    "    test_loss = losses_dict['test_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE_hist = []\n",
    "val_MSE_hist = []\n",
    "\n",
    "train_NMSE_hist = []\n",
    "val_NMSE_hist = []\n",
    "\n",
    "if use_attention_module == True:\n",
    "    encoder_attention_lambdas = {}\n",
    "    for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "        l = ae_net.encoder_attention_modules_list[i]\n",
    "        encoder_attention_lambdas['encoder_attention_module_{}_lambda'.format(i)] = [0]\n",
    "    decoder_attention_lambdas = {}\n",
    "    for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "        l = ae_net.decoder_attention_modules_list[i]\n",
    "        decoder_attention_lambdas['decoder_attention_module_{}_lambda'.format(i)] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666788674957,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Z0oEGp6WKGu2"
   },
   "outputs": [],
   "source": [
    "class NMSE(tf.keras.metrics.MeanSquaredError):\n",
    "    def __init__(self, divisor_arr, name='NMSE', **kwargs):\n",
    "        super(NMSE, self).__init__(name, **kwargs)\n",
    "        self.divisor_arr = divisor_arr\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = y_true / self.divisor_arr\n",
    "        y_pred = y_pred / self.divisor_arr\n",
    "        return super(NMSE, self).update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if strategy is not None:\n",
    "    with strategy.scope():\n",
    "        NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))\n",
    "else:\n",
    "    NMSE_metric = NMSE(divisor_arr=tf.constant(time_stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191278,
     "status": "ok",
     "timestamp": 1666788866231,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "gELga1WnQeMK",
    "outputId": "e923a97a-2d9d-4c74-c328-4793de05b919",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------- LEARNING RATE : 0.001 -----------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0386 - mse: 0.0385 - NMSE: 0.3468 - encoder_attention_module_0_lambda: -0.0352 - encoder_attention_module_1_lambda: 0.0385 - encoder_attention_module_2_lambda: -0.0317 - decoder_attention_module_0_lambda: -0.1015 - decoder_attention_module_1_lambda: -0.1445 - decoder_attention_module_2_lambda: 0.1291 - tot_time: 0h 0m 39.1s\n",
      "\n",
      "Epoch 1: val_NMSE improved from inf to 0.19470, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 38s 27ms/step - loss: 0.0386 - mse: 0.0385 - NMSE: 0.3468 - encoder_attention_module_0_lambda: -0.0352 - encoder_attention_module_1_lambda: 0.0385 - encoder_attention_module_2_lambda: -0.0317 - decoder_attention_module_0_lambda: -0.1015 - decoder_attention_module_1_lambda: -0.1445 - decoder_attention_module_2_lambda: 0.1291 - val_loss: 0.0217 - val_mse: 0.0216 - val_NMSE: 0.1947\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0187 - mse: 0.0186 - NMSE: 0.1675 - encoder_attention_module_0_lambda: -0.0695 - encoder_attention_module_1_lambda: 0.0170 - encoder_attention_module_2_lambda: -0.0106 - decoder_attention_module_0_lambda: -0.1321 - decoder_attention_module_1_lambda: -0.1665 - decoder_attention_module_2_lambda: 0.1740 - tot_time: 0h 1m 10.0s\n",
      "\n",
      "Epoch 2: val_NMSE improved from 0.19470 to 0.15382, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0187 - mse: 0.0186 - NMSE: 0.1675 - encoder_attention_module_0_lambda: -0.0695 - encoder_attention_module_1_lambda: 0.0170 - encoder_attention_module_2_lambda: -0.0106 - decoder_attention_module_0_lambda: -0.1321 - decoder_attention_module_1_lambda: -0.1665 - decoder_attention_module_2_lambda: 0.1740 - val_loss: 0.0172 - val_mse: 0.0171 - val_NMSE: 0.1538\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0153 - mse: 0.0152 - NMSE: 0.1369 - encoder_attention_module_0_lambda: -0.0465 - encoder_attention_module_1_lambda: 0.0138 - encoder_attention_module_2_lambda: -0.0293 - decoder_attention_module_0_lambda: -0.1326 - decoder_attention_module_1_lambda: -0.1596 - decoder_attention_module_2_lambda: 0.2026 - tot_time: 0h 1m 41.9s\n",
      "\n",
      "Epoch 3: val_NMSE improved from 0.15382 to 0.10697, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 0.0153 - mse: 0.0152 - NMSE: 0.1369 - encoder_attention_module_0_lambda: -0.0465 - encoder_attention_module_1_lambda: 0.0138 - encoder_attention_module_2_lambda: -0.0293 - decoder_attention_module_0_lambda: -0.1326 - decoder_attention_module_1_lambda: -0.1595 - decoder_attention_module_2_lambda: 0.2027 - val_loss: 0.0120 - val_mse: 0.0119 - val_NMSE: 0.1070\n",
      "Epoch 4/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0117 - mse: 0.0115 - NMSE: 0.1036 - encoder_attention_module_0_lambda: -0.0464 - encoder_attention_module_1_lambda: 0.0345 - encoder_attention_module_2_lambda: -0.0350 - decoder_attention_module_0_lambda: -0.1233 - decoder_attention_module_1_lambda: -0.1167 - decoder_attention_module_2_lambda: 0.2298 - tot_time: 0h 2m 13.3s\n",
      "\n",
      "Epoch 4: val_NMSE improved from 0.10697 to 0.08994, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0117 - mse: 0.0115 - NMSE: 0.1036 - encoder_attention_module_0_lambda: -0.0464 - encoder_attention_module_1_lambda: 0.0345 - encoder_attention_module_2_lambda: -0.0350 - decoder_attention_module_0_lambda: -0.1233 - decoder_attention_module_1_lambda: -0.1167 - decoder_attention_module_2_lambda: 0.2299 - val_loss: 0.0101 - val_mse: 0.0100 - val_NMSE: 0.0899\n",
      "Epoch 5/200\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0100 - mse: 0.0098 - NMSE: 0.0882 - encoder_attention_module_0_lambda: -0.0507 - encoder_attention_module_1_lambda: 0.0274 - encoder_attention_module_2_lambda: -0.0321 - decoder_attention_module_0_lambda: -0.1168 - decoder_attention_module_1_lambda: -0.1354 - decoder_attention_module_2_lambda: 0.2541 - tot_time: 0h 2m 44.6s\n",
      "\n",
      "Epoch 5: val_NMSE improved from 0.08994 to 0.07563, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0099 - mse: 0.0098 - NMSE: 0.0881 - encoder_attention_module_0_lambda: -0.0507 - encoder_attention_module_1_lambda: 0.0274 - encoder_attention_module_2_lambda: -0.0321 - decoder_attention_module_0_lambda: -0.1168 - decoder_attention_module_1_lambda: -0.1355 - decoder_attention_module_2_lambda: 0.2541 - val_loss: 0.0086 - val_mse: 0.0084 - val_NMSE: 0.0756\n",
      "Epoch 6/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0930 - encoder_attention_module_0_lambda: -0.0286 - encoder_attention_module_1_lambda: -0.0150 - encoder_attention_module_2_lambda: -0.0082 - decoder_attention_module_0_lambda: -0.0978 - decoder_attention_module_1_lambda: -0.1454 - decoder_attention_module_2_lambda: 0.2827 - tot_time: 0h 3m 15.9s\n",
      "\n",
      "Epoch 6: val_NMSE improved from 0.07563 to 0.07320, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0105 - mse: 0.0103 - NMSE: 0.0929 - encoder_attention_module_0_lambda: -0.0286 - encoder_attention_module_1_lambda: -0.0150 - encoder_attention_module_2_lambda: -0.0082 - decoder_attention_module_0_lambda: -0.0978 - decoder_attention_module_1_lambda: -0.1453 - decoder_attention_module_2_lambda: 0.2827 - val_loss: 0.0083 - val_mse: 0.0081 - val_NMSE: 0.0732\n",
      "Epoch 7/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0094 - mse: 0.0091 - NMSE: 0.0823 - encoder_attention_module_0_lambda: -0.0297 - encoder_attention_module_1_lambda: -0.0240 - encoder_attention_module_2_lambda: -0.0012 - decoder_attention_module_0_lambda: -0.0860 - decoder_attention_module_1_lambda: -0.1301 - decoder_attention_module_2_lambda: 0.3297 - tot_time: 0h 3m 46.9s\n",
      "\n",
      "Epoch 7: val_NMSE did not improve from 0.07320\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0093 - mse: 0.0091 - NMSE: 0.0822 - encoder_attention_module_0_lambda: -0.0297 - encoder_attention_module_1_lambda: -0.0240 - encoder_attention_module_2_lambda: -0.0012 - decoder_attention_module_0_lambda: -0.0860 - decoder_attention_module_1_lambda: -0.1301 - decoder_attention_module_2_lambda: 0.3297 - val_loss: 0.0112 - val_mse: 0.0110 - val_NMSE: 0.0987\n",
      "Epoch 8/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0078 - mse: 0.0076 - NMSE: 0.0683 - encoder_attention_module_0_lambda: -0.0312 - encoder_attention_module_1_lambda: -0.0136 - encoder_attention_module_2_lambda: -0.0037 - decoder_attention_module_0_lambda: -0.0767 - decoder_attention_module_1_lambda: -0.1028 - decoder_attention_module_2_lambda: 0.3697 - tot_time: 0h 4m 17.3s\n",
      "\n",
      "Epoch 8: val_NMSE improved from 0.07320 to 0.05824, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.0078 - mse: 0.0076 - NMSE: 0.0683 - encoder_attention_module_0_lambda: -0.0312 - encoder_attention_module_1_lambda: -0.0136 - encoder_attention_module_2_lambda: -0.0037 - decoder_attention_module_0_lambda: -0.0767 - decoder_attention_module_1_lambda: -0.1027 - decoder_attention_module_2_lambda: 0.3697 - val_loss: 0.0067 - val_mse: 0.0065 - val_NMSE: 0.0582\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0063 - mse: 0.0061 - NMSE: 0.0549 - encoder_attention_module_0_lambda: -0.0310 - encoder_attention_module_1_lambda: -0.0047 - encoder_attention_module_2_lambda: -0.0072 - decoder_attention_module_0_lambda: -0.0737 - decoder_attention_module_1_lambda: -0.0865 - decoder_attention_module_2_lambda: 0.3802 - tot_time: 0h 4m 48.2s\n",
      "\n",
      "Epoch 9: val_NMSE improved from 0.05824 to 0.04918, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0063 - mse: 0.0061 - NMSE: 0.0549 - encoder_attention_module_0_lambda: -0.0310 - encoder_attention_module_1_lambda: -0.0047 - encoder_attention_module_2_lambda: -0.0072 - decoder_attention_module_0_lambda: -0.0737 - decoder_attention_module_1_lambda: -0.0865 - decoder_attention_module_2_lambda: 0.3802 - val_loss: 0.0057 - val_mse: 0.0055 - val_NMSE: 0.0492\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0057 - mse: 0.0055 - NMSE: 0.0491 - encoder_attention_module_0_lambda: -0.0377 - encoder_attention_module_1_lambda: -0.0030 - encoder_attention_module_2_lambda: -0.0150 - decoder_attention_module_0_lambda: -0.0747 - decoder_attention_module_1_lambda: -0.0883 - decoder_attention_module_2_lambda: 0.3766 - tot_time: 0h 5m 19.0s\n",
      "\n",
      "Epoch 10: val_NMSE improved from 0.04918 to 0.04522, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0057 - mse: 0.0055 - NMSE: 0.0491 - encoder_attention_module_0_lambda: -0.0378 - encoder_attention_module_1_lambda: -0.0030 - encoder_attention_module_2_lambda: -0.0150 - decoder_attention_module_0_lambda: -0.0747 - decoder_attention_module_1_lambda: -0.0883 - decoder_attention_module_2_lambda: 0.3766 - val_loss: 0.0053 - val_mse: 0.0050 - val_NMSE: 0.0452\n",
      "Epoch 11/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0052 - mse: 0.0050 - NMSE: 0.0450 - encoder_attention_module_0_lambda: -0.0443 - encoder_attention_module_1_lambda: -0.0050 - encoder_attention_module_2_lambda: -0.0203 - decoder_attention_module_0_lambda: -0.0771 - decoder_attention_module_1_lambda: -0.0919 - decoder_attention_module_2_lambda: 0.3457 - tot_time: 0h 5m 50.6s\n",
      "\n",
      "Epoch 11: val_NMSE improved from 0.04522 to 0.03964, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 0.0052 - mse: 0.0050 - NMSE: 0.0450 - encoder_attention_module_0_lambda: -0.0443 - encoder_attention_module_1_lambda: -0.0050 - encoder_attention_module_2_lambda: -0.0203 - decoder_attention_module_0_lambda: -0.0771 - decoder_attention_module_1_lambda: -0.0919 - decoder_attention_module_2_lambda: 0.3457 - val_loss: 0.0046 - val_mse: 0.0044 - val_NMSE: 0.0396\n",
      "Epoch 12/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0050 - mse: 0.0047 - NMSE: 0.0425 - encoder_attention_module_0_lambda: -0.0506 - encoder_attention_module_1_lambda: -0.0030 - encoder_attention_module_2_lambda: -0.0259 - decoder_attention_module_0_lambda: -0.0793 - decoder_attention_module_1_lambda: -0.0875 - decoder_attention_module_2_lambda: 0.3329 - tot_time: 0h 6m 20.2s\n",
      "\n",
      "Epoch 12: val_NMSE did not improve from 0.03964\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 29s 24ms/step - loss: 0.0050 - mse: 0.0047 - NMSE: 0.0425 - encoder_attention_module_0_lambda: -0.0506 - encoder_attention_module_1_lambda: -0.0030 - encoder_attention_module_2_lambda: -0.0259 - decoder_attention_module_0_lambda: -0.0793 - decoder_attention_module_1_lambda: -0.0875 - decoder_attention_module_2_lambda: 0.3329 - val_loss: 0.0050 - val_mse: 0.0048 - val_NMSE: 0.0428\n",
      "Epoch 13/200\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0044 - NMSE: 0.0397 - encoder_attention_module_0_lambda: -0.0562 - encoder_attention_module_1_lambda: -0.0069 - encoder_attention_module_2_lambda: -0.0288 - decoder_attention_module_0_lambda: -0.0810 - decoder_attention_module_1_lambda: -0.0844 - decoder_attention_module_2_lambda: 0.3362 - tot_time: 0h 6m 51.3s\n",
      "\n",
      "Epoch 13: val_NMSE did not improve from 0.03964\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0046 - mse: 0.0044 - NMSE: 0.0397 - encoder_attention_module_0_lambda: -0.0562 - encoder_attention_module_1_lambda: -0.0069 - encoder_attention_module_2_lambda: -0.0288 - decoder_attention_module_0_lambda: -0.0810 - decoder_attention_module_1_lambda: -0.0844 - decoder_attention_module_2_lambda: 0.3361 - val_loss: 0.0048 - val_mse: 0.0046 - val_NMSE: 0.0414\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0369 - encoder_attention_module_0_lambda: -0.0630 - encoder_attention_module_1_lambda: -0.0112 - encoder_attention_module_2_lambda: -0.0328 - decoder_attention_module_0_lambda: -0.0857 - decoder_attention_module_1_lambda: -0.0846 - decoder_attention_module_2_lambda: 0.3228 - tot_time: 0h 7m 23.7s\n",
      "\n",
      "Epoch 14: val_NMSE improved from 0.03964 to 0.03311, saving model to /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/checkpoint\n",
      " - saving loss histories at /home/rkaushik/Documents/Thesis/MLROM/Kolmogorov/saved_ae/ae_018/checkpoints/LossHistoriesCheckpoint\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0043 - mse: 0.0041 - NMSE: 0.0369 - encoder_attention_module_0_lambda: -0.0630 - encoder_attention_module_1_lambda: -0.0112 - encoder_attention_module_2_lambda: -0.0328 - decoder_attention_module_0_lambda: -0.0857 - decoder_attention_module_1_lambda: -0.0846 - decoder_attention_module_2_lambda: 0.3228 - val_loss: 0.0039 - val_mse: 0.0037 - val_NMSE: 0.0331\n",
      "Epoch 15/200\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0038 - NMSE: 0.0346 - encoder_attention_module_0_lambda: -0.0680 - encoder_attention_module_1_lambda: -0.0183 - encoder_attention_module_2_lambda: -0.0395 - decoder_attention_module_0_lambda: -0.0899 - decoder_attention_module_1_lambda: -0.0906 - decoder_attention_module_2_lambda: 0.3064"
     ]
    }
   ],
   "source": [
    "# compiling the network\n",
    "ae_net.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_list[0]),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "#     loss=losses.BinaryCrossentropy(from_logits=False),\n",
    "    run_eagerly=False,\n",
    "    metrics=['mse', NMSE_metric]\n",
    ")\n",
    "\n",
    "if behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # this loads the weights/attributes of the optimizer as well\n",
    "    if strategy is not None:\n",
    "        with strategy.scope():\n",
    "            ae_net.load_weights(wt_file)\n",
    "    else:\n",
    "        ae_net.load_weights(wt_file)\n",
    "\n",
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    # implementing early stopping\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_NMSE',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=True,\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "\n",
    "    # time callback for each epoch\n",
    "    timekeeper_cb = mytimecallback()\n",
    "\n",
    "    # model checkpoint callback\n",
    "    dir_name_ckpt = dir_name_ae+dir_sep+'checkpoints'\n",
    "    if not os.path.isdir(dir_name_ckpt):\n",
    "        os.makedirs(dir_name_ckpt)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=dir_name_ckpt+dir_sep+'checkpoint',#+'/checkpoint--loss={loss:.4f}--vall_loss={val_loss:.4f}',\n",
    "        monitor='val_NMSE',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=2,\n",
    "        period=1  # saves every 5 epochs\n",
    "    )\n",
    "\n",
    "    # save losses callback\n",
    "    savelosses_cb = SaveLosses(\n",
    "        filepath=dir_name_ckpt+dir_sep+'LossHistoriesCheckpoint',\n",
    "        val_loss_arr=savelosses_cb_vallossarr,\n",
    "        train_loss_arr=savelosses_cb_trainlossarr,\n",
    "        total_epochs=epochs,\n",
    "        period=1)\n",
    "\n",
    "    # training the network\n",
    "    for i in range(starting_lr_idx, len(learning_rate_list)):\n",
    "        learning_rate = learning_rate_list[i]\n",
    "        K.set_value(ae_net.optimizer.lr, learning_rate)\n",
    "\n",
    "        savelosses_cb.update_lr_idx(i)\n",
    "\n",
    "        if i == starting_lr_idx:\n",
    "            EPOCHS = num_epochs_left\n",
    "            savelosses_cb.update_offset(epochs-num_epochs_left)\n",
    "        else:\n",
    "            EPOCHS = epochs\n",
    "            savelosses_cb.update_offset(0)\n",
    "\n",
    "        total_s_len = 80\n",
    "        sep_lr_s = ' LEARNING RATE : {} '.format(learning_rate)\n",
    "        sep_lr_s = int((total_s_len - len(sep_lr_s))//2)*'-' + sep_lr_s\n",
    "        sep_lr_s = sep_lr_s + (total_s_len-len(sep_lr_s))*'-'\n",
    "        print('\\n\\n' + '-'*len(sep_lr_s))\n",
    "        print('\\n' + sep_lr_s+'\\n')\n",
    "        print('-'*len(sep_lr_s) + '\\n\\n')\n",
    "        \n",
    "        history = ae_net.fit(training_data, training_data,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=batch_size,\n",
    "#             validation_split=val_split/train_split,\n",
    "            validation_data=(val_data, val_data),\n",
    "            callbacks=[early_stopping_cb, timekeeper_cb, checkpoint_cb, savelosses_cb],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss_hist.extend(history.history['val_loss'])\n",
    "        train_loss_hist.extend(history.history['loss'])\n",
    "        \n",
    "        val_MSE_hist.extend(history.history['val_mse'])\n",
    "        train_MSE_hist.extend(history.history['mse'])\n",
    "        \n",
    "        val_NMSE_hist.extend(history.history['val_NMSE'])\n",
    "        train_NMSE_hist.extend(history.history['NMSE'])\n",
    "        \n",
    "        if use_attention_module == True:\n",
    "            for j in range(len(ae_net.encoder_attention_modules_list)):\n",
    "                key = 'encoder_attention_module_{}_lambda'.format(j)\n",
    "                lst1 = history.history[key]\n",
    "                lst2 = encoder_attention_lambdas[key]\n",
    "                lst2.extend(lst1)\n",
    "                encoder_attention_lambdas[key] = lst2\n",
    "            for j in range(len(ae_net.decoder_attention_modules_list)):\n",
    "                key = 'decoder_attention_module_{}_lambda'.format(j)\n",
    "                lst1 = history.history[key]\n",
    "                lst2 = decoder_attention_lambdas[key]\n",
    "                lst2.extend(lst1)\n",
    "                decoder_attention_lambdas[key] = lst2\n",
    "        \n",
    "        if i == starting_lr_idx:\n",
    "            lr_change[i+1] += len(history.history['val_loss'])\n",
    "        else:\n",
    "            lr_change.append(lr_change[i]+len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_net.encoder_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_net.decoder_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_net.ae_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9705,
     "status": "ok",
     "timestamp": 1666788875924,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "d_Od0ul4P9bK",
    "outputId": "860e9f94-e593-4a74-fcff-6a6657d925de"
   },
   "outputs": [],
   "source": [
    "if behaviour == 'initialiseAndTrainFromScratch' or behaviour == 'loadCheckpointAndContinueTraining':\n",
    "    test_metrics = ae_net.evaluate(\n",
    "        testing_data, testing_data,\n",
    "    )\n",
    "#     train_metrics = ae_net.evaluate(training_data, training_data)\n",
    "#     val_metrics = ae_net.evaluate(val_data, val_data)\n",
    "\n",
    "    save_path = dir_name_ae+dir_sep+'final_net'\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    save_dict = {\n",
    "        'val_loss_hist':val_loss_hist,\n",
    "        'train_loss_hist':train_loss_hist,\n",
    "        'val_MSE_hist':val_MSE_hist,\n",
    "        'train_MSE_hist':train_MSE_hist,\n",
    "        'val_NMSE_hist':val_NMSE_hist,\n",
    "        'train_NMSE_hist':train_NMSE_hist,\n",
    "        'lr_change':lr_change,\n",
    "        'test_loss':test_metrics[0],\n",
    "        'test_mse':test_metrics[1],\n",
    "#         'train_loss':train_metrics[0],\n",
    "#         'train_mse':train_metrics[1],\n",
    "#         'val_loss':val_metrics[0],\n",
    "#         'val_mse':val_metrics[1],\n",
    "    }\n",
    "    if use_attention_module == True:\n",
    "        for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "            key = 'encoder_attention_module_{}_lambda'.format(i)\n",
    "            save_dict[key] = encoder_attention_lambdas[key]\n",
    "        for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "            key = 'decoder_attention_module_{}_lambda'.format(i)\n",
    "            save_dict[key] = decoder_attention_lambdas[key]\n",
    "\n",
    "    with open(save_path+dir_sep+'losses.txt', 'w') as f:\n",
    "        f.write(str(save_dict))\n",
    "\n",
    "    np.savez(\n",
    "        save_path+dir_sep+'losses',\n",
    "        **save_dict\n",
    "    )\n",
    "        \n",
    "\n",
    "    ae_net.save_everything(\n",
    "        file_name=save_path+dir_sep+'final_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666788875925,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Dy8GNcgMVD4T",
    "outputId": "e50e8738-9da1-43de-e551-43f47b64135e"
   },
   "outputs": [],
   "source": [
    "print('lr_change : ', lr_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1666788876686,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "ewTz1COFSocM",
    "outputId": "15bc2be5-d571-433e-b5cd-9c722f38b48b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting losses\n",
    "dir_name_plot = dir_name_ae + '/plots'\n",
    "if not os.path.isdir(dir_name_plot):\n",
    "    os.makedirs(dir_name_plot)\n",
    "\n",
    "# Visualize loss history\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_loss_hist,\n",
    "    val_loss=val_loss_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list\n",
    ")\n",
    "\n",
    "plt.savefig(dir_name_plot + '{ds}loss_history.png'.format(ds=dir_sep), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_MSE_hist,\n",
    "    val_loss=val_MSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training MSE', 'Validation MSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='MSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/MSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "fig, ax = plot_losses(\n",
    "    training_loss=train_NMSE_hist,\n",
    "    val_loss=val_NMSE_hist,\n",
    "    lr_change=lr_change,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    legend_list=['Training NMSE', 'Validation NMSE'],\n",
    "    xlabel='Epoch',\n",
    "    ylabel='NMSE',\n",
    ")\n",
    "plt.savefig(dir_name_plot+'/NMSE_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1666788877562,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wwt4brHcOaXi",
    "outputId": "7ba39105-aa8e-49e8-dbfd-619069123fdd"
   },
   "outputs": [],
   "source": [
    "if use_attention_module == True:\n",
    "    # plotting encoder attention lambdas\n",
    "    plot_lst = []\n",
    "    legend_lst = []\n",
    "    for i in range(len(ae_net.encoder_attention_modules_list)):\n",
    "        key = 'encoder_attention_module_{}_lambda'.format(i)\n",
    "        plot_lst.append(encoder_attention_lambdas[key])\n",
    "        legend_lst.append(\"attention module (encoder) {}\".format(i+1))\n",
    "    fig, ax = plot_losses(\n",
    "        training_loss=plot_lst[0],\n",
    "        val_loss=None,\n",
    "        more_plot_arrs_lst=plot_lst[1:] if len(plot_lst)>1 else [],\n",
    "        lr_change=lr_change,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        legend_list=legend_lst,\n",
    "        xlabel='Epoch',\n",
    "        ylabel=r\"$\\lambda_{attention}$\",\n",
    "        plot_type='plot',\n",
    "        traininglossplot_args=[],\n",
    "        traininglossplot_kwargs={},\n",
    "        epoch_count_begin=0,\n",
    "        epoch_count_end=len(plot_lst[0])-1,\n",
    "    )\n",
    "    plt.savefig(dir_name_plot+'/attention_lambdas_encoder.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plotting decoder attention lambdas\n",
    "    plot_lst = []\n",
    "    legend_lst = []\n",
    "    for i in range(len(ae_net.decoder_attention_modules_list)):\n",
    "        key = 'decoder_attention_module_{}_lambda'.format(i)\n",
    "        plot_lst.append(decoder_attention_lambdas[key])\n",
    "        legend_lst.append(\"attention module (decoder) {}\".format(i+1))\n",
    "    fig, ax = plot_losses(\n",
    "        training_loss=plot_lst[0],\n",
    "        val_loss=None,\n",
    "        more_plot_arrs_lst=plot_lst[1:] if len(plot_lst)>1 else [],\n",
    "        lr_change=lr_change,\n",
    "        learning_rate_list=learning_rate_list,\n",
    "        legend_list=legend_lst,\n",
    "        xlabel='Epoch',\n",
    "        ylabel=r\"$\\lambda_{attention}$\",\n",
    "        plot_type='plot',\n",
    "        traininglossplot_args=[],\n",
    "        traininglossplot_kwargs={},\n",
    "        epoch_count_begin=0,\n",
    "        epoch_count_end=len(plot_lst[0])-1,\n",
    "    )\n",
    "    plt.savefig(dir_name_plot+'/attention_lambdas_decoder.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1kzRwBdNfA2o28NxHkc2fku7QnFPAI8Bo"
    },
    "executionInfo": {
     "elapsed": 4835,
     "status": "ok",
     "timestamp": 1666788882395,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "_6rNhThyQrKc",
    "outputId": "fdeeb3f5-009a-404e-8856-b7655d596a88"
   },
   "source": [
    "# POD Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17515,
     "status": "ok",
     "timestamp": 1666788899903,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "cAiMV0iU0EpK"
   },
   "outputs": [],
   "source": [
    "# pod_training_data = np.empty(shape=(training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "# pod_training_data[:, :] = np.reshape(training_data, (training_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "\n",
    "# pod_centering_means = np.mean(pod_training_data, axis=0)\n",
    "# pod_mean_centered_data = pod_training_data - pod_centering_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C = np.transpose(pod_mean_centered_data) @ pod_mean_centered_data\n",
    "# C /= pod_mean_centered_data.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1666788900494,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "jVqsAwsY0Amw",
    "outputId": "95dd7bc9-f2b0-421e-a1b4-3e7e594cd44a"
   },
   "outputs": [],
   "source": [
    "# eigenvals, eigenvecs = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2127,
     "status": "ok",
     "timestamp": 1666788902619,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wjgPNitSrt5p",
    "outputId": "d60c9340-28f4-479b-8b66-5ee2a5fc5cee"
   },
   "outputs": [],
   "source": [
    "# abs_eigenvals = np.abs(eigenvals)\n",
    "# idx = np.argsort(abs_eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5242,
     "status": "ok",
     "timestamp": 1666788907858,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "Jv8PgBgzV1_s"
   },
   "outputs": [],
   "source": [
    "# idx = idx[::-1]\n",
    "# W = eigenvecs[:, idx[0:4*4*enc_filters[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666788907859,
     "user": {
      "displayName": "Rohan Kaushik",
      "userId": "13918477614376051685"
     },
     "user_tz": -120
    },
    "id": "wnLnqg0Jrt5t"
   },
   "outputs": [],
   "source": [
    "# reconstructed_val_data = val_data.reshape(val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]) @ W @ W.transpose()\n",
    "# reconstructed_val_data = np.reshape(reconstructed_val_data, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_recon_MSE = np.reshape((reconstructed_val_data - val_data)**2, (val_data.shape[0], training_data.shape[1]*training_data.shape[2]*training_data.shape[3]))\n",
    "# val_recon_MSE = np.mean(np.sum(val_recon_MSE, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(val_recon_MSE, val_recon_MSE/np.sum(time_stddev**2), np.sum(time_stddev**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_eigenvals[idx[0:4*4*2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in range(len(ae_net.encoder_layers_list)):\n",
    "    l = ae_net.encoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('attention_module'):\n",
    "        # print(i, name, l.lambda_att.numpy())\n",
    "        s += 'i : {}, name : {}, lambda_att : {}\\n'.format(i, name, l.lambda_att.numpy())\n",
    "print(s)\n",
    "\n",
    "if s != '':\n",
    "    with open(dir_name_ae + '/attention_lambdas_encoder.txt', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in range(len(ae_net.decoder_layers_list)):\n",
    "    l = ae_net.decoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('attention_module'):\n",
    "        # print(i, name, l.lambda_att.numpy())\n",
    "        s += 'i : {}, name : {}, lambda_att : {}\\n'.format(i, name, l.lambda_att.numpy())\n",
    "print(s)\n",
    "\n",
    "if s != '':\n",
    "    with open(dir_name_ae + '/attention_lambdas_decoder.txt', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(ae_net.encoder_layers_list)):\n",
    "    l = ae_net.encoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('periodic_padding'):\n",
    "        print(i, name, l.M_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ae_net.decoder_layers_list)):\n",
    "    l = ae_net.decoder_layers_list[i]\n",
    "    name = str(l.name)\n",
    "    if name.startswith('periodic_padding'):\n",
    "        print(i, name, l.M_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
