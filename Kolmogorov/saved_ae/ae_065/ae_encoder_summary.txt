Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2, 50, 50)]  0           []                               
                                                                                                  
 gaussian_noise (GaussianNoise)  (None, 2, 50, 50)   0           ['input_1[0][0]']                
                                                                                                  
 periodic_padding (periodic_pad  (None, 2, 50, 50)   5000        ['gaussian_noise[0][0]']         
 ding)                                                                                            
                                                                                                  
 periodic_padding_5 (periodic_p  (None, 2, 52, 52)   5200        ['gaussian_noise[0][0]']         
 adding)                                                                                          
                                                                                                  
 conv2d (Conv2D)                (None, 8, 24, 24)    144         ['periodic_padding[0][0]']       
                                                                                                  
 conv2d_5 (Conv2D)              (None, 8, 24, 24)    400         ['periodic_padding_5[0][0]']     
                                                                                                  
 periodic_padding_10 (periodic_  (None, 2, 54, 54)   5400        ['gaussian_noise[0][0]']         
 padding)                                                                                         
                                                                                                  
 batch_normalization (BatchNorm  (None, 8, 24, 24)   32          ['conv2d[0][0]']                 
 alization)                                                                                       
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 8, 24, 24)   32          ['conv2d_5[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 conv2d_10 (Conv2D)             (None, 8, 24, 24)    784         ['periodic_padding_10[0][0]']    
                                                                                                  
 activation (Activation)        (None, 8, 24, 24)    0           ['batch_normalization[0][0]']    
                                                                                                  
 activation_5 (Activation)      (None, 8, 24, 24)    0           ['batch_normalization_5[0][0]']  
                                                                                                  
 batch_normalization_10 (BatchN  (None, 8, 24, 24)   32          ['conv2d_10[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 periodic_padding_1 (periodic_p  (None, 8, 26, 26)   1248        ['activation[0][0]']             
 adding)                                                                                          
                                                                                                  
 periodic_padding_6 (periodic_p  (None, 8, 28, 28)   1344        ['activation_5[0][0]']           
 adding)                                                                                          
                                                                                                  
 activation_10 (Activation)     (None, 8, 24, 24)    0           ['batch_normalization_10[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)              (None, 16, 12, 12)   1152        ['periodic_padding_1[0][0]']     
                                                                                                  
 conv2d_6 (Conv2D)              (None, 16, 12, 12)   3200        ['periodic_padding_6[0][0]']     
                                                                                                  
 periodic_padding_11 (periodic_  (None, 8, 30, 30)   1440        ['activation_10[0][0]']          
 padding)                                                                                         
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 16, 12, 12)  64          ['conv2d_1[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 16, 12, 12)  64          ['conv2d_6[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 conv2d_11 (Conv2D)             (None, 16, 12, 12)   6272        ['periodic_padding_11[0][0]']    
                                                                                                  
 activation_1 (Activation)      (None, 16, 12, 12)   0           ['batch_normalization_1[0][0]']  
                                                                                                  
 activation_6 (Activation)      (None, 16, 12, 12)   0           ['batch_normalization_6[0][0]']  
                                                                                                  
 batch_normalization_11 (BatchN  (None, 16, 12, 12)  64          ['conv2d_11[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 attention_module (attention_mo  (None, 16, 12, 12)  1025        ['activation_1[0][0]']           
 dule)                                                                                            
                                                                                                  
 attention_module_3 (attention_  (None, 16, 12, 12)  1025        ['activation_6[0][0]']           
 module)                                                                                          
                                                                                                  
 activation_11 (Activation)     (None, 16, 12, 12)   0           ['batch_normalization_11[0][0]'] 
                                                                                                  
 periodic_padding_2 (periodic_p  (None, 16, 14, 14)  336         ['attention_module[0][0]']       
 adding)                                                                                          
                                                                                                  
 periodic_padding_7 (periodic_p  (None, 16, 16, 16)  384         ['attention_module_3[0][0]']     
 adding)                                                                                          
                                                                                                  
 attention_module_6 (attention_  (None, 16, 12, 12)  1025        ['activation_11[0][0]']          
 module)                                                                                          
                                                                                                  
 conv2d_2 (Conv2D)              (None, 32, 6, 6)     4608        ['periodic_padding_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)              (None, 32, 6, 6)     12800       ['periodic_padding_7[0][0]']     
                                                                                                  
 periodic_padding_12 (periodic_  (None, 16, 18, 18)  432         ['attention_module_6[0][0]']     
 padding)                                                                                         
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 32, 6, 6)    128         ['conv2d_2[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 32, 6, 6)    128         ['conv2d_7[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 conv2d_12 (Conv2D)             (None, 32, 6, 6)     25088       ['periodic_padding_12[0][0]']    
                                                                                                  
 activation_2 (Activation)      (None, 32, 6, 6)     0           ['batch_normalization_2[0][0]']  
                                                                                                  
 activation_7 (Activation)      (None, 32, 6, 6)     0           ['batch_normalization_7[0][0]']  
                                                                                                  
 batch_normalization_12 (BatchN  (None, 32, 6, 6)    128         ['conv2d_12[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 attention_module_1 (attention_  (None, 32, 6, 6)    4097        ['activation_2[0][0]']           
 module)                                                                                          
                                                                                                  
 attention_module_4 (attention_  (None, 32, 6, 6)    4097        ['activation_7[0][0]']           
 module)                                                                                          
                                                                                                  
 activation_12 (Activation)     (None, 32, 6, 6)     0           ['batch_normalization_12[0][0]'] 
                                                                                                  
 periodic_padding_3 (periodic_p  (None, 32, 8, 8)    96          ['attention_module_1[0][0]']     
 adding)                                                                                          
                                                                                                  
 periodic_padding_8 (periodic_p  (None, 32, 10, 10)  120         ['attention_module_4[0][0]']     
 adding)                                                                                          
                                                                                                  
 attention_module_7 (attention_  (None, 32, 6, 6)    4097        ['activation_12[0][0]']          
 module)                                                                                          
                                                                                                  
 conv2d_3 (Conv2D)              (None, 10, 3, 3)     2880        ['periodic_padding_3[0][0]']     
                                                                                                  
 conv2d_8 (Conv2D)              (None, 10, 3, 3)     8000        ['periodic_padding_8[0][0]']     
                                                                                                  
 periodic_padding_13 (periodic_  (None, 32, 12, 12)  144         ['attention_module_7[0][0]']     
 padding)                                                                                         
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 10, 3, 3)    40          ['conv2d_3[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 10, 3, 3)    40          ['conv2d_8[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 conv2d_13 (Conv2D)             (None, 10, 3, 3)     15680       ['periodic_padding_13[0][0]']    
                                                                                                  
 activation_3 (Activation)      (None, 10, 3, 3)     0           ['batch_normalization_3[0][0]']  
                                                                                                  
 activation_8 (Activation)      (None, 10, 3, 3)     0           ['batch_normalization_8[0][0]']  
                                                                                                  
 batch_normalization_13 (BatchN  (None, 10, 3, 3)    40          ['conv2d_13[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 attention_module_2 (attention_  (None, 10, 3, 3)    401         ['activation_3[0][0]']           
 module)                                                                                          
                                                                                                  
 attention_module_5 (attention_  (None, 10, 3, 3)    401         ['activation_8[0][0]']           
 module)                                                                                          
                                                                                                  
 activation_13 (Activation)     (None, 10, 3, 3)     0           ['batch_normalization_13[0][0]'] 
                                                                                                  
 periodic_padding_4 (periodic_p  (None, 10, 5, 5)    30          ['attention_module_2[0][0]']     
 adding)                                                                                          
                                                                                                  
 periodic_padding_9 (periodic_p  (None, 10, 7, 7)    42          ['attention_module_5[0][0]']     
 adding)                                                                                          
                                                                                                  
 attention_module_8 (attention_  (None, 10, 3, 3)    401         ['activation_13[0][0]']          
 module)                                                                                          
                                                                                                  
 conv2d_4 (Conv2D)              (None, 3, 3, 3)      270         ['periodic_padding_4[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)              (None, 3, 3, 3)      750         ['periodic_padding_9[0][0]']     
                                                                                                  
 periodic_padding_14 (periodic_  (None, 10, 9, 9)    54          ['attention_module_8[0][0]']     
 padding)                                                                                         
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 3, 3, 3)     12          ['conv2d_4[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 3, 3, 3)     12          ['conv2d_9[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 conv2d_14 (Conv2D)             (None, 3, 3, 3)      1470        ['periodic_padding_14[0][0]']    
                                                                                                  
 activation_4 (Activation)      (None, 3, 3, 3)      0           ['batch_normalization_4[0][0]']  
                                                                                                  
 activation_9 (Activation)      (None, 3, 3, 3)      0           ['batch_normalization_9[0][0]']  
                                                                                                  
 batch_normalization_14 (BatchN  (None, 3, 3, 3)     12          ['conv2d_14[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 scalar_multiplication (scalar_  (None, 3, 3, 3)     1           ['activation_4[0][0]']           
 multiplication)                                                                                  
                                                                                                  
 scalar_multiplication_1 (scala  (None, 3, 3, 3)     1           ['activation_9[0][0]']           
 r_multiplication)                                                                                
                                                                                                  
 activation_14 (Activation)     (None, 3, 3, 3)      0           ['batch_normalization_14[0][0]'] 
                                                                                                  
 tf.__operators__.add (TFOpLamb  (None, 3, 3, 3)     0           ['scalar_multiplication[0][0]',  
 da)                                                              'scalar_multiplication_1[0][0]']
                                                                                                  
 scalar_multiplication_2 (scala  (None, 3, 3, 3)     1           ['activation_14[0][0]']          
 r_multiplication)                                                                                
                                                                                                  
 tf.__operators__.add_1 (TFOpLa  (None, 3, 3, 3)     0           ['tf.__operators__.add[0][0]',   
 mbda)                                                            'scalar_multiplication_2[0][0]']
                                                                                                  
==================================================================================================
Total params: 122,168
Trainable params: 100,484
Non-trainable params: 21,684
__________________________________________________________________________________________________
